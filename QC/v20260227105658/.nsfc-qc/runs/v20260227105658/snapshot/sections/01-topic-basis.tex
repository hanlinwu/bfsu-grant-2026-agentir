\section{选题依据}

\subsection{研究意义}

图像恢复旨在从受损观测中重建高质量清晰图像，是计算机视觉领域的基础性研究课题。在安防监控、自动驾驶、医学成像、遥感观测等实际应用中，图像采集与传输过程不可避免地受噪声、模糊、雾霾、雨线、低光照、压缩伪影等多种退化因素干扰，严重制约后续视觉分析任务的精度与可靠性。

现有深度学习图像恢复方法面临的核心瓶颈在于\textbf{退化空间异质性}的表征缺失。真实场景中，同一图像的不同区域往往同时受到类型迥异、程度各异的退化影响，而现有方法普遍采用全图统一的处理策略，无法根据区域级退化特征进行差异化恢复。具体而言，单任务专用模型\cite{swinir,restormer}针对特定退化类型优化，面对多退化共存场景时泛化能力不足；All-in-One统一模型\cite{airnet,promptir,instructir}虽能处理多种退化类型，但受限于训练分布，对未见退化组合的适应性较差；现有智能体化方法虽引入动态决策能力，但普遍将整幅图像视为单一实体，缺乏对退化空间分布的精细化感知，导致在异质退化场景下出现局部过度处理或处理不足的问题。

预研实验定量验证了上述瓶颈的实际影响。在复杂混合退化测试集上，代表性模型的PSNR较单一退化场景下降1.5--3.0~dB，LPIPS感知质量指标出现系统性退化，且推理时延显著增加。实验结果表明，现有方法的理论假设——即退化分布均匀或可通过全局特征统一描述——与真实场景存在显著偏差，这一偏差构成了制约图像恢复技术实用化部署的关键障碍。

针对上述理论瓶颈，本项目研究\textbf{多智能体协同的空间感知图像恢复方法}，构建“空间退化感知—区域协同决策—规划轨迹蒸馏”的层级化框架。该框架的核心思想是将恢复过程从传统的“全图单策略”范式转变为“区域差异化处理”范式：首先通过空间退化图显式建模区域级退化分布，继而由协调智能体进行全局任务分解与资源调度，各区域子智能体针对特定退化特征执行定制化恢复策略，最终通过规划轨迹蒸馏实现大模型能力向轻量级部署模型的有效迁移，形成可感知、可决策、可迭代、可部署的新型恢复范式。

本项目的研究意义可归纳为三个层面。

\textbf{学术层面}，本项目推动图像恢复从“全局统一表征”向“区域级动态表征”演进，建立退化空间异质性的显式建模理论。通过引入空间退化图与多智能体协同机制，丰富复杂场景图像恢复的认知框架，为后续研究提供新的理论视角与分析工具。

\textbf{方法层面}，本项目促进空间感知、多智能体协同与知识蒸馏的深度融合，形成兼顾恢复精度与推理效率的轻量级方法体系。通过轨迹蒸馏机制突破大模型依赖导致的部署瓶颈，实现从研究原型到实用系统的技术跨越。

\textbf{应用层面}，本项目为安防巡检、智能交通、遥感解译等场景提供高可靠视觉基础能力，支撑复杂环境下的智能感知系统部署，具有明确的工程价值与社会效益。

\subsection{国内外研究现状}

图像恢复领域近十年经历了从卷积神经网络到Transformer、从单任务专用模型到统一化All-in-One（AiO）框架、从确定性回归方法到扩散生成模型、再到基于智能体的动态决策范式的多次技术跃迁，每一次范式转换均以解决前驱方法的特定局限为直接动因。``退化空间异质性''——真实场景图像不同区域同时受到类型迥异、程度各异的退化影响——是贯穿各范式演进历程、迄今尚未被充分应对的核心技术问题。以下从五个维度系统梳理国内外研究现状，聚焦各范式的关键方法、技术局限及其与本项目研究动机的内在联系。图~\ref{fig:framework-contrast}给出了传统全图统一恢复与本项目拟研究的空间感知分区恢复的框架对照示意。

\vspace{4pt}
\begin{figure}[H]
\centering
\includegraphics[width=0.92\linewidth]{imgs/Gemini_Generated_Image_lk4hu6lk4hu6lk4h.png}
\caption{传统全图统一恢复与空间感知分区恢复的框架对照示意}
\label{fig:framework-contrast}
\end{figure}
\vspace{4pt}

\textbf{（一）基于Transformer的单任务图像恢复方法}

标准自注意力机制的计算复杂度与图像像素数量的平方成正比，对高分辨率恢复任务代价高昂，这一计算瓶颈驱动了一系列高效Transformer架构的系统性探索。SwinIR\cite{swinir}通过残差Swin Transformer块（RSTB）与移位窗口多头自注意力（SW-MSA）将计算复杂度降至线性，在图像去噪、超分辨率与JPEG压缩伪影消除等基准任务上较此前最优方法分别提升0.14--0.31~dB PSNR，成为基于Transformer图像恢复研究的标准参照基线，并由此催生了大量后续改进工作。SwinIR的核心思想在于：通过在固定空间窗口内计算局部自注意力、并利用窗口移位实现跨窗口信息交互，在保持局部感受野精细建模的同时实现全局上下文的间接建模，为此后一大批高效恢复方法提供了架构范本。Restormer\cite{restormer}以``转置注意力''重新定义了Transformer在图像恢复中的计算路径：提出多深度卷积头转置注意力（MDTA）与门控深度卷积前馈网络（GDFN），沿通道维度而非空间维度计算注意力，以线性空间复杂度保持了真正意义上的全局感受野，在SIDD去噪基准上较前一最优方法提升0.13--0.52~dB，在去雨、去模糊等任务上同样建立了当时的最优基准。Wang等人\cite{uformer}提出Uformer，构建层次化U型Transformer架构，结合编码器-解码器跳跃连接与可学习的多尺度恢复调制器，使模型在去噪、去运动模糊等多个任务中同时保持高性能，为图像恢复中的多尺度特征层次建模提供了有力范本。

在计算效率的进一步提升方面，研究者从频域计算、状态空间模型和自适应窗口划分等多个角度探索了传统自注意力的替代方案。FFTformer\cite{fftformer}将传统空间域自注意力替换为傅里叶域操作，以更低计算代价实现等效的全局感受野——傅里叶变换天然具有全局性，任何一个频率分量都编码了整幅图像的全局信息，因此傅里叶域操作可以以近线性复杂度实现真正的全局建模，在图像去模糊任务上尤为有效。基于Mamba选择性状态空间模型（SSM）的VmambaIR\cite{vmambair}通过多方向选择性状态空间扫描以严格线性复杂度建模长程依赖，与Transformer相比在内存消耗和推理速度上均有显著优势，为超高分辨率图像的高效恢复开辟了新路径。Wu等人\cite{dswinir}指出SwinIR的固定网格窗口划分存在内在局限：当退化区域与窗口边界不对齐时，强制切割同一退化区域的特征会在窗口边界引入分割伪影，影响恢复质量；为此提出内容自适应动态窗口注意力，根据图像内容自适应调整窗口形状与大小，显著改善了非均匀退化场景的处理能力——这一关于``窗口边界与退化分布不对齐''的问题与本项目的研究动机高度相关。

在训练范式方面，Dan Zhang和Fangfang Zhou\cite{selfsup_denoise}提出基于上下文感知Transformer的自监督去噪方法，利用图像内部统计结构学习噪声模式，无需配对洁净-噪声训练数据即可实现与全监督方法相媲美的性能，为无标注退化数据场景提供了重要参考。结合CNN局部纹理提取能力与Transformer全局建模能力的混合架构在特定任务中展现出竞争力：Chen等人\cite{hybrid_rain}提出CNN-Transformer混合特征融合网络，通过交叉注意力实现局部卷积特征与全局自注意力特征的深度融合，在单图去雨任务上取得了较纯Transformer架构更优的性能，表明针对特定退化特性的混合架构设计可以充分发挥两类机制的互补优势。

基于Transformer的单任务方法在各自设计任务上已达到较高性能水平，但其根本局限制约了实际应用：需为每种退化类型单独维护专用模型，部署成本高；面对多退化共存的复杂真实场景时难以有效应对；所有方法均对整幅图像采用统一的恢复策略，完全未能利用退化的空间分布信息。这一局限驱动了统一化AiO方法的发展。

\textbf{（二）统一化All-in-One（AiO）图像恢复方法}

AiO恢复的核心挑战在于使单一模型实现对多种退化类型的判别性表征与差异化处理，同时避免对已习得恢复能力的``灾难性遗忘''。AirNet\cite{airnet}通过对比式降质编码器（CBDE）以无监督方式构建退化判别表征，利用不同退化类型样本之间的对比损失驱动特征空间的有序组织，实现了在去噪、去雾、去雨三类任务上无需显式退化标签的自适应处理，开创了基于对比学习的AiO恢复研究范式。Hu等人\cite{hu2025collab}进一步将对比学习扩展至图像、特征、块三个层级，构建多级协同对比框架，在提升退化判别精度的同时增强了对未见退化强度的泛化能力。

提示学习范式的引入是AiO恢复方法论的重大进展，其核心思想是将退化类型信息以``提示向量''的形式显式注入网络，指导统一骨干网络做出任务差异化的响应。PromptIR\cite{promptir}通过可学习提示向量对Transformer主干进行软条件化（soft-conditioning），在去噪、去雾、去雨、去模糊四类任务内实现统一恢复，验证了连续提示空间能够自然表征不同退化之间的过渡状态。后续多项工作从不同角度扩展和深化了提示范式：Ma等人\cite{prores}的ProRes从退化先验知识中显式构建可解释的视觉提示，增强了提示向量的语义可解释性；Wu等人\cite{wu2025dynamic}提出输入自适应的动态提示生成策略，使提示内容随输入图像的退化特征自动调整；Wu等人\cite{wu2024freq}在FrePrompter中直接从输入图像的频谱特征中提取物理有据的退化提示，赋予提示向量明确的频域物理解释；Wu等人\cite{wu2025beyond}通过对比提示学习解决不同退化类型间提示表征高度相关（冗余）的问题，在多个AiO基准上建立了新的最优结果。

在语言引导与架构创新方向，InstructIR\cite{instructir}首次将自然语言理解引入图像恢复，以用户自然语言指令控制恢复过程，可同时处理七类任务，实现了``以语言为接口''的新型人机协同恢复模式，也预示着图像恢复与大语言模型交互的整合趋势。Tang等人\cite{ramir}提出RamIR，将Mamba状态空间架构与链式思维（Chain-of-Thought）推理相结合，通过显式推理-行动分解处理复杂混合退化，将语言推理能力引入轻量化图像恢复框架。Zamfir等人\cite{moce_ir}提出MoCE-IR混合专家架构，通过动态稀疏专家激活将计算资源按退化处理难度自适应分配，使简单退化由少数专家高效处理、复杂退化调用更多专家协同完成，在多个基准上达到最优性能。Wu等人\cite{wu2024harmony}在``多样中的和谐''框架中，通过动态生成退化感知卷积核，使单一网络能为每个输入图像定制滤波响应，无需显式退化类型切换。Dudhane等人\cite{dudhane2024}采用动态预训练策略，以课程学习方式将模型渐进暴露于从简单到复杂的退化场景，显著提升了模型对未见退化组合的泛化能力。

然而，Jiang等人\cite{aio_survey}在系统综述中明确指出AiO方法存在三项难以克服的持续局限：第一，性能在遇到训练集外的新型退化时显著下降，泛化能力受训练集退化类型的强约束；第二，全图单一处理流程从根本上忽视了退化的空间异质性，对整幅图像施加相同的恢复强度和策略，在退化分布不均匀的真实场景中必然导致局部区域处理不当；第三，单次前向推理的静态处理模式无法基于中间恢复质量进行迭代细化，一旦恢复策略选择有误便无从自我修正。这三项局限共同构成了智能体化方法兴起的直接动因，也明确界定了本项目研究的问题空间。

\textbf{（三）基于扩散模型的生成式图像恢复方法}

扩散概率模型通过迭代去噪过程建模复杂数据分布，为图像恢复提供了强大的生成先验能力，在感知质量评估指标（LPIPS、SSIM等）上取得了显著优于确定性方法的成果。Palette\cite{palette}将条件扩散模型系统化应用于图像间转换任务（包括去噪、修复、着色和超分辨率），证明扩散方法能够生成多样化高质量输出——特别是在严重退化导致信息大量缺失的场景下，生成先验可以``合理补全''丢失细节，而确定性方法在此场景下往往产生过度平滑的结果，成为扩散图像恢复领域的重要奠基工作。Liu等人\cite{rddm}提出残差去噪扩散模型（RDDM），将扩散过程重新定义为在洁净图像与退化图像残差上操作，从而仅需对变化量建模而非完整图像，将所需采样步数从标准扩散模型的数百步显著压缩至少数步骤，在保持高恢复质量的同时大幅降低推理计算成本，为扩散模型实用化部署奠定了基础。

预训练大型扩散模型先验的充分利用是生成式恢复的关键进展。DiffBIR\cite{diffbir}开创了利用大型扩散模型先验的两阶段范式：第一阶段由专用退化消除网络去除主要退化成分，第二阶段借助预训练Stable Diffusion模型的生成先验对中间图像进行高质量细节增强，利用从海量自然图像中学得的丰富视觉语义先验，在真实世界盲图像超分辨率和人脸恢复任务上取得了卓越的感知质量，验证了大规模扩散先验对图像恢复的普适价值。Yang等人\cite{pasd}提出像素感知交叉注意力（PASD），通过像素级对齐机制使扩散模型在利用生成先验合成丰富细节的同时保持对退化输入的高保真度，有效控制了``幻觉细节''的产生，在视觉保真度与感知质量之间取得了更优的平衡。尽管感知质量出众，扩散模型在实际图像恢复应用中面临两项根本性挑战：迭代采样的高计算成本（单次恢复通常需数十次至数百次神经网络前向传播）制约了实时部署；强大的生成先验可能引入与原始场景不符的``幻觉细节''，在医学影像诊断、遥感图像解译等高保真度应用中可能产生严重误导。

\textbf{（四）基于智能体的图像恢复方法}

基于智能体的方法代表着图像恢复领域的新兴范式，将恢复过程重新定义为具有感知-规划-执行-评估闭环的智能决策问题：视觉语言模型（VLM）或大语言模型（LLM）作为协调决策者，动态分析图像退化、规划工具调用序列、评估中间恢复结果质量，并根据评估反馈迭代调整策略。与前述所有方法相比，这一范式的根本突破在于引入了动态推理和迭代细化机制，使恢复过程能够适应每张图像的具体退化特征，而非套用预先设计的固定策略。

AgenticIR\cite{agenticir}是基于智能体图像恢复领域的开创性工作，系统化建立了五阶段动态规划框架：（1）感知阶段——VLM全面分析输入图像的退化类型、严重程度及空间分布；（2）调度阶段——基于感知结果规划专用恢复工具的调用序列；（3）执行阶段——按计划调用图像恢复工具库中的对应工具完成局部处理；（4）反思阶段——VLM评估中间恢复图像的质量，判断是否已满足恢复目标；（5）重调度阶段——若质量不足则修正计划并触发下一轮迭代。该框架支持动态组合任意专用工具序列，并通过深度优先搜索在解空间中探索优质方案，与此前所有方法相比对复杂退化的应对能力有了根本性突破；然而，深度优先搜索策略在最坏情况下导致指数级计算代价，是实时部署的主要障碍。该框架进一步引入按退化复杂度三分（简单、中等、复杂）的自适应系统与经验记忆模块，积累和复用成功的恢复决策路径，使系统能够在部署过程中随经验积累持续自我改进，而无需周期性重训练。

在多智能体协同与效率提升方面，MAIR\cite{mair}引入三阶段退化先验（压缩失真$\to$成像退化$\to$场景退化）构建多智能体协作架构，利用先验知识大幅压缩工具选择的搜索空间，并对独立子任务进行并行化处理，在与AgenticIR相当的恢复质量下将推理效率提升44\%，显著缩小了基于智能体方法与实时部署之间的效率差距。RestoreAgent\cite{restoreagent}通过在大规模恢复任务-决策对上端到端微调多模态LLM，将多步推理压缩为单次前向传播，以牺牲部分动态规划灵活性为代价换取推理速度的大幅提升；Q-Agent\cite{qagent}以图像质量评估模型预测的预期质量提升作为贪婪选择准则，在每一步选择最大化质量提升的工具，将规划复杂度从指数级降至相对于工具数量的线性复杂度，显著提升了大规模工具库场景下的实用部署可行性。

然而，上述所有基于智能体的系统均将整幅图像视为单一实体处理，制定并执行全局统一的恢复策略，未能在决策框架中纳入退化的空间分布信息。在真实复杂场景中，图像前景受运动模糊影响、背景弥漫雾霾、暗部阴影区域充斥噪声，同时还可能横贯整体的雨纹——以统一全图策略处理此类图像，必然在部分区域造成``过度处理''、在部分区域造成``处理不足''，导致明显的局部视觉质量损失。这一``空间感知''能力的缺失，构成了本项目直接的研究起点。

\textbf{（五）空间感知工具基础与视觉退化分析}

实现空间感知图像恢复所需的关键工具链已经逐步成熟，为本项目的技术路线提供了坚实的基础设施支撑，也表明当前是开展此类系统整合研究的最佳时机。

在图像空间分解方面，Kirillov等人\cite{sam}提出的SAM（Segment Anything Model）以超过10亿个掩码的大规模开放图像数据集训练，提供了强大的零样本语义区域分割能力，可在无需特定退化类型先验的情况下将图像分解为具有语义边界的空间区域，为区域级退化感知提供了基础工具。SAM采用简洁的接口设计（点、框、文本等多种提示格式），可以便捷地嵌入智能体系统的工具调用流程中。然而，标准SAM直接应用于退化图像时存在分割质量下降的问题：退化导致的模糊边界、噪声纹理和对比度损失会干扰SAM的特征提取，造成过分割、分割漂移或边界不准确等现象，在高噪声或严重模糊的图像上尤为明显。针对这一问题，Chen等人\cite{robustsam}提出RobustSAM，在保持与SAM相同灵活接口的基础上，通过专项训练在噪声、模糊、低对比度等各类退化条件下保持稳健分割性能，使分割驱动的空间分解能够在真实退化图像上可靠运行，为智能体系统在退化场景下的区域感知提供了保障。Ren等人\cite{grounded_sam}提出Grounded SAM，将开放词汇目标检测与SAM精细分割相结合，支持通过任意自然语言提示精确定位特定语义区域，例如``受雾霾影响的天空区域''或``强噪声干扰的阴影区域''。这种语言引导的精细空间定位能力使协调智能体能够通过自然语言表达对特定退化区域的感知结果，直接连接VLM的语言推理输出与分割工具的区域定位输入，构建了完整的语言引导空间感知链路。

在视觉退化描述与质量评估方面，You等人\cite{depictqa}提出DepictQA系列工作，借助视觉语言模型提供对图像质量属性的详细自然语言描述，内容包括具体退化类型（噪声、模糊、雾霾等）、退化严重程度（轻微、中等、严重），以及受各类退化影响的空间区域，其表达粒度远超传统无参考质量评估方法的单一质量分值，为智能体感知阶段提供了语义丰富、空间精确的退化信息输入。Wu等人\cite{qinstruct}构建了Q-Instruct——专门面向低级视觉感知任务的大规模指令遵循数据集，包含丰富的退化描述、质量比较和感知分析等指令类型；在此数据集上微调的视觉语言模型在退化类型识别和细粒度质量描述方面显著优于通用VLM，为构建区域级退化感知的VLM提供了数据构建方法论参考。Wu等人\cite{qbench}建立的Q-Bench基准系统化覆盖低级视觉感知、图像质量描述和比较评估三类核心任务，提供了视觉语言模型在图像质量感知场景下能力评估的标准化协议，为本项目选择合适的基础VLM感知组件提供了方法参照。

上述空间分解工具（SAM、RobustSAM、Grounded SAM）与视觉退化分析工具（DepictQA、Q-Instruct、Q-Bench）的汇聚，在技术层面已为本项目所设想的空间感知多智能体恢复框架提供了完整的组件基础：协调智能体调用Grounded SAM将图像分解为退化语义区域；经Q-Instruct微调的VLM对各空间区域独立进行退化类型识别与严重程度评估；区域专用子智能体针对各区域的具体退化特征施加定制化恢复策略；各区域恢复结果经融合模块无缝整合为全局一致的高质量输出。然而，协调上述工具与多智能体协同恢复策略的系统性框架在方法论层面尚属空白——现有基于智能体的方法均未将空间感知能力纳入其感知-规划-执行框架，这正是本项目拟填补的核心研究缺口。

\textbf{（六）现有研究的局限性}

综合上述分析，现有研究存在以下三个层面的理论局限，构成本项目的直接研究动因。

\textbf{（1）退化表征层面：空间异质性建模不足}

现有方法对退化的表征停留在图像级或全局特征级，缺乏对"退化类型—严重程度—空间位置"耦合关系的区域级建模能力。Transformer 类方法虽具备全局上下文建模能力，但其窗口划分策略与退化区域边界往往不对齐，导致在窗口边界引入分割伪影；AiO 方法的提示向量虽能区分不同退化类型，但无法定位退化在空间上的具体分布；基于智能体的方法虽引入动态决策，但感知阶段缺乏对空间区域的精细化分析能力。这一表征粒度的缺失，使得现有方法在面对异质退化时难以实现区域级的差异化处理。

\textbf{（2）恢复决策层面：缺乏工具链与参数的联合优化机制}

现有基于智能体的方法在决策层面存在两大瓶颈：一是工具选择策略多基于贪婪搜索或经验规则，缺乏对"工具链组合—超参数配置—区域特征"的联合优化能力；二是规划与执行之间存在语义鸿沟，协调智能体生成的抽象计划难以精确映射到具体工具的参数配置。这导致恢复策略的选择往往次优，且无法根据区域级退化特征进行自适应调整。

\textbf{（3）部署效率层面：大模型依赖导致的实时性瓶颈}

现有智能体化方法普遍依赖 VLM/LLM 进行感知与规划，虽然增强了决策灵活性，但大模型的推理时延和算力消耗显著制约了实时部署可行性。如何在保持空间感知与动态决策能力的前提下，通过知识蒸馏、轨迹压缩等手段降低推理开销，是从研究原型走向实用部署的关键挑战。

\subsection{本课题独到的学术价值和应用价值}

\textbf{（一）学术价值}：

（1）提出空间退化图的区域级表征方法，将退化建模从图像级细化为区域级，为异质退化场景的分析与处理提供新的技术途径；

（2）构建多智能体协同的恢复框架，通过任务分解与分工协作实现差异化处理，为复杂场景图像恢复提供可扩展的架构参考；

（3）探索规划轨迹蒸馏机制，在保持恢复质量的同时降低模型部署成本，为高效图像恢复系统的实现提供可行方案。

\textbf{（二）应用价值}：

（1）提升安防监控与自动驾驶场景下的图像可用性，改善夜间及恶劣天气条件下的视觉感知能力；

（2）改善遥感图像的地物边界与纹理细节质量，辅助变化检测与精细化解译任务；

（3）为医学成像、工业视觉质检等相关领域提供可迁移的技术框架，支撑低质量影像的质量增强需求。

本节小结：通过上述选题依据与价值分析，可进一步明确本项目需在"目标可量化、框架可执行、难点可攻关"的前提下展开研究，因此第2节将围绕研究目标、总体框架与重点难点进行系统展开。

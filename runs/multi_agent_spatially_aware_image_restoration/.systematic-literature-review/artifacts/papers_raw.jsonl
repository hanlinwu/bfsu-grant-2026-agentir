{"openalex_id": "https://openalex.org/W3042989521", "doi": "https://doi.org/10.1172/jci.insight.140329", "title": "Severe immunosuppression and not a cytokine storm characterizes COVID-19 infections", "abstract": "COVID-19-associated morbidity and mortality have been attributed to a pathologic host response. Two divergent hypotheses have been proposed: hyperinflammatory cytokine storm; and failure of host protective immunity that results in unrestrained viral dissemination and organ injury. A key explanation for the inability to address this controversy has been the lack of diagnostic tools to evaluate immune function in COVID-19 infections. ELISpot, a highly sensitive, functional immunoassay, was employed in 27 patients with COVID-19, 51 patients with sepsis, 18 critically ill nonseptic (CINS) patients, and 27 healthy control volunteers to evaluate adaptive and innate immune status by quantitating T cell IFN-ɣ and monocyte TFN-α production. Circulating T cell subsets were profoundly reduced in COVID-19 patients. Additionally, stimulated blood mononuclear cells produced less than 40%-50% of the IFN-ɣ and TNF-α observed in septic and CINS patients, consistent with markedly impaired immune effector cell function. Approximately 25% of COVID-19 patients had increased IL-6 levels that were not associated with elevations in other canonical proinflammatory cytokines. Collectively, these findings support the hypothesis that COVID-19 suppresses host functional adaptive and innate immunity. Importantly, IL-7 administered ex vivo restored T cell IFN-ɣ production in COVID-19 patients. Thus, ELISpot may functionally characterize host immunity in COVID-19 and inform prospective therapies.", "authors": ["Kenneth E. Remy", "Monty B. Mazer", "David A. Striker", "Ali H. Ellebedy", "Andrew H. Walton", "Jacqueline Unsinger", "Teresa Blood", "Philip A. Mudd", "Daehan J. Yi", "Daniel A. Mannion", "Dale F. Osborne", "R. Scott Martin", "Nitin J. Anand", "James P. Bosanquet", "Jane Blood", "Anne M. Drewry", "Charles C. Caldwell", "Isaiah R. Turnbull", "Scott C. Brakenridge", "Lyle L. Moldwawer", "Richard S. Hotchkiss"], "year": 2020, "venue": "JCI Insight", "cited_by_count": 314, "type": "article", "concepts": ["Cytokine storm", "Coronavirus disease 2019 (COVID-19)", "Immunosuppression", "2019-20 coronavirus outbreak", "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4390880765", "doi": "https://doi.org/10.3390/buildings14010220", "title": "Opportunities and Challenges of Generative AI in Construction Industry: Focusing on Adoption of Text-Based Models", "abstract": "In the last decade, despite rapid advancements in artificial intelligence (AI) transforming many industry practices, construction largely lags in adoption. Recently, the emergence and rapid adoption of advanced large language models (LLMs) like OpenAI’s GPT, Google’s PaLM, and Meta’s Llama have shown great potential and sparked considerable global interest. However, the current surge lacks a study investigating the opportunities and challenges of implementing Generative AI (GenAI) in the construction sector, creating a critical knowledge gap for researchers and practitioners. This underlines the necessity to explore the prospects and complexities of GenAI integration. Bridging this gap is fundamental to optimizing GenAI’s early stage adoption within the construction sector. Given GenAI’s unprecedented capabilities to generate human-like content based on learning from existing content, we reflect on two guiding questions: What will the future bring for GenAI in the construction industry? What are the potential opportunities and challenges in implementing GenAI in the construction industry? This study delves into reflected perception in literature, analyzes the industry perception using programming-based word cloud and frequency analysis, and integrates authors’ opinions to answer these questions. This paper recommends a conceptual GenAI implementation framework, provides practical recommendations, summarizes future research questions, and builds foundational literature to foster subsequent research expansion in GenAI within the construction and its allied architecture and engineering domains.", "authors": ["Prashnna Ghimire", "Kyungki Kim", "Manoj Acharya"], "year": 2024, "venue": "Buildings", "cited_by_count": 99, "type": "article", "concepts": ["Generative grammar", "Engineering", "Knowledge management", "Perception", "Bridging (networking)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4283795305", "doi": "https://doi.org/10.1108/9781802626056", "title": "Big Data: A Game Changer for Insurance Industry", "abstract": "Striking a balance between the technical characteristics of the subject and the practical aspects of decision making, spanning from fraud analytics in claims management, to customer analytics, to risk analytics in solvency, the comprehensive coverage presented makes Big Data an invaluable resource for any insurance professional.", "authors": ["Ercan Özen", "Simon Grima", "Pallavi Seth", "Kamal Gulati", "Aradhana Rana"], "year": 2022, "venue": "", "cited_by_count": 151, "type": "book", "concepts": ["Big data", "Big game", "Insurance industry", "Business", "Computer science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4392168796", "doi": "https://doi.org/10.3390/bioengineering11030219", "title": "A Comprehensive Review on Synergy of Multi-Modal Data and AI Technologies in Medical Diagnosis", "abstract": "Disease diagnosis represents a critical and arduous endeavor within the medical field. Artificial intelligence (AI) techniques, spanning from machine learning and deep learning to large model paradigms, stand poised to significantly augment physicians in rendering more evidence-based decisions, thus presenting a pioneering solution for clinical practice. Traditionally, the amalgamation of diverse medical data modalities (e.g., image, text, speech, genetic data, physiological signals) is imperative to facilitate a comprehensive disease analysis, a topic of burgeoning interest among both researchers and clinicians in recent times. Hence, there exists a pressing need to synthesize the latest strides in multi-modal data and AI technologies in the realm of medical diagnosis. In this paper, we narrow our focus to five specific disorders (Alzheimer's disease, breast cancer, depression, heart disease, epilepsy), elucidating advanced endeavors in their diagnosis and treatment through the lens of artificial intelligence. Our survey not only delineates detailed diagnostic methodologies across varying modalities but also underscores commonly utilized public datasets, the intricacies of feature engineering, prevalent classification models, and envisaged challenges for future endeavors. In essence, our research endeavors to contribute to the advancement of diagnostic methodologies, furnishing invaluable insights for clinical decision making.", "authors": ["Xi Xu", "Jianqiang Li", "Zhichao Zhu", "Linna Zhao", "Huina Wang", "Changwei Song", "Yining Chen", "Qing Zhao", "Ji‐Jiang Yang", "Yan Pei"], "year": 2024, "venue": "Bioengineering", "cited_by_count": 153, "type": "review", "concepts": ["Modalities", "Computer science", "Artificial intelligence", "Data science", "Realm"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4391615698", "doi": "https://doi.org/10.3390/heritage7020038", "title": "Artificial Intelligence for Digital Heritage Innovation: Setting up a R&amp;D Agenda for Europe", "abstract": "Artificial intelligence (AI) is a game changer in many fields, including cultural heritage. It supports the planning and preservation of heritage sites and cities, enables the creation of virtual experiences to enrich cultural tourism and engagement, supports research, and increases access and understanding of heritage objects. Despite some impressive examples, the full potential of AI for economic, social, and cultural change is not yet fully visible. Against this background, this article aims to (a) highlight the scope of AI in the field of cultural heritage and innovation, (b) highlight the state of the art of AI technologies for cultural heritage, (c) highlight challenges and opportunities, and (d) outline an agenda for AI, cultural heritage, and innovation.", "authors": ["Sander Münster", "Ferdinand Maiwald", "Isabella di Lenardo", "Juha Henriksson", "Antoine Isaac", "Manuela Milica Graf", "Clemens Beck", "Johan Oomen"], "year": 2024, "venue": "Heritage", "cited_by_count": 58, "type": "article", "concepts": ["Political science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4393004558", "doi": "https://doi.org/10.3390/buildings14030835", "title": "Advancing Urban Life: A Systematic Review of Emerging Technologies and Artificial Intelligence in Urban Design and Planning", "abstract": "The advancement of cutting-edge technologies significantly transforms urban lifestyles and is indispensable in sustainable urban design and planning. This systematic review focuses on the critical role of innovative technologies and digitalization, particularly artificial intelligence (AI), in urban planning through geo-design, aiming to enhance urban life. It begins with exploring the importance of AI and digital tools in revolutionizing contemporary urban planning practices. Through the methodology based on the Systematic Reviews and Meta-Analyses (PRISMA) protocol, this review sifts through relevant literature over the past two decades by categorizing artificial intelligence technologies based on their functionalities. These technologies are examined for their utility in urban planning, environmental modeling, and infrastructure development, highlighting how they contribute to creating smarter and more livable cities. For instance, machine learning techniques like supervised learning excel in forecasting urban trends, whereas artificial neural networks and deep learning are superior in pattern recognition and vital for environmental modeling. This analysis, which refers to the comprehensive evaluation conducted in this Systematic Review, encompasses studies based on diverse data inputs and domains of application, revealing a trend toward leveraging AI for predictive analytics, decision-making improvements, and the automation of complex geospatial tasks in urban areas. The paper also addresses the challenges encountered, including data privacy, ethical issues, and the demand for cross-disciplinary knowledge. The concluding remarks emphasize the transformative potential of innovative technologies and digitalization in urban planning, advocating for their role in fostering better urban life. It also identifies future research avenues and development opportunities. In light of our review findings, this study concludes that AI technologies indeed hold transformative promise for the field of geo-design and urban planning. They have proven instrumental in advancing predictive analytics, refining decision-making, and streamlining complex geospatial tasks. The AI’s capacity to process expansive datasets and improve urban planning accuracy has facilitated more sustainable urban development and enhanced the resilience of urban environments.", "authors": ["Wei He", "Mingze Chen"], "year": 2024, "venue": "Buildings", "cited_by_count": 56, "type": "review", "concepts": ["Urban design", "Engineering", "Architectural engineering", "Urban planning", "Computer science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W3156012754", "doi": "https://doi.org/10.1111/joes.12611", "title": "Artificial Intelligence and Big Data in Sustainable Entrepreneurship", "abstract": "Abstract There is an urgent need to transition our economy, society, and culture towards systems and actions that facilitate ecological sustainability. Such radical change requires equally radical transformation of approaches to decision making and resource use. Sustainable entrepreneurship (SE) is often presented as the answer to meeting the triple‐bottom‐line challenges that businesses face; however, there are very real limits to what it can achieve. SE is in the early stages of adopting tools at the technological frontier that offer empirical guidance at every point of an entrepreneurial decision‐making process. Big Data (BD) advances the potential for artificial intelligence (AI) to inform decision making, while also charting pathways to achieve desired outcomes. So far, the interactions between AI, BD, and SE have been generally under‐studied. In this primarily conceptual paper, we address the lack of work consolidating and synthesizing these literatures. We suggest that AI and BD readily contribute to further sustainable development of the weak form, but that it also holds great promise for achieving the strong sustainability ideal. We offer two propositions regarding how the integration of AI and BD can inform/support SE. We conclude by mapping out potential avenues for future research.", "authors": ["Steve J. Bickley", "Alison Macintyre", "Benno Torgler"], "year": 2024, "venue": "Journal of Economic Surveys", "cited_by_count": 89, "type": "article", "concepts": ["Sustainability", "Frontier", "Entrepreneurship", "Big data", "Face (sociological concept)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4388760605", "doi": "https://doi.org/10.3390/su152216071", "title": "Assessing the Accuracy of ChatGPT Use for Risk Management in Construction Projects", "abstract": "Artificial Intelligence (AI) is considered promising digital technology that has important opportunities for enhancing project oversight and delivering improved decision-making in the risk management domain. However, there is a limited amount of research that has evaluated AI tools’ performance in risk management. Therefore, with the intention of sustaining more accurate risk-based decision-making process in the construction industry, this paper investigates the accuracy of ChatGPT in risk management for different project types. In this context, Key Performance Indicators (KPIs) related to each risk management sub-process were determined, and then a questionnaire that consisted of prompt templates was prepared for collecting data from ChatGPT. Afterwards, ChatGPT’s responses were evaluated by experts with focus group sessions. The findings indicate that ChatGPT has a moderate level of performance in managing risks. It provides more accurate knowledge in risk response and risk monitoring rather than risk identification and risk analysis sub-processes. This research paves the way for future studies by demonstrating an implication of ChatGPT use for risk-based decision making. In addition, gaining insight into the precision of ChatGPT in the risk-based decision-making process will empower decision-makers to establish resilience in business operations through technology-driven risk management.", "authors": ["Hande Aladağ"], "year": 2023, "venue": "Sustainability", "cited_by_count": 45, "type": "article", "concepts": ["Risk management", "Risk analysis (engineering)", "Context (archaeology)", "IT risk management", "Risk assessment"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W3159474192", "doi": "https://doi.org/10.1523/jneurosci.0119-21.2021", "title": "Heightened Hippocampal β-Adrenergic Receptor Function Drives Synaptic Potentiation and Supports Learning and Memory in the TgF344-AD Rat Model during Prodromal Alzheimer's Disease", "abstract": "The central noradrenergic (NA) system is critical for the maintenance of attention, behavioral flexibility, spatial navigation, and learning and memory, those cognitive functions lost first in early Alzheimer's disease (AD). In fact, the locus coeruleus (LC), the sole source of norepinephrine (NE) for >90% of the brain, is the first site of pathologic tau accumulation in human AD with axon loss throughout forebrain, including hippocampus. The dentate gyrus is heavily innervated by LC-NA axons, where released NE acts on β-adrenergic receptors (ARs) at excitatory synapses from entorhinal cortex to facilitate long-term synaptic plasticity and memory formation. These synapses experience dysfunction in early AD before cognitive impairment. In the TgF344-AD rat model of AD, degeneration of LC-NA axons in hippocampus recapitulates human AD, providing a preclinical model to investigate synaptic and behavioral consequences. Using immunohistochemistry, Western blot analysis, and brain slice electrophysiology in 6- to 9-month-old wild-type and TgF344-AD rats, we discovered that the loss of LC-NA axons coincides with the heightened β-AR function at medial perforant path-dentate granule cell synapses that is responsible for the increase in LTP magnitude at these synapses. Furthermore, novel object recognition is facilitated in TgF344-AD rats that requires β-ARs, and pharmacological blockade of β-ARs unmasks a deficit in extinction learning only in TgF344-AD rats, indicating a greater reliance on β-ARs in both behaviors. Thus, a compensatory increase in β-AR function during prodromal AD in TgF344-AD rats heightens synaptic plasticity and preserves some forms of learning and memory.<b>SIGNIFICANCE STATEMENT</b> The locus coeruleus (LC), a brain region located in the brainstem which is responsible for attention and arousal, is damaged first by Alzheimer's disease (AD) pathology. The LC sends axons to hippocampus where released norepinephrine (NE) modulates synaptic function required for learning and memory. How degeneration of LC axons and loss of NE in hippocampus in early AD impacts synaptic function and learning and memory is not well understood despite the importance of LC in cognitive function. We used a transgenic AD rat model with LC axon degeneration mimicking human AD and found that heightened function of β-adrenergic receptors in the dentate gyrus increased synaptic plasticity and preserved learning and memory in early stages of the disease.", "authors": ["Anthoni M. Goodman", "Bethany M. Langner", "Nateka L. Jackson", "Capri Alex", "Lori L. McMahon"], "year": 2021, "venue": "Journal of Neuroscience", "cited_by_count": 68, "type": "article", "concepts": ["Neuroscience", "Long-term potentiation", "Dentate gyrus", "Entorhinal cortex", "Synaptic plasticity"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4391884123", "doi": "https://doi.org/10.3390/urbansci8010016", "title": "Creativity and Innovation in Civic Spaces Supported by Cognitive Flexibility When Learning with AI Chatbots in Smart Cities", "abstract": "The purpose of this study is to advance conceptual understandings of the cognitive flexibility construct, in support of creativity and innovation in smart city civic spaces, employing the use of large language model artificial intelligence chatbots such as ChatGPT. Based on a review of the research and practice literature, this study formulates a conceptual framework for cognitive flexibility in support of creativity and innovation in AI environments, adaptable to smart cities. A research design is used that employs AI as a design material, in combination with a topical inquiry involving boundary setting and perspective taking, to co-pilot an exploration with ChatGPT-3.5/4. This study operationalizes the framework for applications to learning approaches, addressing flexibility and inclusivity in smart city spaces and regions. With the rapid evolving of chatbot technologies, ChatGPT-4 is used in the exploration of a speculative real-world urban example. This work is significant in that AI chatbots are explored for application in urban spaces involving creative ideation, iteration, engagement, and cognitive flexibility; future directions for exploration are identified pertaining to ethical and civil discourse in smart cities and learning cities, as well as the notion that AI chatbots and GPTs (generative pre-trained transformers) may become a zeitgeist for understanding and learning in smart cities.", "authors": ["Sarah A. Chauncey", "H. Patricia McKenna"], "year": 2024, "venue": "Urban Science", "cited_by_count": 19, "type": "article", "concepts": ["Creativity", "Flexibility (engineering)", "Chatbot", "Smart city", "Generative grammar"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W2409468935", "doi": "https://doi.org/10.5038/1911-9933.10.1.1323", "title": "A Year of Truth and the Possibilities for Reconciliation in Indonesia", "abstract": "Since the end of the New Order military regime in 1998, successive Indonesian administrations have yet deal with crimes against humanity perpetrated by the old regime, particularly the 1965–1966 massacres. Attempts for reconciliation have mainly come from grass-roots organizations which employ oral historical methods to both document these crimes and to serve as the basis for claims of truth-telling about the past. In this paper, I examine the work of some of these grass-roots organizations and, in particular, the ‘Year of Truth’ initiative. I outline the ‘Hearing Testimony’ forum held in November 2013 and contrast this work with the failed attempts at the national level to deal with this past.", "authors": ["Annie Pohlman"], "year": 2016, "venue": "Genocide Studies and Prevention", "cited_by_count": 30, "type": "article", "concepts": ["Genocide", "Crimes against humanity", "Indonesian", "Humanity", "Work (physics)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W2014471638", "doi": "https://doi.org/10.1371/journal.pone.0051300", "title": "Functional Analysis of Leishmania Cyclopropane Fatty Acid Synthetase", "abstract": "The single gene encoding cyclopropane fatty acid synthetase (CFAS) is present in Leishmania infantum, L. mexicana and L. braziliensis but absent from L. major, a causative agent of cutaneous leishmaniasis. In L. infantum, usually causative agent of visceral leishmaniasis, the CFAS gene is transcribed in both insect (extracellular) and host (intracellular) stages of the parasite life cycle. Tagged CFAS protein is stably detected in intracellular L. infantum but only during the early log phase of extracellular growth, when it shows partial localisation to the endoplasmic reticulum. Lipid analyses of L. infantum wild type, CFAS null and complemented parasites detect a low abundance CFAS-dependent C19Δ fatty acid, characteristic of a cyclopropanated species, in wild type and add-back cells. Sub-cellular fractionation studies locate the C19Δ fatty acid to both ER and plasma membrane-enriched fractions. This fatty acid is not detectable in wild type L. major, although expression of the L. infantum CFAS gene in L. major generates cyclopropanated fatty acids, indicating that the substrate for this modification is present in L. major, despite the absence of the modifying enzyme. Loss of the L. infantum CFAS gene does not affect extracellular parasite growth, phagocytosis or early survival in macrophages. However, while endocytosis is also unaffected in the extracellular CFAS nulls, membrane transporter activity is defective and the null parasites are more resistant to oxidative stress. Following infection in vivo, L. infantum CFAS nulls exhibit lower parasite burdens in both the liver and spleen of susceptible hosts but it has not been possible to complement this phenotype, suggesting that loss of C19Δ fatty acid may lead to irreversible changes in cell physiology that cannot be rescued by re-expression. Aberrant cyclopropanation in L. major decreases parasite virulence but does not influence parasite tissue tropism.", "authors": ["Samuel O. Oyola", "Krystal J. Evans", "Terry Smith", "Barbara A. Smith", "James D. Hilley", "Jeremy C. Mottram", "Paul M. Kaye", "Deborah F. Smith"], "year": 2012, "venue": "PLoS ONE", "cited_by_count": 28, "type": "article", "concepts": ["Biology", "Leishmania infantum", "Leishmania", "Extracellular", "Fatty acid"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4409347536", "doi": "https://doi.org/10.1609/aaai.v39i20.35435", "title": "HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers", "abstract": "Low-cost accelerometers play a crucial role in modern society due to their advantages of small size, ease of integration, wearability, and mass production, making them widely applicable in automotive systems, aerospace, and wearable technology. However, this widely used sensor suffers from severe accuracy and range limitations. To this end, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost sensor signals into high-cost equivalents, thereby overcoming the precision and range limitations of low-cost accelerometers. Due to the lack of frame-level paired low-cost and high-cost signals for training, we propose an Optimal Transport Supervision (OTS), which leverages optimal transport theory to explore potential consistency between unpaired data, thereby maximizing supervisory information. Moreover, we propose a Modulated Laplace Energy (MLE), which injects appropriate energy into the generator to encourage it to break range limitations, enhance local changes, and enrich signal details. Given the absence of a dedicated dataset, we specifically establish a Low-cost Accelerometer Signal Enhancement Dataset (LASED) containing tens of thousands of samples, which is the first dataset serving to improve the accuracy and range of accelerometers and is released in Github. Experimental results demonstrate that a GAN combined with either OTS or MLE alone can surpass the previous signal enhancement SOTA methods by an order of magnitude. Integrating both OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the accelerometer range while reducing signal noise by two orders of magnitude, establishing a benchmark in the accelerometer signal processing.", "authors": ["Yifeng Wang", "Yi Zhao"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 11, "type": "article", "concepts": ["Accelerometer", "Range (aeronautics)", "Energy (signal processing)", "Optoelectronics", "Computer science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4361282639", "doi": "https://doi.org/10.1080/13600869.2023.2192569", "title": "Governing fiduciary relationships or building up a governance model for trust in AI? Review of healthcare as a socio-technical system", "abstract": "‘: Fiduciary law aims to mitigate the inherent risk of ‘trust’, which helps restore interpersonal trust. It remains to be answered how trust should be governed in an AI-driven socio-technical system where technical and social factors are involved including interpersonal relationships and AI-human interactions. Taking interpersonal trust as the backdrop of analysis, this article seeks answers to this question focusing on healthcare. It firstly draws a conceptual framework regarding 'trust' and investigates its interplay with AI as well as examines how it is governed under the fiduciary law. Subsequently, it upholds a socio-technical system perspective, examining how to enable and sustain trust in an AI-driven socio-technical system. A governance model is then developed to elicit ‘intrinsic’, ‘dynamic’ and ‘ethical’ values of trust attributed to various elements under a tri-partite framework. It is recognised that findings of the literature as to trust, its trajectory and implications can be implemented within the proposed framework. Furthermore, it brings novelty by re-conceptualising the elements of 'trust' and associated values, marking distinction to its interpersonal roots and fiduciary relationships. It is considered this governance model, by upholding a holistic viewpoint, provides a generalisable framework that can construct, maintain and restore trust in AI-driven socio-technical systems.", "authors": ["Mehmet Bilal Ünver"], "year": 2023, "venue": "International Review of Law Computers & Technology", "cited_by_count": 10, "type": "article", "concepts": ["Fiduciary", "Interpersonal communication", "Corporate governance", "Novelty", "Construct (python library)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4283797510", "doi": "https://doi.org/10.1108/978-1-80262-605-620221020", "title": "Prelims", "abstract": "Citation (2022), \"Prelims\", Sood, K., Dhanaraj, R.K., Balusamy, B., Grima, S. and Uma Maheshwari, R. (Ed.) Big Data: A Game Changer for Insurance Industry (Emerald Studies in Finance, Insurance, and Risk Management), Emerald Publishing Limited, Bingley, pp. i-xxiii. https://doi.org/10.1108/978-1-80262-605-620221020", "authors": [], "year": 2022, "venue": "", "cited_by_count": 10, "type": "book-chapter", "concepts": ["Emerald", "Publishing", "Citation", "Business", "Library science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4399626283", "doi": "https://doi.org/10.3389/fpsyt.2024.1422939", "title": "Omics approaches open new horizons in major depressive disorder: from biomarkers to precision medicine", "abstract": "Major depressive disorder (MDD) is a recurrent episodic mood disorder that represents the third leading cause of disability worldwide. In MDD, several factors can simultaneously contribute to its development, which complicates its diagnosis. According to practical guidelines, antidepressants are the first-line treatment for moderate to severe major depressive episodes. Traditional treatment strategies often follow a one-size-fits-all approach, resulting in suboptimal outcomes for many patients who fail to experience a response or recovery and develop the so-called “therapy-resistant depression”. The high biological and clinical inter-variability within patients and the lack of robust biomarkers hinder the finding of specific therapeutic targets, contributing to the high treatment failure rates. In this frame, precision medicine, a paradigm that tailors medical interventions to individual characteristics, would help allocate the most adequate and effective treatment for each patient while minimizing its side effects. In particular, multi-omic studies may unveil the intricate interplays between genetic predispositions and exposure to environmental factors through the study of epigenomics, transcriptomics, proteomics, metabolomics, gut microbiomics, and immunomics. The integration of the flow of multi-omic information into molecular pathways may produce better outcomes than the current psychopharmacological approach, which targets singular molecular factors mainly related to the monoamine systems, disregarding the complex network of our organism. The concept of system biomedicine involves the integration and analysis of enormous datasets generated with different technologies, creating a “patient fingerprint”, which defines the underlying biological mechanisms of every patient. This review, centered on precision medicine, explores the integration of multi-omic approaches as clinical tools for prediction in MDD at a single-patient level. It investigates how combining the existing technologies used for diagnostic, stratification, prognostic, and treatment-response biomarkers discovery with artificial intelligence can improve the assessment and treatment of MDD.", "authors": ["Fabiola Stolfi", "Hugo Abreu", "Riccardo Sinella", "Sara Nembrini", "Sara Centonze", "Virginia Landra", "Claudio Brasso", "Giuseppe Cappellano", "Paola Rocca", "Annalisa Chiocchetti"], "year": 2024, "venue": "Frontiers in Psychiatry", "cited_by_count": 28, "type": "article", "concepts": ["Precision medicine", "Biomedicine", "Major depressive disorder", "Omics", "Systems medicine"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4412974610", "doi": "https://doi.org/10.3389/frai.2025.1590105", "title": "Evaluation of large language model-driven AutoML in data and model management from human-centered perspective", "abstract": "As organizations increasingly seek to leverage machine learning (ML) capabilities, the technical complexity of implementing ML solutions creates significant barriers to adoption and impacts operational efficiency. This research examines how Large Language Models (LLMs) can transform the accessibility of ML technologies within organizations through a human-centered Automated Machine Learning (AutoML) approach. Through a comprehensive user study involving 15 professionals across various roles and technical backgrounds, we evaluate the organizational impact of an LLM-based AutoML framework compared to traditional implementation methods. Our research offers four significant contributions to both management practice and technical innovation: First, we present pioneering evidence that LLM-based interfaces can dramatically improve ML implementation success rates, with 93.34% of users achieved superior performance in the LLM condition, with 46.67% showing higher accuracy (10%-25% improvement over baseline) and 46.67% demonstrating significantly higher accuracy (>25% improvement over baseline), while 6.67% maintained comparable performance levels; and 60% reporting substantially reduced development time. Second, we demonstrate how natural language interfaces can effectively bridge the technical skills gap in organizations, cutting implementation time by 50% while improving accuracy across all expertise levels. Third, we provide valuable insights for organizations designing human-AI collaborative systems, showing that our approach reduced error resolution time by 73% and significantly accelerated employee learning curves. Finally, we establish empirical support for natural language as an effective interface for complex technical systems, offering organizations a path to democratize ML capabilities without compromising quality or performance.", "authors": ["Jian Yao", "Lantian Zhang", "Jiping Huang"], "year": 2025, "venue": "Frontiers in Artificial Intelligence", "cited_by_count": 3, "type": "article", "concepts": ["Leverage (statistics)", "Baseline (sea)", "Computer science", "Perspective (graphical)", "Artificial intelligence"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4405967193", "doi": "https://doi.org/10.3390/computers14010007", "title": "Seeing the Sound: Multilingual Lip Sync for Real-Time Face-to-Face Translation", "abstract": "Imagine a future where language is no longer a barrier to real-time conversations, enabling instant and lifelike communication across the globe. As cultural boundaries blur, the demand for seamless multilingual communication has become a critical technological challenge. This paper addresses the lack of robust solutions for real-time face-to-face translation, particularly for low-resource languages, by introducing a comprehensive framework that not only translates language but also replicates voice nuances and synchronized facial expressions. Our research tackles the primary challenge of achieving accurate lip synchronization across culturally diverse languages, filling a significant gap in the literature by evaluating the generalizability of lip sync models beyond English. Specifically, we develop a novel evaluation framework combining quantitative lip sync error metrics and qualitative assessments by human observers. This framework is applied to assess two state-of-the-art lip sync models with different architectures for Turkish, Persian, and Arabic languages, using a newly collected dataset. Based on these findings, we propose and implement a modular system that integrates language-agnostic lip sync models with neural networks to deliver a fully functional face-to-face translation experience. Inference Time Analysis shows this system achieves highly realistic, face-translated talking heads in real time, with a throughput as low as 0.381 s. This transformative framework is primed for deployment in immersive environments such as VR/AR, Metaverse ecosystems, and advanced video conferencing platforms. It offers substantial benefits to developers and businesses aiming to build next-generation multilingual communication systems for diverse applications. While this work focuses on three languages, its modular design allows scalability to additional languages. However, further testing in broader linguistic and cultural contexts is required to confirm its universal applicability, paving the way for a more interconnected and inclusive world where language ceases to hinder human connection.", "authors": ["Amirkia Rafiei Oskooei", "Mehmet S. Aktaş", "Mustafa Keleş"], "year": 2024, "venue": "Computers", "cited_by_count": 7, "type": "article", "concepts": ["Face (sociological concept)", "sync", "Translation (biology)", "Sound (geography)", "Speech recognition"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4388831665", "doi": "https://doi.org/10.3390/app132212497", "title": "Relevance of Machine Learning Techniques in Water Infrastructure Integrity and Quality: A Review Powered by Natural Language Processing", "abstract": "Water infrastructure integrity, quality, and distribution are fundamental for public health, environmental sustainability, economic development, and climate change resilience. Ensuring the robustness and quality of water infrastructure is pivotal for sectors like agriculture, industry, and energy production. Machine learning (ML) offers potential for bolstering water infrastructure integrity and quality by analyzing extensive data from sensors and other sources, optimizing treatment protocols, minimizing water losses, and improving distribution methods. This study delves into ML applications in water infrastructure integrity and quality by analyzing English-language articles from 2015 onward, compiling a total of 1087 articles. Initially, a natural language processing approach centered on topic modeling was adopted to classify salient topics. From each identified topic, key terms were extracted and utilized in a semi-automatic selection process, pinpointing the most relevant articles for further scrutiny, while unsupervised ML algorithms can assist in extracting themes from the documents, generating meaningful topics often requires intricate hyperparameter adjustments. Leveraging the Bidirectional Encoder Representations from Transformers (BERTopic) enhanced the study’s contextual comprehension in topic modeling. This semi-automatic methodology for bibliographic exploration begins with a broad topic categorization, advancing to an exhaustive analysis of each topic. The insights drawn underscore ML’s instrumental role in enhancing water infrastructure’s integrity and quality, suggesting promising future research directions. Specifically, the study has identified four key areas where ML has been applied to water management: (1) advancements in the detection of water contaminants and soil erosion; (2) forecasting of water levels; (3) advanced techniques for leak detection in water networks; and (4) evaluation of water quality and potability. These findings underscore the transformative impact of ML on water infrastructure and suggest promising paths for continued investigation.", "authors": ["José García", "Andrés Leiva-Araos", "Emerson Diaz-Saavedra", "Paola Moraga", "Hernán Pinto", "Víctor Yepes"], "year": 2023, "venue": "Applied Sciences", "cited_by_count": 19, "type": "review", "concepts": ["Computer science", "Water quality", "Data science", "Artificial intelligence", "Machine learning"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W252306533", "doi": null, "title": "Hope and Despair for a New South Africa: The Limits of Rights Discourse", "abstract": "This article is a critique of the struggle to end apartheid in South Africa. It explores the assumptions employed by the African National Congress and the international community to construct a post-apartheid society. It argues that the reliance on the law as the key medium for economic, social, and political change was insufficient to transform the legacy of apartheid. Instead, the piece contends that apartheid was privatized and its beneficiaries protected under the new dispensation. It makes the argument that the lot of the black majority is unlikely to be changed such gradualist approach to social change.", "authors": ["Makau W. Mutua"], "year": 1997, "venue": "", "cited_by_count": 22, "type": "article", "concepts": ["Argument (complex analysis)", "Construct (python library)", "Politics", "Political science", "Political economy"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4406725058", "doi": "https://doi.org/10.1007/s00170-025-15033-9", "title": "A generative pre-trained transformer industrial bot to improve operators’ working experience in a small Industry 5.0 factory", "abstract": "Abstract The industrial sector is embracing a new revolution, Industry 5.0 (I5.0), focusing on human well-being and ecosystem preservation. Previous industrial revolutions have emphasized incorporating the latest state-of-the-art innovations and technologies to improve production processes, overseeing some of their long-term damaging impact on human beings. Our research contributes to the I5.0 practical implementation in factories by proposing the design of a generative pre-trained transformer (GPT) industrial bot as a tool to assist workers of a small experimental factory in improving their daily working experience. The industrial bot closely tracks factory production and allows operators to monitor a few fundamental elements of their well-being via text queries, such as the pollution level and the maximum overtime hours per worker. It also provides factories with three valuable functions: faulty equipment discovery, root cause analysis, and synthetic data generation. These features originate from factory-customized data loaded into the OpenAI GPT4 language model (LM) presented in two industrial bot versions. The first is an offline version, created using a Langchain agent connected to the GPT4 LM through OpenAI APIs and visualized with Streamlit, an open-source front-end tool. The second is an online version produced by the GPT4 internal function that creates customs GPTs. We highlight both versions’ advantages and disadvantages to guide factories in considering the suitable environmental model when adopting I5.0. Our system also allows operators to receive additional tips, thanks to the online GPT4 robust database, to enhance their knowledge on maintaining their well-being and their factory contextualized on the query sent to the industrial bot.", "authors": ["Kahiomba Sonia Kiangala", "Zenghui Wang"], "year": 2025, "venue": "The International Journal of Advanced Manufacturing Technology", "cited_by_count": 7, "type": "article", "concepts": ["Factory (object-oriented programming)", "Transformer", "Manufacturing engineering", "Engineering", "Industrial and production engineering"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4405720878", "doi": "https://doi.org/10.3390/app142412072", "title": "MIRA-ChatGLM: A Fine-Tuned Large Language Model for Intelligent Risk Assessment in Coal Mining", "abstract": "Intelligent mining risk assessment (MIRA) is a vital approach for enhancing safety and operational efficiency in mining. In this study, we introduce MIRA-ChatGLM, which leverages pre-trained large language models (LLMs) for the domain of gas risk assessment in coal mines. We meticulously constructed a dataset specifically designed for mining risk analysis and performed parameter-efficient fine-tuning on the locally deployed GLM-4-9B-chat base model to develop MIRA-ChatGLM. By utilizing consumer-grade GPUs and employing LoRA and various levels of quantization algorithms such as QLoRA, we investigated the impact of different data scales and instruction settings on model performance. The evaluation results show that MIRA-ChatGLM achieved excellent performance with BLEU-4, ROUGE-1, ROUGE-2, and ROUGE-L scores of 84.47, 90.63, 86.88, and 90.63, respectively, highlighting its outstanding performance in coal mine gas risk assessment. Through comparative experiments with other large language models of similar size and manual evaluation, MIRA-ChatGLM demonstrated superior performance across multiple key metrics, fully demonstrating its tremendous potential in intelligent mine risk assessment and decision support.", "authors": ["Yi Sun", "Chao Zhang", "Chen Wang", "Ying Han"], "year": 2024, "venue": "Applied Sciences", "cited_by_count": 4, "type": "article", "concepts": ["Coal", "Computer science", "Engineering", "Waste management"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W3216769000", "doi": "https://doi.org/10.1038/s41598-021-02462-1", "title": "Insights into the palaeobiology of an early Homo infant: multidisciplinary investigation of the GAR IVE hemi-mandible, Melka Kunture, Ethiopia", "abstract": "", "authors": ["Adeline Le Cabec", "Thomas Colard", "Damien Charabidzé", "Catherine Chaussain", "Gabriele Di Carlo", "Sabine Gaudzinski‐Windheuser", "Jean‐Jacques Hublin", "Rita Teresa Melis", "L. Pioli", "Fernando Ramírez Rozzi", "Margherita Mussi"], "year": 2021, "venue": "Scientific Reports", "cited_by_count": 13, "type": "article", "concepts": ["Taphonomy", "Context (archaeology)", "Homo sapiens", "Biology", "Evolutionary biology"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4391174260", "doi": "https://doi.org/10.3390/app14030977", "title": "Digital Twins in Software Engineering—A Systematic Literature Review and Vision", "abstract": "Digital twins are a powerful consequence of digital transformation. In fact, they have been applied to many industries to enhance operations, predict needs, improve decision making, or optimize performance, even though the definition of digital twins is still evolving. However, their impact on the software industry is still limited. Thus, this work aims to analyze the current adoption of digital twins in the software industry as a potential path to integrate them into application lifecycle management. To achieve this objective, first, the significant characteristics of current digital twins are analyzed in their application to manufacturing to understand how the knowledge and the lessons learned can be transferred to the software industry. Second, a systematic literature review was conducted on Scopus, the Web of Science, and the ScienceDirect database. The literature review revealed 93 documents after data screening and cleaning 251 initial documents. Our main findings are that digital twins are already influencing and will significantly affect the software industry, revolutionizing various aspects of the software development lifecycle. This study tackles what identifies a digital twin in the software industry, the specific domains and areas where they can be applied in the software lifecycle, and the proposed approaches explored to build digital twins for developing, deploying, and maintaining software systems. Finally, this study proposes some guidelines for building digital twins in the context of application lifecycle management. Determining an appropriate roadmap shortly is essential to achieve a widespread applicability to building suitable digital twins and preparing organizations for the software industry.", "authors": ["Miguel A. Guinea-Cabrera", "Juan A. Holgado-Terriza"], "year": 2024, "venue": "Applied Sciences", "cited_by_count": 15, "type": "article", "concepts": ["Computer science", "Engineering drawing", "Engineering"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4414812718", "doi": "https://doi.org/10.13088/jiis.2025.31.3.141", "title": "A Study on the MCP x A2A Framework for Enhancing Interoperability of LLM-based Autonomous Agents", "abstract": "This paper provides an in-depth technical analysis and implementation methodology of the open-source Agent-to-Agent (A2A) protocol developed by Google and the Model Context Protocol (MCP) introduced by Anthropic. While the evolution of LLM-based autonomous agents is rapidly accelerating, efficient interactions among these agents and their integration with external systems remain significant challenges. In modern AI systems, collaboration between autonomous agents and integration with external tools have become essential elements for building practical AI applications. A2A offers a standardized communication method that enables agents developed in heterogeneous environments to collaborate effectively, while MCP provides a structured I/O framework for agents to connect with external tools and resources. Prior studies have focused primarily on the features and applications of either A2A or MCP individually. In contrast, this study takes an integrated approach, exploring how the two protocols can complement each other to address interoperability issues and facilitate efficient collaboration within complex agent ecosystems.", "authors": ["C. Jeong"], "year": 2025, "venue": "ArXiv.org", "cited_by_count": 2, "type": "article", "concepts": [], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W2951987241", "doi": "https://doi.org/10.29173/alr2526", "title": "The Harms Caused: A Narrative of Intergenerational Responsibility", "abstract": "Born out of the Indian Residential Schools Settlement Agreement, the Independent Assessment Process is a program that provides monetary compensation to former students who suffered sexual and physical abuse at Indian Residential Schools. As “Canada’s Representative” during hearings of the Independent Assessment Process, this author, a young lawyer at the time, bore witness to grizzly accounts of acts perpetrated against claimants that left her unsettled. Unsettled by what was heard, yes, but also in her observations that the process did not satisfy the needs of all claimants, nor did it engage with her own sense of responsibility as a non-Indigenous Canadian.&#x0D; The author weaves together her experiences and observations as “Canada’s Representative” to explore intergenerational justice in a Canadian setting, and what processes might offer a more complete approach in handling the Indian Residential Schools legacy. First, shecanvasses the existing framework of dispute settlement in the context of Indian Residential Schools, namely criminal, tort, and alternative dispute resolution mechanisms. While pointing out the strengths these mechanisms do have to address some of the harms of Indian Residential Schools, she ultimately suggests their inherent legal limitations make them inadequate tools to provide redress to victims and engage society more broadly.&#x0D; The author goes on to define transitional justice, set out its established tenets and themes, and begins to map out a Canadian application of these principles to the Indian Residential Schools policy by drawing on examples from Australia, New Zealand, and the United States. These principles take shape as innovative instruments for advancing the goals of reconciliation and of Canadian society. They are not without their own flaws, however, as the author also points out, that may affect how Canadians—in particular, non-Indigenous Canadians—view their legitimacy.&#x0D; Lastly, the author analyzes prevailing views of societal responsibility to provide a normative underpinning for intergenerational justice in a Canadian context. She concludes by advocating Canadians move from a stance of guilt and blame toward one of a broad assumption of responsibility as they continue to grapple with the legacy of Indian Residential Schools.", "authors": ["Maegan Hough"], "year": 2019, "venue": "Alberta Law Review", "cited_by_count": 12, "type": "article", "concepts": ["Redress", "Witness", "Economic Justice", "Context (archaeology)", "Settlement (finance)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4394928179", "doi": "https://doi.org/10.48175/ijarsct-17449", "title": "AI based Operating System", "abstract": "This review paper examines the potential applications of artificial intelligence (AI) in the development of an operating system (OS) that not only provides functionalities for software and hardware management, as well as common system services, but also integrates intelligent management capabilities. Advanced AI techniques such as expert systems, neural networks, pattern recognition, fuzzy logic prediction, and other AI features can be leveraged in the creation of such an AI-based OS. Features of an AI-based OS may include abstraction, associative AI thinking, perceptual intelligence, contextual imagination, context-specific search, context priming, and various other AI methodologies. Integrating and using smart agents based on large language models (LLMs) face tough challenges that affect how well they work. These challenges include problems like not scheduling and sharing resources efficiently for agent requests on the LLM, difficulties in keeping track of context when agents interact with the LLM, and the complexity of blending different agents with various skills and specialties. The rising number and complexity of agents often cause problems like bottlenecks and inefficient use of resources. To tackle this, our paper introduces AIOS, a unique operating system that incorporates a large language model. This innovation gives the operating system a kind of \"intelligence\" and brings us closer to achieving Artificial General Intelligence (AGI). AIOS is designed to better manage resources, help agents switch between tasks smoothly, allow multiple agents to work at the same time, offer tools for agents, and control access to the system. We explain how AIOS works, highlight the main issues it solves, and provide a basic overview of its design and implementation", "authors": ["Ashutosh Kumar", "Ankit Kumar Singh", "Ashima Mehta"], "year": 2024, "venue": "International Journal of Advanced Research in Science Communication and Technology", "cited_by_count": 1, "type": "article", "concepts": ["Computer science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4410311508", "doi": "https://doi.org/10.63665/aajed.v01i01.02", "title": "Enhancing Paint Formula Innovation Using Generative AI and Historical Data Analytics", "abstract": "This work implements a generative artificial intelligence approach and a search algorithm to recreate and innovate paint formulas on a hardware-near level. We use clustering techniques to explore data latent space and then implement Markov Chain Monte Carlo techniques to sample from the posterior distribution. The approach is designed for multi-objective optimization problems, where in the case of paint formulas, the objectives are the cost and the color difference from a reference formula. We demonstrate the feasibility of the idea by building and testing water-based acrylic paint formulas. The approach is general and can be applied to many different formulations at chemical or hardware-near levels. The paint industry is very competitive and new formulations must be assembled quickly while adhering to predefined criteria regarding sustainability, cost, and performance. In recent years with the advent of generative artificial intelligence approaches, large-scale and rapid assembly and design of formulations became possible. Current commercial approaches to develop new formulations are based on an AI-trained linear regression type approach that does not produce chemical-related formulations when trained with data at the hardware-near level and can also lead to a lower diversity of ideas since it is limited to extrapolating small changes around the reference samples. In this work, we implement a generative artificial intelligence approach that permits to sample of the posterior search space by using tools such as Markov Chain Monte Carlo techniques, to provide access to a wide diversity of potential new formulations. Our approach accomplishes this by employing a search sub-algorithm that relies on prescribed objective functions such as cost and color difference with a reference formulation, that is sampled for many different formulations, and pre-processes the data. We tested our idea using compositional data from water-based acrylic paint formulas that were developed and tested. Our implementation is general and can be used to develop new formulations for many different products at the chemical formulation or hardware-near levels.", "authors": ["Raviteja Meda"], "year": 2025, "venue": "American Advanced Journal for Emerging Disciplinaries", "cited_by_count": 4, "type": "article", "concepts": ["Analytics", "Generative grammar", "Data science", "Computer science", "Data analysis"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4410155916", "doi": "https://doi.org/10.3390/app15095208", "title": "A Helping Hand: A Survey About AI-Driven Experimental Design for Accelerating Scientific Research", "abstract": "Designing and conducting experiments is a fundamental process across various scientific disciplines, such as materials science, biology, medicine, and chemistry. However, experimental research still predominantly relies on traditional, time-consuming, resource-intensive, and costly trial-and-error experimentation approaches that hinder rapid discovery, reproducibility, and scalability. Recent advances in artificial intelligence (AI) and machine learning (ML) offer promising alternatives, but a comprehensive overview of their implementations in experimental design is lacking. This research fills this gap by providing a structured overview and analysis of existing frameworks for AI-driven experimental design, supporting researchers in selecting and developing suitable AI-driven approaches to automate and accelerate their experimental research. Moreover, it discusses the current limitations and challenges of AI techniques and ethical issues related to AI-driven experimental design frameworks. A search and filter strategy is developed and applied to appropriate databases with the objective of identifying the relevant literature. Here, active learning, particularly Bayesian optimization, stands out as the predominantly used methodology. The majority of frameworks are partially autonomous, while fully autonomous frameworks are underrepresented. However, more research is needed in the field of AI-driven experimental design due to the low number of relevant papers obtained.", "authors": ["Lukas Nolte", "Sven Tomforde"], "year": 2025, "venue": "Applied Sciences", "cited_by_count": 3, "type": "article", "concepts": ["Engineering ethics", "Computer science", "Psychology", "Management science", "Engineering"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4385734352", "doi": "https://doi.org/10.18653/v1/2023.nlp4convai-1", "title": "Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)", "abstract": "Conversational AI has revolutionized the way we interact with technology, holding the potential to create positive impact on a variety of domains.In this talk, we present two studies that develops inclusive conversational AI techniques to empower users in different contexts for social impact.The first one looks at linguistic prejudice with a participatory design approach to develop dialect-inclusive language tools for low-resourced dialects in conversational question answering, together with efficient adaptation of models trained on Standard American English (SAE) to different dialects.The second work introduces CARE, an interactive conversational agent that supports peer counselors by generating personalized suggestions.CARE diagnoses suitable counseling strategies and provides tailored example responses during training, empowering counselors to respond effectively.These works showcase the potential of how inclusive language technologies can address language and communication barriers and foster positive impact.", "authors": ["General Chair", "Abhinav Rastogi", "Georgios Spithourakis", "Ex-Polyai", "Yun-Nung Chen", "Bing Liu", "Meta Diversity", "Publicity Chair", "Yu Li", "Elnaz Chair", "Nouri", "Alon Albalak", "Alexandros Papangelis", "Alexa Iii", "Meta Nouri", "Georgios Spithourakis, Ex-Polyai", "Entrepreneur First", "Barbara Arora", "Meta Kartikeya Badola", "Mukul Bhutani", "Alexandra Birch", "Yuan Cao", "Google Brain", "Guan-Lin Chao", "Microsoft Chen", "Nina Dethlefs", "Ashwinkumar Ganesan", "Alexa Ai", "Shubham Garg", "Christian Geishauser", "Heinrich Heine", "Alborz Geramifard", "Facebook Ai", "Liane Guillou", "Raghav Gupta", "Inc Google", "H Shachi", "Intel Kumar", "Dilek Labs", "Alexa Hakkani-Tur", "Michael Ai", "Heinrich Heck", "Heine", "David Howcroft", "Rishabh Joshi", "Mihir Kale", "Saarthak Google", "Seokhwan Khanna", "Alexa Kim", "Stefan Ai", "Larson", "Hsien-Chin Lin", "Heinrich University", "Liangchen Luo", "Wolfgang Google", "Mercedes-Benz Maier", "Sneha Ag", "Bloomberg Mehta", "Siddhesh Patel", "Pawar", "Baolin Google", "A Peng", "Wei Lab", "Huawei Peng", "Shiva Technologies", "Salesforce Pentyala", "Samrat Ai", "Phatale", "Lina Rojas Barahona", "Akshat Shrivastava", "Shubham Facebook", "Independent Shukla", "Kai Researcher", "Meta Sun", "Trinh Duong", "Stefan Ultes", "David Vandyke", "Nikolas Vitsakis", "Peidong Wang", "Peratham Wiriyathammabhum", "Chien-Sheng Wu", "Hongyuan Zhan", "Meta Ai", "Jianguo Zhang", "Salesforce Research", "Lukas Zilka", "Google", "Diyi Yang", "Larry Heck", "Vipul Raheja", "Nurul Lubis", "Jason Weston", "Seyed Mousavi", "Simone Caldarella", "Giuseppe Riccardi", "Lorenzo De Mattei", "Michele Cafagna", "Gabriel Roccabruna", "Michela Lorandi", "Lalchand Pandia"], "year": 2023, "venue": "", "cited_by_count": 4, "type": "paratext", "concepts": ["Computer science", "Natural language processing", "Artificial intelligence", "Linguistics", "Philosophy"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W2131244808", "doi": null, "title": "What Remains of Srebrenica? Motherhood, Transitional Justice and Yearning for the Truth", "abstract": "This article explores the role of the local non-governmental association 'Mothers of Srebrenica' in the complex transitional justice processes in Bosnia and Herzegovina. The association gathers women who survived the Srebrenica genocide in July 1995 and creates an important public space for the crying out of their grievances and lobbing for their goals. The 'Mothers of Srebrenica' also create a space for widows and displaced women to share their concerns and support each other. While the 'Mothers of Srebrenica' use the rhetoric of victimhood and motherhood whenever they speak out, I argue that they, in fact, challenge the notion of passive victims by the actions they have tirelessly undertaken over the last 13 years. With their resilience and activities, the 'Mothers of Srebrenica' have become known worldwide. Their existence and actions have generated a mixture of feelings: respect, regret and shame among not only those accountable for the crimes in Srebrenica, but also the wider international community. Yet, although 'Mothers of Srebrenica' use a variety of approaches to address past atrocities, it appears that their emphasis is on punitive justice which, they believe, is the only means to bring the peace that they have long yearned to their souls.", "authors": ["Olivera Simić"], "year": 2009, "venue": "Journal of international women's studies", "cited_by_count": 7, "type": "article", "concepts": ["Shame", "Economic Justice", "Genocide", "Transitional justice", "Criminology"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W2786175120", "doi": null, "title": "Practices of the wild: A rewilding of landscape architecture", "abstract": "The wild, in the discipline of landscape architecture, has been on the outer. What is it about the wild – despite the deep landscape-centric dimensions found in its forms, ecologies, meanings, and cultural attachments – that causes landscape architecture to find scant opportunity and appeal in it? This question is especially relevant, given the scale of the world's wilderness areas and their social and commercial value in terms of cultural identity, recreation and tourism, and what is now commonly referred to as ecosystem services. A more proactive and intentional practice of landscape is possible. Yet the question as to what behaviors provide the most benefit to both landscape and people, and then the design of the prompts that could enable such a dialogue, remains very much our \"landscopic\" frontier. For landscape architecture there is significant scope to expand its generative and creative relationship with landscape beyond the understanding of a landscape's system and the shaping of specific sites. Given landscape architecture's intimate knowledge of the value of landscape, and the ways it enables people and ecology to interact, there are opportunities to design behaviors, tools, technologies, devices, and strategies where endemic biodiversity and ecological resilience are nurtured. This \"new wild\" demands a design of landscape-centric behaviors in which landscape is produced rather than shaped. Investigating this can also open landscape architecture to the potential of designing innovative actions in other contexts: to foster activities, for example, founded in practices of carbon reduction, waste elimination, water use, mobility, and food production.", "authors": ["Michael R. Abbott"], "year": 2015, "venue": "Lincoln University Research Archive (Lincoln University)", "cited_by_count": 2, "type": "article", "concepts": ["Architecture", "Geography", "Archaeology"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4391037341", "doi": "https://doi.org/10.1017/beq.2023.33", "title": "Can Digitally Transformed Work Be Virtuous?", "abstract": "This essay inquires whether digitally transformed work can be virtuous and under what conditions. It eschews technological determinism in both utopian and dystopian versions, opting for the premise of free human agency. This work is distinctive in adopting an actor-centric and explicitly ethical analysis based on neo-Aristotelian, Catholic social teaching (CST), and MacIntyrean teachings on the virtues. Beginning with an analysis of digital disruption, it identifies the most salient human advantages vis-à-vis technology in digitally transformed work and provides philosophical anthropological explanations for each. It also looks into external, organizational characteristics on both the macro and the micro levels of digitally transformed work, underscoring their ambivalence (efficiency and profits vs. exclusion and exploitation, flexibility and freedom vs. standardization and dependency) and the need to mitigate their polarizing effects for the sake of shared flourishing. The article presents standards for virtuous work according to neo-Aristotelian, CST, and MacIntyrean frames and applies them to digitally transformed work, giving rise to five fundamental principles. These basic guidelines indicate, on one hand, actions to be avoided and, on the other, actions to be pursued, together with their rationales.", "authors": ["Alejo José G. Sisón"], "year": 2024, "venue": "Business Ethics Quarterly", "cited_by_count": 7, "type": "article", "concepts": ["Premise", "Epistemology", "Flourishing", "Determinism", "Technological determinism"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4413297572", "doi": "https://doi.org/10.3389/fclim.2025.1585331", "title": "Enhancing system resilience to climate change through artificial intelligence: a systematic literature review", "abstract": "The growing urgency of climate change necessitates innovative strategies to enhance system resilience across many sectors. Artificial Intelligence (AI) emerges as a transformative tool in this regard, yet existing research remains fragmented across sectors and regions. We conducted a systematic literature review of 385 peer-reviewed articles published between 2000 and early 2025, following the PRISMA protocol. The analysis classifies AI applications across nine key sectors and evaluates their relevance to adaptation, mitigation, or both. AI methodologies and regional distribution were also assessed. The findings show a dominant focus on adaptation (64.4%), with only 16% of studies addressing mitigation, and 19.4% engaging both. Classical Machine Learning techniques are the most used (51.4%), followed by deep learning models (22.3%). Regional disparities are evident: Asia and global-scale studies account for two-thirds of the literature, while Africa and South America are underrepresented. Sectorally, agriculture and urban infrastructure receive the most attention. Despite the promise of AI, major challenges persist in data access, model transparency, and equitable deployment, particularly in vulnerable regions. This review distinguishes itself by offering a comprehensive, cross-sectoral synthesis and emphasizing system-level resilience. It highlights the need for regionally tailored AI solutions, interdisciplinary collaboration, and ethical frameworks to ensure AI contributes meaningfully to global climate resilience efforts.", "authors": ["Rym Ayadi", "Yeganeh Forouheshfar", "Omid Moghadas"], "year": 2025, "venue": "Frontiers in Climate", "cited_by_count": 9, "type": "article", "concepts": ["Resilience (materials science)", "Climate change", "Environmental resource management", "Systematic review", "Psychology"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4395671822", "doi": "https://doi.org/10.2172/2340139", "title": "Advanced Research Directions on AI for Energy", "abstract": "This AI for Energy report further details grand challenges that provide significant opportunities for energy applications across nuclear energy, the power grid, carbon management, energy storage, and energy materials over the next decade. The main conclusions and opportunities from this study are available in the Key Findings section of this report.", "authors": ["Claus Daniel", "Jess C Gehin", "K.F. Laurin-Kovitz", "Bryan D. Morreale", "Rick Stevens", "William Tumas", "Mihai Anitescu", "Alec Poczatek", "Andrew Siegel", "Sibendu Som", "Richard Vilim", "Ray Grout", "Benjamin Kroposki", "Meng Yue", "Kelly Rose", "Ahmad Al Rashdan", "Christopher Ritter", "Prasanna Balaprakash", "Prashant Jain", "Teja Kuruganti", "Mary Ann Piette", "Tianzhen Hong", "Court Corley", "Robert Ralló", "John Grosh", "Brian Van Essen", "Marissa Reno", "Hari Viswanathan", "Frank Alexander", "Emily Dietrich"], "year": 2024, "venue": "", "cited_by_count": 3, "type": "report", "concepts": ["Renewable energy", "Environmental economics", "Capital cost", "Software deployment", "Efficient energy use"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4409381826", "doi": "https://doi.org/10.1609/aaai.v39i28.35377", "title": "AutoMV: An Autonomous Agent Framework for Real Estate Marketing Video Generation", "abstract": "In this paper, we introduce AutoMV, an autonomous agent framework designed for generating real estate marketing videos. The framework integrates a diverse set of existing models into a tool library, allowing the agent to intelligently select and execute the appropriate tools. Given property images and text, the agent decomposes the task into manageable subtasks, generating storyline directives and corresponding camera movement trajectories to guide the video production process. By automatically applying video synthesis techniques and incorporating multimedia elements such as subtitles and background music, the agent transforms static real estate images into dynamic, visually appealing videos, thereby optimizing their impact for digital marketing purposes.", "authors": ["Kai-Hua Wu", "Shaozu Yuan", "Chang Shen", "Xu Long", "Meng Chen"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 1, "type": "article", "concepts": ["Real estate", "Business", "Computer science", "Marketing", "Finance"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W3135953397", "doi": "https://doi.org/10.1155/2021/8890541", "title": "A New Neurorehabilitative Postsurgery Intervention for Facial Palsy Based on Smile Observation and Hand-Mouth Motor Synergies", "abstract": "A pre- and postsurgery longitudinal design was adopted to study the efficacy of FIT-SAT. Four patients with bilateral facial nerve paralysis (Moebius syndrome) were included. They underwent two surgeries with free muscle transfers, one year apart from each other. The side of the face first operated on was rehabilitated with the traditional treatment, while the second side was rehabilitated with FIT-SAT. The FIT-SAT treatment includes video clips of an actor performing a unilateral or a bilateral smile to be imitated (FIT condition). In addition to this, while smiling, the participants close their hand in order to exploit the overlapped cortical motor representation of the hand and the mouth, which may facilitate the synergistic activity of the two effectors during the early phases of recruitment of the transplanted muscles (SAT). The treatment was also aimed at avoiding undesired movements such as teeth grinding. <i>Discussion</i>. Results support FIT-SAT as a viable alternative for smile rehabilitation after free muscle transfer. We propose that the treatment potentiates the effect of smile observation by activating the same neural structures responsible for the execution of the smile and therefore by facilitating its production. Closing of the hand induces cortical recruitment of hand motor neurons, recruiting the transplanted muscles, and reducing the risk of associating other unwanted movements such as teeth clenching to the smile movements.", "authors": ["Elisa De Stefani", "Anna Barbot", "Chiara Bertolini", "Mauro Belluardo", "Gioacchino Garofalo", "Nicola Bruno", "Bernardo Bianchi", "Andrea Ferri", "Pier Francesco Ferrari"], "year": 2021, "venue": "Neural Plasticity", "cited_by_count": 6, "type": "article", "concepts": ["Palsy", "Medicine", "Facial muscles", "Facial paralysis", "Intervention (counseling)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W2470061013", "doi": "https://doi.org/10.36634/mimp4640", "title": "State of Green Infrastructure in the GCR", "abstract": "This State of Green Infrastructure report is both an assessment of the set of natural and manmade landscape features in the Gauteng City-Region (GCR) and an interrogation into how the services provided by these assets are perceived, understood and valued. Inspiration is drawn from the conceptual and planning framework of ‘green infrastructure’, through which ecological systems, green spaces and other landscape features are regarded as providing services to society in the same way as those offered by traditional ‘hard’ infrastructure.", "authors": ["Natasha Lantana", "Christopher, Natasha", "Bobbins, Kerry", "Otto, Emmarie", "Nhlozi, Mduduzi W", "de Wit, Martin", "van Zyl, Hugo", "Crookes, Douglas", "Gotz, Graeme", "Trangoš, Guy", "Wray, Chris", "Phasha, Potsiso"], "year": 2013, "venue": "Gauteng City-Region Observatory eBooks", "cited_by_count": 4, "type": "book", "concepts": ["State (computer science)", "Green infrastructure", "Business", "Environmental science", "Computer science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4390595494", "doi": "https://doi.org/10.36059/978-966-397-345-6", "title": "АКАДЕМІЧНА ДОБРОЧЕСНІСТЬ, ВІДКРИТА НАУКА ТА ШТУЧНИЙ ІНТЕЛЕКТ: ЯК СТВОРИТИ ДОБРОЧЕСНЕ ОСВІТНЄ СЕРЕДОВИЩЕ", "abstract": "Академічна доброчесність, відкрита наука та штучний інтелект: як створити доброчесне освітнє середовище : збірник есе програми підвищення кваліфікації / упорядники: А. Артюхов, М. Віхляєв, Ю. Волк. 18 вересня – 18 жовтня 2023 року. – Львів – Торунь : Liha-Pres, 2023. – 524 с.", "authors": ["А. С. Абдель Фатах", "Ага-заде Лейла Відаді-кизи", "М. О. Акімов", "В. І. Андріяш", "І. Г. Андрущенко", "Л. В. Анісімова", "І. В. Антоненко", "П. Б. Антоненко", "І. А. Анчева", "Г. О. Бабеня", "Н. О. Бережний", "З. В. Білоусова", "С. І. Богату", "А. М. Боднар", "О. Г. Боднарчук", "О. І. Боднарчук", "К. В. Бондаревська", "О. В. Бондар-Підгурська", "М. В. Босий", "М. С. Бричук", "Н. О. Бублієнко", "Н. М. Булатнікова", "М. А. Бурдоносова", "Т. М. Бусарова", "О. В. Вараксіна", "Г. Б. Варіна", "І. A. Vasylenko", "С. І. Василішин", "С. В. Василюк-Зайцева", "Н. М. Вдовенко", "І. М. Вегеш", "К. М. Вергелес", "Є. Ю. Верескун", "А. Є. Висоцька", "В. П. Власова", "В. М. Волошин", "О. В. Волошина", "В. О. Волошина-Нарожна", "У. Б. Воробель", "О. Б. Галицька", "А. В. Гарбінська-Руденко", "О. В. Гасій", "В. О. Гельмбольдт", "К. В. Гнедіна", "Т. Г. Головань", "І. В. Горб-Гаврильченко", "О. В. Гоц-Яковлєва", "Г. І. Гримашевич", "Ю. В. Грицевич", "Т. С. Гришечкіна", "А. Б. Грищук", "Н. В. Громова", "Н. В. Грона", "І. О. Данилова", "С. П. Дерев’янко", "А. К. Димовська", "Р. Ф. Димовський", "О. Л. Дишко", "Л. В. Діденко", "О. В. Длугопольський", "О. М. Домбровська", "О. В. Дорогін", "В. В. Дроздов", "І. С. Дружкова", "В. Г. Дутчак", "М. В. Дяків", "О. В. Дяків", "О. В. Євтушенко", "Р. С. Єделєв", "М. Д. Ждан", "Г. М. Завадських", "М. Ю. Задніпряна-Корінна", "О. В. Захарова", "Н. В. Зачосова", "С. І. Іванніков", "Н. В. Ільків", "М. А. Ільченко", "T. V. Ishchenko", "О. О. Кармаза", "А. С. Карпенко", "О. В. Карчевська", "М. В. Карчевський", "В. С. Касюра", "Р. С. Квасницька", "Т. Ю. Кісіль", "Р. Д. Клим", "К. Є. Княгницька", "Л. М. Князькова", "А. Ф. Коваленко", "О. О. Коваленко", "E. H. Kovach", "Л. О. Ковтун", "О. О. Ковтуненко", "І. А. Когут", "Г. В. Козаченко", "Н. С. Колесник", "М. О. Колесніков", "О. В. Коляса", "В. І. Корбутяк", "С. О. Корінний"], "year": 2023, "venue": "", "cited_by_count": 4, "type": "paratext", "concepts": ["Computer science", "Environmental science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4382139934", "doi": "https://doi.org/10.5194/isprs-archives-xlviii-m-2-2023-1387-2023", "title": "CULTURAL HERITAGE AND RISK: LET'S <i>GIVE INTELLIGENCE</i> TO OUR TECHNOLOGIES", "abstract": "Abstract. In the last decades, the evolution in the sector of technologies applied to cultural heritage has taken on extraordinary accelerations in terms of accuracy and reliability of the measurement and restitution, as well as in the management of acquired data. In particular, the complex of these measurement and documentation actions are of fundamental importance if interfaced with other types of heterogeneous data acquired in different ways. Nevertheless, in face of such a complex framework of know- how, increasingly advanced technologies, dedicated programs and funding, meetings and debates, the establishment of specific Institutional Bodies to manage decision-making plans and their implementation, we continue to witness the frantic chasing of emergencies after the occurrence of catastrophic events. The spectrum of risks is more and more manifesting itself in its breadth: to the evidence of the effects due to Climate Change, those deriving from hydrogeological instability, from the lack of care of the territory and coasts, the devastation of an anthropic nature due to the senseless consumption of soil, and the unsustainable pressure of an uncultured, omnivorous tourism, are added with increasing frequency. This contribution deals in a general way with the theme of technologies for the knowledge of Cultural Heritage. It intends to critically question about the dangers inherent in the \"indiscriminate, unconscious and uncritical\" use of technologies for the knowledge of Cultural Heritage oriented towards its preservation. The aim is to prompt a discussion within the scientific community dealing with the documentation and conservation of cultural heritage in order to promote an indispensable culture of prevention and planned conservation, in which the intelligent relationship between Man and technology must be rediscovered.", "authors": ["Paolo Salonia"], "year": 2023, "venue": "The international archives of the photogrammetry, remote sensing and spatial information sciences/International archives of the photogrammetry, remote sensing and spatial information sciences", "cited_by_count": 2, "type": "article", "concepts": ["Witness", "Environmental ethics", "Cultural heritage", "Documentation", "Industrial heritage"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4406247592", "doi": "https://doi.org/10.3390/computers14010021", "title": "Impact of Chatbots on User Experience and Data Quality on Citizen Science Platforms", "abstract": "Citizen science (CS) projects, which engage the general public in scientific research, often face challenges in ensuring high-quality data collection and maintaining user engagement. Recent advancements in Large Language Models (LLMs) present a promising solution by providing automated, real-time assistance to users, reducing the need for extensive human intervention, and offering instant support. The CS project Les Herbonautes, dedicated to mass digitization of the French National Herbarium, serves as a case study for this paper, which details the development and evaluation of a network of open source LLM agents to assist users during data collection. The research involved the review of related work, stakeholder meetings with the Muséum National d’Histoire Naturelle, and user and context analyses to formalize system requirements. With these, a prototype with a user interface in the form of a chatbot was designed and implemented using LangGraph, and afterward evaluated through expert evaluation to assess its effect on usability and user experience (UX). The findings indicate that such a chatbot can enhance UX and improve data quality by guiding users and providing immediate feedback. However, limitations due to the non-deterministic nature of LLMs exist, suggesting that workflows must be carefully designed to mitigate potential errors and ensure reliable performance.", "authors": ["Anthony Kessel", "Soror Sahri", "Sven Groppe", "Jinghua Groppe", "Hanieh Khorashadizadeh", "Marc Pignal", "Eva Perez Pimparé", "Régine Vignes‐Lebbe"], "year": 2025, "venue": "Computers", "cited_by_count": 1, "type": "article", "concepts": ["Workflow", "Chatbot", "Usability", "Computer science", "Citizen science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W2943741607", "doi": "https://doi.org/10.7764/rda.0.2.121", "title": "Adaptive Management and its Potential to Protect Biodiversity in Chile", "abstract": "Adaptive management is a useful tool to improve resource management decisions in the face of uncertainty. An active concept of adaptive management privileges the use of controlled experimentation with management practices, to obtain valuable information that may improve management through feedback loops. This notion defies the slow-changing mechanisms of Environmental Law. In the context of an ongoing discussion within the Chilean Congress about a new agency oriented towards biodiversity conservation and recovery, this article explores the advantages and risks of introducing adaptive management as a tool that may improve knowledge about endangered species and optimize management practices.", "authors": ["Gonzalo Andrés Parot Hillmer"], "year": 2018, "venue": "Revista de Derecho Aplicado LLM UC", "cited_by_count": 1, "type": "article", "concepts": ["Adaptive management", "Endangered species", "Context (archaeology)", "Agency (philosophy)", "Environmental resource management"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4385571062", "doi": "https://doi.org/10.18653/v1/2023.acl-long.727", "title": "Exploring and Verbalizing Academic Ideas by Concept Co-occurrence", "abstract": "Researchers usually come up with new ideas only after thoroughly comprehending vast quantities of literature. The difficulty of this procedure is exacerbated by the fact that the number of academic publications is growing exponentially. In this study, we devise a framework based on concept co-occurrence for academic idea inspiration, which has been integrated into a research assistant system. From our perspective, the emergence of a new idea can be regarded as the fusion of two concepts that co-occur in an academic paper. We construct evolving concept graphs according to the co-occurrence relationship of concepts from 20 disciplines or topics. Then we design a temporal link prediction method based on masked language model to explore potential connections between different concepts. To verbalize the newly discovered connections, we also utilize the pretrained language model to generate a description of an idea based on a new data structure called co-occurrence citation quintuple. We evaluate our proposed system using both automatic metrics and human assessment. The results demonstrate that our system has broad prospects and can assist researchers in expediting the process of discovering new ideas.", "authors": ["Yi Xu", "Shuqian Sheng", "Bo Xue", "Luoyi Fu", "Xinbing Wang", "Chenghu Zhou"], "year": 2023, "venue": "", "cited_by_count": 5, "type": "article", "concepts": ["Expediting", "Computer science", "Construct (python library)", "Perspective (graphical)", "Process (computing)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4409587791", "doi": "https://doi.org/10.36227/techrxiv.174494994.46313754/v1", "title": "Unifying Modern AI with Robotics: Survey on MDPs with Diffusion and Foundation Models", "abstract": "Recent advances in artificial intelligence, particularly in foundation models and diffusion techniques, have created new opportunities for enhancing robotic systems. This survey provides a comprehensive review of the integration of foundation models and diffusion techniques with Markov Decision Processes (MDPs) in robotics. We examine how these advanced AI models address key challenges in robotics, including operation in diverse environments, long-term task execution, and the need for high precision and efficiency. The survey first discusses three main applications of diffusion models in robotics: trajectory generation, policy representation, and data augmentation for offline reinforcement learning. We analyze how various foundation models-including large language models (LLMs), Video-Language models (Vid-LLMs), Visual-Language models (VLMs), and large vision models (LVMs)-are being combined with MDP-based methods such as reinforcement learning and Monte Carlo tree search to enhance robotic capabilities. Our review categorizes and consolidates common requirements and challenges across various robotic tasks from multiple dimensions, offering a layered analysis of the technologies involved. We also analyze how these methods improve decisionmaking capabilities, overall performance, and training efficiency in robotic systems. Finally, we provide insights into potential issues and future directions for using foundation models and diffusion techniques with MDP-based approaches in robotics, aiming to guide future research in this rapidly evolving field. We have created a project associated with this survey, which is available at https://github.com/FANnn100/Awesome-Survey-on-Foundation-Models-for-RL-Robotics.", "authors": ["Zhaofan Zhang", "Rufeng Chen", "Zhejian Yang", "Sihong Xie", "Hechang Chen", "Hui Xiong"], "year": 2025, "venue": "", "cited_by_count": 1, "type": "preprint", "concepts": ["Foundation (evidence)", "Robotics", "Artificial intelligence", "Computer science", "Cognitive science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4386555488", "doi": "https://doi.org/10.48550/arxiv.2309.03895", "title": "InstructDiffusion: A Generalist Modeling Interface for Vision Tasks", "abstract": "We present InstructDiffusion, a unifying and generic framework for aligning computer vision tasks with human instructions. Unlike existing approaches that integrate prior knowledge and pre-define the output space (e.g., categories and coordinates) for each vision task, we cast diverse vision tasks into a human-intuitive image-manipulating process whose output space is a flexible and interactive pixel space. Concretely, the model is built upon the diffusion process and is trained to predict pixels according to user instructions, such as encircling the man's left shoulder in red or applying a blue mask to the left car. InstructDiffusion could handle a variety of vision tasks, including understanding tasks (such as segmentation and keypoint detection) and generative tasks (such as editing and enhancement). It even exhibits the ability to handle unseen tasks and outperforms prior methods on novel datasets. This represents a significant step towards a generalist modeling interface for vision tasks, advancing artificial general intelligence in the field of computer vision.", "authors": ["Zigang Geng", "Binxin Yang", "Tiankai Hang", "Chen Li", "Shuyang Gu", "Ting Zhang", "Jianmin Bao", "Zheng Zhang", "Hu Han", "Dong Chen", "Baining Guo"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 5, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Task (project management)", "Interface (matter)", "Process (computing)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4399328352", "doi": "https://doi.org/10.62608/2831-3550.1023", "title": "Visionarium, June 2024, Full Issue", "abstract": "addresses the intricate dynamics of Human-AI Symbiosis in higher education.This edition focuses on the ethical, skill-based, and philosophical implications of Generative Artificial Intelligence as it integrates with human capabilities within educational frameworks.The issue draws on Dov Seidman's philosophy that \"how we do things matters more than what we do,\" therefore, the manner in which we accomplish activities is of greater significance than the activities themselves.The articles within this issue do not merely speculate on the potential of AI in education; they provide a deep dive into the necessary ethical frameworks, underscore the irreplaceable value of human skills, and consider the philosophical challenges posed by this technological integration.Articles in this issue explore various themes, emphasizing the critical nature of human skills such as empathy, ethical judgment, and nuanced understanding, which are deemed indispensable even in an AI-driven educational landscape.Furthermore, the issue examines the concept of 'Fearing the Other', analyzing how AI might either perpetuate or alleviate deeply ingrained biases and fears within educational environments.Insights on the potential uses of AI to develop human and power skills like creativity, leadership, and teamwork are also discussed, highlighting their importance in the rapidly evolving educational sector.This issue presents a range of interdisciplinary perspectives, shedding light on AI's diverse impacts across different academic disciplines.It challenges existing paradigms and encourages a reevaluation of the boundaries between human creativity and algorithmic precision.Readers are invited to critically engage with the content, reflecting on the broader implications for the future of education in an AI-enhanced world.The academic community is encouraged to navigate this new terrain with knowledge, guided by ethical considerations, and inspired by the boundless possibilities of collaboration between human and artificial intelligence.In synthesizing these diverse perspectives, the issue aims to contribute to the academic discourse and impact practical AI implementations in educational settings globally.As we move forward, the insights from this issue should inform ongoing dialogues and initiatives, ensuring AI enhances educational outcomes while preserving the essential human interactions that underpin effective learning environments.The commitment to continuous inquiry and ethical consideration is pivotal as we collectively explore the future of education in an AI-augmented reality.This journey promises to transform educational landscapes while adhering to the values that define our humanity.The first paper by Col. Mayer in this special issue addresses the critical need for higher education institutions to maintain a balance between cultivating human skills and enhancing AI literacy.Amidst a landscape increasingly influenced by artificial intelligence, the emphasis remains on the continuing importance of human skills such as creativity, critical thinking, and 1 et al.", "authors": ["James Hutson", "Chris Mayer", "Kathi Vosevich", "Jason Lively", "Piper Hutson", "Jason Ceballos", "Tavsimran Luthra", "Lucia Garces-Torres", "Valerie Lentz", "Jack L. Nelson", "Claudia Carceles-Roman", "Ian Holyoak", "Jane Harrington", "Andrew Begemann", "A Carnevale", "N Smith", "M Van Der Werf", "M Quinn", "M Dondi", "J Klier", "F Panier", "J Schubert", "K Ellingrud", "S Sanghvi", "G Dandona", "A Madgavkar", "M Chui", "O White", "P Hasebe", "K Lakhani", "Linkedin", "L Lo", "M Minevich", "M Sigelman", "B Taska", "L O'kane", "J Nitschke", "R Strack", "J Baier", "F Breitling", "A Kotsis", "R Vischer", "A Babaniyazovich", "S Berretta", "A Tausch", "C Peifer", "A Kluge", "H Blum", "M Campbell", "T Chakrabarty", "P Laban", "D Agarwal", "S Muresan", "C Wu", "G Evans", "H Felperin", "F Fui-Hoon Nah", "R Zheng", "J Cai", "K Siau", "L Chen", "A Greer", "K Inkpen", "S Chappidi", "K Mallari", "B Nushi", "D Ramesh", "P Michelucci", ". Quinn", "G", "D Jardine", "J Batycky", "A Jones", "P Stallybrass", "H Khogali", "S Mekid", "N Mellamphy", "I Mondal", "S Shwetha", "A Natarajan", "A Garimella", "S Bandyopadhyay", "J Boyd-Graber", "A Obaigbena", "O Lottu", "E Ugwuanyi"], "year": 2024, "venue": "International Journal of Emerging and Disruptive Innovation in Education VISIONARIUM", "cited_by_count": 1, "type": "article", "concepts": ["Computer science"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4406041704", "doi": "https://doi.org/10.3389/fnbot.2024.1517960", "title": "Architectural planning robot driven by unsupervised learning for space optimization", "abstract": "The results show significant improvements in layout efficiency and processing time compared to traditional methods, indicating the potential for real-world applications in automated architectural planning and dynamic space management. This work contributes to the field by providing a scalable solution for architectural space optimization that adapts to diverse spatial requirements through unsupervised learning.", "authors": ["Zhe Zhang", "Yang Zheng"], "year": 2025, "venue": "Frontiers in Neurorobotics", "cited_by_count": 1, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Unsupervised learning", "Robot", "Space (punctuation)"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4410841389", "doi": "https://doi.org/10.5815/ijcnis.2025.03.07", "title": "Development and Testing of Voice User Interfaces Based on BERT Models for Speech Recognition in Distance Learning and Smart Home Systems", "abstract": "Voice User Interfaces (VUIs) focus on their application in IT and linguistics. Our research examines the capabilities and limitations of small and multilingual BERT models in the context of speech recognition and command conversion. We evaluate the performance of these models through a series of experiments, including the application of confusion matrices to assess their effectiveness. The findings reveal that larger models like multilingual BERT theoretically offer advanced capabilities but often demand more substantial resources and well-balanced datasets. Conversely, smaller models, though less resource-intensive, may sometimes provide more practical solutions. Our study underscores the importance of dataset quality, model fine-tuning, and efficient resource management in optimising VUIS. Insights gained from this research highlight the potential of neural networks to enhance and improve user interaction. Despite challenges in achieving a fully functional interface, the study provides valuable contributions to the VUIs development and sets the stage for future advancements in integrating AI with linguistic technologies. The article describes the development of a voice user interface (VUI) capable of recognising, analysing, and interpreting the Ukrainian language. For this purpose, several neural network architectures were used, including the Squeezeformer-CTC model, as well as a modified w2v-bert-2.0-uk model, which was used to decode speech commands into text. The multilingual BERT model (mBERT) for the classification of intentions was also tested. The developed system showed the prospects of using BERT models in combination with lightweight ASR architectures to create an effective voice interface in Ukrainian. Accuracy indicators (F1 = 91.5%, WER = 12.7%) indicate high-quality recognition, which is provided even in models with low memory capacity. The system is adaptable to conditions with limited resources, particularly for educational and living environments with a Ukrainian-speaking audience.", "authors": ["Victoria Vysotska", "Zhengbing Hu", "Nikita Mykytyn", "Olena Nagachevska", "Kateryna Hazdiuk", "Dmytro Uhryn"], "year": 2025, "venue": "International Journal of Computer Network and Information Security", "cited_by_count": 1, "type": "article", "concepts": ["Computer science", "Speech recognition", "Human–computer interaction", "Home automation", "Speech technology"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4394834294", "doi": "https://doi.org/10.1007/978-3-658-43705-3", "title": "First Working Conference on Artificial Intelligence Development for a Resilient and Sustainable Tomorrow", "abstract": "In the contemporary debate, surrounding the future of work and life, Artificial Intelligence (AI), resilience, and sustainability have emerged as pivotal concepts.Within the industrial realm, their collective convergence is driving unprecedented transformative shifts, challenging traditional paradigms.This positioning paper delves into the intricate interlinkages binding these three paradigms.Examples such as AI-driven automation, enhancing efficiency, and predictive maintenance, reducing machinery downtime, underscore the transformative role of AI in the industry.Meanwhile, an increasing emphasis on environmental responsibility highlights the growing importance of sustainability in the industrial sector.Resilience, embodied through the ability to withstand crises and maintain strong supply chains, is equally essential.The article also delves deep into the specific relations between AI, sustainability and resilience.By weaving these concepts together, the paper aims to provide a holistic perspective on the interconnectedness, emphasizing the need for a balanced approach in the modern industry to ensure not only technological advancement but also a resilient and sustainable future.", "authors": ["Working Conference on Artificial Intelligence Development for a Resilient and Sustainable Tomorrow 2023 Leipzig", "Zinke-Wehlmann, Christian 1983-", "Friedrich, Julia"], "year": 2024, "venue": "Informatik aktuell", "cited_by_count": 3, "type": "book", "concepts": ["Sustainable development", "Engineering ethics", "Engineering", "Political science", "Law"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4390016249", "doi": "https://doi.org/10.36740/wlek202311107", "title": "A STUDY OF THE INFLUENCE OF JUVENILE ADJUVANT ARTHRITIS ON DENTAL HARD TISSUES CONDITION IN EXPERIMENTAL ANIMALS", "abstract": "Conclusions: It has been established that adjuvant arthritis is accompanied by 100% prevalence of dental caries, high intensity of carious process, presence of middle and deep carious cavities, that confirm the negative influence of autoimmune disease on the condition of the hard tooth tissues.", "authors": ["V. M. Kulygina", "Olha Yu. Pylypiuk", "Iurii V. Turchyn", "Н. Г. Гаджула", "Mariia M. Shinkaruk-Dykovytska", "А. В. Повшенюк", "L.O. Kovalchuk"], "year": 2023, "venue": "Wiadomości Lekarskie", "cited_by_count": 1, "type": "article", "concepts": ["Juvenile", "Arthritis", "Dentistry", "Adjuvant", "Medicine"], "search_query": "agent image restoration LLM tool planning"}
{"openalex_id": "https://openalex.org/W4393154152", "doi": "https://doi.org/10.1609/aaai.v38i7.28597", "title": "NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models", "abstract": "Trained with an unprecedented scale of data, large language models (LLMs) like ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities from model scaling. Such a trend underscored the potential of training LLMs with unlimited language data, advancing the development of a universal embodied agent. In this work, we introduce the NavGPT, a purely LLM-based instruction-following navigation agent, to reveal the reasoning capability of GPT models in complex embodied scenes by performing zero-shot sequential action prediction for vision-and-language navigation (VLN). At each step, NavGPT takes the textual descriptions of visual observations, navigation history, and future explorable directions as inputs to reason the agent's current status, and makes the decision to approach the target. Through comprehensive experiments, we demonstrate NavGPT can explicitly perform high-level planning for navigation, including decomposing instruction into sub-goals, integrating commonsense knowledge relevant to navigation task resolution, identifying landmarks from observed scenes, tracking navigation progress, and adapting to exceptions with plan adjustment. Furthermore, we show that LLMs is capable of generating high-quality navigational instructions from observations and actions along a path, as well as drawing accurate top-down metric trajectory given the agent's navigation history. Despite the performance of using NavGPT to zero-shot R2R tasks still falling short of trained models, we suggest adapting multi-modality inputs for LLMs to use as visual navigation agents and applying the explicit reasoning of LLMs to benefit learning-based models. Code is available at: https://github.com/GengzeZhou/NavGPT.", "authors": ["Gengze Zhou", "Yicong Hong", "Qi Wu"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 111, "type": "article", "concepts": ["Computer science", "Linguistics", "Cognitive science", "Artificial intelligence", "Psychology"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2026616100", "doi": "https://doi.org/10.1016/j.mri.2012.05.001", "title": "3D Slicer as an image computing platform for the Quantitative Imaging Network", "abstract": "", "authors": ["Andriy Fedorov", "Reinhard Beichel", "Jayashree Kalpathy–Cramer", "Julien Finet", "Jean‐Christophe Fillion‐Robin", "Sonia Pujol", "Christian Bauer", "Dominique Jennings", "Fiona Fennessy", "Milan Sonka", "John M. Buatti", "Stephen Aylward", "James V. Miller", "Steve Pieper", "Ron Kikinis"], "year": 2012, "venue": "Magnetic Resonance Imaging", "cited_by_count": 8392, "type": "article", "concepts": ["Computer science", "Visualization", "Workstation", "Software", "Context (archaeology)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4378465306", "doi": "https://doi.org/10.48550/arxiv.2305.15021", "title": "EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought", "abstract": "Embodied AI is a crucial frontier in robotics, capable of planning and executing action sequences for robots to accomplish long-horizon tasks in physical environments. In this work, we introduce EmbodiedGPT, an end-to-end multi-modal foundation model for embodied AI, empowering embodied agents with multi-modal understanding and execution capabilities. To achieve this, we have made the following efforts: (i) We craft a large-scale embodied planning dataset, termed EgoCOT. The dataset consists of carefully selected videos from the Ego4D dataset, along with corresponding high-quality language instructions. Specifically, we generate a sequence of sub-goals with the \"Chain of Thoughts\" mode for effective embodied planning. (ii) We introduce an efficient training approach to EmbodiedGPT for high-quality plan generation, by adapting a 7B large language model (LLM) to the EgoCOT dataset via prefix tuning. (iii) We introduce a paradigm for extracting task-related features from LLM-generated planning queries to form a closed loop between high-level planning and low-level control. Extensive experiments show the effectiveness of EmbodiedGPT on embodied tasks, including embodied planning, embodied control, visual captioning, and visual question answering. Notably, EmbodiedGPT significantly enhances the success rate of the embodied control task by extracting more effective features. It has achieved a remarkable 1.6 times increase in success rate on the Franka Kitchen benchmark and a 1.3 times increase on the Meta-World benchmark, compared to the BLIP-2 baseline fine-tuned with the Ego4D dataset.", "authors": ["Yao Mu", "Qinglong Zhang", "Mengkang Hu", "Wenhai Wang", "Mingyu Ding", "Jun Jin", "Bin Wang", "Jifeng Dai", "Yu Qiao", "Ping Luo"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 41, "type": "preprint", "concepts": ["Embodied cognition", "Computer science", "Task (project management)", "Artificial intelligence", "Benchmark (surveying)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3140854437", "doi": "https://doi.org/10.1186/s40537-021-00444-8", "title": "Review of deep learning: concepts, CNN architectures, challenges, applications, future directions", "abstract": "", "authors": ["Laith Alzubaidi", "Jinglan Zhang", "Amjad J. Humaidi", "Ayad Q. Al-Dujaili", "Ye Duan", "Omran Al-Shamma", "José Santamaría", "Mohammed A. Fadhel", "Muthana Al‐Amidie", "Laith Farhan"], "year": 2021, "venue": "Journal Of Big Data", "cited_by_count": 7030, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Field (mathematics)", "Deep learning", "Convolutional neural network"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3123893780", "doi": "https://doi.org/10.1136/bmj.n160", "title": "PRISMA 2020 explanation and elaboration: updated guidance and exemplars for reporting systematic reviews", "abstract": "The PRISMA 2020 statement includes a checklist of 27 items to guide reporting of systematic reviews In this article we explain why reporting of each item is recommended, present bullet points that detail the reporting recommendations, and present examples from published reviews We hope that uptake of the PRISMA 2020 statement will lead to more transparent, complete, and accurate reporting of systematic reviews, thus facilitating evidence based decision making on 1 September", "authors": ["Matthew J. Page", "David Moher", "Patrick M. Bossuyt", "Isabelle Boutron", "Tammy Hoffmann", "Cynthia D. Mulrow", "Larissa Shamseer", "Jennifer Tetzlaff", "Elie A. Akl", "Sue Brennan", "Roger Chou", "Julie Glanville", "Jeremy Grimshaw", "Asbjørn Hróbjartsson", "Manoj M. Lalu", "Tianjing Li", "Elizabeth Loder", "Evan Mayo‐Wilson", "Steve McDonald", "Luke A. McGuinness", "Lesley Stewart", "James Thomas", "Andrea C. Tricco", "Vivian Welch", "Penny Whiting", "Joanne E. McKenzie"], "year": 2021, "venue": "BMJ", "cited_by_count": 10008, "type": "article", "concepts": ["Systematic review", "Terminology", "Guideline", "Computer science", "MEDLINE"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2153791616", "doi": "https://doi.org/10.1017/s0140525x12000477", "title": "Whatever next? Predictive brains, situated agents, and the future of cognitive science", "abstract": "Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this \"hierarchical prediction machine\" approach, concluding that it offers the best clue yet to the shape of a unified science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.", "authors": ["Andy Clark"], "year": 2013, "venue": "Behavioral and Brain Sciences", "cited_by_count": 5620, "type": "review", "concepts": ["Situated", "Cognitive science", "Cognition", "Psychology", "Computer science"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4404371576", "doi": "https://doi.org/10.1109/tvcg.2024.3496112", "title": "LightVA: Lightweight Visual Analytics With LLM Agent-Based Task Planning and Execution", "abstract": "Visual analytics (VA) requires analysts to iteratively propose analysis tasks based on observations and execute tasks by creating visualizations and interactive exploration to gain insights. This process demands skills in programming, data processing, and visualization tools, highlighting the need for a more intelligent, streamlined VA approach. Large language models (LLMs) have recently been developed as agents to handle various tasks with dynamic planning and tool-using capabilities, offering the potential to enhance the efficiency and versatility of VA. We propose LightVA, a lightweight VA framework that supports task decomposition, data analysis, and interactive exploration through human-agent collaboration. Our method is designed to help users progressively translate high-level analytical goals into low-level tasks, producing visualizations and deriving insights. Specifically, we introduce an LLM agent-based task planning and execution strategy, employing a recursive process involving a planner, executor, and controller. The planner is responsible for recommending and decomposing tasks, the executor handles task execution, including data analysis, visualization generation and multi-view composition, and the controller coordinates the interaction between the planner and executor. Building on the framework, we develop a system with a hybrid user interface that includes a task flow diagram for monitoring and managing the task planning process, a visualization panel for interactive data exploration, and a chat view for guiding the model through natural language instructions. We examine the effectiveness of our method through a usage scenario and an expert study.", "authors": ["Yuheng Zhao", "Junjie Wang", "Luo Xiang", "Xiaowen Zhang", "Zifei Guo", "Çağatay Turkay", "Yu Zhang", "Siming Chen"], "year": 2024, "venue": "IEEE Transactions on Visualization and Computer Graphics", "cited_by_count": 19, "type": "article", "concepts": ["Computer science", "Visual analytics", "Interactive visual analysis", "Task (project management)", "Analytics"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3135028703", "doi": "https://doi.org/10.1007/s42979-021-00592-x", "title": "Machine Learning: Algorithms, Real-World Applications and Research Directions", "abstract": "", "authors": ["Iqbal H. Sarker"], "year": 2021, "venue": "SN Computer Science", "cited_by_count": 4729, "type": "review", "concepts": ["Computer science", "Artificial intelligence", "Machine learning", "Key (lock)", "Big data"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W1641498739", "doi": "https://doi.org/10.1109/tmi.2014.2377694", "title": "The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)", "abstract": "In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low- and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.", "authors": ["Bjoern Menze", "András Jakab", "Stefan Bauer", "Jayashree Kalpathy–Cramer", "Keyvan Farahani", "Justin Kirby", "Yuliya Burren", "Nicole Porz", "Johannes Slotboom", "Roland Wiest", "Levente Lánczi", "Elizabeth R. Gerstner", "Marc‐An﻿dré Weber", "Tal Arbel", "Brian Avants", "Nicholas Ayache", "Patricia Buendia", "D. Louis Collins", "Nicolas Cordier", "Jason J. Corso", "Antonio Criminisi", "Tilak Das", "Hervé Delingette", "Çağatay Demiralp", "Christopher R. Durst", "Michel Dojat", "Senan Doyle", "Joana Festa", "Florence Forbes", "Ezequiel Geremia", "Ben Glocker", "Polina Golland", "Xiaotao Guo", "Andaç Hamamcı", "Khan M. Iftekharuddin", "R. Jena", "Nigel John", "Ender Konukoğlu", "Danial Lashkari", "José Mariz", "Raphael Meier", "Sérgio Pereira", "Doina Precup", "Stephen J. Price", "Tammy Riklin Raviv", "Syed M. S. Reza", "Michael J. Ryan", "Duygu Sarıkaya", "Lawrence H. Schwartz", "Hoo-Chang Shin", "Jamie Shotton", "Carlos A. Silva", "Nuno Sousa", "Nagesh K. Subbanna", "Gábor Székely", "Thomas J. Taylor", "Owen Thomas", "Nicholas J. Tustison", "Gözde Ünal", "Flor Vasseur", "Max Wintermark", "Dong Hye Ye", "Liang Zhao", "Binsheng Zhao", "Darko Zikic", "Marcel Prastawa", "Mauricio Reyes", "Koen Van Leemput"], "year": 2014, "venue": "IEEE Transactions on Medical Imaging", "cited_by_count": 6187, "type": "review", "concepts": ["Artificial intelligence", "Image segmentation", "Benchmark (surveying)", "Computer science", "Computer vision"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2099019320", "doi": "https://doi.org/10.1016/s0921-8890(02)00372-x", "title": "A survey of socially interactive robots", "abstract": "", "authors": ["Terrence Fong", "Illah Nourbakhsh", "Kerstin Dautenhahn"], "year": 2003, "venue": "Robotics and Autonomous Systems", "cited_by_count": 3060, "type": "article", "concepts": ["Robot", "Computer science", "Human–computer interaction", "Robotics", "Taxonomy (biology)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4383604274", "doi": "https://doi.org/10.48550/arxiv.2307.01848", "title": "Embodied Task Planning with Large Language Models", "abstract": "Equipping embodied agents with commonsense is important for robots to successfully complete complex human instructions in general environments. Recent large language models (LLM) can embed rich semantic knowledge for agents in plan generation of complex tasks, while they lack the information about the realistic world and usually yield infeasible action sequences. In this paper, we propose a TAsk Planing Agent (TaPA) in embodied tasks for grounded planning with physical scene constraint, where the agent generates executable plans according to the existed objects in the scene by aligning LLMs with the visual perception models. Specifically, we first construct a multimodal dataset containing triplets of indoor scenes, instructions and action plans, where we provide the designed prompts and the list of existing objects in the scene for GPT-3.5 to generate a large number of instructions and corresponding planned actions. The generated data is leveraged for grounded plan tuning of pre-trained LLMs. During inference, we discover the objects in the scene by extending open-vocabulary object detectors to multi-view RGB images collected in different achievable locations. Experimental results show that the generated plan from our TaPA framework can achieve higher success rate than LLaVA and GPT-3.5 by a sizable margin, which indicates the practicality of embodied task planning in general and complex environments.", "authors": ["Zhenyu Wu", "Ziwei Wang", "Xiuwei Xu", "Jiwen Lu", "Haibin Yan"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 18, "type": "preprint", "concepts": ["Computer science", "Embodied cognition", "Task (project management)", "Artificial intelligence", "Executable"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2128677857", "doi": "https://doi.org/10.1145/174666.174668", "title": "The interdisciplinary study of coordination", "abstract": "This survey characterizes an emerging research area, sometimes called coordination theory , that focuses on the interdisciplinary study of coordination. Research in this area uses and extends ideas about coordination from disciplines such as computer science, organization theory, operations research, economics, linguistics, and psychology. A key insight of the framework presented here is that coordination can be seen as the process of managing dependencies among activities. Further progress, therefore, should be possible by characterizing different kinds of dependencies and identifying the coordination processes that can be used to manage them. A variety of processes are analyzed from this perspective, and commonalities across disciplines are identified. Processes analyzed include those for managing shared resources, producer/consumer relationships, simultaneity constraints , and task/subtask dependencies . Section 3 summarizes ways of applying a coordination perspective in three different domains:(1) understanding the effects of information technology on human organizations and markets, (2) designing cooperative work tools, and (3) designing distributed and parallel computer systems. In the final section, elements of a research agenda in this new area are briefly outlined.", "authors": ["Thomas W. Malone", "Kevin Crowston"], "year": 1994, "venue": "ACM Computing Surveys", "cited_by_count": 3393, "type": "review", "concepts": ["Computer science", "Perspective (graphical)", "Process (computing)", "Key (lock)", "Variety (cybernetics)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3185341429", "doi": "https://doi.org/10.1145/3560815", "title": "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing", "abstract": "This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P ( y|x ), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂ , from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting to new scenarios with few or no labeled data. In this article, we introduce the basics of this promising paradigm, describe a unified set of mathematical notations that can cover a wide variety of existing work, and organize existing work along several dimensions, e.g., the choice of pre-trained language models, prompts, and tuning strategies. To make the field more accessible to interested beginners, we not only make a systematic review of existing works and a highly structured typology of prompt-based concepts but also release other resources, e.g., a website NLPedia–Pretrain including constantly updated survey and paperlist.", "authors": ["Pengfei Liu", "Weizhe Yuan", "Jinlan Fu", "Zhengbao Jiang", "Hiroaki Hayashi", "Graham Neubig"], "year": 2022, "venue": "ACM Computing Surveys", "cited_by_count": 3365, "type": "review", "concepts": ["Computer science", "Variety (cybernetics)", "Set (abstract data type)", "Notation", "Cover (algebra)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2032568497", "doi": "https://doi.org/10.1007/s12369-008-0001-3", "title": "Measurement Instruments for the Anthropomorphism, Animacy, Likeability, Perceived Intelligence, and Perceived Safety of Robots", "abstract": "This study emphasizes the need for standardized measurement tools for human robot interaction (HRI). If we are to make progress in this field then we must be able to compare the results from different studies. A literature review has been performed on the measurements of five key concepts in HRI: anthropomorphism, animacy, likeability, perceived intelligence, and perceived safety. The results have been distilled into five consistent questionnaires using semantic differential scales. We report reliability and validity indicators based on several empirical studies that used these questionnaires. It is our hope that these questionnaires can be used by robot developers to monitor their progress. Psychologists are invited to further develop the questionnaires by adding new concepts, and to conduct further validations where it appears necessary.", "authors": ["Christoph Bartneck", "Dana Kulić", "Elizabeth A. Croft", "Susana Zoghbi"], "year": 2008, "venue": "International Journal of Social Robotics", "cited_by_count": 2900, "type": "article", "concepts": ["Animacy", "Psychology", "Reliability (semiconductor)", "Applied psychology", "Robot"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W1972098965", "doi": "https://doi.org/10.1145/99977.99987", "title": "Groupware: some issues and experiences", "abstract": "article Free Access Share on Groupware: some issues and experiences Authors: Clarence A. Ellis MCC, Austin, TX MCC, Austin, TXView Profile , Simon J. Gibbs View Profile , Gail Rein View Profile Authors Info & Claims Communications of the ACMVolume 34Issue 1Jan. 1991pp 39–58https://doi.org/10.1145/99977.99987Published:03 January 1991Publication History 1,687citation14,513DownloadsMetricsTotal Citations1,687Total Downloads14,513Last 12 Months827Last 6 weeks82 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteeReaderPDF", "authors": ["Clarence A. Ellis", "Simon Gibbs", "Gail L. Rein"], "year": 1991, "venue": "Communications of the ACM", "cited_by_count": 2751, "type": "article", "concepts": ["Collaborative software", "Computer science", "Knowledge management", "Human–computer interaction", "World Wide Web"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3194730353", "doi": "https://doi.org/10.1007/s42979-021-00815-1", "title": "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions", "abstract": "", "authors": ["Iqbal H. Sarker"], "year": 2021, "venue": "SN Computer Science", "cited_by_count": 2276, "type": "review", "concepts": ["Artificial intelligence", "Deep learning", "Computer science", "Big data", "Taxonomy (biology)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4360620450", "doi": "https://doi.org/10.1016/j.ijinfomgt.2023.102642", "title": "Opinion Paper: “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy", "abstract": "", "authors": ["Yogesh K. Dwivedi", "Nir Kshetri", "Laurie Hughes", "Emma Slade", "Anand Jeyaraj", "Arpan Kumar Kar", "Abdullah M. Baabdullah", "Alex Koohang", "Vishnupriya Raghavan", "Manju Ahuja", "Hanaa Albanna", "Mousa Ahmad Albashrawi", "Adil S. Al-Busaidi", "Janarthanan Balakrishnan", "Yves Barlette", "Sriparna Basu", "Indranil Bose", "Laurence Brooks", "Dimitrios Buhalis", "Lemuria Carter", "Soumyadeb Chowdhury", "Tom Crick", "Scott W. Cunningham", "Gareth H. Davies", "Robert M. Davison", "Rahul Dé", "Denis Dennehy", "Yanqing Duan", "Rameshwar Dubey", "Rohita Dwivedi", "John S. Edwards", "Carlos Flavián", "Robin Gauld", "Varun Grover", "Mei‐Chih Hu", "Marijn Janssen", "Paul Jones", "Iris Junglas", "Sangeeta Khorana", "Sascha Kraus", "Kai R. Larsen", "Paul Latreille", "Sven Laumer", "Tegwen Malik", "Abbas Mardani", "Marcello Mariani", "Sunil Mithas", "Emmanuel Mogaji", "Jeretta Horn Nord", "Siobhán O’Connor", "Fevzi Okumus", "Margherita Pagani", "Neeraj Pandey", "Savvas Papagiannidis", "Ilias O. Pappas", "Nishith Pathak", "Jan Pries‐Heje", "Ramakrishnan Raman", "Nripendra P. Rana", "Sven‐Volker Rehm", "Samuel Ribeiro‐Navarrete", "Alexander Richter", "Frantz Rowe", "Suprateek Sarker", "Bernd Carsten Stahl", "Manoj Tiwari", "Wil van der Aalst", "Viswanath Venkatesh", "Giampaolo Viglia", "Michael Wade", "Paul Walton", "Jochen Wirtz", "Ryan Wright"], "year": 2023, "venue": "International Journal of Information Management", "cited_by_count": 3239, "type": "article", "concepts": ["Transformative learning", "Generative grammar", "Knowledge management", "Hospitality", "Engineering ethics"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2969625533", "doi": "https://doi.org/10.1016/j.ijinfomgt.2019.08.002", "title": "Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy", "abstract": "As far back as the industrial revolution, significant development in technical innovation has succeeded in transforming numerous manual tasks and processes that had been in existence for decades where humans had reached the limits of physical capacity. Artificial Intelligence (AI) offers this same transformative potential for the augmentation and potential replacement of human tasks and activities within a wide range of industrial, intellectual and social applications. The pace of change for this new AI technological age is staggering, with new breakthroughs in algorithmic machine learning and autonomous decision-making, engendering new opportunities for continued innovation. The impact of AI could be significant, with industries ranging from: finance, healthcare, manufacturing, retail, supply chain, logistics and utilities, all potentially disrupted by the onset of AI technologies. The study brings together the collective insight from a number of leading expert contributors to highlight the significant opportunities, realistic assessment of impact, challenges and potential research agenda posed by the rapid emergence of AI within a number of domains: business and management, government, public sector, and science and technology. This research offers significant and timely insight to AI technology and its impact on the future of industry and society in general, whilst recognising the societal and industrial influence on pace and direction of AI development.", "authors": ["Yogesh K. Dwivedi", "Laurie Hughes", "Elvira Ismagilova", "Gert Aarts", "Crispin Coombs", "Tom Crick", "Yanqing Duan", "Rohita Dwivedi", "John S. Edwards", "Aled Eirug", "Vassilis Galanos", "P. Vigneswara Ilavarasan", "Marijn Janssen", "Paul Jones", "Arpan Kumar Kar", "Hatice Kizgin", "Bianca Kronemann", "Banita Lal", "Biagio Lucini", "Rony Medaglia", "Kenneth Le Meunier‐FitzHugh", "Leslie Caroline Le Meunier-FitzHugh", "Santosh K. Misra", "Emmanuel Mogaji", "Sujeet Kumar Sharma", "Jang Bahadur Singh", "Vishnupriya Raghavan", "Ramakrishnan Raman", "Nripendra P. Rana", "Spyridon Samothrakis", "Jak Spencer", "Kuttimani Tamilmani", "Annie Tubadji", "Paul Walton", "Michael D. Williams"], "year": 2019, "venue": "International Journal of Information Management", "cited_by_count": 3715, "type": "article", "concepts": ["Pace", "Transformative learning", "Government (linguistics)", "Multidisciplinary approach", "Supply chain"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4206484811", "doi": "https://doi.org/10.1109/access.2021.3140175", "title": "A Metaverse: Taxonomy, Components, Applications, and Open Challenges", "abstract": "Unlike previous studies on the Metaverse based on Second Life, the current Metaverse is based on the social value of Generation Z that online and offline selves are not different. With the technological development of deep learning-based high-precision recognition models and natural generation models, Metaverse is being strengthened with various factors, from mobile-based always-on access to connectivity with reality using virtual currency. The integration of enhanced social activities and neural-net methods requires a new definition of Metaverse suitable for the present, different from the previous Metaverse. This paper divides the concepts and essential techniques necessary for realizing the Metaverse into three components (i.e., hardware, software, and contents) and three approaches (i.e., user interaction, implementation, and application) rather than marketing or hardware approach to conduct a comprehensive analysis. Furthermore, we describe essential methods based on three components and techniques to Metaverse&#x2019;s representative Ready Player One, Roblox, and Facebook research in the domain of films, games, and studies. Finally, we summarize the limitations and directions for implementing the immersive Metaverse as social influences, constraints, and open challenges.", "authors": ["Sangmin Park", "Young‐Gab Kim"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 1680, "type": "article", "concepts": ["Computer science", "Taxonomy (biology)", "Metaverse", "Data science", "World Wide Web"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3017131514", "doi": "https://doi.org/10.1109/access.2020.2988510", "title": "Artificial Intelligence in Education: A Review", "abstract": "The purpose of this study was to assess the impact of Artificial Intelligence (AI) on education. Premised on a narrative and framework for assessing AI identified from a preliminary analysis, the scope of the study was limited to the application and effects of AI in administration, instruction, and learning. A qualitative research approach, leveraging the use of literature review as a research design and approach was used and effectively facilitated the realization of the study purpose. Artificial intelligence is a field of study and the resulting innovations and developments that have culminated in computers, machines, and other artifacts having human-like intelligence characterized by cognitive abilities, learning, adaptability, and decision-making capabilities. The study ascertained that AI has extensively been adopted and used in education, particularly by education institutions, in different forms. AI initially took the form of computer and computer related technologies, transitioning to web-based and online intelligent education systems, and ultimately with the use of embedded computer systems, together with other technologies, the use of humanoid robots and web-based chatbots to perform instructors' duties and functions independently or with instructors. Using these platforms, instructors have been able to perform different administrative functions, such as reviewing and grading students' assignments more effectively and efficiently, and achieve higher quality in their teaching activities. On the other hand, because the systems leverage machine learning and adaptability, curriculum and content has been customized and personalized in line with students' needs, which has fostered uptake and retention, thereby improving learners experience and overall quality of learning.", "authors": ["Lijia Chen", "Pingping Chen", "Zhijian Lin"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 3069, "type": "review", "concepts": ["Computer science", "Adaptability", "Personalized learning", "Artificial intelligence", "Curriculum"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2157853130", "doi": "https://doi.org/10.1080/02643290442000310", "title": "The Brain's concepts: the role of the Sensory-motor system in conceptual knowledge", "abstract": "Concepts are the elementary units of reason and linguistic meaning. They are conventional and relatively stable. As such, they must somehow be the result of neural activity in the brain. The questions are: Where? and How? A common philosophical position is that all concepts-even concepts about action and perception-are symbolic and abstract, and therefore must be implemented outside the brain's sensory-motor system. We will argue against this position using (1) neuroscientific evidence; (2) results from neural computation; and (3) results about the nature of concepts from cognitive linguistics. We will propose that the sensory-motor system has the right kind of structure to characterise both sensory-motor and more abstract concepts. Central to this picture are the neural theory of language and the theory of cogs, according to which, brain structures in the sensory-motor regions are exploited to characterise the so-called \"abstract\" concepts that constitute the meanings of grammatical constructions and general inference patterns.", "authors": ["Vittorio Gallese", "George Lakoff"], "year": 2005, "venue": "Cognitive Neuropsychology", "cited_by_count": 2617, "type": "article", "concepts": ["Sensory system", "Psychology", "Perception", "Cognitive science", "Cognition"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2164314939", "doi": "https://doi.org/10.17705/1cais.01601", "title": "Clarifying Business Models: Origins, Present, and Future of the Concept", "abstract": "This paper aims to clarify the concept of business models, its usages, and its roles in the Information Systems domain. A review of the literature shows a broad diversity of understandings, usages, and places in the firm. The paper identifies the terminology or ontology used to describe a business model, and compares this terminology with previous work. Then the general usages, roles and potential of the concept are outlined. Finally, the connection between the business model concept and Information Systems is described in the form of eight propositions to be analyzed in future work.", "authors": ["Alexander Osterwalder", "Yves Pigneur", "Christopher L. Tucci"], "year": 2005, "venue": "Communications of the Association for Information Systems", "cited_by_count": 3288, "type": "article", "concepts": ["Terminology", "Computer science", "Ontology", "Business domain", "Knowledge management"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4404181300", "doi": "https://doi.org/10.14778/3685800.3685816", "title": "AutoTQA: Towards Autonomous Tabular Question Answering through Multi-Agent Large Language Models", "abstract": "With the growing significance of data analysis, several studies aim to provide precise answers to users' natural language questions from tables, a task referred to as tabular question answering (TQA). The state-of-the-art TQA approaches are limited to handling only single-table questions. However, real-world TQA problems are inherently complex and frequently involve multiple tables, which poses challenges in directly extending single-table TQA designs to handle multiple tables, primarily due to the limited extensibility of the majority of single-table TQA methods. This paper proposes AutoTQA, a novel Auto nomous T abular Q uestion A nswering framework that employs multi-agent large language models (LLMs) across multiple tables from various systems (e.g., TiDB, BigQuery). AutoTQA comprises five agents: the User , responsible for receiving the user's natural language inquiry; the Planner , tasked with creating an execution plan for the user's inquiry; the Engineer , responsible for executing the plan step-by-step; the Executor , provides various execution environments (e.g., text-to-SQL) to fulfill specific tasks assigned by the Engineer ; and the Critic , responsible for judging whether to complete the user's natural language inquiry and identifying gaps between the current results and initial tasks. To facilitate the interaction between different agents, we have also devised agent scheduling algorithms. Furthermore, we have developed LinguFlow, an open-source, low-code visual programming tool, to quickly build and debug LLM-based applications, and to accelerate the creation of various external tools and execution environments. We also implemented a series of data connectors, which allows AutoTQA to access various tables from multiple systems. Extensive experiments show that AutoTQA delivers outstanding performance on four representative datasets.", "authors": ["Jun-Peng Zhu", "Peng Cai", "Kai Xu", "Li Li", "Yishen Sun", "Shuai Zhou", "Han Su", "Tang Liu", "Qi Liu"], "year": 2024, "venue": "Proceedings of the VLDB Endowment", "cited_by_count": 16, "type": "article", "concepts": ["Question answering", "Computer science", "Natural language processing", "Linguistics", "Artificial intelligence"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3153990350", "doi": "https://doi.org/10.1007/s12525-021-00475-2", "title": "Machine learning and deep learning", "abstract": "", "authors": ["Christian Janiesch", "Patrick Zschech", "Kai Heinrich"], "year": 2021, "venue": "Electronic Markets", "cited_by_count": 2279, "type": "article", "concepts": [], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2623521763", "doi": "https://doi.org/10.1212/wnl.0000000000004058", "title": "Diagnosis and management of dementia with Lewy bodies", "abstract": "The Dementia with Lewy Bodies (DLB) Consortium has refined its recommendations about the clinical and pathologic diagnosis of DLB, updating the previous report, which has been in widespread use for the last decade. The revised DLB consensus criteria now distinguish clearly between clinical features and diagnostic biomarkers, and give guidance about optimal methods to establish and interpret these. Substantial new information has been incorporated about previously reported aspects of DLB, with increased diagnostic weighting given to REM sleep behavior disorder and <sup>123</sup>iodine-metaiodobenzylguanidine (MIBG) myocardial scintigraphy. The diagnostic role of other neuroimaging, electrophysiologic, and laboratory investigations is also described. Minor modifications to pathologic methods and criteria are recommended to take account of Alzheimer disease neuropathologic change, to add previously omitted Lewy-related pathology categories, and to include assessments for substantia nigra neuronal loss. Recommendations about clinical management are largely based upon expert opinion since randomized controlled trials in DLB are few. Substantial progress has been made since the previous report in the detection and recognition of DLB as a common and important clinical disorder. During that period it has been incorporated into DSM-5, as major neurocognitive disorder with Lewy bodies. There remains a pressing need to understand the underlying neurobiology and pathophysiology of DLB, to develop and deliver clinical trials with both symptomatic and disease-modifying agents, and to help patients and carers worldwide to inform themselves about the disease, its prognosis, best available treatments, ongoing research, and how to get adequate support.", "authors": ["Ian G. McKeith", "Bradley F. Boeve", "Dennis W. Dickson", "Glenda M. Halliday", "John‐Paul Taylor", "Daniel Weintraub", "Dag Aarsland", "James E. Galvin", "Johannes Attems", "Clive Ballard", "Ashley Bayston", "Thomas G. Beach", "‪Frederic Blanc‬", "Nicolaas I. Bohnen", "Laura Bonanni", "José Brás", "Patrik Brundin", "David J. Burn", "Alice Chen‐Plotkin", "John E. Duda", "Omar M. A. El‐Agnaf", "Howard Feldman", "Tanis J. Ferman", "Dominic ffytche", "Hiroshige Fujishiro", "Douglas Galasko", "Jennifer G. Goldman", "Stephen N. Gomperts", "Neill R. Graff‐Radford", "Lawrence S. Honig", "Álex Iranzo", "Kejal Kantarci", "Daniel Kaufer", "Walter A. Kukull", "Virginia M.‐Y. Lee", "James B. Leverenz", "Simon J.G. Lewis", "Carol F. Lippa", "Angela Lunde", "Mario Masellis", "Eliezer Masliah", "Pamela J. McLean", "Brit Mollenhauer", "Thomas J. Montine", "Emilio Moreno", "Etsuro Mori", "Melissa E. Murray", "John T. O’Brien", "Sotoshi Orimo", "Ronald B. Postuma", "Shankar Ramaswamy", "Owen A. Ross", "David P. Salmon", "Andrew Singleton", "Angela Taylor", "Alan Thomas", "Pietro Tiraboschi", "Jon B. Toledo", "John Q. Trojanowski", "Debby W. Tsuang", "Zuzana Walker", "Masahito Yamada", "Kenji Kosaka"], "year": 2017, "venue": "Neurology", "cited_by_count": 4192, "type": "review", "concepts": ["Dementia with Lewy bodies", "Neurocognitive", "REM sleep behavior disorder", "Medicine", "Clinical trial"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W1552847225", "doi": "https://doi.org/10.3233/sw-140134", "title": "DBpedia – A large-scale, multilingual knowledge base extracted from Wikipedia", "abstract": "The DBpedia community project extracts structured, multilingual knowledge from Wikipedia and makes it freely available on the Web using Semantic Web and Linked Data technologies. The project extracts knowledge from 111 different language editions of", "authors": ["Jens Lehmann", "Robert Isele", "Max Jakob", "Anja Jentzsch", "Dimitris Kontokostas", "Pablo N. Mendes", "Sebastian Hellmann", "Mohamed Morsey", "Patrick van Kleef", "Sören Auer", "Christian Bizer"], "year": 2015, "venue": "Semantic Web", "cited_by_count": 3156, "type": "article", "concepts": ["Computer science", "Scale (ratio)", "Knowledge base", "Information retrieval", "Base (topology)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2119046642", "doi": "https://doi.org/10.1016/j.adhoc.2012.02.016", "title": "Internet of things: Vision, applications and research challenges", "abstract": "", "authors": ["Daniele Miorandi", "Sabrina Sicari", "Francesco De Pellegrini", "Imrich Chlamtac"], "year": 2012, "venue": "Ad Hoc Networks", "cited_by_count": 3523, "type": "article", "concepts": ["Software deployment", "The Internet", "Realm", "Computer science", "Internet of Things"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2617547828", "doi": "https://doi.org/10.1609/aaai.v32i1.11794", "title": "Counterfactual Multi-Agent Policy Gradients", "abstract": "Many real-world problems, such as network packet routing and the coordination of autonomous vehicles, are naturally modelled as cooperative multi-agent systems. There is a great need for new reinforcement learning methods that can efficiently learn decentralised policies for such systems. To this end, we propose a new multi-agent actor-critic method called counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents' policies. In addition, to address the challenges of multi-agent credit assignment, it uses a counterfactual baseline that marginalises out a single agent's action, while keeping the other agents' actions fixed. COMA also uses a critic representation that allows the counterfactual baseline to be computed efficiently in a single forward pass. We evaluate COMA in the testbed of StarCraft unit micromanagement, using a decentralised variant with significant partial observability. COMA significantly improves average performance over other multi-agent actor-critic methods in this setting, and the best performing agents are competitive with state-of-the-art centralised controllers that get access to the full state.", "authors": ["Jakob Foerster", "Gregory Farquhar", "Triantafyllos Afouras", "Nantas Nardelli", "Shimon Whiteson"], "year": 2018, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 1568, "type": "article", "concepts": ["Counterfactual thinking", "Computer science", "Reinforcement learning", "Baseline (sea)", "Observability"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2338335491", "doi": "https://doi.org/10.1145/130994.130998", "title": "Process modeling", "abstract": "raditionally, the modeling of information systems has focused on analyzing data flows and transformations. This modeling accounted only for the organization's data and that portion of its processes that interacted with data. Newer uses of information technology extend computer use beyond transaction processing into communication and coordination. Successfully integrating these systems into the enterprise often requires modeling even the manual organizational processes into which these systems intervene. The following are three such applications:", "authors": ["Bill Curtis", "Marc I. Kellner", "Jim Over"], "year": 1992, "venue": "Communications of the ACM", "cited_by_count": 1623, "type": "article", "concepts": ["Citation", "Software engineering", "Software", "Computer science", "Library science"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4391376827", "doi": "https://doi.org/10.48550/arxiv.2401.16158", "title": "Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual Perception", "abstract": "Mobile device agent based on Multimodal Large Language Models (MLLM) is becoming a popular application. In this paper, we introduce Mobile-Agent, an autonomous multi-modal mobile device agent. Mobile-Agent first leverages visual perception tools to accurately identify and locate both the visual and textual elements within the app's front-end interface. Based on the perceived vision context, it then autonomously plans and decomposes the complex operation task, and navigates the mobile Apps through operations step by step. Different from previous solutions that rely on XML files of Apps or mobile system metadata, Mobile-Agent allows for greater adaptability across diverse mobile operating environments in a vision-centric way, thereby eliminating the necessity for system-specific customizations. To assess the performance of Mobile-Agent, we introduced Mobile-Eval, a benchmark for evaluating mobile device operations. Based on Mobile-Eval, we conducted a comprehensive evaluation of Mobile-Agent. The experimental results indicate that Mobile-Agent achieved remarkable accuracy and completion rates. Even with challenging instructions, such as multi-app operations, Mobile-Agent can still complete the requirements. Code and model will be open-sourced at https://github.com/X-PLUG/MobileAgent.", "authors": ["Junyang Wang", "Haiyang Xu", "Jiabo Ye", "Ming Yan", "Weizhou Shen", "Ji Zhang", "Fei Huang", "Jitao Sang"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 10, "type": "preprint", "concepts": ["Modal", "Computer science", "Perception", "Human–computer interaction", "Mobile agent"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2159398820", "doi": "https://doi.org/10.1017/s0140525x04000056", "title": "Toward a mechanistic psychology of dialogue", "abstract": "Traditional mechanistic accounts of language processing derive almost entirely from the study of monologue. Yet, the most natural and basic form of language use is dialogue. As a result, these accounts may only offer limited theories of the mechanisms that underlie language processing in general. We propose a mechanistic account of dialogue, the interactive alignment account, and use it to derive a number of predictions about basic language processes. The account assumes that, in dialogue, the linguistic representations employed by the interlocutors become aligned at many levels, as a result of a largely automatic process. This process greatly simplifies production and comprehension in dialogue. After considering the evidence for the interactive alignment model, we concentrate on three aspects of processing that follow from it. It makes use of a simple interactive inference mechanism, enables the development of local dialogue routines that greatly simplify language processing, and explains the origins of self-monitoring in production. We consider the need for a grammatical framework that is designed to deal with language in dialogue rather than monologue, and discuss a range of implications of the account.", "authors": ["Martin J. Pickering", "Simon Garrod"], "year": 2004, "venue": "Behavioral and Brain Sciences", "cited_by_count": 2570, "type": "review", "concepts": ["Comprehension", "Computer science", "Process (computing)", "Inference", "Mechanism (biology)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4213147678", "doi": "https://doi.org/10.1109/access.2019.2909530", "title": "Unmanned Aerial Vehicles (UAVs): A Survey on Civil Applications and Key Research Challenges", "abstract": "The use of unmanned aerial vehicles (UAVs) is growing rapidly across many civil application domains, including real-time monitoring, providing wireless coverage, remote sensing, search and rescue, delivery of goods, security and surveillance, precision agriculture, and civil infrastructure inspection. Smart UAVs are the next big revolution in the UAV technology promising to provide new opportunities in different applications, especially in civil infrastructure in terms of reduced risks and lower cost. Civil infrastructure is expected to dominate more than $45 Billion market value of UAV usage. In this paper, we present UAV civil applications and their challenges. We also discuss the current research trends and provide future insights for potential UAV uses. Furthermore, we present the key challenges for UAV civil applications, including charging challenges, collision avoidance and swarming challenges, and networking and security-related challenges. Based on our review of the recent literature, we discuss open research challenges and draw high-level insights on how these challenges might be approached.", "authors": ["Hazim Shakhatreh", "Ahmad Sawalmeh", "Ala Al‐Fuqaha", "Zuochao Dou", "Eyad Almaita", "Issa Khalil", "Noor Shamsiah Othman", "Abdallah Khreishah", "Mohsen Guizani"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 2119, "type": "article", "concepts": ["Drone", "Computer science", "Key (lock)", "Open research", "Search and rescue"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2041711461", "doi": "https://doi.org/10.1016/j.tourman.2008.01.005", "title": "Progress in information technology and tourism management: 20 years on and 10 years after the Internet—The state of eTourism research", "abstract": "", "authors": ["Dimitrios Buhalis", "Rob Law"], "year": 2008, "venue": "Tourism Management", "cited_by_count": 3594, "type": "article", "concepts": ["Tourism", "Variety (cybernetics)", "The Internet", "Context (archaeology)", "Marketing"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2747680751", "doi": "https://doi.org/10.1007/s11042-022-13428-4", "title": "Natural language processing: state of the art, current trends and challenges", "abstract": "", "authors": ["Diksha Khurana", "Aditya Koli", "Kiran Khatter", "Sukhdev Singh"], "year": 2022, "venue": "Multimedia Tools and Applications", "cited_by_count": 1620, "type": "article", "concepts": ["Automatic summarization", "Computer science", "Natural language processing", "Machine translation", "Artificial intelligence"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4365799947", "doi": "https://doi.org/10.18653/v1/2020.coling-main", "title": "Proceedings of the 28th International Conference on Computational Linguistics", "abstract": "Only eighteen months ago, I joined Leo, Horacio, Mónica, and Nuria on a tour of the delights that the Barcelona venue would be offering us in September 2020.Together with Chengqing, we made great plans for a fantastic intellectual and social gathering with our colleagues from far and wide, Catalanstyle.We held on to this plan for as long as we could but the second wave of the COVID-19 pandemic eventually put paid to that idea, and the conference is now a virtual one.We also received a record 2195 submissions -eclipsing by double the already record-breaking number at our last COLING in 2018 in Santa Fe.For these reasons, COLING2020 will be remembered for the conference that forced us to innovate and do things differently.Transforming our well-made plans to become a virtual conference has obviously involved introducing a de facto disruptive innovation, one that has taken us far out of our comfort zone of experience.The Organising Committee thoroughly embraced this challenge, doing everything that they could and more; I am in awe of them and of the exciting offering that they have created for COLING2020.We now have before us a rich programme of over 653 papers, 7 tutorials, and 22 workshops.I want to take this opportunity to thank the entire Organising Committee for their extraordinary effort in helping to make this virtual COLING2020 possible.The PC Chairs (Núria Bel, Chengqing Zong) and Local Organisation Chairs (Leo Wanner, Horacio Saggion, Mónica Domínguez) bore the brunt of the organisational burden and worked tirelessly despite the other unexpected demands to their professional and personal lives.Enormous efforts were made by Workshop Chairs (", "authors": ["Xiaodan Zhu", "Preslav Nakov", "Jun Zhao", "Michal Ptaszynski", "Bartosz Ziolko", "Website Chairs", "Laura Prez- Mayos", "Amita Misra", "Derek Wong", "Yang Zhang", "Liang Huang", "Ted Pedersen", "Anna Rogers", "Ghazaleh Kazeminejad", "Feiyu Xu", "Alexander Lser", "Jose Manuel Gmez Prez", "Paul Piwek", "Padr Llus", "Luis Cirera", "Anke Espinosa", "Esther Seyffarth", "Local Support", "Joana Clotet", "Amanda Stent", "Emily Bender", "Dirk Hovy", "Pascale Fung", "Donia Scott", "Leo Wanner", "Horacio Saggion", "Mnica Domnguez", "Yang Zhao", "Ethics Group", "Tim Baldwin", "Saif Mohammadl", "Joana We", "Harald Bloomberg", "Baayen", "Eberhard Karls", "Margaret Mitchell", "Google", "Nuria Bel", "Chengqing Zong", "Lucia Specia", "Daniel Beck", "Workshops Co-Chairs", "Jun Zhao", "Ann Clifton", "Courtney Napoles", "Grammarly", "Techmo", "Cirera", "Luis Anke", "Publicity Co-Chairs", "Tiejun Zhao", "Beuth", "Laura Prez-Mayos", "Ibm Watson", "Emily Bloomberg", "Bender", "Sophia Ananiadou", "Rafael Banchs", "Intapp Miwa", "Alessandro Lenci", "Michael Strube", "Jian-Yun Nie", "Gareth Jones", "Wenjie Li", "Michael White", "Anya Belz", "Sina Zarrie", "Friedrich Schiller", "Universitt Jena", "Fei Huang", "Alibaba Academy", "Sebastian Ruder", "Deepmind Qiu", "Fei Xia", "Nicoletta Calzolari", "Jong Park", "Shujie Liu", "Ding Liu", "Mei Ling", "Helen Meng", "Kentaro Inui", "Kallirroi Georgila", "Girish Kumar", "David Griol", "Rhee Yoo", "Justin Oh", "Kristiina Dauwels", "Lan Joki- Nen", "Patrick Du", "Yuki Paroubek", "Kotaro Arase", "Michael Funakoshi", "Jin-Dong Mctear", "Zoraida Kim", "Lasguido Callejas"], "year": 2020, "venue": "", "cited_by_count": 1422, "type": "paratext", "concepts": ["Computer science", "Computational linguistics", "Linguistics", "Natural language processing", "Philosophy"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2000196122", "doi": "https://doi.org/10.1017/s0140525x0999094x", "title": "The myth of language universals: Language diversity and its importance for cognitive science", "abstract": "Talk of linguistic universals has given cognitive scientists the impression that languages are all built to a common pattern. In fact, there are vanishingly few universals of language in the direct sense that all languages exhibit them. Instead, diversity can be found at almost every level of linguistic organization. This fundamentally changes the object of enquiry from a cognitive science perspective. This target article summarizes decades of cross-linguistic work by typologists and descriptive linguists, showing just how few and unprofound the universal characteristics of language are, once we honestly confront the diversity offered to us by the world's 6,000 to 8,000 languages. After surveying the various uses of \"universal,\" we illustrate the ways languages vary radically in sound, meaning, and syntactic organization, and then we examine in more detail the core grammatical machinery of recursion, constituency, and grammatical relations. Although there are significant recurrent patterns in organization, these are better explained as stable engineering solutions satisfying multiple design constraints, reflecting both cultural-historical factors and the constraints of human cognition. Linguistic diversity then becomes the crucial datum for cognitive science: we are the only species with a communication system that is fundamentally variable at all levels. Recognizing the true extent of structural diversity in human language opens up exciting new research directions for cognitive scientists, offering thousands of different natural experiments given by different languages, with new opportunities for dialogue with biological paradigms concerned with change and diversity, and confronting us with the extraordinary plasticity of the highest human skills.", "authors": ["Nicholas Evans", "Stephen C. Levinson"], "year": 2009, "venue": "Behavioral and Brain Sciences", "cited_by_count": 2599, "type": "article", "concepts": ["Linguistic universal", "Problem of universals", "Linguistics", "Cognition", "Diversity (politics)"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4294010056", "doi": "https://doi.org/10.48550/arxiv.2208.13266", "title": "JARVIS: A Neuro-Symbolic Commonsense Reasoning Framework for Conversational Embodied Agents", "abstract": "Building a conversational embodied agent to execute real-life tasks has been a long-standing yet quite challenging research goal, as it requires effective human-agent communication, multi-modal understanding, long-range sequential decision making, etc. Traditional symbolic methods have scaling and generalization issues, while end-to-end deep learning models suffer from data scarcity and high task complexity, and are often hard to explain. To benefit from both worlds, we propose JARVIS, a neuro-symbolic commonsense reasoning framework for modular, generalizable, and interpretable conversational embodied agents. First, it acquires symbolic representations by prompting large language models (LLMs) for language understanding and sub-goal planning, and by constructing semantic maps from visual observations. Then the symbolic module reasons for sub-goal planning and action generation based on task- and action-level common sense. Extensive experiments on the TEACh dataset validate the efficacy and efficiency of our JARVIS framework, which achieves state-of-the-art (SOTA) results on all three dialog-based embodied tasks, including Execution from Dialog History (EDH), Trajectory from Dialog (TfD), and Two-Agent Task Completion (TATC) (e.g., our method boosts the unseen Success Rate on EDH from 6.1\\% to 15.8\\%). Moreover, we systematically analyze the essential factors that affect the task performance and also demonstrate the superiority of our method in few-shot settings. Our JARVIS model ranks first in the Alexa Prize SimBot Public Benchmark Challenge.", "authors": ["Kaizhi Zheng", "Kaiwen Zhou", "Jing Gu", "Yue Fan", "Jialu Wang", "Zonglin Di", "Xuehai He", "Xin Eric Wang"], "year": 2022, "venue": "arXiv (Cornell University)", "cited_by_count": 8, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Dialog box", "Task (project management)", "Embodied cognition"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2953303875", "doi": "https://doi.org/10.1109/access.2020.2983149", "title": "A Survey of Autonomous Driving: <i>Common Practices and Emerging Technologies</i>", "abstract": "Automated driving systems (ADSs) promise a safe, comfortable and efficient driving experience. However, fatalities involving vehicles equipped with ADSs are on the rise. The full potential of ADSs cannot be realized unless the robustness of state-of-the-art is improved further. This paper discusses unsolved problems and surveys the technical aspect of automated driving. Studies regarding present challenges, high-level system architectures, emerging methodologies and core functions including localization, mapping, perception, planning, and human machine interfaces, were thoroughly reviewed. Furthermore, many state-of-the-art algorithms were implemented and compared on our own platform in a real-world driving setting. The paper concludes with an overview of available datasets and tools for ADS development.", "authors": ["Ekim Yurtsever", "Jacob Lambert", "Alexander Carballo", "Kazuya Takeda"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 1641, "type": "article", "concepts": ["Robustness (evolution)", "Computer science", "Perception", "Emerging technologies", "Data science"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4384464487", "doi": "https://doi.org/10.1186/s41239-023-00411-8", "title": "Students’ voices on generative AI: perceptions, benefits, and challenges in higher education", "abstract": "", "authors": ["Cecilia Ka Yuk Chan", "Wenjie Hu"], "year": 2023, "venue": "International Journal of Educational Technology in Higher Education", "cited_by_count": 1442, "type": "article", "concepts": ["Brainstorming", "Higher education", "Perception", "Psychology", "Engineering ethics"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2104357911", "doi": "https://doi.org/10.15215/aupress/9781897425084.01", "title": "The Theory and Practice of Online Learning", "abstract": "The revised version of the Theory and Practice of Online Learning, edited by Terry Anderson, brings together recent developments in both the practice and our understanding of online learning.Five years have since passed between this new edition and the first version.Five years is certainly a long time in this business as this second edition illustrates.The improvement in versatility and sophistication of the technologies that have been coming into common use has been so significant that a revisit of our knowledge of learning technologies and their application was becoming increasingly necessary.Anderson and the other authors of this text have responded to the need and have done the higher education community a great service by bringing it out in the electronic open access format under a Creative Commons License.Those of us from the other world are beneficiaries of this generosity and intellectual benevolence.Online learning has begun to embed itself as a part of our educational environment, especially in the higher education and training Theory and Practice of Online Learning", "authors": ["Terry Anderson", "Mohamed Ally", "M Ally", "M Ally", "P Fahy", "D Ausubel", "Z Berge", "Z Berge", "M Beynon", "C Bonk", "T Reynolds", "S Cassidy", "L Chittaro", "R Ranon", "R Clark", "R Clark", "P Cooper", "F Craik", "R Lockhart", "F Craik", "E Tulving", "T Duffy", "D Cunningham", "P Ertmer", "T Newby", "D Garrison", "L Gilbert", "D Moore", "A Hirumi", "C Holley", "D Dansereau", "B Mcdonald", "J Garland", "K Collins", "S Hooper", "M Hannafin", "D Hung", "C Looi", "T Koh", "T Janicki", "J Liegle", "D Johnson", "R Johnson", "J Keller", "J Keller", "K Suzuki", "B Khan", "R Kozma", "T Malone", "R Mayer", "R Mayer", "G Miller", "M Moore", "M Mukhopadhyay", "M Parhar", "K Murphy", "L Cifuentes", "D Phillips", "G Ring", "G Mathieux", "D Ritchie", "B Hoffman", "A Rossett", "L Rourke", "T Anderson", "D Garrison", "W Archer", "A Rovai", "J Schmidt", "C Werner", "D Simmons", "R Sternberg", "N Stoyanova", "P Kommers", "D Wiley", "B Wilson", "H Witkin", "C Moore", "D Goodenough", "P Cox", "M Yorke", "P Knight", "G Baxter", "A Elder", "R Glaser", "M Benedikt", "M Byrne", "B Flood", "P Willis", "L Christenson", "K Menzel", "D Clements", "B Nastassi", "R Cutler", "J Dixon", "S Eggins", "D Slade", "J Esposito", "J Farmer", "D Feng"], "year": 2008, "venue": "Athabasca University Press eBooks", "cited_by_count": 1806, "type": "book", "concepts": ["License", "Sophistication", "Generosity", "Online learning", "Knowledge management"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2118796430", "doi": "https://doi.org/10.1002/hbm.20547", "title": "Social cognition and the brain: A meta‐analysis", "abstract": "This meta-analysis explores the location and function of brain areas involved in social cognition, or the capacity to understand people's behavioral intentions, social beliefs, and personality traits. On the basis of over 200 fMRI studies, it tests alternative theoretical proposals that attempt to explain how several brain areas process information relevant for social cognition. The results suggest that inferring temporary states such as goals, intentions, and desires of other people-even when they are false and unjust from our own perspective--strongly engages the temporo-parietal junction (TPJ). Inferring more enduring dispositions of others and the self, or interpersonal norms and scripts, engages the medial prefrontal cortex (mPFC), although temporal states can also activate the mPFC. Other candidate tasks reflecting general-purpose brain processes that may potentially subserve social cognition are briefly reviewed, such as sequence learning, causality detection, emotion processing, and executive functioning (action monitoring, attention, dual task monitoring, episodic memory retrieval), but none of them overlaps uniquely with the regions activated during social cognition. Hence, it appears that social cognition particularly engages the TPJ and mPFC regions. The available evidence is consistent with the role of a TPJ-related mirror system for inferring temporary goals and intentions at a relatively perceptual level of representation, and the mPFC as a module that integrates social information across time and allows reflection and representation of traits and norms, and presumably also of intentionality, at a more abstract cognitive level.", "authors": ["Frank Van Overwalle"], "year": 2008, "venue": "Human Brain Mapping", "cited_by_count": 1782, "type": "review", "concepts": ["Psychology", "Social cognition", "Temporoparietal junction", "Theory of mind", "Cognition"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W3149839747", "doi": "https://doi.org/10.1016/j.engappai.2022.105151", "title": "Ensemble deep learning: A review", "abstract": "", "authors": ["M. A. Ganaie", "Minghui Hu", "A. K. Malik", "M. Tanveer", "Ponnuthurai Nagaratnam Suganthan"], "year": 2022, "venue": "Engineering Applications of Artificial Intelligence", "cited_by_count": 1873, "type": "review", "concepts": ["Ensemble learning", "Computer science", "Artificial intelligence", "Boosting (machine learning)", "Deep learning"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2113033841", "doi": "https://doi.org/10.4065/mcp.2010.0575", "title": "Medication Adherence: WHO Cares?", "abstract": "", "authors": ["Marie T. Brown", "Jennifer K. Bussell"], "year": 2011, "venue": "Mayo Clinic Proceedings", "cited_by_count": 1834, "type": "article", "concepts": ["Medicine", "MEDLINE", "Health literacy", "Medical prescription", "Pharmacotherapy"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2954503794", "doi": "https://doi.org/10.1609/aimag.v40i2.2850", "title": "DARPA's Explainable Artificial Intelligence Program", "abstract": "Dramatic success in machine learning has led to a new wave of AI applications (for example, transportation, security, medicine, finance, defense) that offer tremendous benefits but cannot explain their decisions and actions to human users. DARPA's explainable artificial intelligence (XAI) program endeavors to create AI systems whose learned models and decisions can be understood and appropriately trusted by end users. Realizing this goal requires methods for learning more explainable models, designing effective explanation interfaces, and understanding the psychologic requirements for effective explanations. The XAI developer teams are addressing the first two challenges by creating ML techniques and developing principles, strategies, and human‐computer interaction techniques for generating effective explanations. Another XAI team is addressing the third challenge by summarizing, extending, and applying psychologic theories of explanation to help the XAI evaluator define a suitable evaluation framework, which the developer teams will use to test their systems. The XAI teams completed the first of this 4‐year program in May 2018. In a series of ongoing evaluations, the developer teams are assessing how well their XAM systems' explanations improve user understanding, user trust, and user task performance.", "authors": ["David Gunning", "David W. Aha"], "year": 2019, "venue": "AI Magazine", "cited_by_count": 1121, "type": "article", "concepts": ["Computer science", "Task (project management)", "Artificial intelligence", "Knowledge management", "Management science"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2165349656", "doi": "https://doi.org/10.1161/cir.0b013e31823ba622", "title": "2011 ACCF/AHA/SCAI Guideline for Percutaneous Coronary Intervention", "abstract": "", "authors": ["Glenn N. Levine", "Eric Bates", "James C. Blankenship", "Steven R. Bailey", "John A. Bittl", "Bojan Cercek", "Charles E. Chambers", "Stephen G. Ellis", "Robert A. Guyton", "Steven M. Hollenberg", "Umesh N. Khot", "Richard A. Lange", "Laura Mauri", "Roxana Mehran", "Issam Moussa", "Debabrata Mukherjee", "Brahmajee K. Nallamothu", "Henry H. Ting"], "year": 2011, "venue": "Circulation", "cited_by_count": 3291, "type": "article", "concepts": ["Medicine", "Guideline", "BATES", "Percutaneous coronary intervention", "Task force"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4387835442", "doi": "https://doi.org/10.1145/3586183.3606763", "title": "Generative Agents: Interactive Simulacra of Human Behavior", "abstract": "Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents: computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent’s experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty-five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors. For example, starting with only a single user-specified notion that one agent wants to throw a Valentine’s Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.", "authors": ["Joon Sung Park", "Joseph O’Brien", "Carrie J. Cai", "Meredith Ringel Morris", "Percy Liang", "Michael S. Bernstein"], "year": 2023, "venue": "", "cited_by_count": 1129, "type": "article", "concepts": ["Generative grammar", "Computer science", "Artificial intelligence", "Human–computer interaction", "Generative model"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2944523811", "doi": "https://doi.org/10.20870/ijvr.2010.9.2.2767", "title": "A Survey of Augmented Reality Technologies, Applications and Limitations", "abstract": "A Survey of Augmented Reality Technologies, Applications and Limitations", "authors": ["D. W. F. van Krevelen", "Ronald Poelman"], "year": 2010, "venue": "International Journal of Virtual Reality", "cited_by_count": 1632, "type": "article", "concepts": ["Augmented reality", "Computer science", "Data science", "Human–computer interaction"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2538626945", "doi": "https://doi.org/10.1093/scan/nsw154", "title": "The theory of constructed emotion: an active inference account of interoception and categorization", "abstract": "The science of emotion has been using folk psychology categories derived from philosophy to search for the brain basis of emotion. The last two decades of neuroscience research have brought us to the brink of a paradigm shift in understanding the workings of the brain, however, setting the stage to revolutionize our understanding of what emotions are and how they work. In this article, we begin with the structure and function of the brain, and from there deduce what the biological basis of emotions might be. The answer is a brain-based, computational account called the theory of constructed emotion.", "authors": ["Lisa Feldman Barrett"], "year": 2016, "venue": "Social Cognitive and Affective Neuroscience", "cited_by_count": 1386, "type": "article", "concepts": ["Interoception", "Psychology", "Categorization", "Folk psychology", "Inference"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W2958089299", "doi": "https://doi.org/10.1109/tnnls.2020.3027314", "title": "A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI", "abstract": "Recently, artificial intelligence and machine learning in general have demonstrated remarkable performances in many tasks, from image processing to natural language processing, especially with the advent of deep learning (DL). Along with research progress, they have encroached upon many different fields and disciplines. Some of them require high level of accountability and thus transparency, for example, the medical sector. Explanations for machine decisions and predictions are thus needed to justify their reliability. This requires greater interpretability, which often means we need to understand the mechanism underlying the algorithms. Unfortunately, the blackbox nature of the DL is still unresolved, and many machine decisions are still poorly understood. We provide a review on interpretabilities suggested by different research works and categorize them. The different categories show different dimensions in interpretability research, from approaches that provide \"obviously\" interpretable information to the studies of complex patterns. By applying the same categorization to interpretability in medical research, it is hoped that: 1) clinicians and practitioners can subsequently approach these methods with caution; 2) insight into interpretability will be born with more considerations for medical practices; and 3) initiatives to push forward data-based, mathematically grounded, and technically grounded medical education are encouraged.", "authors": ["Erico Tjoa", "Cuntai Guan"], "year": 2020, "venue": "IEEE Transactions on Neural Networks and Learning Systems", "cited_by_count": 1953, "type": "article", "concepts": ["Croatian", "Linguistics", "Philosophy"], "search_query": "multi-agent visual task planning large language model"}
{"openalex_id": "https://openalex.org/W4403792113", "doi": "https://doi.org/10.1145/3664647.3680762", "title": "Harmony in Diversity: Improving All-in-One Image Restoration via Multi-Task Collaboration", "abstract": "Deep learning-based all-in-one image restoration methods have garnered significant attention in recent years due to capable of addressing multiple degradation tasks. These methods focus on extracting task-oriented information to guide the unified model and have achieved promising results through elaborate architecture design. They commonly adopt a simple mix training paradigm, and the proper optimization strategy for all-in-one tasks has been scarcely investigated. This oversight neglects the intricate relationships and potential conflicts among various restoration tasks, consequently leading to inconsistent optimization rhythms. In this paper, we extend and redefine the conventional all-in-one image restoration task as a multi-task learning problem and propose a straightforward yet effective active-reweighting strategy, dubbed Art, to harmonize the optimization of multiple degradation tasks. Art is a plug-and-play optimization strategy designed to mitigate hidden conflicts among multi-task optimization processes. Through extensive experiments on a diverse range of all-in-one image restoration settings, Art has been demonstrated to substantially enhance the performance of existing methods. When incorporated into the AirNet and TransWeather models, it achieves average improvements of 1.16 dB and 1.21 dB on PSNR, respectively. We hope this work will provide a principled framework for collaborating multiple tasks in all-in-one image restoration and pave the way for more efficient and effective restoration models, ultimately advancing the state-of-the-art in this critical research domain. Code and pre-trained models are available at our project page https://github.com/Aitical/Art.", "authors": ["Gang Wu", "Junjun Jiang", "Kui Jiang", "Xianming Liu"], "year": 2024, "venue": "", "cited_by_count": 14, "type": "article", "concepts": ["Harmony (color)", "Image restoration", "Computer science", "Diversity (politics)", "Task (project management)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4413114136", "doi": "https://doi.org/10.1109/tpami.2025.3598132", "title": "A Survey on All-in-One Image Restoration: Taxonomy, Evaluation and Future Trends", "abstract": "Image restoration (IR) seeks to recover high-quality images from degraded observations caused by a wide range of factors, including noise, blur, compression, and adverse weather. While traditional IR methods have made notable progress by targeting individual degradation types, their specialization often comes at the cost of generalization, leaving them ill-equipped to handle the multifaceted distortions encountered in real-world applications. In response to this challenge, the all-in-one image restoration (AiOIR) paradigm has recently emerged, offering a unified framework that adeptly addresses multiple degradation types. These innovative models enhance the convenience and versatility by adaptively learning degradation-specific features while simultaneously leveraging shared knowledge across diverse corruptions. In this survey, we provide the first in-depth and systematic overview of AiOIR, delivering a structured taxonomy that categorizes existing methods by architectural designs, learning paradigms, and their core innovations. We systematically categorize current approaches and assess the challenges these models encounter, outlining research directions to propel this rapidly evolving field. To facilitate the evaluation of existing methods, we also consolidate widely-used datasets, evaluation protocols, and implementation practices, and compare and summarize the most advanced open-source models. As the first comprehensive review dedicated to AiOIR, this paper aims to map the conceptual landscape, synthesize prevailing techniques, and ignite further exploration toward more intelligent, unified, and adaptable visual restoration systems.", "authors": ["Junjun Jiang", "Zhiyi Zuo", "Gang Wu", "Kui Jiang", "Xianming Liu"], "year": 2025, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 11, "type": "article", "concepts": ["Computer science", "Data science", "Taxonomy (biology)", "Categorization", "Image restoration"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2100235918", "doi": "https://doi.org/10.1155/2009/421425", "title": "A Survey of Collaborative Filtering Techniques", "abstract": "As one of the most successful approaches to building recommender systems, collaborative filtering ( CF ) uses the known preferences of a group of users to make recommendations or predictions of the unknown preferences for other users. In this paper, we first introduce CF tasks and their main challenges, such as data sparsity, scalability, synonymy, gray sheep, shilling attacks, privacy protection, etc., and their possible solutions. We then present three main categories of CF techniques: memory-based, model-based, and hybrid CF algorithms (that combine CF with other recommendation techniques), with examples for representative algorithms of each category, and analysis of their predictive performance and their ability to address the challenges. From basic techniques to the state-of-the-art, we attempt to present a comprehensive survey for CF techniques, which can be served as a roadmap for research and practice in this area.", "authors": ["Xiaoyuan Su", "Taghi M. Khoshgoftaar"], "year": 2009, "venue": "Advances in Artificial Intelligence", "cited_by_count": 3568, "type": "article", "concepts": ["Computer science", "Collaborative filtering", "Scalability", "Recommender system", "Data science"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W3212516020", "doi": "https://doi.org/10.1145/3528233.3530757", "title": "Palette: Image-to-Image Diffusion Models", "abstract": "This paper develops a unified framework for image-to-image translation based on conditional diffusion models and evaluates this framework on four challenging image-to-image translation tasks, namely colorization, inpainting, uncropping, and JPEG restoration. Our simple implementation of image-to-image diffusion models outperforms strong GAN and regression baselines on all tasks, without task-specific hyper-parameter tuning, architecture customization, or any auxiliary loss or sophisticated new techniques needed. We uncover the impact of an L2 vs. L1 loss in the denoising diffusion objective on sample diversity, and demonstrate the importance of self-attention in the neural architecture through empirical studies. Importantly, we advocate a unified evaluation protocol based on ImageNet, with human evaluation and sample quality scores (FID, Inception Score, Classification Accuracy of a pre-trained ResNet-50, and Perceptual Distance against original images). We expect this standardized evaluation protocol to play a role in advancing image-to-image translation research. Finally, we show that a generalist, multi-task diffusion model performs as well or better than task-specific specialist counterparts. Check out https://diffusion-palette.github.io/ for an overview of the results and code.", "authors": ["Chitwan Saharia", "William Chan", "Huiwen Chang", "Chris Lee", "Jonathan Ho", "Tim Salimans", "David J. Fleet", "Mohammad Norouzi"], "year": 2022, "venue": "", "cited_by_count": 1396, "type": "preprint", "concepts": ["Computer science", "Inpainting", "Artificial intelligence", "Image (mathematics)", "Task (project management)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2034135634", "doi": "https://doi.org/10.1109/79.560323", "title": "Positron-emission tomography", "abstract": "We review positron-emission tomography (PET), which has inherent advantages that avoid the shortcomings of other nuclear medicine imaging methods. PET image reconstruction methods with origins in signal and image processing are discussed, including the potential problems of these methods. A summary of statistical image reconstruction methods, which can yield improved image quality, is also presented.", "authors": ["John Ollinger", "Jeffrey A. Fessler"], "year": 1997, "venue": "IEEE Signal Processing Magazine", "cited_by_count": 1172, "type": "article", "concepts": ["Positron emission tomography", "Iterative reconstruction", "Computer science", "Image quality", "Tomography"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4413157794", "doi": "https://doi.org/10.1109/cvpr52734.2025.00705", "title": "Vision-Language Gradient Descent-driven All-in-One Deep Unfolding Networks", "abstract": "Dynamic image degradations, including noise, blur and lighting inconsistencies, pose significant challenges in image restoration, often due to sensor limitations or adverse environmental conditions. Existing Deep Unfolding Networks (DUNs) offer stable restoration performance but require manual selection of degradation matrices for each degradation type, limiting their adaptability across diverse scenarios. To address this issue, we propose the Vision-Language-guided Unfolding Network (VLU-Net), a unified DUN framework for handling multiple degradation types simultaneously. VLU-Net leverages a VisionLanguage Model (VLM) refined on degraded image-text pairs to align image features with degradation descriptions, selecting the appropriate transform for target degradation. By integrating an automatic VLM-based gradient estimation strategy into the Proximal Gradient Descent (PGD) algorithm, VLU-Net effectively tackles complex multi-degradation restoration tasks while maintaining interpretability. Furthermore, we design a hierarchical feature unfolding structure to enhance VLU-Net framework, efficiently synthesizing degradation patterns across various levels. VLU-Net is the first all-in-one DUN framework and outperforms current leading one-by-one and all-in-one end- to-end methods by 3.74 dB on the SOTS dehazing dataset and 1.70 dB on the Rain100L deraining dataset.", "authors": ["Haijin Zeng", "Xiangming Wang", "Yongyong Chen", "Jingyong Su", "Jie Liu"], "year": 2025, "venue": "", "cited_by_count": 6, "type": "article", "concepts": ["Computer science", "Gradient descent", "Artificial intelligence", "Descent (aeronautics)", "Stochastic gradient descent"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4402851724", "doi": "https://doi.org/10.1016/j.knosys.2024.112543", "title": "RDM-IR: Task-adaptive deep unfolding network for All-In-One image restoration", "abstract": "", "authors": ["Yuanshuo Cheng", "Mingwen Shao", "Yecong Wan", "Chao Wang"], "year": 2024, "venue": "Knowledge-Based Systems", "cited_by_count": 5, "type": "article", "concepts": ["RDM", "Task (project management)", "Image restoration", "Image (mathematics)", "Computer science"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W3081345311", "doi": null, "title": "Variational Image Restoration Network", "abstract": "Deep neural networks (DNNs) have achieved significant success in image restoration tasks by directly learning a powerful non-linear mapping from corrupted images to their latent clean ones. However, there still exist two major limitations for these deep learning (DL)-based methods. Firstly, the noises contained in real corrupted images are very complex, usually neglected and largely under-estimated in most current methods. Secondly, existing DL methods are mostly trained on one pre-assumed degradation process for all of the training image pairs, such as the widely used bicubic downsampling assumption in the image super-resolution task, inevitably leading to poor generalization performance when the true degradation does not match with such assumed one. To address these issues, we propose a unified generative model for the image restoration, which elaborately configures the degradation process from the latent clean image to the observed corrupted one. Specifically, different from most of current methods, the pixel-wisely non-i.i.d. Gaussian distribution, being with more flexibility, is adopted in our method to fit the complex real noises. Furthermore, the method is built on the general image degradation process, making it capable of adapting diverse degradations under one single model. Besides, we design a variational inference algorithm to learn all parameters involved in the proposed model with explicit form of objective loss. Specifically, beyond traditional variational methodology, two DNNs are employed to parameterize the posteriori distributions, one to infer the distribution of the latent clean image, and another to infer the distribution of the image noise. Extensive experiments demonstrate the superiority of the proposed method on three classical image restoration tasks, including image denoising, image super-resolution and JPEG image deblocking.", "authors": ["Zongsheng Yue", "Hongwei Yong", "Qian Zhao", "Lei Zhang", "Deyu Meng"], "year": 2020, "venue": "arXiv (Cornell University)", "cited_by_count": 6, "type": "preprint", "concepts": ["Upsampling", "Image restoration", "Computer science", "Inference", "Image (mathematics)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4409581375", "doi": "https://doi.org/10.1109/tpami.2025.3562211", "title": "Degradation-Aware Residual-Conditioned Optimal Transport for Unified Image Restoration", "abstract": "Unified, or more formally, all-in-one image restoration has emerged as a practical and promising low-level vision task for real-world applications. In this context, the key issue lies in how to deal with different types of degraded images simultaneously. Existing methods fit joint regression models over multi-domain degraded-clean image pairs of different degradations. However, due to the severe ill-posedness of inverting heterogeneous degradations, they often struggle with thoroughly perceiving the degradation semantics and rely on paired data for supervised training, yielding suboptimal restoration maps with structurally compromised results and lacking practicality for real-world or unpaired data. To break the barriers, we present a Degradation-Aware Residual-Conditioned Optimal Transport (DA-RCOT) approach that models (all-in-one) image restoration as an optimal transport (OT) problem for unpaired and paired settings, introducing the transport residual as a degradation-specific cue for both the transport cost and the transport map. Specifically, we formalize image restoration with a residual-guided OT objective by exploiting the degradation-specific patterns of the Fourier residual in the transport cost. More crucially, we design the transport map for restoration as a two-pass DA-RCOT map, in which the transport residual is computed in the first pass and then encoded as multi-scale residual embeddings to condition the second-pass restoration. This conditioning process injects intrinsic degradation knowledge (e.g., degradation type and level) and structural information from the multi-scale residual embeddings into the OT map, which thereby can dynamically adjust its behaviors for all-in-one restoration. Extensive experiments across five degradations demonstrate the favorable performance of DA-RCOT as compared to state-of-the-art methods, in terms of distortion measures, perceptual quality, and image structure preservation. Notably, DA-RCOT delivers superior adaptability to real-world scenarios even with mixed degradations and shows distinctive robustness to both degradation levels and the number of degradations.", "authors": ["Xiaole Tang", "Xiang Gu", "Xiaoyi He", "Xin Hu", "Jian Sun"], "year": 2025, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 5, "type": "article", "concepts": ["Degradation (telecommunications)", "Residual", "Image restoration", "Computer science", "Artificial intelligence"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4410294577", "doi": "https://doi.org/10.1109/tip.2025.3567205", "title": "Learning Dynamic Prompts for All-in-One Image Restoration", "abstract": "All-in-one image restoration, which seeks to handle multiple types of degradation within a unified model, has become a prominent research topic in computer vision. While existing deep learning models have achieved remarkable success in specific restoration tasks, extending these models to heterogenous degradations presents significant challenges. Current all-in-one methods predominantly concentrate on extracting degradation priors, often employing learned and fixed task prompts to guide the restoration process. However, these static prompts are inclined to generate an average distribution characteristics of degradations, unable to accurately depict the unique attribute of the given input, consequently providing suboptimal restoration results. To tackle these challenges, we propose a novel dynamic prompt approach called Degradation Prototype Assignment and Prompt Distribution Learning (DPPD). Our approach decouples the degradation prior extraction into two novel components: Degradation Prototype Assignment (DPA) and Prompt Distribution Learning (PDL). DPA anchors the degradation representations to predefined prototypes, providing discriminative and scalable representations. In addition, PDL models prompts as distributions rather than fixed parameters, facilitating dynamic and adaptive prompt sampling. Extensive experiments demonstrate that our DPPD framework can achieve significant performance improvement on different image restoration tasks. Codes are available at our project page https://github.com/Aitical/DPPD.", "authors": ["Gang Wu", "Junjun Jiang", "Kui Jiang", "Xianming Liu", "Liqiang Nie"], "year": 2025, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 5, "type": "article", "concepts": ["Image restoration", "Computer science", "Computer vision", "Artificial intelligence", "Image processing"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4413147433", "doi": "https://doi.org/10.1109/cvpr52734.2025.01190", "title": "Complexity Experts are Task-Discriminative Learners for Any Image Restoration", "abstract": "Recent advancements in all-in-one image restoration models have revolutionized the ability to address diverse degradations through a unified framework. However, parameters tied to specific tasks often remain inactive for other tasks, making mixture-of-experts (MoE) architectures a natural extension. Despite this, MoEs often show inconsistent behavior, with some experts unexpectedly generalizing across tasks while others struggle within their intended scope. This hinders leveraging MoEs’ computational benefits by bypassing irrelevant experts during inference. We attribute this undesired behavior to the uniform and rigid architecture of traditional MoEs. To address this, we introduce “complexity experts” – flexible expert blocks with varying computational complexity and receptive fields. A key challenge is assigning tasks to each expert, as degradation complexity is unknown in advance. Thus, we execute tasks with a simple bias toward lower complexity. To our surprise, this preference effectively drives task-specific allocation, assigning tasks to experts with the appropriate complexity. Extensive experiments validate our approach, demonstrating the ability to bypass irrelevant experts during inference while maintaining superior performance. The proposed MoCE-IR model outperforms state-of-the-art methods, affirming its efficiency and practical applicability. The source code and models are publicly available at eduardzamfir.github.io/MoCE-IR/", "authors": ["Eduard Zamfir", "Zongwei Wu", "Nancy Mehta", "Yuedong Tan", "Danda Pani Paudel", "Yulun Zhang", "Radu Timofte"], "year": 2025, "venue": "", "cited_by_count": 11, "type": "article", "concepts": ["Discriminative model", "Computer science", "Task (project management)", "Artificial intelligence", "Image restoration"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4406110715", "doi": "https://doi.org/10.1109/access.2025.3526168", "title": "Always Clear Days: Degradation Type and Severity Aware All-in-One Adverse Weather Removal", "abstract": "All-in-one adverse weather removal is an emerging topic on image restoration, which aims to restore multiple weather degradations in a unified model, and the challenges are twofold. First, discover and handle the properties of the multi-domain in the target distribution formed by multiple weather conditions. Second, design efficient and effective operations for different degradations. To resolve this problem, most prior works focus on the multi-domain caused by different weather types. Inspired by inter&intra-domain adaptation literature, we observe that not only weather type but also weather severity introduce multi-domain within each weather type domain, which is ignored by previous methods and further limits their performance. To this end, we propose a degradation type and severity aware model, called UtilityIR, for blind all-in-one bad weather image restoration. To extract weather information from a single image, we propose a novel Marginal Quality Ranking Loss (MQRL) and utilize Contrastive Loss (CL) to guide weather severity and type extraction, and leverage a bag of novel techniques such as Multi-Head Cross Attention (MHCA) and Local-Global Adaptive Instance Normalization (LG-AdaIN) to efficiently restore spatial varying weather degradation. The proposed method can outperform the state-of-the-art methods subjectively and objectively on different weather removal tasks with a large margin, and enjoy fewer model parameters. The proposed method can even restore previously unseen combined multiple degradation images, and modulate restoration level. Implementation code and pre-trained weights will be available at https://github.com/fordevoted/UtilityIR.", "authors": ["Y.-T Chen", "Soo‐Chang Pei"], "year": 2025, "venue": "IEEE Access", "cited_by_count": 5, "type": "article", "concepts": ["Computer science", "Adverse weather", "Leverage (statistics)", "Domain adaptation", "Normalization (sociology)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4405488387", "doi": "https://doi.org/10.1109/tcsvt.2024.3519352", "title": "IPT-ILR: Image Pyramid Transformer Coupled With Information Loss Regularization for All-in-One Image Restoration", "abstract": "All-in-one image restoration has recently developed to be a new research trend in the low-level computer vision field, aiming to tackle multiple image degradation types simultaneously in a unified model. As a typical multi-task learning, existing approaches focus on modeling either the specificity or commonality among different image restoration tasks. To exploit the unique strengths of both worlds, we propose a method of Image Pyramid Transformer coupled with Information Loss Regularization (IPT-ILR), in which the multi-scale architecture structure can excavate more information for multiple restoration tasks concurrently, while the learning strategy can identify the difference among multiple restoration tasks depending on the degree of information loss in each restoration task. Specifically, it first establishes a new Image Pyramid Transformer Network (IPT-Network) to accommodate multiple image restoration tasks. Given original degraded images, the IPT-Network exploits the image pyramid technique to establish a series of images with different scales, which are then restored by transformer-like auto-encoders. Moreover, the restored image on a low-level scale is referenced to assist restoring the degraded image on a high-level scale. Next, Information Loss Regularization (ILR) is presented to optimize the IPT-Network. ILR calculates the average distance between degraded images and their clean counterparts as the weights, which automatically implement different penalties for different image restoration tasks, thus avoiding the short-cut phenomenon for the easy task while encouraging the hard task. Extensive experiments have been conducted with 6 image restoration tasks in the all-in-one setting. The results show our method performs favorably against numerous state-of-the-art methods across most tasks, including image denoising, image deblurring, image dehazing, image deraining, image desnowing, as well as low-light enhancement.", "authors": ["Sai Yang", "Bin Hu", "Fan Liu", "Xiaoxin Wu", "Weiping Ding", "Jun Zhou"], "year": 2024, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 4, "type": "article", "concepts": ["Image restoration", "Artificial intelligence", "Computer vision", "Computer science", "Regularization (linguistics)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2970227790", "doi": "https://doi.org/10.3233/jifs-179375", "title": "Medical image restoration method via multiple nonlocal prior constraints", "abstract": "Medical image restoration is a fundamental issue in the area of medical signal processing, which aims recove high quality medical image from its degradation observation. Recently, the methods with nonlocal self-similarity prior have led to a great improvement on many medical image restoration tasks. Nevertheless, the nonlocal technique is generally embedded with only one kind of constraint, such as sparsity or low-rank in the conventional model, which limits their abilities and show good performance on certain prior. To address this problem, in this paper, we present a novel medical image restoration method with multiple nonlocal-based prior regularizations. The surfacelet transformation is introduced to construct a cubic sparsity constraint to a group of nonlocal similar patches. Likewise, due to the self-similarity existed in the medical image, two extra kinds of nonlocal-based priors, nonlocal total variation and nonlocal weighted low-rank, are also exploited to constrain the local smoothness and nonlocal relationship jointly. In this way, each of the designed priors can well recover a group of patches with similar structure. And then, the designed priors are combined into a unified proposed optimization framework, which will obtain the advantages from all of them simultaneously. Finally, to solve the objective function in the proposed framework, we develop an iterative numerical scenario based on alternating direction multipliers method. The extensive experiments on test medical images demonstrate that our proposed model outperforms the comparison methods on both of visual quality and objective evaluation results.", "authors": ["Qidi Wu", "Yibing Li", "Yun Lin"], "year": 2019, "venue": "Journal of Intelligent & Fuzzy Systems", "cited_by_count": 7, "type": "article", "concepts": ["Prior probability", "Smoothness", "Computer science", "Image restoration", "Constraint (computer-aided design)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4406039833", "doi": "https://doi.org/10.1007/s10489-024-06226-y", "title": "RamIR: Reasoning and action prompting with Mamba for all-in-one image restoration", "abstract": "", "authors": ["A. H. Tang", "Yan Wu", "Yuwei Zhang"], "year": 2025, "venue": "Applied Intelligence", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Benchmark (surveying)", "Transformer", "Block (permutation group theory)", "Artificial intelligence"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2081278295", "doi": "https://doi.org/10.1371/journal.pone.0032366", "title": "Neutrophil Extracellular Traps Directly Induce Epithelial and Endothelial Cell Death: A Predominant Role of Histones", "abstract": "Neutrophils play an important role in innate immunity by defending the host organism against invading microorganisms. Antimicrobial activity of neutrophils is mediated by release of antimicrobial peptides, phagocytosis as well as formation of neutrophil extracellular traps (NET). These structures are composed of DNA, histones and granular proteins such as neutrophil elastase and myeloperoxidase. This study focused on the influence of NET on the host cell functions, particularly on human alveolar epithelial cells as the major cells responsible for gas exchange in the lung. Upon direct interaction with epithelial and endothelial cells, NET induced cytotoxic effects in a dose-dependent manner, and digestion of DNA in NET did not change NET-mediated cytotoxicity. Pre-incubation of NET with antibodies against histones, with polysialic acid or with myeloperoxidase inhibitor but not with elastase inhibitor reduced NET-mediated cytotoxicity, suggesting that histones and myeloperoxidase are responsible for NET-mediated cytotoxicity. Although activated protein C (APC) did decrease the histone-induced cytotoxicity in a purified system, it did not change NET-induced cytotoxicity, indicating that histone-dependent cytotoxicity of NET is protected against APC degradation. Moreover, in LPS-induced acute lung injury mouse model, NET formation was documented in the lung tissue as well as in the bronchoalveolar lavage fluid. These data reveal the important role of protein components in NET, particularly histones, which may lead to host cell cytotoxicity and may be involved in lung tissue destruction.", "authors": ["Mona Saffarzadeh", "Christiane Juenemann", "Markus A. Queisser", "Günter Lochnit", "Guillermo Barreto", "Sebastian P. Galuska", "Juergen Lohmeyer", "Klaus T. Preissner"], "year": 2012, "venue": "PLoS ONE", "cited_by_count": 1264, "type": "article", "concepts": ["Cytotoxicity", "Neutrophil extracellular traps", "Myeloperoxidase", "Neutrophil elastase", "Innate immune system"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W7126221274", "doi": "https://doi.org/10.48550/arxiv.2601.21592", "title": "Unifying Heterogeneous Degradations: Uncertainty-Aware Diffusion Bridge Model for All-in-One Image Restoration", "abstract": "All-in-One Image Restoration (AiOIR) faces the fundamental challenge in reconciling conflicting optimization objectives across heterogeneous degradations. Existing methods are often constrained by coarse-grained control mechanisms or fixed mapping schedules, yielding suboptimal adaptation. To address this, we propose an Uncertainty-Aware Diffusion Bridge Model (UDBM), which innovatively reformulates AiOIR as a stochastic transport problem steered by pixel-wise uncertainty. By introducing a relaxed diffusion bridge formulation which replaces the strict terminal constraint with a relaxed constraint, we model the uncertainty of degradations while theoretically resolving the drift singularity inherent in standard diffusion bridges. Furthermore, we devise a dual modulation strategy: the noise schedule aligns diverse degradations into a shared high-entropy latent space, while the path schedule adaptively regulates the transport trajectory motivated by the viscous dynamics of entropy regularization. By effectively rectifying the transport geometry and dynamics, UDBM achieves state-of-the-art performance across diverse restoration tasks within a single inference step.", "authors": ["Luwei Tu", "Jiawei Wu", "Xing Luo", "Zhi Jin"], "year": 2026, "venue": "arXiv (Cornell University)", "cited_by_count": 0, "type": "preprint", "concepts": ["Computer science", "Schedule", "Mathematical optimization", "Path (computing)", "Image restoration"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W3047104964", "doi": "https://doi.org/10.3390/pharmaceutics12080735", "title": "Skin Wound Healing Process and New Emerging Technologies for Skin Wound Care and Regeneration", "abstract": "Skin wound healing shows an extraordinary cellular function mechanism, unique in nature and involving the interaction of several cells, growth factors and cytokines. Physiological wound healing restores tissue integrity, but in many cases the process is limited to wound repair. Ongoing studies aim to obtain more effective wound therapies with the intention of reducing inpatient costs, providing long-term relief and effective scar healing. The main goal of this comprehensive review is to focus on the progress in wound medication and how it has evolved over the years. The main complications related to the healing process and the clinical management of chronic wounds are described in the review. Moreover, advanced treatment strategies for skin regeneration and experimental techniques for cellular engineering and skin tissue engineering are addressed. Emerging skin regeneration techniques involving scaffolds activated with growth factors, bioactive molecules and genetically modified cells are exploited to overcome wound healing technology limitations and to implement personalized therapy design.", "authors": ["Erika Maria Tottoli", "Rossella Dorati", "Ida Genta", "Enrica Chiesa", "Silvia Pisani", "Bice Conti"], "year": 2020, "venue": "Pharmaceutics", "cited_by_count": 1218, "type": "review", "concepts": ["Wound healing", "Regeneration (biology)", "Medicine", "Skin repair", "Wound care"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4291819654", "doi": "https://doi.org/10.1007/s11042-022-13644-y", "title": "Object detection using YOLO: challenges, architectural successors, datasets and applications", "abstract": "", "authors": ["Tausif Diwan", "G. Anirudh", "Jitendra V. Tembhurne"], "year": 2022, "venue": "Multimedia Tools and Applications", "cited_by_count": 1266, "type": "article", "concepts": ["Computer science", "Detector", "Object detection", "Artificial intelligence", "Inference"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4406347607", "doi": "https://doi.org/10.1016/j.engappai.2025.110017", "title": "Collaborative Semantic Contrastive for All-in-one Image Restoration", "abstract": "", "authors": ["Bin Hu", "Sai Yang", "Fan Liu", "Weiping Ding"], "year": 2025, "venue": "Engineering Applications of Artificial Intelligence", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Image (mathematics)", "Natural language processing", "Artificial intelligence", "Information retrieval"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2914911817", "doi": "https://doi.org/10.1145/3474085", "title": "Proceedings of the 29th ACM International Conference on Multimedia", "abstract": "Recently deep neural networks (DNNs) have achieved significant success in\\nreal-world image super-resolution (SR). However, adversarial image samples with\\nquasi-imperceptible noises could threaten deep learning SR models. In this\\npaper, we propose a robust deep learning framework for real-world SR that\\nrandomly erases potential adversarial noises in the frequency domain of input\\nimages or features. The rationale is that on the SR task clean images or\\nfeatures have a different pattern from the attacked ones in the frequency\\ndomain. Observing that existing adversarial attacks usually add high-frequency\\nnoises to input images, we introduce a novel random frequency mask module that\\nblocks out high-frequency components possibly containing the harmful\\nperturbations in a stochastic manner. Since the frequency masking may not only\\ndestroys the adversarial perturbations but also affects the sharp details in a\\nclean image, we further develop an adversarial sample classifier based on the\\nfrequency domain of images to determine if applying the proposed mask module.\\nBased on the above ideas, we devise a novel real-world image SR framework that\\ncombines the proposed frequency mask modules and the proposed adversarial\\nclassifier with an existing super-resolution backbone network. Experiments show\\nthat our proposed method is more insensitive to adversarial attacks and\\npresents more stable SR results than existing models and defenses.\\n", "authors": ["Jiutao Yue", "Haofeng Li", "Pengxu Wei", "Guanbin Li", "Liang Lin"], "year": 2021, "venue": "", "cited_by_count": 922, "type": "paratext", "concepts": ["Computer science", "Face (sociological concept)", "Multimedia", "Downtown", "Coronavirus disease 2019 (COVID-19)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4413146948", "doi": "https://doi.org/10.1109/cvpr52734.2025.02623", "title": "Degradation-Aware Feature Perturbation for All-in-One Image Restoration", "abstract": "All-in-one image restoration aims to recover clear images from various degradation types and levels with a unified model. Nonetheless, the significant variations among degradation types present challenges for training a universal model, often resulting in task interference, where the gradient update directions of different tasks may diverge due to shared parameters. To address this issue, motivated by the routing strategy, we propose DFPIR, a novel all-in-one image restorer that introduces Degradation-aware Feature Perturbations(DFP) to adjust the feature space to align with the unified parameter space. In this paper, the feature perturbations primarily include channel-wise perturbations and attention-wise perturbations. Specifically, channel-wise perturbations are implemented by shuffling the channels in high-dimensional space guided by degradation types, while attention-wise perturbations are achieved through selective masking in the attention space. To achieve these goals, we propose a Degradation-Guided Perturbation Block (DGPB) to implement these two functions, positioned between the encoding and decoding stages of the encoder-decoder architecture. Extensive experimental results demonstrate that DFPIR achieves state-of-the-art performance on several all-in-one image restoration tasks including image denoising, image dehazing, image deraining, motion deblurring, and low-light image enhancement. Our codes are available at https://github.com/TxpHome/DFPIR.", "authors": ["Xiangpeng Tian", "Xiangyu Liao", "Xiao Liu", "Meng Li", "Chao Ren"], "year": 2025, "venue": "", "cited_by_count": 2, "type": "article", "concepts": ["Image restoration", "Degradation (telecommunications)", "Perturbation (astronomy)", "Computer science", "Feature (linguistics)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4415970876", "doi": "https://doi.org/10.1109/tcsvt.2025.3629686", "title": "Diff-Restorer: Unleashing Visual Prompts for Diffusion-based Universal Image Restoration", "abstract": "Image restoration aims to recover high-quality images from degraded observations, yet real-world degradations are complex, coupled, and difficult to model. Existing task-specific methods struggle to generalize beyond predefined degradation types, while recent all-in-one or prompt-based methods still face three key challenges: (1) they rely on task-specific training or fixed prompt pools, limiting adaptability to real-world and mixed degradations; (2) human-instruction or implicit-prompt mechanisms make them difficult to use in practice; and (3) they often fail to balance structural fidelity and perceptual realism. To address these issues, we propose Diff-Restorer, a diffusion-based universal image restoration framework that unifies diverse degradation handling within a single model. Diff-Restorer adaptively extracts decoupled visual prompts from a visual-language model (CLIP), including clear semantic and degradation embeddings. The clear semantic embeddings serve as content prompts to guide the diffusion model for generation, improving perceptual quality. The degradation embeddings as the task identifier modulate the Image-guided Control Module to generate structure control, ensuring faithfulness. Furthermore, we design a Task-aware Decoder to perform structural correction and convert the latent code to the pixel domain. Extensive experiments on various single, real-world, and mixed degradation tasks show that Diff-Restorer outperforms state-of-the-art methods in terms of generality, realism, and fidelity.", "authors": ["Yuhong Zhang", "Hengsheng Zhang", "Xinning Chai", "Zhengxue Cheng", "Rong Xie", "Li Song", "Wenjun Zhang"], "year": 2025, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 3, "type": "article", "concepts": [], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4415535463", "doi": "https://doi.org/10.1145/3746027.3758196", "title": "WeatherBench: A Real-World Benchmark Dataset for All-in-One Adverse Weather Image Restoration", "abstract": "Existing all-in-one image restoration approaches, which aim to handle multiple weather degradations within a single framework, are predominantly trained and evaluated using mixed single-weather synthetic datasets. However, these datasets often differ significantly in resolution, style, and domain characteristics, leading to substantial domain gaps that hinder the development and fair evaluation of unified models. Furthermore, the lack of a large-scale, real-world all-in-one weather restoration dataset remains a critical bottleneck in advancing this field. To address these limitations, we present a real-world all-in-one adverse weather image restoration benchmark dataset, which contains image pairs captured under various weather conditions, including rain, snow, and haze, as well as diverse outdoor scenes and illumination settings. The resulting dataset provides precisely aligned degraded and clean images, enabling supervised learning and rigorous evaluation. We conduct comprehensive experiments by benchmarking a variety of task-specific, task-general, and all-in-one restoration methods on our dataset. Our dataset offers a valuable foundation for advancing robust and practical all-in-one image restoration in real-world scenarios. The dataset has been publicly released and is available at https://github.com/guanqiyuan/WeatherBench.", "authors": ["Qiyuan Guan", "Qianfeng Yang", "Xiang Chen", "Tianyu Song", "Guiyue Jin", "Jiyu Jin"], "year": 2025, "venue": "", "cited_by_count": 2, "type": "article", "concepts": [], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2735224642", "doi": "https://doi.org/10.1109/cvprw.2017.151", "title": "Enhanced Deep Residual Networks for Single Image Super-Resolution", "abstract": "Recent research on super-resolution has progressed with the development of deep convolutional neural networks (DCNN). In particular, residual learning techniques exhibit improved performance. In this paper, we develop an enhanced deep super-resolution network (EDSR) with performance exceeding those of current state-of-the-art SR methods. The significant performance improvement of our model is due to optimization by removing unnecessary modules in conventional residual networks. The performance is further improved by expanding the model size while we stabilize the training procedure. We also propose a new multi-scale deep super-resolution system (MDSR) and training method, which can reconstruct high-resolution images of different upscaling factors in a single model. The proposed methods show superior performance over the state-of-the-art methods on benchmark datasets and prove its excellence by winning the NTIRE2017 Super-Resolution Challenge.", "authors": ["Bee Lim", "Sanghyun Son", "Heewon Kim", "Seungjun Nah", "Kyoung Mu Lee"], "year": 2017, "venue": "", "cited_by_count": 614, "type": "preprint", "concepts": ["Residual", "Benchmark (surveying)", "Convolutional neural network", "Deep learning", "Computer science"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4309673498", "doi": "https://doi.org/10.1038/s41392-022-01229-y", "title": "Copper homeostasis and cuproptosis in health and disease", "abstract": "As an essential micronutrient, copper is required for a wide range of physiological processes in virtually all cell types. Because the accumulation of intracellular copper can induce oxidative stress and perturbing cellular function, copper homeostasis is tightly regulated. Recent studies identified a novel copper-dependent form of cell death called cuproptosis, which is distinct from all other known pathways underlying cell death. Cuproptosis occurs via copper binding to lipoylated enzymes in the tricarboxylic acid (TCA) cycle, which leads to subsequent protein aggregation, proteotoxic stress, and ultimately cell death. Here, we summarize our current knowledge regarding copper metabolism, copper-related disease, the characteristics of cuproptosis, and the mechanisms that regulate cuproptosis. In addition, we discuss the implications of cuproptosis in the pathogenesis of various disease conditions, including Wilson's disease, neurodegenerative diseases, and cancer, and we discuss the therapeutic potential of targeting cuproptosis.", "authors": ["Liyun Chen", "Junxia Min", "Fudi Wang"], "year": 2022, "venue": "Signal Transduction and Targeted Therapy", "cited_by_count": 1246, "type": "review", "concepts": ["Homeostasis", "Disease", "Medicine", "Computational biology", "Biology"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2275204317", "doi": "https://doi.org/10.1161/circresaha.115.306301", "title": "Endothelial Cell Dysfunction and the Pathobiology of Atherosclerosis", "abstract": "Dysfunction of the endothelial lining of lesion-prone areas of the arterial vasculature is an important contributor to the pathobiology of atherosclerotic cardiovascular disease. Endothelial cell dysfunction, in its broadest sense, encompasses a constellation of various nonadaptive alterations in functional phenotype, which have important implications for the regulation of hemostasis and thrombosis, local vascular tone and redox balance, and the orchestration of acute and chronic inflammatory reactions within the arterial wall. In this review, we trace the evolution of the concept of endothelial cell dysfunction, focusing on recent insights into the cellular and molecular mechanisms that underlie its pivotal roles in atherosclerotic lesion initiation and progression; explore its relationship to classic, as well as more recently defined, clinical risk factors for atherosclerotic cardiovascular disease; consider current approaches to the clinical assessment of endothelial cell dysfunction; and outline some promising new directions for its early detection and treatment.", "authors": ["Michael A. Gimbrone", "Guillermo García‐Cardeña"], "year": 2016, "venue": "Circulation Research", "cited_by_count": 3226, "type": "review", "concepts": ["Endothelial dysfunction", "Disease", "Endothelial stem cell", "Hemostasis", "Endothelium"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W1984020445", "doi": "https://doi.org/10.1109/access.2014.2325029", "title": "Big Data Deep Learning: Challenges and Perspectives", "abstract": "Deep learning is currently an extremely active research area in machine learning and pattern recognition society. It has gained huge successes in a broad area of applications such as speech recognition, computer vision, and natural language processing. With the sheer size of data available today, big data brings big opportunities and transformative potential for various sectors; on the other hand, it also presents unprecedented challenges to harnessing data and information. As the data keeps getting bigger, deep learning is coming to play a key role in providing big data predictive analytics solutions. In this paper, we provide a brief overview of deep learning, and highlight current research efforts and the challenges to big data, as well as the future trends.", "authors": ["Xuewen Chen", "Xiaotong Lin"], "year": 2014, "venue": "IEEE Access", "cited_by_count": 1245, "type": "article", "concepts": ["Big data", "Transformative learning", "Deep learning", "Computer science", "Data science"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2064036807", "doi": "https://doi.org/10.1038/ng1429", "title": "Nonsense surveillance regulates expression of diverse classes of mammalian transcripts and mutes genomic noise", "abstract": "", "authors": ["Joshua T. Mendell", "Neda Sharifi", "Jennifer Meyers", "Francisco Martínez-Murillo", "Harry C. Dietz"], "year": 2004, "venue": "Nature Genetics", "cited_by_count": 863, "type": "article", "concepts": ["Nonsense-mediated decay", "Biology", "Genetics", "Intron", "Upstream open reading frame"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2792805849", "doi": "https://doi.org/10.1161/circresaha.117.311586", "title": "Diabetic Cardiomyopathy", "abstract": "Heart failure and related morbidity and mortality are increasing at an alarming rate, in large part, because of increases in aging, obesity, and diabetes mellitus. The clinical outcomes associated with heart failure are considerably worse for patients with diabetes mellitus than for those without diabetes mellitus. In people with diabetes mellitus, the presence of myocardial dysfunction in the absence of overt clinical coronary artery disease, valvular disease, and other conventional cardiovascular risk factors, such as hypertension and dyslipidemia, has led to the descriptive terminology, diabetic cardiomyopathy. The prevalence of diabetic cardiomyopathy is increasing in parallel with the increase in diabetes mellitus. Diabetic cardiomyopathy is initially characterized by myocardial fibrosis, dysfunctional remodeling, and associated diastolic dysfunction, later by systolic dysfunction, and eventually by clinical heart failure. Impaired cardiac insulin metabolic signaling, mitochondrial dysfunction, increases in oxidative stress, reduced nitric oxide bioavailability, elevations in advanced glycation end products and collagen-based cardiomyocyte and extracellular matrix stiffness, impaired mitochondrial and cardiomyocyte calcium handling, inflammation, renin-angiotensin-aldosterone system activation, cardiac autonomic neuropathy, endoplasmic reticulum stress, microvascular dysfunction, and a myriad of cardiac metabolic abnormalities have all been implicated in the development and progression of diabetic cardiomyopathy. Molecular mechanisms linked to the underlying pathophysiological changes include abnormalities in AMP-activated protein kinase, peroxisome proliferator-activated receptors, O-linked N-acetylglucosamine, protein kinase C, microRNA, and exosome pathways. The aim of this review is to provide a contemporary view of these instigators of diabetic cardiomyopathy, as well as mechanistically based strategies for the prevention and treatment of diabetic cardiomyopathy.", "authors": ["Guanghong Jia", "Michael A. Hill", "James R. Sowers"], "year": 2018, "venue": "Circulation Research", "cited_by_count": 1691, "type": "review", "concepts": ["Medicine", "Diabetic cardiomyopathy", "Internal medicine", "Heart failure", "Diabetes mellitus"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4393946425", "doi": "https://doi.org/10.48550/arxiv.2404.02154", "title": "Dynamic Pre-training: Towards Efficient and Scalable All-in-One Image Restoration", "abstract": "All-in-one image restoration tackles different types of degradations with a unified model instead of having task-specific, non-generic models for each degradation. The requirement to tackle multiple degradations using the same model can lead to high-complexity designs with fixed configuration that lack the adaptability to more efficient alternatives. We propose DyNet, a dynamic family of networks designed in an encoder-decoder style for all-in-one image restoration tasks. Our DyNet can seamlessly switch between its bulkier and lightweight variants, thereby offering flexibility for efficient model deployment with a single round of training. This seamless switching is enabled by our weights-sharing mechanism, forming the core of our architecture and facilitating the reuse of initialized module weights. Further, to establish robust weights initialization, we introduce a dynamic pre-training strategy that trains variants of the proposed DyNet concurrently, thereby achieving a 50% reduction in GPU hours. Our dynamic pre-training strategy eliminates the need for maintaining separate checkpoints for each variant, as all models share a common set of checkpoints, varying only in model depth. This efficient strategy significantly reduces storage overhead and enhances adaptability. To tackle the unavailability of large-scale dataset required in pre-training, we curate a high-quality, high-resolution image dataset named Million-IRD, having 2M image samples. We validate our DyNet for image denoising, deraining, and dehazing in all-in-one setting, achieving state-of-the-art results with 31.34\\% reduction in GFlops and a 56.75\\% reduction in parameters compared to baseline models. The source codes and trained models are available at https://github.com/akshaydudhane16/DyNet.", "authors": ["Akshay Dudhane", "Omkar Thawakar", "Syed Waqas Zamir", "Salman Khan", "Fahad Shahbaz Khan", "Ming–Hsuan Yang"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 2, "type": "preprint", "concepts": ["Training (meteorology)", "Scalability", "Computer science", "Image (mathematics)", "Image restoration"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W3127839532", "doi": "https://doi.org/10.1038/s41392-020-00428-9", "title": "Ferroptosis: mechanisms and links with diseases", "abstract": "Ferroptosis is an iron-dependent cell death, which is different from apoptosis, necrosis, autophagy, and other forms of cell death. The process of ferroptotic cell death is defined by the accumulation of lethal lipid species derived from the peroxidation of lipids, which can be prevented by iron chelators (e.g., deferiprone, deferoxamine) and small lipophilic antioxidants (e.g., ferrostatin, liproxstatin). This review summarizes current knowledge about the regulatory mechanism of ferroptosis and its association with several pathways, including iron, lipid, and cysteine metabolism. We have further discussed the contribution of ferroptosis to the pathogenesis of several diseases such as cancer, ischemia/reperfusion, and various neurodegenerative diseases (e.g., Alzheimer's disease and Parkinson's disease), and evaluated the therapeutic applications of ferroptosis inhibitors in clinics.", "authors": ["Hong-Fa Yan", "Ting Zou", "Qing‐zhang Tuo", "Shuo Xu", "Hua Li", "Abdel Ali Belaidi", "Peng Lei"], "year": 2021, "venue": "Signal Transduction and Targeted Therapy", "cited_by_count": 1334, "type": "review", "concepts": ["Programmed cell death", "Autophagy", "Apoptosis", "Lipid peroxidation", "Deferoxamine"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2895357007", "doi": "https://doi.org/10.1101/gad.314617.118", "title": "Roles of the immune system in cancer: from tumor initiation to metastatic progression", "abstract": "The presence of inflammatory immune cells in human tumors raises a fundamental question in oncology: How do cancer cells avoid the destruction by immune attack? In principle, tumor development can be controlled by cytotoxic innate and adaptive immune cells; however, as the tumor develops from neoplastic tissue to clinically detectable tumors, cancer cells evolve different mechanisms that mimic peripheral immune tolerance in order to avoid tumoricidal attack. Here, we provide an update of recent accomplishments, unifying concepts, and future challenges to study tumor-associated immune cells, with an emphasis on metastatic carcinomas.", "authors": ["Hugo González", "Catharina Hagerling", "Zena Werb"], "year": 2018, "venue": "Genes & Development", "cited_by_count": 2085, "type": "review", "concepts": ["Immune system", "Biology", "Cancer", "Cytotoxic T cell", "Cancer research"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2768033029", "doi": "https://doi.org/10.1083/jcb.201708092", "title": "Senescence and aging: Causes, consequences, and therapeutic avenues", "abstract": "Aging is the major risk factor for cancer, cardiovascular disease, diabetes, and neurodegenerative disorders. Although we are far from understanding the biological basis of aging, research suggests that targeting the aging process itself could ameliorate many age-related pathologies. Senescence is a cellular response characterized by a stable growth arrest and other phenotypic alterations that include a proinflammatory secretome. Senescence plays roles in normal development, maintains tissue homeostasis, and limits tumor progression. However, senescence has also been implicated as a major cause of age-related disease. In this regard, recent experimental evidence has shown that the genetic or pharmacological ablation of senescent cells extends life span and improves health span. Here, we review the cellular and molecular links between cellular senescence and aging and discuss the novel therapeutic avenues that this connection opens.", "authors": ["Domhnall McHugh", "Jesús Gil"], "year": 2017, "venue": "The Journal of Cell Biology", "cited_by_count": 1184, "type": "review", "concepts": ["Senescence", "Disease", "Biology", "Cellular senescence", "Cancer"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W1977276601", "doi": "https://doi.org/10.1111/j.1442-8903.2006.00285.x", "title": "The meanings of vegetation condition", "abstract": "The meanings of vegetation condition. David Keith1 and Emma Gorrod1,2 (NSW Department of Environment & Conservation, PO Box 1967, Hurstville, NSW 2220. Tel.: (02) 9585 6498; Fax: (02) 9585 6606; E-mail: [email protected]; 2Botany Department, University of Melbourne, Parkville Vic. 3052, Australia). Key words: biodiversity conservation, conservation policy, natural resource management, uncertainty, vegetation assessment. Introduction. ‘Vegetation condition’ is a concept that has rapidly gained currency in recent land management policy within Australia. Recent applications of the concept have been developed to assist decision-making for incentive payments, clearing approvals and offset actions in the management of native vegetation. In general terms, ‘condition’ means state of being or health. When applied in biology at the scale of individuals, it refers to fitness – the ability of an individual to survive and reproduce (Begon et al. 1986). Coops et al. (2004) provide an example of such an application in which the health of eucalypt trees is assessed using a spectral reflectance algorithm. At higher levels of organization (communities, ecosystems, landscapes), the ecological meaning of ‘condition’ is less clear. We argue that confusion is at least in part due to historical legacies that have led to independent development and use of the term in several related, but different, ecological concepts. Like ‘rarity’, ‘condition’ has gained currency as one term with many meanings (Harper 1981), which is implicit within much policy and management discourse about vegetation condition (Thackway et al. 2005). In this note, we identify three main meanings of vegetation condition that are derived from the concepts of aesthetics, production and biodiversity. We briefly review these meanings with examples and discuss their interrelationships. We conclude that confusion about what ‘good condition’ means for contemporary management of native vegetation can be reduced with: (i) more explicit explanations accompanying usage of the term; (ii) further development of the condition concept to deal with the multidimensional properties of biodiversity; and (iii) explicit links to more robust models of vegetation dynamics than those currently implicit within assessments. Aesthetics, production and biodiversity. Aesthetic values derive from human perceptions about what makes ‘a good patch of bush’. These perceptions are, by definition, subjective and likely to vary between people and with landscape context. Nevertheless, scientific approaches to evaluation of natural aesthetic values have been developed for such purposes as heritage listing (UNESCO 2005) and wilderness identification (Lesslie & Maslen 1995). The concept of naturalness is central to both of these applications (Kirkpatrick & Haney 1980), and an area with high naturalness values may be considered aesthetically to be in ‘good condition’. An assessment methodology proposed by Lesslie et al. (1988) considers two forms of naturalness that are inversely related to the impact of human activities. One of these (aesthetic naturalness) is dependent on the presence of modern human structures, such as fences, tracks, dams, buildings, etc., and the other (biophysical naturalness) is dependent on the history and intensity of human land uses or their effects, such as logging, grazing, weed invasion, etc. These attributes may be mapped using distance functions, remote sensing, tenure data and historical information, which may be synthesized in GIS applications to calculate naturalness values across a landscape (e.g. Lesslie et al. 1988). Although these assessment methodologies were developed for landscapes containing large natural areas, some of the principles are also applicable to finer scales. Relevant indicators of human disturbance, such as cut stumps, fences, tracks, soil compaction, etc., may be used to assess the naturalness of remnant patches. More generally, comparative approaches may be used to assess the aesthetic values of native vegetation by comparing particular sites with reference examples or ‘benchmarks’ that define one or more levels of aesthetic value. Production values derive from the ability of native vegetation to deliver resources for human consumption. A patch of native vegetation may be considered to be in ‘good condition’ if it maintains a high capacity to produce resources such as livestock, timber, water, and other ‘ecosystem services’ (Heal 2000). The scientific basis for assessing these values derives from a long tradition in agriculture, particularly for the assessment of pasture condition. Landscape Function Analysis (Ludwig & Tongway 1992) provides an example of condition assessment with a strong theoretical basis and well-developed practical methodologies. The approach was originally developed in arid and semiarid rangelands used as native pastures for livestock production. Its central concept is based on the capacity of land to retain resources that are essential for plant growth, particularly water, soils and their nutrients. Assessments are focused on surface features (such as cover of perennial plants, soil lichens, leaf litter and woody debris) that interrupt, divert or absorb runoff and transported materials, and hence reduce loss of resources. Sites and landscapes with an abundance of such features are in ‘good condition’, able to sustain production of fodder and are relatively robust to degradation during drought or heavy rain. Landscape function, hence condition, may be degraded by overgrazing, which reduces the abundance of critical surface features and the capacity of the land to retain resources and sustain livestock. Assessments of rangeland condition therefore provide important guidance for sustainable management of livestock grazing. Methodologies are available for site-level assessments (Ludwig & Tongway 1992) and landscape scales using satellite image analysis and modelling of grazing halos around watering points (Bastin & Ludwig 2006). Biodiversity values in part relate to the capacity of native vegetation to sustain local populations of native plants and animals (as well as their genetic diversity and ecological interactions). ‘Good condition’ in this sense is related to high carrying capacity from population theory or high ‘habitat quality’ (Begon et al. 1986). However, unlike these species-specific parameters, the concept of condition for biodiversity applies to all species that may be reasonably expected to use a site (Parkes et al. 2003). Because the habitat requirements of all species are not known, assessment methods are based on surrogates that represent habitat features for some better-known groups of species (e.g. density of large trees), as well as features that, conversely, are indicators of habitat degradation for certain groups of species (e.g. weed abundance). Available site assessment methods (e.g. Gibbons & Freudenberger 2006) differ in their weightings for different attributes, as well as the mathematical details of index calculation. These variations could influence the performance of alternative methods for different biotic groups and habitats. Recent approaches incorporate reference or benchmark values in the assessment to standardize assessments across different types of habitat. Landscape-scale approaches for assessing the biodiversity component of vegetation condition based on remote sensing and spatial modelling are currently under development (e.g. Newell et al. 2006). Confusion in the usage of ‘condition’. Each of the three main facets of vegetation condition share commonalities. For example, in forest and woodland vegetation, large trees contribute to aesthetic value through visual splendour; they contribute to production value if they represent a timber resource and also to biodiversity value by providing habitat for a variety of organisms. An abundance of large trees should therefore be an indicator of good condition across a range of value types. On the other hand, each facet of condition has unique elements that are not shared by others. Tree hollows of a particular size and configuration confer biodiversity value through provision of habitat for particular tree-dwelling vertebrates, but might be negatively related to production value if they render the timber unusable. Thus, any given patch in a landscape may have any combination of high and low values for each of the three components (Fig. 1). Diagrammatic representation of the ‘condition space’ for areas of native vegetation. Site 1 has high values for all three components. Site 2 has high values for production and biodiversity components, but low aesthetic value. Site 3 has low values for all three components. The space that may be identified as vegetation in ‘good condition’ is discussed in the text. Confusion may emerge when different meanings of condition are applied to the values represented in Figure 1. For example, some may interpret a site as being in ‘good condition’ only if it contains high values for each of the aesthetic, production and biodiversity components. Others may interpret a site as being in ‘good condition’ if it contains high values for any one of the three components. Still others may interpret a site as being in ‘good condition’ if it contains high values for one particular component (e.g. aesthetic), irrespective of its values for other components (production and biodiversity). Further scope for confusion emerges when one considers that aesthetic, production and biodiversity values are each comprised of a number of components that may not be well correlated with one another. These simple examples illustrate what Regan et al. (2002) defined as ambiguity – a form of uncertainty in which a term may have more than one meaning. We contend that ambiguity, along with underspecificity, context-dependence, vagueness and other forms of linguistic uncertainty (Regan et al. 2002), are pervasive in both the assessment and planning dialogue for vegetation condition. If the condition concept is to be used effectively in decision support, linguistic uncertainty needs to be reduced by articulating explicitly the scope, context and meaning of ‘condition’ in each application. Beyond semantics: Conceptual difficulties and further development. Although more disciplined usage would benefit practical applications of the term, more fundamental problems stem from the efficacy of ‘condition’ as a model of vegetation state and change. At the heart of its use in policy and management is the presumption that vegetation condition represents a generalized measure of ecosystem function and habitat suitability for native biota, which varies along a dynamic continuum of degradation and restoration. The underlying model of change is implicitly Clementsian (Begon et al. 1986), and has been subject to little scientific scrutiny. One of the main difficulties in applying a concept of vegetation condition stems from its univariate property – condition varies on a single scale from ‘good’ to ‘poor’. The univariate property of condition does not sit well with its common interpretation, which demands generalization across multiple values that may not be well correlated with one another. This is especially evident for biodiversity, which comprises many species with habitat requirements that may be poorly correlated or inversely correlated with one another – what may be good habitat for one species may be poor for another. The possible reduction of suitable habitat (open grassland) for the endangered Plains Wanderer (Pedionomus torquatus) in response to exclusion of grazing required to encourage regeneration of Myall (Acacia pendula) Woodland, also endangered, is a case in point (NPWS 2002). In general, the nature of these correlations within habitat types is poorly understood, but is crucial to understanding the dynamics of degradation, regeneration and restoration in vegetation. Further theoretical development of the condition concept is needed to overcome these practical difficulties. In particular, vegetation condition for biodiversity is in need of a theory of dynamics that unifies its components and defines ecological processes that mediate vegetation change. It is noteworthy that applications of the condition concept that have a strong theoretical basis, including the Eucalypt Canopy Condition Index (Coops et al. 2004) and Landscape Function Analysis (Ludwig & Tongway 1992), deal with established causal links between indicators and a univariate response (leaf productivity and soil productivity, respectively). Existing models of succession and diversity (Connell & Slatyer 1977; Westoby et al. 1989; Silvertown 2004) provide some guidance for future development of the condition concept and represent a considerable advance on simplistic Clementsian thinking that underpins current policies aimed at improving biodiversity values across landscapes.", "authors": ["David A. Keith", "Emma Gorrod"], "year": 2006, "venue": "Ecological Management & Restoration", "cited_by_count": 27, "type": "article", "concepts": ["Vegetation (pathology)", "Clearing", "Payment", "Meaning (existential)", "Incentive"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4226042837", "doi": "https://doi.org/10.1609/aaai.v36i2.20072", "title": "Image-Adaptive YOLO for Object Detection in Adverse Weather Conditions", "abstract": "Though deep learning-based object detection methods have achieved promising results on the conventional datasets, it is still challenging to locate objects from the low-quality images captured in adverse weather conditions. The existing methods either have difficulties in balancing the tasks of image enhancement and object detection, or often ignore the latent information beneficial for detection. To alleviate this problem, we propose a novel Image-Adaptive YOLO (IA-YOLO) framework, where each image can be adaptively enhanced for better detection performance. Specifically, a differentiable image processing (DIP) module is presented to take into account the adverse weather conditions for YOLO detector, whose parameters are predicted by a small convolutional neural network (CNN-PP). We learn CNN-PP and YOLOv3 jointly in an end-to-end fashion, which ensures that CNN-PP can learn an appropriate DIP to enhance the image for detection in a weakly supervised manner. Our proposed IA-YOLO approach can adaptively process images in both normal and adverse weather conditions. The experimental results are very encouraging, demonstrating the effectiveness of our proposed IA-YOLO method in both foggy and low-light scenarios. The source code can be found at https://github.com/wenyyu/Image-Adaptive-YOLO.", "authors": ["Wenyu Liu", "Gaofeng Ren", "Runsheng Yu", "Shi Guo", "Jianke Zhu", "Lei Zhang"], "year": 2022, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 496, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Object detection", "Convolutional neural network", "Code (set theory)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2004936701", "doi": "https://doi.org/10.1097/01.blo.0000175122.50804.ce", "title": "Local Antibiotic Delivery Systems", "abstract": "The use of local antibiotic delivery systems has become an accepted treatment method that continues to evolve for a variety of reasons. There has been an explosion of new technologies that are designed to facilitate the delivery of local antibiotics in new and creative ways. The primary reason for using these local antibiotic delivery vehicles is the ability to achieve very high local concentrations of antibiotics without associated systemic toxicity. In the typical infected wound environment, which frequently has zones of avascularity, the ability to achieve high levels of antibiotics in these otherwise inaccessible areas is highly desirable.5 Additional reasons for use of these delivery vehicles include the desire to treat remaining planktonic organisms and sessile organisms in biofilms more effectively with high concentrations of antibiotics. Because bone regeneration often is required as a part of the treatment plan, a recent trend has been simultaneously to provide a framework of osteoinductive and osteoconductive materials along with antibiotic delivery.11 Despite the rapid acceptance of these antibiotic delivery vehicles, there are many unanswered questions related to their use, particularly when viewed within the environment of biofilms that were discussed in this symposium. Some of the questions discussed are outlined below. How high do we need to get the concentration of these antibiotics and what is the desirable duration of these high levels? What are the adverse clinical consequences of extremely high levels of antibiotics, particularly at the local level and specifically with regard to the process of bone regeneration? Are new and creative dosing regimens required with multiple combinations of antibiotics to address unique patterns of resistance associated with biofilms? Can the traditional methods of assessing antimicrobial susceptibility of pathogenic organisms be extrapolated to the efficacy obtained with these high concentrations of antibiotics? What types of models are required to study the efficacy of antibiotics on sessile organisms contained within biofilms? Are there nonantimicrobial options to consider that can augment the efficacy of current antimicrobials? And finally, how do clinical investigators actively use these new concepts and rapidly changing technologies when the burdens of federal regulation seem to prevent their use? High Local Antibiotic Concentrations Local antibiotic delivery vehicles are capable of achieving extremely high local tissue concentrations when compared with the antibiotic tissue levels obtained with traditional systemic antibiotic therapy. Antibiotic concentrations with local antibiotic delivery vehicles that reach levels of 3800 μg/mL21 and 4746 μg/mL24 have been reported. Although the symposia participants all agreed that the higher levels obtained with local delivery seem desirable and present the potential for improved efficacy, it was recognized that very little data are available to determine the optimal level of these antibiotics that are required for efficacy against these pathogenic organisms. The optimal antibiotic concentration likely is to be variable depending on the characteristics of the organism, the organism’s bioenvironment, and the specific antibiotic being used. One of the most obvious concerns regarding extremely high levels of local antibiotics is the potential for systemic toxicity, particularly in patients with abnormal renal function. Although there is considerable clinical experience to suggest that systemic toxicity associated with the use of high-dose antibiotic-loaded cement (ABLC) spacers is relatively rare, this remains a notable concern.32 One of the reasons for this concern is the inability to control the variables of antibiotic elution accurately in the postsurgical wound environment. The potential exists for large depots of antibiotics to be released erratically as a result of unexpected degradation patterns with newer biodegradable delivery vehicles. The concern regarding extremely high concentrations of local antibiotics particularly is valid in the face of dose-dependant, adverse consequences of bone regeneration with many currently used antibiotics.15,16,17,18,22 The need to profile the advantages of increasing higher doses of antibiotics must be balanced with the adverse effects of each specific antibiotic so that dosing regimens can be created and understood. It is also recognized that the antibiotic release characteristics of the various delivery systems need to be documented carefully so that the antibiotic concentrations that are achieved are known when these implants are used in vivo. Biofilms It is well recognized that biofilms play an important role in many chronic bacterial infections.6,13 Using tools such as the scanning electron microscope and the confocal laser scanning microscope, it is now understood that biofilms are not unstructured, homogeneous deposits of cells and accumulated slime, but complex communities of surface-associated cells enclosed in a polymer matrix containing open water channels.9 Current intervention strategies against biofilm infections are designed to prevent initial device colonization, to minimize microbial cell attachment to the device, and to penetrate or to disrupt the biofilm matrix to kill the associated cells.9 One of the most effective strategies to deal with biofilms in orthopaedic infection has been to remove the affected device or tissue that harbors the biofilm completely.13 The diagnostic and therapeutic strategies developed for acute bacterial diseases have not yielded accurate data or favorable outcomes when applied to these biofilm diseases.6 Bacteria residing within the biofilms (sessile) are less susceptible to antimicrobial agents than free-living (planktonic) cells. It is also known that young sessile cells are not as resistant to therapy as are older sessile cells associated with chronic infection.2 Several mechanisms have been proposed to explain this phenomenon of resistance within biofilms. Sessile bacteria may survive antibiotic exposure because of delayed penetration of the antimicrobial into the biofilm, marked slowing of growth rate of organisms within biofilms, but also because of an increased frequency of resistance traits within these sessile organisms.7,8 Practical implications of the altered response of sessile organisms within biofilm is that alternative strategies must be devised for susceptibility testing of these organisms and that new antimicrobial dosing regimens may be required to treat organisms within biofilms. Some of the possibilities include using higher concentrations of antibiotic, combination antimicrobial therapy that creates synergy,25 repetitive pulsing of antibiotic delivery,6 and nonantimicrobial strategies that disrupt the biofilm or augment the response of antibiotics against organisms contained within the extracellular matrix.9 These antibiotic delivery strategies need to be developed within the context of known information because simply increasing the concentration of antibiotics may be illogical in some circumstances. For example, cell-wall active antibiotics, such as vancomycin, would not be expected to be very effective against sessile organisms within biofilm, which exhibit a reduced growth rate, and indeed it has been shown in animal models that vancomycin is relatively ineffective when used as single-agent therapy.10,29 In one of these studies, rifampin alone, among 35 antibiotics studied, penetrated the biofilm.10 Importantly, antibiotics of the cell-wall active class (including vancomycin) were synergistic with rifampin whereas some other antibiotics (including aminoglycosides) antagonized rifampin activity. One of the industrial concepts that has been effective in the treatment of organisms within biofilms is to provide intermittent pulsing of high doses of antibiotics as this facilitates attack of sessile cells that have become planktonic.6 Although this technique can be shown to be effective in controlled industrial models, the difficulties associated with using this approach in the setting of large orthopaedic wounds that are dynamic and have considerable variability make this approach relatively unrealistic at this time. The concept of providing high local loading doses of antibiotic and then providing constant sustained levels of antibiotics seems to be an achievable goal with local antibiotic delivery devices and indeed there are many developmental products that use this as a part of the device design. Antimicrobial Susceptibility Testing Traditional culture and susceptibility testing have been based on retrieval, identification, and assessment of planktonic bacteria. Finally, susceptibility patterns based on traditional culture techniques with relatively low levels of antibiotics may or may not correlate with the susceptibility of planktonic or sessile bacteria confronted with antibiotic concentrations are 10-fold or even 1000-fold higher. Based on current knowledge, this information may not be relevant to the susceptibility of any remaining sessile bacteria contained within biomaterial that is left in the wound. In an in vitro study, all Propionibacterium acnes isolates in biofilm showed considerably greater resistance to cefamandole, ciprofloxacin and vancomycin.30 All staphylococcus species biofilm isolates showed large increases in resistance to gentamicin and cefamandole with a considerable increase in resistance to vancomycin; however there was little difference observed with ciprofloxacin.30 Based on these results, it seems that the susceptibility of antibiotics against organisms growing within biofilms should be determined to ensure optimal treatment. An experimental Staphylococcus aureus rat osteomyelitis model was designed to correlate in vitro testing with in vivo findings using cefuroxime, vancomycin, and tobramycin.12 The implants were studied for presence of bacteria by adenosine triphosphate (ATP) bioluminescence after treatment and compared with an in vitro assay using three concentrations of each antibiotic (8, 100, and 500 μg/mL).12 In the in vivo model, cefuroxime reduced the number of bacteria more effectively than vancomycin (p < 0.05) whereas tobramycin had no effect. The in vitro assay directly correlated with the in vivo data as cefuroxime significantly (p < 0.05) reduced the number of viable bacteria at all concentrations, tobramycin did not affect viability, and vancomycin affected viability except at the lowest concentration studied (8 μg/mL).12 These results show the usefulness of such an osteomyelitis model to provide evidence for correlation between the in vitro and in vivo findings on the effect of antibiotics being studied. Methods of Monitoring Antibiotic Effect on Biofilms It generally was accepted by symposium participants that methods to monitor biofilm activity in real time would be helpful to assess the effect of treatment strategies on cells contained within biofilms in experimental models. There currently are many methods being investigated, which include measurements with a specialized respirometer, use of nuclear magnetic resonance imaging, and bioluminescence imaging.6 Some bacteria produce or can be made to produce bioluminescent signals allowing real-time assessment of the physiologic state of the biofilms.19 This method measures the metabolic activity of viable cells nondestructively, which is appealing for drug-efficacy studies of chronic biofilm infections. In an S. aureus isolate made bioluminescent by inserting a modified lux operon into the bacterial chromosome model, treatment with rifampin, tobramycin, and ciprofloxacin was assessed.20 A rapid dose-dependent decline in metabolic activity in rifampin-treated groups was observed and the disappearance of light emission correlated with colony counts. Because the metabolic activities of viable cells and a post antibiotic effect could be detected directly, this methodology is appealing for investigating the effects of antibiotics on biofilms. Adjunctive Biofilm Therapies The application of low-frequency ultrasound to enhance vancomycin activity against coagulase negative staphylococcal (CNS) and Escherichia coli biofilm has been shown to be effective because pulsed ultrasound significantly reduced bacterial viability below that of nontreated biofilms.4,31 Although the CNS biofilms responded favorably to various combinations of ultrasound and vancomycin, longer treatment times were required for CNS than those observed for E. coli biofilms.4 The possible mechanisms of this phenomenon were explored with the enhanced action of gentamicin against Pseudomonas aeruginosa biofilms.28 The dependence on peak power density suggests that acoustic pressure plays a notable role. There is also a strong frequency component that causes the killing effect to decrease as frequency increases. It is possible that stable cavitation and the accompanying microstreaming contribute to the bioacoustic effect.28 Others have investigated the in vitro effects of pulsed electromagnetic fields (PEMF) on the efficacy of antibiotics in CNS biofilms.26 Exposure to a PEMF increased the effectiveness of gentamicin against 5-day CNS biofilms with a reduction of at least 50% in the minimum biofilm inhibitory concentration (p < 0.05). There was no significant effect with vancomycin. In one arm of the experiment, there was a two-log difference in colony count at 160 mg/L of gentamicin indicating that synergy was more pronounced at higher levels of gentamicin. Other study results indicate that application of static magnetic fields may also enhance the activity of gentamicin against biofilm-forming P. aeruginosa.3 The effect seems to be limited to magnetic fields between 5 and 20 G and the effect was independent of substrate surface. One of the intriguing aspects of these observations regarding use of these adjunctive methods to augment the efficacy of certain antibiotics is that these methods could be used to augment the process of bone restoration simultaneously. Although still controversial, it increasingly is accepted that signals from electromagnetic fields (EMF) and ultrasound (US) have a clinically significant effect on bone repair, and both methods are now a common part of the orthopaedist’s armamentarium.1,27 It has been shown that both have common waveform characteristics at the treatment site and therefore can deliver similar doses of electrical stimulation to the bone.24 Further investigations into this area-to unify the effects of EMF and US on antibiotics and bone healing-seem warranted because it may be possible to modulate the bone reparative process by several different mechanisms during the treatment of musculoskeletal infection. The most obvious would be caused by the direct effects of EMF and US on bone healing and also an indirect effect might be realized by limiting the dosage of locally delivered antibiotics because of increased efficacy with EMF or US, reducing the dose related adverse effects of antibiotics on osteoblasts. Regulatory Issues One of the sources of great frustration for clinicians engaged in the treatment of musculoskeletal infection has been the inevitable delays that have occurred with FDA approval for local antibiotic delivery vehicles.23 Only recently, after decades of use as a clinician-directed application, is there now approval of commercial ABLC.23 Unfortunately, these approvals are for low-dose aminoglycoside ABLC, which is suitable for prophylaxis; current treatment strategies for established infection require higher doses and multiple choices of antibiotics.14 As such, physicians who choose to treat established musculoskeletal infection with high-dose ABLC must continue to do so as a clinician-directed application. The emergence of composite local antibiotic delivery vehicles, which have the potential to deliver different types of antibiotics, provide creative methods of antibiotic dosing, and also provide materials that contribute to osteogenesis will need to be used as clinician-directed application for the foreseeable future. Hopefully with careful development of these composite biomaterials combined with efficacy and safety data will enable FDA approval for wider use in the treatment of musculoskeletal infections. There is still much to do regarding the investigation and development of treatment tools for treatment of musculoskeletal infection. However, the potential opportunities appear optimistic particularly if biofilm researchers, infectious disease specialists, microbiologists, and orthopaedic surgeons continue to interact and to communicate openly so that some of their seemingly disparate activities ultimately can be combined in a synergistic manner.", "authors": ["Arlen D. Hanssen", "Douglas R. Osmon", "Robin Patel"], "year": 2005, "venue": "Clinical Orthopaedics and Related Research", "cited_by_count": 67, "type": "article", "concepts": ["Antibiotics", "Medicine", "Intensive care medicine", "Dosing", "Adverse effect"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2890970077", "doi": "https://doi.org/10.1038/s41396-019-0383-2", "title": "Agricultural intensification reduces microbial network complexity and the abundance of keystone taxa in roots", "abstract": "Root-associated microbes play a key role in plant performance and productivity, making them important players in agroecosystems. So far, very few studies have assessed the impact of different farming systems on the root microbiota and it is still unclear whether agricultural intensification influences the structure and complexity of microbial communities. We investigated the impact of conventional, no-till, and organic farming on wheat root fungal communities using PacBio SMRT sequencing on samples collected from 60 farmlands in Switzerland. Organic farming harbored a much more complex fungal network with significantly higher connectivity than conventional and no-till farming systems. The abundance of keystone taxa was the highest under organic farming where agricultural intensification was the lowest. We also found a strong negative association (R<sup>2</sup> = 0.366; P < 0.0001) between agricultural intensification and root fungal network connectivity. The occurrence of keystone taxa was best explained by soil phosphorus levels, bulk density, pH, and mycorrhizal colonization. The majority of keystone taxa are known to form arbuscular mycorrhizal associations with plants and belong to the orders Glomerales, Paraglomerales, and Diversisporales. Supporting this, the abundance of mycorrhizal fungi in roots and soils was also significantly higher under organic farming. To our knowledge, this is the first study to report mycorrhizal keystone taxa for agroecosystems, and we demonstrate that agricultural intensification reduces network complexity and the abundance of keystone taxa in the root microbiome.", "authors": ["Samiran Banerjee", "Florian Walder", "Lucie Büchi", "Marcel Meyer", "Alain Held", "Andreas Gattinger", "Thomas Keller", "Raphaël Charles", "Marcel G. A. van der Heijden"], "year": 2019, "venue": "The ISME Journal", "cited_by_count": 1236, "type": "article", "concepts": ["Biology", "Agroecosystem", "Keystone species", "Abundance (ecology)", "Organic farming"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2050839858", "doi": "https://doi.org/10.1161/01.cir.100.9.999", "title": "Mechanisms and Models in Heart Failure", "abstract": "The people who bind themselves to systems are those who are unable to encompass the whole truth and try to catch", "authors": ["Douglas L. Mann"], "year": 1999, "venue": "Circulation", "cited_by_count": 773, "type": "review", "concepts": ["Medicine", "Heart failure", "Cardiology", "Intensive care medicine", "Internal medicine"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4417248878", "doi": "https://doi.org/10.1109/tpami.2025.3642852", "title": "Beyond Degradation Redundancy: Contrastive Prompt Learning for All-in-One Image Restoration", "abstract": "All-in-one image restoration, addressing diverse degradation types with a unified model, presents significant challenges in designing task-aware prompts that effectively guide restoration across multiple degradation scenarios. While adaptive prompt learning enables end-to-end optimization, it often yields overlapping or redundant task representations. Conversely, explicit prompts derived from pretrained classifiers enhance discriminability but may discard critical visual information for reconstruction. To address these limitations, we introduce Contrastive Prompt Learning (CPL), a novel framework that fundamentally enhances prompt-task alignment through two complementary innovations: a Sparse Prompt Module (SPM) that efficiently captures degradation-specific features while minimizing redundancy, and a Contrastive Prompt Regularization (CPR) that explicitly strengthens task boundaries by incorporating negative prompt samples across different degradation types. Unlike previous approaches that focus primarily on degradation classification, CPL optimizes the critical interaction between prompts and the restoration model itself. Extensive experiments across five comprehensive benchmarks demonstrate that CPL consistently enhances state-of-the-art all-in-one restoration models, achieving significant improvements in both standard multi-task scenarios and challenging composite degradation settings. Our framework establishes new state-of-the-art performance while maintaining parameter efficiency, offering a principled solution for unified image restoration.", "authors": ["Gang Wu", "Junjun Jiang", "Kui Jiang", "Xianming Liu", "Liqiang Nie"], "year": 2025, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 1, "type": "article", "concepts": [], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W2397311736", "doi": "https://doi.org/10.5194/hess-21-589-2017", "title": "MSWEP: 3-hourly 0.25° global gridded precipitation (1979–2015) by merging gauge, satellite, and reanalysis data", "abstract": "Abstract. Current global precipitation (P) datasets do not take full advantage of the complementary nature of satellite and reanalysis data. Here, we present Multi-Source Weighted-Ensemble Precipitation (MSWEP) version 1.1, a global P dataset for the period 1979–2015 with a 3-hourly temporal and 0.25° spatial resolution, specifically designed for hydrological modeling. The design philosophy of MSWEP was to optimally merge the highest quality P data sources available as a function of timescale and location. The long-term mean of MSWEP was based on the CHPclim dataset but replaced with more accurate regional datasets where available. A correction for gauge under-catch and orographic effects was introduced by inferring catchment-average P from streamflow (Q) observations at 13 762 stations across the globe. The temporal variability of MSWEP was determined by weighted averaging of P anomalies from seven datasets; two based solely on interpolation of gauge observations (CPC Unified and GPCC), three on satellite remote sensing (CMORPH, GSMaP-MVK, and TMPA 3B42RT), and two on atmospheric model reanalysis (ERA-Interim and JRA-55). For each grid cell, the weight assigned to the gauge-based estimates was calculated from the gauge network density, while the weights assigned to the satellite- and reanalysis-based estimates were calculated from their comparative performance at the surrounding gauges. The quality of MSWEP was compared against four state-of-the-art gauge-adjusted P datasets (WFDEI-CRU, GPCP-1DD, TMPA 3B42, and CPC Unified) using independent P data from 125 FLUXNET tower stations around the globe. MSWEP obtained the highest daily correlation coefficient (R) among the five P datasets for 60.0 % of the stations and a median R of 0.67 vs. 0.44–0.59 for the other datasets. We further evaluated the performance of MSWEP using hydrological modeling for 9011 catchments (&lt; 50 000 km2) across the globe. Specifically, we calibrated the simple conceptual hydrological model HBV (Hydrologiska Byråns Vattenbalansavdelning) against daily Q observations with P from each of the different datasets. For the 1058 sparsely gauged catchments, representative of 83.9 % of the global land surface (excluding Antarctica), MSWEP obtained a median calibration NSE of 0.52 vs. 0.29–0.39 for the other P datasets. MSWEP is available via http://www.gloh2o.org.", "authors": ["Hylke E. Beck", "Albert I. J. M. van Dijk", "Vincenzo Levizzani", "Jaap Schellekens", "Diego G. Miralles", "Brecht Martens", "Ad de Roo"], "year": 2017, "venue": "Hydrology and earth system sciences", "cited_by_count": 1060, "type": "article", "concepts": ["Orography", "Environmental science", "Satellite", "Meteorology", "Rain gauge"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4409262098", "doi": "https://doi.org/10.1109/wacv61041.2025.00069", "title": "All-in-One Image Compression and Restoration", "abstract": "Visual images corrupted by various types and levels of degradations are commonly encountered in practical image compression. However, most existing image compression methods are tailored for clean images, therefore struggling to achieve satisfying results on these images. Joint compression and restoration methods typically focus on a single type of degradation and fail to address a variety of degradations in practice. To this end, we propose a unified framework for all-in-one image compression and restoration, which incorporates the image restoration capability against various degradations into the process of image compression. The key challenges involve distinguishing authentic image content from degradations, and flexibly eliminating various degradations without prior knowledge. Specifically, the proposed framework approaches these challenges from two perspectives: i.e., content information aggregation, and degradation representation aggregation. Extensive experiments demonstrate the following merits of our model: 1) superior rate-distortion (RD) performance on various degraded inputs while preserving the performance on clean data; 2) strong generalization ability to real-world and unseen scenarios; 3) higher computing efficiency over compared methods. Our code is available at https://github.com/ZeldaM1/All-in-one.", "authors": ["H. Zeng", "Jiacheng Li", "Ziqiang Zheng", "Zhiwei Xiong"], "year": 2025, "venue": "", "cited_by_count": 1, "type": "article", "concepts": ["Image restoration", "Image compression", "Computer science", "Computer vision", "Compression (physics)"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W3089028909", "doi": "https://doi.org/10.1109/jproc.2021.3052449", "title": "A Unifying Review of Deep and Shallow Anomaly Detection", "abstract": "Deep learning approaches to anomaly detection (AD) have recently improved the state of the art in detection performance on complex data sets, such as large collections of images or text. These results have sparked a renewed interest in the AD problem and led to the introduction of a great variety of new methods. With the emergence of numerous such methods, including approaches based on generative models, one-class classification, and reconstruction, there is a growing need to bring methods of this field into a systematic and unified perspective. In this review, we aim to identify the common underlying principles and the assumptions that are often made implicitly by various methods. In particular, we draw connections between classic “shallow” and novel deep approaches and show how this relation might cross-fertilize or extend both directions. We further provide an empirical assessment of major existing methods that are enriched by the use of recent explainability techniques and present specific worked-through examples together with practical advice. Finally, we outline critical open challenges and identify specific paths for future research in AD.", "authors": ["Lukas Ruff", "Jacob R. Kauffmann", "Robert A. Vandermeulen", "Gregoire Montavon", "Wojciech Samek", "Marius Kloft", "Thomas G. Dietterich", "Klaus-Robert Muller"], "year": 2021, "venue": "Proceedings of the IEEE", "cited_by_count": 755, "type": "article", "concepts": [], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W1996113298", "doi": "https://doi.org/10.1002/ijc.27316", "title": "Cellular senescence and tumor suppressor gene p16", "abstract": "Abstract Cellular senescence is an irreversible arrest of cell growth. Biochemical and morphological changes occur during cellular senescence, including the formation of a unique cellular morphology such as flattened cytoplasm. Function of mitochondria, endoplasmic reticulum and lysosomes are affected resulting in the inhibition of lysosomal and proteosomal pathways. Cellular senescence can be triggered by a number of factors including, aging, DNA damage, oncogene activation and oxidative stress. While the molecular mechanism of senescence involves p16 and p53 tumor suppressor genes and telomere shortening, this review is focused on the mechanism of p16 control. The p16‐mediated senescence acts through the retinoblastoma (Rb) pathway inhibiting the action of the cyclin dependant kinases leading to G1 cell cycle arrest. Rb is maintained in a hypophosphorylated state resulting in the inhibition of transcription factor E2F1. Regulation of p16 expression is complex and involves epigenetic control and multiple transcription factors. PRC1 (Pombe repressor complex (1) and PRC2 (Pombe repressor complex (2) proteins and histone deacetylases play an important role in the promoter hypermethylation for suppressing p16 expression. While transcription factors YY1 and Id1 suppress p16 expression, transcription factors CTCF, Sp1 and Ets family members activate p16 transcription. Senescence occurs with the inactivation of suppressor elements leading to the enhanced expression of p16.", "authors": ["Hani Rayess", "Marilene B. Wang", "Eri S. Srivatsan"], "year": 2011, "venue": "International Journal of Cancer", "cited_by_count": 793, "type": "review", "concepts": ["Cell biology", "Biology", "Senescence", "Retinoblastoma protein", "E2F1"], "search_query": "all-in-one image restoration unified model degradation"}
{"openalex_id": "https://openalex.org/W4405974083", "doi": "https://doi.org/10.1109/tcsi.2024.3519532", "title": "A Unified Accelerator for All-in-One Image Restoration Based on Prompt Degradation Learning", "abstract": "All-in-one image restoration (IR) recovers images from various unknown distortions by a single model, such as rain, haze, and blur. Transformer-based IR methods have significantly improved the visual effects of the restored images. However, deploying complex IR models on edge devices is challenging due to massive parameters and intensive computations. Moreover, existing accelerators are typically customized for a single task, resulting in severe resource underutilization when executing multiple tasks. Therefore, this paper develops an algorithm-hardware co-design framework to accelerate a novel CNN-Transformer cooperative model for multiple IR tasks. Firstly, on the algorithm level, an Efficient Restoration Foundational Model (ERFM) is proposed to recover corrupted images from various degradations with low model complexity. Secondly, to guide adaptive corruption removal, a novel prompt learning scheme is introduced to fuse context-related degradation cues and boost high-quality reconstruction. Thirdly, on the hardware level, an integer approximation method is proposed to avoid expensive hardware overhead caused by complex nonlinear operations, such as layer normalization and softmax while maintaining comparable IR quality. Moreover, a head stationary dataflow and softmax fusion mechanism are designed to reduce data movement and enhance on-chip resource utilization. Finally, an overall hardware architecture is developed and implemented in TSMC 28 nm CMOS technology. Experimental results show that our ERFM achieves better visual perception than other baselines on seven challenging IR tasks without task-specific fine-tuning. Moreover, compared to other accelerators for vision Transformers, our design can achieve 3.3 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\times$</tex-math> </inline-formula> and 3.7 <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$\\times$</tex-math> </inline-formula> improvements in throughput and energy efficiency.", "authors": ["Siyu Zhang", "Qiwei Dong", "Wendong Mao", "Zhongfeng Wang"], "year": 2025, "venue": "IEEE Transactions on Circuits and Systems I Regular Papers", "cited_by_count": 3, "type": "article", "concepts": ["Degradation (telecommunications)", "Image restoration", "Computer science", "Image (mathematics)", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4381798022", "doi": "https://doi.org/10.48550/arxiv.2306.13090", "title": "PromptIR: Prompting for All-in-One Blind Image Restoration", "abstract": "Image restoration involves recovering a high-quality clean image from its degraded version. Deep learning-based methods have significantly improved image restoration performance, however, they have limited generalization ability to different degradation types and levels. This restricts their real-world application since it requires training individual models for each specific degradation and knowing the input degradation type to apply the relevant model. We present a prompt-based learning approach, PromptIR, for All-In-One image restoration that can effectively restore images from various types and levels of degradation. In particular, our method uses prompts to encode degradation-specific information, which is then used to dynamically guide the restoration network. This allows our method to generalize to different degradation types and levels, while still achieving state-of-the-art results on image denoising, deraining, and dehazing. Overall, PromptIR offers a generic and efficient plugin module with few lightweight prompts that can be used to restore images of various types and levels of degradation with no prior information on the corruptions present in the image. Our code and pretrained models are available here: https://github.com/va1shn9v/PromptIR", "authors": ["Vaishnav Potlapalli", "Syed Waqas Zamir", "Salman Khan", "Fahad Shahbaz Khan"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 34, "type": "preprint", "concepts": ["Image restoration", "Computer science", "Degradation (telecommunications)", "Image (mathematics)", "Generalization"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4405865448", "doi": "https://doi.org/10.1016/j.patcog.2024.111312", "title": "Visual style prompt learning using diffusion models for blind face restoration", "abstract": "", "authors": ["Wanglong Lu", "J P Wang", "Tao Wang", "Kaihao Zhang", "Xianta Jiang", "Hanli Zhao"], "year": 2024, "venue": "Pattern Recognition", "cited_by_count": 39, "type": "article", "concepts": ["Face (sociological concept)", "Style (visual arts)", "Computer science", "Artificial intelligence", "Computer vision"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4396782894", "doi": "https://doi.org/10.1109/tcsvt.2024.3398810", "title": "Prompt-Based Ingredient-Oriented All-in-One Image Restoration", "abstract": "Image restoration aims to recover the high-quality images from their degraded observations. Since most existing methods have been dedicated into single degradation removal, they may not yield optimal results on other types of degradations, which do not satisfy the applications in real world scenarios. In this paper, we propose a novel data ingredient-oriented approach that leverages prompt-based learning to enable a single model to efficiently tackle multiple image degradation tasks. Specifically, we utilize a encoder to capture features and introduce prompts with degradation-specific information to guide the decoder in adaptively recovering images affected by various degradations. In order to model the local invariant properties and non-local information for high-quality image restoration, we combine CNNs operations and Transformers. Simultaneously, we make several key designs in the Transformer blocks (multi-head rearranged attention with prompts and simple-gate feed-forward network) to reduce computational requirements and selectively determines what information should be persevered to facilitate efficient recovery of potentially sharp images. Furthermore, we incorporate a feature fusion mechanism further explores the multi-scale information to improve the aggregated features. The resulting tightly interlinked hierarchy architecture, named as CAPTNet, extensive experiments demonstrate that our method performs competitively to the state-of-the-art. The code and the pre-trained models are released at https://github.com/Tombs98/CAPTNet.", "authors": ["Hu Gao", "Jing Yang", "Ying Zhang", "Ning Wang", "Jingfan Yang", "Depeng Dang"], "year": 2024, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 26, "type": "article", "concepts": ["Ingredient", "Image restoration", "Computer science", "Image processing", "Computer vision"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4404844036", "doi": "https://doi.org/10.1016/j.patcog.2024.111223", "title": "FrePrompter: Frequency self-prompt for all-in-one image restoration", "abstract": "", "authors": ["Zhijian Wu", "Wenhui Liu", "Jingchao Wang", "Jun Li", "Dingjiang Huang"], "year": 2024, "venue": "Pattern Recognition", "cited_by_count": 14, "type": "article", "concepts": ["Image restoration", "Image (mathematics)", "Artificial intelligence", "Computer vision", "Computer science"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4402915930", "doi": "https://doi.org/10.1109/cvprw63382.2024.00645", "title": "PromptCIR: Blind Compressed Image Restoration with Prompt Learning", "abstract": "Blind Compressed Image Restoration (CIR) has garnered significant attention due to its practical applications. It aims to mitigate compression artifacts caused by unknown quality factors, particularly with JPEG codecs. Existing works on blind CIR often seek assistance from a quality factor prediction network to facilitate their network to restore compressed images. However, the predicted numerical quality factor lacks spatial information, preventing network adaptability toward image contents. Recent studies in prompt-learning-based image restoration have showcased the potential of prompts to generalize across varied degradation types and degrees. This motivated us to design a prompt-learning-based compressed image restoration network, dubbed PromptCIR, which can effectively restore images from various compress levels. Specifically, PromptCIR exploits prompts to encode compression information implicitly, where prompts directly interact with soft weights generated from image features, thus providing dynamic content-aware and distortion-aware guidance for the restoration process. The light-weight prompts enable our method to adapt to different compression levels, while introducing minimal parameter overhead. Overall, Prompt-CIR leverages the powerful transformer-based backbone with the dynamic prompt module to proficiently handle blind CIR tasks, winning first place in the NTIRE 2024 challenge of blind compressed image enhancement track. Extensive experiments have validated the effectiveness of our proposed PromptCIR. The code is available at https://github.com/lbc12345/PromptCIR-NTIRE24.", "authors": ["Bingchen Li", "Xin Li", "Yiting Lu", "Ruoyu Feng", "Mengxi Guo", "Shijie Zhao", "Zhang Li", "Zhibo Chen"], "year": 2024, "venue": "", "cited_by_count": 17, "type": "article", "concepts": ["Computer science", "Image restoration", "Artificial intelligence", "Computer vision", "Image (mathematics)"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4379141198", "doi": "https://doi.org/10.1016/j.eswa.2023.120646", "title": "Exposing low-quality deepfake videos of Social Network Service using Spatial Restored Detection Framework", "abstract": "", "authors": ["Ying Li", "Shan Bian", "Chuntao Wang", "Kemal Polat", "Adi Alhudhaif", "Fayadh Alenezi"], "year": 2023, "venue": "Expert Systems with Applications", "cited_by_count": 26, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Block (permutation group theory)", "Feature (linguistics)", "Quality (philosophy)"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4406092414", "doi": "https://doi.org/10.1016/j.inffus.2025.102930", "title": "Ada4DIR: An adaptive model-driven all-in-one image restoration network for remote sensing images", "abstract": "", "authors": ["Ziyang Lihe", "Qiangqiang Yuan", "Jiang He", "Xianyu Jin", "Yi Xiao", "Yuzeng Chen", "Huanfeng Shen", "Liangpei Zhang"], "year": 2025, "venue": "Information Fusion", "cited_by_count": 5, "type": "article", "concepts": ["Computer science", "Image (mathematics)", "Artificial intelligence", "Image restoration", "Computer vision"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4387486933", "doi": "https://doi.org/10.1109/icamechs59878.2023.10272811", "title": "An Attempt at Zero-shot Ancient Documents Restoration Based on Diffusion Models", "abstract": "The virtual restoration of ancient documents using deep learning is an emergency and an expected work. However, GANs-based image-to-image translation approaches hit the degradation data shortage, a hardness to build one-to-many restoration models, and a limitation for large deformation. In this study, we apply zero-shot restoration based on Diffusion models to ancient degraded documents, specifically, leverage inpainting of Denoing Diffusion Restoration Models (DDRM) for missing ancient characters. Furthermore, we introduce a noise masking method, which limits the attention area of predicted noise images in the reverse process. Noise masking forces DDRM to generate faithful objects following mask images, so that has high usability without re-training of deep neural networks. The zero-shot restoration and noise masking prompt GUI-connecting restoration of missing characters, leading to realizing a cooperative application with humans for ancient document restoration.", "authors": ["Hayata Kaneko", "Yuuya Yoshizu", "Ryuto Ishibashi", "Lin Meng"], "year": 2023, "venue": "", "cited_by_count": 5, "type": "article", "concepts": ["Computer science", "Image restoration", "Masking (illustration)", "Artificial intelligence", "Noise (video)"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4404176632", "doi": "https://doi.org/10.1007/978-3-031-72855-6_11", "title": "UniProcessor: A Text-Induced Unified Low-Level Image Processor", "abstract": "", "authors": ["Huiyu Duan", "Xiongkuo Min", "Sijing Wu", "Wei Shen", "Guangtao Zhai"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 6, "type": "book-chapter", "concepts": ["Uniprocessor system", "Computer science", "Image (mathematics)", "Artificial intelligence", "Parallel computing"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2971398159", "doi": "https://doi.org/10.1111/rec.13035", "title": "International principles and standards for the practice of ecological restoration. Second edition", "abstract": "The Society for Ecological Restoration (SER) is an international non-profit organization with members in 70 countries. SER advances the science, practice and policy of ecological restoration to sustain biodiversity, improve resilience in a changing climate, and re-establish an ecologically healthy relationship between nature and culture. SER is a dynamic global network, linking researchers, practitioners, land managers, community leaders and decision-makers to restore ecosystems and the human communities that depend on them. Via its members, publications, conferences, policy work, and outreach, SER defines and delivers excellence in the field of ecological restoration.", "authors": ["George D. Gann", "Tein McDonald", "Bethanie Walder", "James Aronson", "Cara R. Nelson", "Justin Jonson", "James G. Hallett", "Cristina Eisenberg", "Manuel R. Guariguata", "Junguo Liu", "Fangyuan Hua", "Cristián Echeverría", "Emily K. Gonzales", "Nancy L. Shaw", "Kris Decleer", "Kingsley W. Dixon"], "year": 2019, "venue": "Restoration Ecology", "cited_by_count": 1302, "type": "article", "concepts": ["Restoration ecology", "Ecology", "Geography", "Environmental resource management", "Environmental ethics"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4411047697", "doi": "https://doi.org/10.1016/j.patcog.2025.111875", "title": "AdaPrompt-IR: Adaptive learning to perceive degradation semantic and prompting for all-in-one image restoration", "abstract": "", "authors": ["Wei Sun", "Qianzhou Wang", "Yaqi Wang", "Zhiqiang Hou", "Qingsen Yan", "Shuicheng Yan"], "year": 2025, "venue": "Pattern Recognition", "cited_by_count": 3, "type": "article", "concepts": ["Degradation (telecommunications)", "Computer science", "Artificial intelligence", "Image (mathematics)", "Image restoration"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4401444389", "doi": "https://doi.org/10.1007/s11760-024-03493-7", "title": "Rethinking all-in-one adverse weather removal for object detection", "abstract": "", "authors": ["Yufeng Li", "Jiayu Chen", "Chuanlong Xie", "Hongming Chen"], "year": 2024, "venue": "Signal Image and Video Processing", "cited_by_count": 4, "type": "article", "concepts": ["Adverse weather", "Object (grammar)", "Computer science", "Artificial intelligence", "Environmental science"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4407677384", "doi": "https://doi.org/10.1016/j.engappai.2025.110267", "title": "Adaptive prompt guided unified image restoration with latent diffusion model", "abstract": "", "authors": ["Xiang Lv", "Mingwen Shao", "Yecong Wan", "Yuanjian Qiao", "Changzhong Wang"], "year": 2025, "venue": "Engineering Applications of Artificial Intelligence", "cited_by_count": 4, "type": "article", "concepts": ["Computer science", "Diffusion", "Image (mathematics)", "Image restoration", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4402915827", "doi": "https://doi.org/10.1109/tcsvt.2024.3469190", "title": "Multi-Weather Restoration: An Efficient Prompt-Guided Convolution Architecture", "abstract": "Addressing degraded weather conditions plays a vital role in practical applications. Many existing restoration approaches are limited to specific weather types, which limits their applicability to different weather scenarios. Advanced technologies, encompassing Transformer and diffusion model, have been harnessed to confront this challenge. However, these methods often heighten network complexity and prolong inference duration. To this end, we present MW-ConvNet, a U-shaped convolution-based network for multi-weather restoration. Specifically, the MW-Enc block and MW-Dec block are introduced to achieve simple yet strong feature extraction, which rely entirely on traditional 2D convolution. To improve adaptability to multiple weather conditions, a prompt generation module is designed to generate a representative weather prompt at the encoder’s terminus. Drawing inspiration from style transfer, the weather prompt is used to guide the decoder learning through a progressive restoration procedure. For future high-fidelity restoration, we introduce frequency separation through wavelet pooling blocks in encoder phase and corresponding up-sampling blocks in decoder phase. The segregated treatment of low-frequency and high-frequency features curbs the loss of textural information during network computation. It also future improves the quality and accuracy of generated weather prompt. Extensive experiments demonstrate that the proposed MW-ConvNet obtains superior performance compared to state-of-the-art methods across both weather-specific and real-world restoration tasks. Significantly, our method achieves an impressive inference speed of 0.12 seconds per <inline-formula xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"> <tex-math notation=\"LaTeX\">$256\\times 256$ </tex-math></inline-formula> image, outpacing transformer-based and diffusion-based models.", "authors": ["Chengyang Li", "Fangwei Sun", "Heng Zhou", "Yongqiang Xie", "Zhongbo Li", "Li Zhu"], "year": 2024, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 6, "type": "article", "concepts": ["Architecture", "Convolution (computer science)", "Computer science", "Artificial intelligence", "Geography"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4311263589", "doi": "https://doi.org/10.5281/zenodo.3553579", "title": "Summary for policymakers of the global assessment report on biodiversity and ecosystem services", "abstract": "IPBES is an independent intergovernmental body comprising over 130 member Governments. Established by Governments in 2012, IPBES provides policymakers with objective scientific assessments about the state of knowledge regarding the planet’s biodiversity, ecosystems and the contributions they make to people, as well as options and actions to protect and sustainably use these vital natural assets. The IPBES Global Assessment of Biodiversity and Ecosystem Services represents the landmark product of the first work programme of IPBES (2014-2018). The Global Assessment was initiated following a decision from the IPBES Plenary at its fourth session (IPBES 4, Kuala Lumpur, 2016), and considered by the IPBES Plenary at its seventh session (IPBES 7, Paris, 2019). It is composed of a summary for policymakers, which was approved at IPBES 7, and six chapters, which were accepted at IPBES 7.", "authors": ["IPBES"], "year": 2019, "venue": "Zenodo (CERN European Organization for Nuclear Research)", "cited_by_count": 1078, "type": "report", "concepts": ["Ecosystem services", "Biodiversity", "Ecosystem", "Environmental resource management", "Business"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4404635286", "doi": "https://doi.org/10.1016/j.neucom.2024.128955", "title": "Multi-modal degradation feature learning for unified image restoration based on contrastive learning", "abstract": "In this paper, we address the unified image restoration challenge by reframing it as a contrastive learning-based classification problem. Despite the significant strides made by deep learning methods in enhancing image restoration quality, their limited capacity to generalize across diverse degradation types and intensities necessitates the training of separate models for each specific degradation scenario. We proposes an all-encompassing approach that can restore images from various unknown corruption types and levels. We devise a method that learns representations of the latent sharp image’s degradation and accompanying textual features (such as dataset categories and image content descriptions), converting these into prompts which are then embedded within a reconstruction network model to enhance cross-database restoration performance. This culminates in a unified image reconstruction framework. The study involves two stages: In the first stage, we design a MultiContentNet that learns multi-modal features (MMFs) of the latent sharp image. This network encodes the visual degradation expressions and contextual text features into latent variables, thereby exerting a guided classification effect. Specifically, MultiContentNet is trained as an auxiliary controller capable of taking the degraded input image and, through contrastive learning , extracts MMFs of the latent target image. This effectively generates natural classifiers tailored for different degradation types. The second phase integrates the learned MMFs into an image restoration network via cross-attention mechanisms. This guides the restoration model to learn high-fidelity image recovery. Experiments conducted on six blind image restoration tasks demonstrate that the proposed method achieves state-of-the-art performance, highlighting the potential significance of large-scale pretrained vision-language models’ MMFs in advancing high-quality unified image reconstruction.", "authors": ["Lei Chen", "Qibing Xiong", "Wei Zhang", "Xiaoli Liang", "Zhihua Gan", "Lianqing Li", "Xin He"], "year": 2024, "venue": "Neurocomputing", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Feature (linguistics)", "Modal", "Degradation (telecommunications)"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4415124039", "doi": "https://doi.org/10.1109/tits.2025.3617507", "title": "Frequency-Prompted Image Restoration to Enhance Perception in Intelligent Transportation Systems", "abstract": "High perceptual image quality is crucial for intelligent transportation systems (ITS), including autonomous vehicles, digital twins, and surveillance infrastructure. However, images captured in adverse weather conditions or dynamic environments often suffer from various visibility degradations. To address this issue, image restoration aims to recover missing details and remove distortions from degraded observations, thereby enhancing the usability of visual data in intelligent transportation applications. Inspired by the success of prompt learning in natural language processing, recent studies have explored prompt-based approaches for various image restoration tasks. However, most of these methods operate in the spatial domain. Given the importance of frequency learning in image restoration, particularly in reducing the spectral discrepancy between degraded and sharp image pairs, this study investigates the use of frequency prompts through a plug-and-play mechanism consisting of a prompt generation module and a prompt integration module. Specifically, the prompt generation module encodes frequency information by aggregating pre-defined learnable parameters, guided by the implicitly decomposed spectra of the input features. The learned prompts are then integrated into the feature spectra via dual-dimensional attention, dynamically guiding the reconstruction process and enabling more effective frequency-aware learning. To validate the effectiveness of the proposed plug-in module, we integrate it into both CNN-based and Transformer-based backbones. Extensive experiments demonstrate that the CNN-based variant achieves state-of-the-art performance on 15 datasets across five representative image restoration tasks. Furthermore, it generalizes well to composite degradation scenarios. The Transformer-based model performs competitively with state-of-the-art methods under two all-in-one image restoration settings. Finally, the effectiveness of our models in enhancing perception for ITS is empirically verified.", "authors": ["Yuning Cui", "Mingyu Liu", "Xiongfei Su", "Alois Knoll"], "year": 2025, "venue": "IEEE Transactions on Intelligent Transportation Systems", "cited_by_count": 2, "type": "article", "concepts": [], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4394617226", "doi": "https://doi.org/10.3389/fmars.2024.1382147", "title": "Learning degradation-aware visual prompt for maritime image restoration under adverse weather conditions", "abstract": "Adverse weather conditions such as rain and haze often lead to a degradation in the quality of maritime images, which is crucial for activities like navigation, fishing, and search and rescue. Therefore, it is of great interest to develop an effective algorithm to recover high-quality maritime images under adverse weather conditions. This paper proposes a prompt-based learning method with degradation perception for maritime image restoration, which contains two key components: a restoration module and a prompting module. The former is employed for image restoration, whereas the latter encodes weather-related degradation-specific information to modulate the restoration module, enhancing the recovery process for improved results. Inspired by the recent trend of prompt learning in artificial intelligence, this paper adopts soft-prompt technology to generate learnable visual prompt parameters for better perceiving the degradation-conditioned cues. Extensive experimental results on several benchmarks show that our approach achieves superior restoration performance in maritime image dehazing and deraining tasks.", "authors": ["Xin He", "Tong Jia", "Junjie Li"], "year": 2024, "venue": "Frontiers in Marine Science", "cited_by_count": 1, "type": "article", "concepts": ["Adverse weather", "Degradation (telecommunications)", "Environmental science", "Computer science", "Meteorology"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4399740511", "doi": "https://doi.org/10.3390/electronics13122346", "title": "Underwater Fish Object Detection with Degraded Prior Knowledge", "abstract": "Understanding fish distribution, behavior, and abundance is crucial for marine ecological research, fishery management, and environmental monitoring. However, the distinctive features of the underwater environment, including low visibility, light attenuation, water turbidity, and strong currents, significantly impact the quality of data gathered by underwater imaging systems, posing considerable challenges in accurately detecting fish objects. To address this challenge, our study proposes an innovative fish detection network based on prior knowledge of image degradation. In our research process, we first delved into the intrinsic relationship between visual image quality restoration and detection outcomes, elucidating the obstacles the underwater environment poses to object detection. Subsequently, we constructed a dataset optimized for object detection using image quality evaluation metrics. Building upon this foundation, we designed a fish object detection network that integrates a prompt-based degradation feature learning module and a two-stage training scheme, effectively incorporating prior knowledge of image degradation. To validate the efficacy of our approach, we develop a multi-scene Underwater Fish image Dataset (UFD2022). The experimental results demonstrate significant improvements of 2.4% and 2.5%, respectively, in the mAP index compared to the baseline methods ResNet50 and ResNetXT101. This outcome robustly confirms the effectiveness and superiority of our process in addressing the challenge of fish object detection in underwater environments.", "authors": ["Shijian Zheng", "Rujing Wang", "Liusan Wang"], "year": 2024, "venue": "Electronics", "cited_by_count": 5, "type": "article", "concepts": ["Underwater", "Fish <Actinopterygii>", "Object (grammar)", "Computer science", "Object detection"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4404338208", "doi": "https://doi.org/10.48550/arxiv.2410.18666", "title": "DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation", "abstract": "Image restoration (IR) in real-world scenarios presents significant challenges due to the lack of high-capacity models and comprehensive datasets. To tackle these issues, we present a dual strategy: GenIR, an innovative data curation pipeline, and DreamClear, a cutting-edge Diffusion Transformer (DiT)-based image restoration model. GenIR, our pioneering contribution, is a dual-prompt learning pipeline that overcomes the limitations of existing datasets, which typically comprise only a few thousand images and thus offer limited generalizability for larger models. GenIR streamlines the process into three stages: image-text pair construction, dual-prompt based fine-tuning, and data generation &amp; filtering. This approach circumvents the laborious data crawling process, ensuring copyright compliance and providing a cost-effective, privacy-safe solution for IR dataset construction. The result is a large-scale dataset of one million high-quality images. Our second contribution, DreamClear, is a DiT-based image restoration model. It utilizes the generative priors of text-to-image (T2I) diffusion models and the robust perceptual capabilities of multi-modal large language models (MLLMs) to achieve photorealistic restoration. To boost the model's adaptability to diverse real-world degradations, we introduce the Mixture of Adaptive Modulator (MoAM). It employs token-wise degradation priors to dynamically integrate various restoration experts, thereby expanding the range of degradations the model can address. Our exhaustive experiments confirm DreamClear's superior performance, underlining the efficacy of our dual strategy for real-world image restoration. Code and pre-trained models are available at: https://github.com/shallowdream204/DreamClear.", "authors": ["Yuang Ai", "Xiaoqiang Zhou", "Huaibo Huang", "Xiaotian Han", "Zhengyu Chen", "Quanzeng You", "Hongxia Yang"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 2, "type": "preprint", "concepts": ["Computer science", "Image (mathematics)", "Privacy protection", "Internet privacy", "Data science"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W3171835979", "doi": "https://doi.org/10.1038/s41573-021-00219-z", "title": "Noncoding RNA therapeutics — challenges and potential solutions", "abstract": "", "authors": ["Melanie Winkle", "Sherien M. El‐Daly", "Muller Fabbri", "George A. Călin"], "year": 2021, "venue": "Nature Reviews Drug Discovery", "cited_by_count": 1504, "type": "review", "concepts": ["microRNA", "Non-coding RNA", "RNA", "Long non-coding RNA", "Computational biology"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4387583542", "doi": "https://doi.org/10.1109/etfa54631.2023.10275673", "title": "Non-Contact Heart Rate Measurement from Deteriorated Videos", "abstract": "Remote photoplethysmography (rPPG) offers a state-of-the-art, non-contact methodology for estimating human pulse by analyzing facial videos. Despite its potential, rPPG methods can be susceptible to various artifacts, such as noise, occlusions, and other obstructions caused by sunglasses, masks, or even involuntary face touching. In this study, we apply image processing transformations to intentionally degrade video quality, mimicking these challenging conditions, and subsequently evaluate the performance of both non-learning and learning-based rPPG methods on the deteriorated data. Our results reveal a significant decrease in accuracy in the presence of these artifacts, prompting us to propose the application of restoration techniques, such as denoising and inpainting, to improve heart-rate estimation outcomes. By addressing these challenging conditions and occlusion artifacts, our approach aims to make rPPG methods more robust and adaptable to real-world situations. To assess the effectiveness of our proposed methods, we undertake comprehensive experiments on three publicly available datasets, encompassing a wide range of scenarios and artifact types. Our findings underscore the potential to construct a robust rPPG system by employing an optimal combination of restoration algorithms and rPPG techniques. Moreover, our study contributes to the advancement of privacy-conscious rPPG methodologies, thereby bolstering the overall utility and impact of this innovative technology in the field of remote heart-rate estimation under realistic and diverse conditions.", "authors": ["Nhi Nguyen", "Le Ngu Nguyen", "Constantino Álvarez Casado", "Olli Sílven", "Miguel Bordallo López"], "year": 2023, "venue": "", "cited_by_count": 4, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Artifact (error)", "Inpainting", "Computer vision"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4392783067", "doi": "https://doi.org/10.1038/s41392-024-01743-1", "title": "Microbiota–gut–brain axis and its therapeutic applications in neurodegenerative diseases", "abstract": "The human gastrointestinal tract is populated with a diverse microbial community. The vast genetic and metabolic potential of the gut microbiome underpins its ubiquity in nearly every aspect of human biology, including health maintenance, development, aging, and disease. The advent of new sequencing technologies and culture-independent methods has allowed researchers to move beyond correlative studies toward mechanistic explorations to shed light on microbiome-host interactions. Evidence has unveiled the bidirectional communication between the gut microbiome and the central nervous system, referred to as the \"microbiota-gut-brain axis\". The microbiota-gut-brain axis represents an important regulator of glial functions, making it an actionable target to ameliorate the development and progression of neurodegenerative diseases. In this review, we discuss the mechanisms of the microbiota-gut-brain axis in neurodegenerative diseases. As the gut microbiome provides essential cues to microglia, astrocytes, and oligodendrocytes, we examine the communications between gut microbiota and these glial cells during healthy states and neurodegenerative diseases. Subsequently, we discuss the mechanisms of the microbiota-gut-brain axis in neurodegenerative diseases using a metabolite-centric approach, while also examining the role of gut microbiota-related neurotransmitters and gut hormones. Next, we examine the potential of targeting the intestinal barrier, blood-brain barrier, meninges, and peripheral immune system to counteract glial dysfunction in neurodegeneration. Finally, we conclude by assessing the pre-clinical and clinical evidence of probiotics, prebiotics, and fecal microbiota transplantation in neurodegenerative diseases. A thorough comprehension of the microbiota-gut-brain axis will foster the development of effective therapeutic interventions for the management of neurodegenerative diseases.", "authors": ["Jian Sheng Loh", "Wen Qi Mak", "Li Tan", "Chu Xin Ng", "Hong Hao Chan", "Shiau Hueh Yeow", "Jhi Biau Foo", "Yong Sze Ong", "Chee Wun How", "Kooi Yeong Khaw"], "year": 2024, "venue": "Signal Transduction and Targeted Therapy", "cited_by_count": 730, "type": "review", "concepts": ["Gut–brain axis", "Microbiome", "Gut flora", "Neurodegeneration", "Biology"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4403556433", "doi": "https://doi.org/10.48550/arxiv.2409.03455", "title": "Data-free Distillation with Degradation-prompt Diffusion for Multi-weather Image Restoration", "abstract": "Multi-weather image restoration has witnessed incredible progress, while the increasing model capacity and expensive data acquisition impair its applications in memory-limited devices. Data-free distillation provides an alternative for allowing to learn a lightweight student model from a pre-trained teacher model without relying on the original training data. The existing data-free learning methods mainly optimize the models with the pseudo data generated by GANs or the real data collected from the Internet. However, they inevitably suffer from the problems of unstable training or domain shifts with the original data. In this paper, we propose a novel Data-free Distillation with Degradation-prompt Diffusion framework for multi-weather Image Restoration (D4IR). It replaces GANs with pre-trained diffusion models to avoid model collapse and incorporates a degradation-aware prompt adapter to facilitate content-driven conditional diffusion for generating domain-related images. Specifically, a contrast-based degradation prompt adapter is firstly designed to capture degradation-aware prompts from web-collected degraded images. Then, the collected unpaired clean images are perturbed to latent features of stable diffusion, and conditioned with the degradation-aware prompts to synthesize new domain-related degraded images for knowledge distillation. Experiments illustrate that our proposal achieves comparable performance to the model distilled with original training data, and is even superior to other mainstream unsupervised methods.", "authors": ["Pei Wang", "Xiaotong Luo", "Yuan Xie", "Yanyun Qu"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 1, "type": "preprint", "concepts": ["Degradation (telecommunications)", "Distillation", "Environmental science", "Diffusion", "Image (mathematics)"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4409367756", "doi": "https://doi.org/10.1609/aaai.v39i5.32587", "title": "UP-Restorer: When Unrolling Meets Prompts for Unified Image Restoration", "abstract": "All-in-one restoration needs to implicitly distinguish between different degradation conditions and apply specific prior constraints accordingly. To fulfill this goal, our work makes the first effort to create an all-in-one restoration via unrolling from the typical maximum a-posterior optimization function. This unrolling framework naturally leads to the construction of progressively solving models, which are equivalent to a diffusion enhancer taking as input dynamically generated prompts. Under a score-based diffusion model, the prompts are integrated for propogating and updating several context-related variables, i.e. transmission map, atmospheric light map and noise or rain map progressively. Such learned prompt generation process, which simulates the nonlinear operations in the unrolled solution, is combined with linear operations owning clear physics implications to make the diffusion models well reguarlized and more effective in learning degradation-related visual priors. Experimental results demonstrate that our method achieves significant performance improvements across various image restoration tasks, realizing true all-in-one image restoration.", "authors": ["Minghao Liu", "Wenhan Yang", "Jinyi Luo", "Jiaying Liu"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 1, "type": "article", "concepts": ["Image (mathematics)", "Computer science", "Psychology", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4392972181", "doi": "https://doi.org/10.48550/arxiv.2403.11157", "title": "Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model", "abstract": "Universal image restoration is a practical and potential computer vision task for real-world applications. The main challenge of this task is handling the different degradation distributions at once. Existing methods mainly utilize task-specific conditions (e.g., prompt) to guide the model to learn different distributions separately, named multi-partite mapping. However, it is not suitable for universal model learning as it ignores the shared information between different tasks. In this work, we propose an advanced selective hourglass mapping strategy based on diffusion model, termed DiffUIR. Two novel considerations make our DiffUIR non-trivial. Firstly, we equip the model with strong condition guidance to obtain accurate generation direction of diffusion model (selective). More importantly, DiffUIR integrates a flexible shared distribution term (SDT) into the diffusion algorithm elegantly and naturally, which gradually maps different distributions into a shared one. In the reverse process, combined with SDT and strong condition guidance, DiffUIR iteratively guides the shared distribution to the task-specific distribution with high image quality (hourglass). Without bells and whistles, by only modifying the mapping strategy, we achieve state-of-the-art performance on five image restoration tasks, 22 benchmarks in the universal setting and zero-shot generalization setting. Surprisingly, by only using a lightweight model (only 0.89M), we could achieve outstanding performance. The source code and pre-trained models are available at https://github.com/iSEE-Laboratory/DiffUIR", "authors": ["Dian Zheng", "Xiaoming Wu", "Shuzhou Yang", "Jian Zhang", "Jian–Fang Hu", "Wei‐Shi Zheng"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Hourglass", "Image restoration", "Image (mathematics)", "Computer vision", "Computer science"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2529869467", "doi": "https://doi.org/10.1016/j.scitotenv.2016.09.228", "title": "The EU Water Framework Directive: From great expectations to problems with implementation", "abstract": "The Water Framework Directive 2000/60/EC (WFD) is widely accepted as the most substantial and ambitious piece of European environmental legislation to date. It has been referred to as a once in a generation opportunity to restore Europe's waters and a potential template for future environmental regulations. However, fifteen years since it was adopted, and with many problems and delays in its implementation, the WFD has not delivered its main objectives of non-deterioration of water status and the achievement of good status for all EU waters. Putting aside the daunting technical and organisational challenges of its implementation, this paper aims to shed light on why the great expectations that came with the WFD have not yet been fully realised. It reviews how the Directive has been interpreted, focusing on its intentions and how they were applied. The findings reveal the absence of the paradigm shift towards the systems (integrated) thinking that the WFD was grounded on, as a fundamental problem with its implementation. This is also evident in cases where the Directive has been criticised as a policy tool or when implementation efforts were reviewed, indicating misunderstandings even of its core principles. This inherent departure from the Directive's systemic intention and methodological approach needs further investigation, as it could be the reason behind many of its problems and delays. Unless current implementation efforts are reviewed or revised in light of this, enabling the paradigm shift required to ensure a more sustainable and holistic approach to water management, the fading aspirations of the initial great expectations that came with the Directive could disappear for good.", "authors": ["Nikolaos Voulvoulis", "Karl Dominic Arpon", "Theodoros Giakoumis"], "year": 2016, "venue": "The Science of The Total Environment", "cited_by_count": 521, "type": "article", "concepts": ["Water Framework Directive", "Directive", "Legislation", "Environmental planning", "Paradigm shift"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2904110151", "doi": "https://doi.org/10.1002/wcc.565", "title": "Explaining differential vulnerability to climate change: A social science review", "abstract": "The varied effects of recent extreme weather events around the world exemplify the uneven impacts of climate change on populations, even within relatively small geographic regions. Differential human vulnerability to environmental hazards results from a range of social, economic, historical, and political factors, all of which operate at multiple scales. While adaptation to climate change has been the dominant focus of policy and research agendas, it is essential to ask as well why some communities and peoples are disproportionately exposed to and affected by climate threats. The cases and synthesis presented here are organized around four key themes (resource access, governance, culture, and knowledge), which we approach from four social science fields (cultural anthropology, archaeology, human geography, and sociology). Social scientific approaches to human vulnerability draw vital attention to the root causes of climate change threats and the reasons that people are forced to adapt to them. Because vulnerability is a multidimensional process rather than an unchanging state, a dynamic social approach to vulnerability is most likely to improve mitigation and adaptation planning efforts. This article is categorized under:Vulnerability and Adaptation to Climate Change > Values-Based Approach to Vulnerability and Adaptation.", "authors": ["Kimberley Anh Thomas", "Dean Hardy", "Heather Lazrus", "Michael Méndez", "Ben Orlove", "Isabel Rivera‐Collazo", "J. Timmons Roberts", "Marcy Rockman", "Benjamin P. Warner", "Robert Winthrop"], "year": 2018, "venue": "Wiley Interdisciplinary Reviews Climate Change", "cited_by_count": 794, "type": "review", "concepts": ["Vulnerability (computing)", "Climate change", "Social vulnerability", "Vulnerability assessment", "Adaptation (eye)"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4411445611", "doi": "https://doi.org/10.2139/ssrn.5311960", "title": "Multi-Dimension Visual Prompt Enhanced Image Restoration Network Via Mamba-Transformer Aggregation", "abstract": "", "authors": ["Aiwen Jiang", "Hourong Chen", "Jihua Ye", "Mingwen Wang", "Bo Liu"], "year": 2025, "venue": "SSRN Electronic Journal", "cited_by_count": 1, "type": "preprint", "concepts": ["Transformer", "Dimension (graph theory)", "Image (mathematics)", "Computer science", "Mathematics"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2336023654", "doi": "https://doi.org/10.5751/es-02716-130240", "title": "Adaptive Capacity and Traps", "abstract": "Adaptive capacity is the ability of a living system, such as a social-ecological system, to adjust responses to changing internal demands and external drivers. Although adaptive capacity is a frequent topic of study in the resilience literature, there are few formal models. This paper introduces such a model and uses it to explore adaptive capacity by contrast with the opposite condition, or traps. In a socialecological rigidity trap, strong self-reinforcing controls prevent the flexibility needed for adaptation. In the model, too much control erodes adaptive capacity and thereby increases the risk of catastrophic breakdown. In a social-ecological poverty trap, loose connections prevent the mobilization of ideas and resources to solve problems. In the model, too little control impedes the focus needed for adaptation. Fluctuations of internal demand or external shocks generate pulses of adaptive capacity, which may gain traction and pull the system out of the poverty trap. The model suggests some general properties of traps in social-ecological systems. It is general and flexible, so it can be used as a building block in more specific and detailed models of adaptive capacity for a particular region.", "authors": ["Stephen R. Carpenter", "William A. Brock"], "year": 2008, "venue": "Ecology and Society", "cited_by_count": 475, "type": "article", "concepts": ["Adaptive capacity", "Environmental resource management", "Geography", "Climate change", "Business"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4412488893", "doi": "https://doi.org/10.1109/tpami.2025.3589606", "title": "Re-Boosting Self-Collaboration Parallel Prompt GAN for Unsupervised Image Restoration", "abstract": "Deep learning methods have demonstrated state-of-the-art performance in image restoration, especially when trained on large-scale paired datasets. However, acquiring paired data in real-world scenarios poses a significant challenge. Unsupervised restoration approaches based on generative adversarial networks (GANs) offer a promising solution without requiring paired datasets. Yet, these GAN-based approaches struggle to surpass the performance of conventional unsupervised GAN-based frameworks without significantly modifying model structures or increasing the computational complexity. To address these issues, we propose a self-collaboration (SC) strategy for existing restoration models. This strategy utilizes information from the previous stage as feedback to guide subsequent stages, achieving significant performance improvement without increasing the framework's inference complexity. The SC strategy comprises a prompt learning (PL) module and a restorer ($Res$Res). It iteratively replaces the previous less powerful fixed restorer $\\overline{Res}$Res¯ in the PL module with a more powerful $Res$Res. The enhanced PL module generates better pseudo-degraded/clean image pairs, leading to a more powerful $Res$Res for the next iteration. Our SC can significantly improve the $Res$Res 's performance by over 1.5 dB without adding extra parameters or computational complexity during inference. Meanwhile, existing self-ensemble (SE) and our SC strategies enhance the performance of pre-trained restorers from different perspectives. As SE increases computational complexity during inference, we propose a re-boosting module to the SC (Reb-SC) to improve the SC strategy further by incorporating SE into SC without increasing inference time. This approach further enhances the restorer's performance by approximately 0.3 dB. Additionally, we present a baseline framework that includes parallel generative adversarial branches with complementary \"self-synthesis\" and \"unpaired-synthesis\" constraints, ensuring the effectiveness of the training framework. Extensive experimental results on restoration tasks demonstrate that the proposed model performs favorably against existing state-of-the-art unsupervised restoration methods.", "authors": ["Lin Xin", "Yuyan Zhou", "Jingtong Yue", "Chao Ren", "Kelvin C. K. Chan", "Qi Lu", "Ming-Hsuan Yang"], "year": 2025, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 2, "type": "article", "concepts": ["Boosting (machine learning)", "Inference", "Computer science", "Computational complexity theory", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W3009526937", "doi": "https://doi.org/10.1002/pan3.10080", "title": "Action needed for the EU Common Agricultural Policy to address sustainability challenges", "abstract": "Making agriculture sustainable is a global challenge. In the European Union (EU), the Common Agricultural Policy (CAP) is failing with respect to biodiversity, climate, soil, land degradation as well as socio-economic challenges.The European Commission's proposal for a CAP post-2020 provides a scope for enhanced sustainability. However, it also allows Member States to choose low-ambition implementation pathways. It therefore remains essential to address citizens' demands for sustainable agriculture and rectify systemic weaknesses in the CAP, using the full breadth of available scientific evidence and knowledge.Concerned about current attempts to dilute the environmental ambition of the future CAP, and the lack of concrete proposals for improving the CAP in the draft of the European Green Deal, we call on the European Parliament, Council and Commission to adopt 10 urgent action points for delivering sustainable food production, biodiversity conservation and climate mitigation.Knowledge is available to help moving towards evidence-based, sustainable European agriculture that can benefit people, nature and their joint futures.The statements made in this article have the broad support of the scientific community, as expressed by above 3,600 signatories to the preprint version of this manuscript. The list can be found here (https://doi.org/10.5281/zenodo.3685632).", "authors": ["Guy Pe’er", "Aletta Bonn", "Helge Bruelheide", "Petra Dieker", "Nico Eisenhauer", "Peter H. Feindt", "Gregor Hagedorn", "Bernd Hansjürgens", "Irina Herzon", "Ângela Lomba", "Elisabeth Marquard", "Francisco Moreira", "Heike Nitsch", "Rainer Oppermann", "Andrea Perino", "Norbert Röder", "Christian Schleyer", "Stefan Schindler", "Christine Wolf", "Yves Zinngrebe", "Sebastian Lakner"], "year": 2020, "venue": "People and Nature", "cited_by_count": 548, "type": "article", "concepts": ["Common Agricultural Policy", "Sustainability", "European union", "Business", "Parliament"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2604754546", "doi": "https://doi.org/10.1038/ncomms14727", "title": "Dopamine neuronal loss contributes to memory and reward dysfunction in a model of Alzheimer’s disease", "abstract": "", "authors": ["Annalisa Nobili", "Emanuele Claudio Latagliata", "Maria Teresa Viscomi", "Virve Cavallucci", "Debora Cutuli", "Giacomo Giacovazzo", "Paraskevi Krashia", "Francesca Romana Rizzo", "Ramona Marino", "Mauro Federici", "Paola De Bartolo", "Daniela Aversa", "Maria Concetta Dell’Acqua", "Alberto Cordella", "Marco Sancandi", "Flavio Keller", "Laura Petrosini", "Stefano Puglisi‐Allegra", "Nicola Biagio Mercuri", "Roberto Coccurello", "Nicola Berretta", "Marcello D’Amelio"], "year": 2017, "venue": "Nature Communications", "cited_by_count": 487, "type": "article", "concepts": ["Ventral tegmental area", "Pars compacta", "Neuroscience", "Substantia nigra", "Dopamine"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4292488030", "doi": "https://doi.org/10.1038/s41591-022-01923-y", "title": "Cellular senescence and senolytics: the path to the clinic", "abstract": "", "authors": ["Selim Chaib", "Tamar Tchkonia", "James L. Kirkland"], "year": 2022, "venue": "Nature Medicine", "cited_by_count": 941, "type": "review", "concepts": ["Senescence", "Cellular senescence", "Medicine", "Clinical trial", "Psychological intervention"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2775636951", "doi": "https://doi.org/10.1016/j.preteyeres.2017.11.003", "title": "Optical coherence tomography angiography", "abstract": "", "authors": ["Richard F. Spaide", "James G. Fujimoto", "Nadia K. Waheed", "Srinivas R. Sadda", "Giovanni Staurenghi"], "year": 2017, "venue": "Progress in Retinal and Eye Research", "cited_by_count": 1618, "type": "review", "concepts": ["Choroid", "Medicine", "Optical coherence tomography", "Macular degeneration", "Retina"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W3000049009", "doi": "https://doi.org/10.3390/land9010028", "title": "A Bibliometric Analysis on Land Degradation: Current Status, Development, and Future Directions", "abstract": "Land degradation is a global issue receiving much attention currently. In order to objectively reveal the research situation of land degradation, bibliometrix and biblioshiny software packages have been used to conduct data mining and quantitative analysis on research papers in the fields of land degradation during 1990–2019 (data update time was 8 April 2019) in the Web of Science core collection database. The results show that: (1) during the past 20 years, the number of papers on land degradation has increased. According to the number of articles, it is divided into four stages: a low-production exploration period, a developmental sprout period, expansion of the promotion period, and a high-yield active period. (2) Land-degradation research covers 93 countries or regions. The top five countries in terms of research volume are China, the United States, the United Kingdom, Germany, and Australia. China, the United States, and the United Kingdom are the most important countries for international cooperation in the field of land degradation. However, cooperation between countries is not very close overall. (3) Land degradation, degradation, desertification, remote sensing, soil erosion, and soil degradation are high-frequency keywords in the field of land degradation in recent years. (4) The research hotspots in the field of land degradation mainly focus on research directions such as restoration and reconstruction of land degradation, and sustainable management of land resources. (5) The themes of various periods in the field of land degradation are diversified, and the evolutionary relationship is complex. There are 15 evolutionary paths with regard to dynamic monitoring of land degradation, environmental governance of land degradation, and responses of land degradation to land-use change. Finally, the paper concludes that the research directions on land degradation in future include the process, mechanism, and effect of land degradation, the application of new technologies, new monitoring methods for land degradation, theory enhancement, methods and models of ecological restoration, reconstruction of degraded land, multidisciplinary integrated system research, constructing a policy guarantee system for the reconstruction of degraded land, and strengthening research on land resource engineering.", "authors": ["Hualin Xie", "Yanwei Zhang", "Zhilong Wu", "Tiangui Lv"], "year": 2020, "venue": "Land", "cited_by_count": 406, "type": "article", "concepts": ["Land degradation", "Desertification", "Sustainable land management", "China", "Land management"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W3169893408", "doi": "https://doi.org/10.1007/s40747-021-00428-4", "title": "Methods for image denoising using convolutional neural network: a review", "abstract": "Abstract Image denoising faces significant challenges, arising from the sources of noise. Specifically, Gaussian, impulse, salt, pepper, and speckle noise are complicated sources of noise in imaging. Convolutional neural network (CNN) has increasingly received attention in image denoising task. Several CNN methods for denoising images have been studied. These methods used different datasets for evaluation. In this paper, we offer an elaborate study on different CNN techniques used in image denoising. Different CNN methods for image denoising were categorized and analyzed. Popular datasets used for evaluating CNN image denoising methods were investigated. Several CNN image denoising papers were selected for review and analysis. Motivations and principles of CNN methods were outlined. Some state-of-the-arts CNN image denoising methods were depicted in graphical forms, while other methods were elaborately explained. We proposed a review of image denoising with CNN. Previous and recent papers on image denoising with CNN were selected. Potential challenges and directions for future research were equally fully explicated.", "authors": ["Ademola E. Ilesanmi", "Taiwo Ilesanmi"], "year": 2021, "venue": "Complex & Intelligent Systems", "cited_by_count": 348, "type": "review", "concepts": ["Noise reduction", "Convolutional neural network", "Computer science", "Artificial intelligence", "Non-local means"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W7117495353", "doi": "https://doi.org/10.1109/tgrs.2025.3649014", "title": "INP-Net: Implicit Neural Prompting Network for Remote Sensing Image Dehazing", "abstract": "Restoring high-quality images from hazy observations is crucial for visual perception and downstream detection in remote sensing applications. Recent deep learning-based methods have achieved remarkable progress in dehazing, however, they often suffer from either unreliable prompting guidance or inadequate global modeling. To bridge these gaps, we propose INP-Net, an Implicit Neural Prompting Network for remote sensing image dehazing. INP-Net introduces an implicit neural prompting mechanism that exploits learnable implicit neural representations (INR) in the YCbCr color space as degradation-insensitive prompts, which are dynamically injected into the RGB decoding pipeline. In addition, we design the Adaptive Sampling and Prior-enhanced (ASP) Transformer Block to enrich global feature diversity. The ASP comprises two core components: Adaptive Soft Sampling Self-Attention (ASSA), which performs probabilistic token selection to eliminate channel redundancy and enhance discriminative representations; and the Prior-Modulated Mixed-Scale Feed-Forward Network (PMFN), which leverages haze prior knowledge as a multi-scale modulator to guide local feature restoration. Extensive experiments on multiple benchmark datasets demonstrate that the proposed INP-Net surpasses state-of-the-art methods both quantitatively and qualitatively. Our method achieves PSNR gains of 0.47 dB and 0.75 dB over state-of-the-art methods on the challenging StateHaze1K-thick and NH-Haze datasets, respectively.", "authors": ["Shan Liang", "Tao Gao", "Ting Chen", "Yuanbo Wen", "Qianxi Zhang", "Xiao Wang"], "year": 2025, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 1, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Redundancy (engineering)", "Computer vision", "Decoding methods"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2114655563", "doi": "https://doi.org/10.3389/fnagi.2013.00034", "title": "A delicate balance: Iron metabolism and diseases of the brain", "abstract": "Iron is the most abundant transition metal within the brain, and is vital for a number of cellular processes including neurotransmitter synthesis, myelination of neurons, and mitochondrial function. Redox cycling between ferrous and ferric iron is utilized in biology for various electron transfer reactions essential to life, yet this same chemistry mediates deleterious reactions with oxygen that induce oxidative stress. Consequently, there is a precise and tightly controlled mechanism to regulate iron in the brain. When iron is dysregulated, both conditions of iron overload and iron deficiencies are harmful to the brain. This review focuses on how iron metabolism is maintained in the brain, and how an alteration to iron and iron metabolism adversely affects neurological function.", "authors": ["Dominic J. Hare", "Scott Ayton", "Ashley I. Bush", "Peng Lei"], "year": 2013, "venue": "Frontiers in Aging Neuroscience", "cited_by_count": 429, "type": "article", "concepts": ["Ferrous", "Metabolism", "Oxidative stress", "Brain function", "Ferric"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W3202997660", "doi": "https://doi.org/10.1038/s43587-021-00121-8", "title": "Strategies for targeting senescent cells in human disease", "abstract": "", "authors": ["Nathan Gasek", "George A. Kuchel", "James L. Kirkland", "Ming Xu"], "year": 2021, "venue": "Nature Aging", "cited_by_count": 455, "type": "review", "concepts": ["Senescence", "Paracrine signalling", "Biology", "Carcinogenesis", "Disease"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4404431554", "doi": "https://doi.org/10.1016/j.jenvman.2024.123336", "title": "Characterizing and modeling spatiotemporal trends in rangelands: Prosopis juliflora impact in middle Awash Basin, Ethiopia", "abstract": "", "authors": ["Kalid Hassen Yasin"], "year": 2024, "venue": "Journal of Environmental Management", "cited_by_count": 3, "type": "article", "concepts": ["Rangeland", "Environmental science", "Vegetation (pathology)", "Edaphic", "Prosopis juliflora"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4392775085", "doi": "https://doi.org/10.1038/s41392-024-01745-z", "title": "Nanotechnology’s frontier in combatting infectious and inflammatory diseases: prevention and treatment", "abstract": "Inflammation-associated diseases encompass a range of infectious diseases and non-infectious inflammatory diseases, which continuously pose one of the most serious threats to human health, attributed to factors such as the emergence of new pathogens, increasing drug resistance, changes in living environments and lifestyles, and the aging population. Despite rapid advancements in mechanistic research and drug development for these diseases, current treatments often have limited efficacy and notable side effects, necessitating the development of more effective and targeted anti-inflammatory therapies. In recent years, the rapid development of nanotechnology has provided crucial technological support for the prevention, treatment, and detection of inflammation-associated diseases. Various types of nanoparticles (NPs) play significant roles, serving as vaccine vehicles to enhance immunogenicity and as drug carriers to improve targeting and bioavailability. NPs can also directly combat pathogens and inflammation. In addition, nanotechnology has facilitated the development of biosensors for pathogen detection and imaging techniques for inflammatory diseases. This review categorizes and characterizes different types of NPs, summarizes their applications in the prevention, treatment, and detection of infectious and inflammatory diseases. It also discusses the challenges associated with clinical translation in this field and explores the latest developments and prospects. In conclusion, nanotechnology opens up new possibilities for the comprehensive management of infectious and inflammatory diseases.", "authors": ["Yujing Huang", "Xiaohan Guo", "Yi Wu", "Xingyu Chen", "Lixiang Feng", "Na Xie", "Guobo Shen"], "year": 2024, "venue": "Signal Transduction and Targeted Therapy", "cited_by_count": 368, "type": "article", "concepts": ["Medicine", "Drug development", "Immunogenicity", "Drug", "Intensive care medicine"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2553239728", "doi": "https://doi.org/10.1523/jneurosci.2351-16.2016", "title": "Casting a Wide Net: Role of Perineuronal Nets in Neural Plasticity", "abstract": "Perineuronal nets (PNNs) are unique extracellular matrix structures that wrap around certain neurons in the CNS during development and control plasticity in the adult CNS. They appear to contribute to a wide range of diseases/disorders of the brain, are involved in recovery from spinal cord injury, and are altered during aging, learning and memory, and after exposure to drugs of abuse. Here the focus is on how a major component of PNNs, chondroitin sulfate proteoglycans, control plasticity, and on the role of PNNs in memory in normal aging, in a tauopathy model of Alzheimer's disease, and in drug addiction. Also discussed is how altered extracellular matrix/PNN formation during development may produce synaptic pathology associated with schizophrenia, bipolar disorder, major depression, and autism spectrum disorders. Understanding the molecular underpinnings of how PNNs are altered in normal physiology and disease will offer insights into new treatment approaches for these diseases.", "authors": ["Barbara A. Sorg", "Sabina Berretta", "Jordan M. Blacktop", "James W. Fawcett", "Hiroshi Kitagawa", "Jessica C. F. Kwok", "Marta Miquel"], "year": 2016, "venue": "Journal of Neuroscience", "cited_by_count": 453, "type": "review", "concepts": ["Perineuronal net", "Neuroscience", "Neuroplasticity", "Synaptic plasticity", "Biology"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2023606650", "doi": "https://doi.org/10.1016/j.echo.2004.07.013", "title": "American Society of Echocardiography recommendations for use of echocardiography in clinical trials", "abstract": "", "authors": ["John S. Gottdiener", "James Bednarz", "Richard B. Devereux", "Julius M. Gardin", "Allan L. Klein", "Warren J. Manning", "Annitta Morehead", "Dalane W. Kitzman", "Jae K. Oh", "Miguel A. Quiñones", "Nelson B. Schiller", "James H. Stein", "Neil J. Weissman"], "year": 2004, "venue": "Journal of the American Society of Echocardiography", "cited_by_count": 906, "type": "review", "concepts": ["Medicine", "Reproducibility", "Cardiology", "Internal medicine", "Doppler echocardiography"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4387533377", "doi": "https://doi.org/10.1016/j.jenvman.2023.119230", "title": "A systematic review of industrial wastewater management: Evaluating challenges and enablers", "abstract": "", "authors": ["Bikram Jit Singh", "Ayon Chakraborty", "Rippin Sehgal"], "year": 2023, "venue": "Journal of Environmental Management", "cited_by_count": 454, "type": "review", "concepts": ["Stakeholder", "Sustainability", "Business", "Circular economy", "Industrial wastewater treatment"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4388461325", "doi": "https://doi.org/10.1016/j.ecoinf.2023.102365", "title": "The first inventory of gullies in the Upper Taquari River Basin (Brazil) and its agreement with land use classes", "abstract": "", "authors": ["Rômullo Oliveira Louzada", "Ivan Bergier", "Fábio de Oliveira Roque"], "year": 2023, "venue": "Ecological Informatics", "cited_by_count": 3, "type": "article", "concepts": ["Context (archaeology)", "Vegetation (pathology)", "Hydrology (agriculture)", "Land use", "Terrain"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W2084852600", "doi": "https://doi.org/10.1007/s13280-012-0256-7", "title": "A Review of the Elements of Human Well-Being with an Emphasis on the Contribution of Ecosystem Services", "abstract": "", "authors": ["James K. Summers", "Lisa M. Smith", "Jason L. Case", "Rick A. Linthurst"], "year": 2012, "venue": "AMBIO", "cited_by_count": 377, "type": "review", "concepts": ["Emphasis (telecommunications)", "Ecosystem services", "Ecosystem", "Environmental resource management", "Business"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4304780007", "doi": "https://doi.org/10.1038/s41586-022-05318-4", "title": "A function-based typology for Earth’s ecosystems", "abstract": "", "authors": ["David A. Keith", "José R. Ferrer‐Paris", "Emily Nicholson", "Melanie J. Bishop", "Beth Polidoro", "Eva Ramírez-Llodra", "Mark G. Tozer", "Jeanne Nel", "Ralph Mac Nally", "Edward J. Gregr", "Kate E. Watermeyer", "Franz Essl", "Don Faber‐Langendoen", "Janet Franklin", "Caroline E. R. Lehmann", "Andrés Etter", "Dirk J. Roux", "Jonathan S. Stark", "Jessica A. Rowland", "Neil Brummitt", "U. Fernández-Arcaya", "Iain M. Suthers", "Susan K. Wiser", "Ian Donohue", "Leland J. Jackson", "R. Toby Pennington", "Thomas M. Iliffe", "Vasilis Gerovasileiou", "Paul S. Giller", "Belinda J. Robson", "Nathalie Pettorelli", "Ángela Andrade", "Arild Lindgaard", "Teemu Tahvanainen", "Aleks Terauds", "Michael A. Chadwick", "Nicholas Murray", "Justin Moat", "Patricio Pliscoff", "Irene Zager", "Richard T. Kingsford"], "year": 2022, "venue": "Nature", "cited_by_count": 302, "type": "article", "concepts": ["Ecosystem services", "Environmental resource management", "Convention on Biological Diversity", "Ecosystem management", "Total human ecosystem"], "search_query": "prompt-based image restoration learning degradation"}
{"openalex_id": "https://openalex.org/W4225672218", "doi": "https://doi.org/10.1109/cvpr52688.2022.00564", "title": "Restormer: Efficient Transformer for High-Resolution Image Restoration", "abstract": "Since convolutional neural networks (CNNs) perform well at learning generalizable image priors from large-scale data, these models have been extensively applied to image restoration and related tasks. Recently, another class of neural architectures, Transformers, have shown significant performance gains on natural language and high-level vision tasks. While the Transformer model mitigates the shortcomings of CNNs (i.e., limited receptive field and inadaptability to input content), its computational complexity grows quadratically with the spatial resolution, therefore making it infeasible to apply to most image restoration tasks involving high-resolution images. In this work, we propose an efficient Transformer model by making several key designs in the building blocks (multi-head attention and feed-forward network) such that it can capture long-range pixel interactions, while still remaining applicable to large images. Our model, named Restoration Transformer (Restormer), achieves state-of-the-art results on several image restoration tasks, including image deraining, single-image motion deblurring, defocus deblurring (single-image and dual-pixel data), and image denoising (Gaussian grayscale/color denoising, and real image denoising). The source code and pre-trained models are available at https://github.com/swz30/Restormer.", "authors": ["Syed Waqas Zamir", "Aditya Arora", "Salman Khan", "Munawar Hayat", "Fahad Shahbaz Khan", "Ming–Hsuan Yang"], "year": 2022, "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "cited_by_count": 3123, "type": "article", "concepts": ["Deblurring", "Computer science", "Artificial intelligence", "Image restoration", "Computer vision"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4312812783", "doi": "https://doi.org/10.1109/cvpr52688.2022.01716", "title": "Uformer: A General U-Shaped Transformer for Image Restoration", "abstract": "In this paper, we present Uformer, an effective and efficient Transformer-based architecture for image restoration, in which we build a hierarchical encoder-decoder network using the Transformer block. In Uformer, there are two core designs. First, we introduce a novel locally-enhanced window (LeWin) Transformer block, which performs non-overlapping window-based self-attention instead of global self-attention. It significantly reduces the computational complexity on high resolution feature map while capturing local context. Second, we propose a learnable multi-scale restoration modulator in the form of a multi-scale spatial bias to adjust features in multiple layers of the Uformer decoder. Our modulator demonstrates superior capability for restoring details for various image restoration tasks while introducing marginal extra parameters and computational cost. Powered by these two designs, Uformer enjoys a high capability for capturing both local and global dependencies for image restoration. To evaluate our approach, extensive experiments are conducted on several image restoration tasks, including image denoising, motion deblurring, defocus deblurring and deraining. Without bells and whistles, our Uformer achieves superior or comparable performance compared with the state-of-the-art algorithms. The code and models are available at https://github.com/ZhendongWang6/Uformer.", "authors": ["Zhendong Wang", "Xiaodong Cun", "Jianmin Bao", "Wengang Zhou", "Jianzhuang Liu", "Houqiang Li"], "year": 2022, "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "cited_by_count": 1866, "type": "article", "concepts": ["Deblurring", "Image restoration", "Computer science", "Transformer", "Encoder"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4386075642", "doi": "https://doi.org/10.1109/cvpr52729.2023.00570", "title": "Efficient Frequency Domain-based Transformers for High-Quality Image Deblurring", "abstract": "We present an effective and efficient method that explores the properties of Transformers in the frequency domain for high-quality image deblurring. Our method is motivated by the convolution theorem that the correlation or convolution of two signals in the spatial domain is equivalent to an element-wise product of them in the frequency domain. This inspires us to develop an efficient frequency domain-based self-attention solver (FSAS) to estimate the scaled dot-product attention by an element-wise product operation instead of the matrix multiplication in the spatial domain. In addition, we note that simply using the naive feed-forward network (FFN) in Transformers does not generate good deblurred results. To overcome this problem, we propose a simple yet effective discriminative frequency domain-based FFN (DFFN), where we introduce a gated mechanism in the FFN based on the Joint Photographic Experts Group (JPEG) compression algorithm to discriminatively determine which low- and high-frequency information of the features should be preserved for latent clear image restoration. We formulate the proposed FSAS and DFFN into an asymmetrical network based on an encoder and decoder architecture, where the FSAS is only used in the decoder module for better image deblurring. Experimental results show that the proposed method performs favorably against the state-of-the-art approaches.", "authors": ["Lingshun Kong", "Jiangxin Dong", "Jianjun Ge", "Mingqiang Li", "Jinshan Pan"], "year": 2023, "venue": "", "cited_by_count": 263, "type": "article", "concepts": ["Deblurring", "Computer science", "Frequency domain", "Transformer", "Image quality"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4321497943", "doi": "https://doi.org/10.3390/s23052385", "title": "Vision Transformers in Image Restoration: A Survey", "abstract": "The Vision Transformer (ViT) architecture has been remarkably successful in image restoration. For a while, Convolutional Neural Networks (CNN) predominated in most computer vision tasks. Now, both CNN and ViT are efficient approaches that demonstrate powerful capabilities to restore a better version of an image given in a low-quality format. In this study, the efficiency of ViT in image restoration is studied extensively. The ViT architectures are classified for every task of image restoration. Seven image restoration tasks are considered: Image Super-Resolution, Image Denoising, General Image Enhancement, JPEG Compression Artifact Reduction, Image Deblurring, Removing Adverse Weather Conditions, and Image Dehazing. The outcomes, the advantages, the limitations, and the possible areas for future research are detailed. Overall, it is noted that incorporating ViT in the new architectures for image restoration is becoming a rule. This is due to some advantages compared to CNN, such as better efficiency, especially when more data are fed to the network, robustness in feature extraction, and a better feature learning approach that sees better the variances and characteristics of the input. Nevertheless, some drawbacks exist, such as the need for more data to show the benefits of ViT over CNN, the increased computational cost due to the complexity of the self-attention block, a more challenging training process, and the lack of interpretability. These drawbacks represent the future research direction that should be targeted to increase the efficiency of ViT in the image restoration domain.", "authors": ["Anas M. Ali", "Bilel Benjdira", "Anis Koubâa", "Walid El‐Shafai", "Zahid Khan", "Wadii Boulila"], "year": 2023, "venue": "Sensors", "cited_by_count": 109, "type": "article", "concepts": ["Image restoration", "Deblurring", "Computer science", "Artificial intelligence", "Convolutional neural network"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4360887305", "doi": "https://doi.org/10.1109/tip.2023.3261747", "title": "CTCNet: A CNN-Transformer Cooperation Network for Face Image Super-Resolution", "abstract": "Recently, deep convolution neural networks (CNNs) steered face super-resolution methods have achieved great progress in restoring degraded facial details by joint training with facial priors. However, these methods have some obvious limitations. On the one hand, multi-task joint learning requires additional marking on the dataset, and the introduced prior network will significantly increase the computational cost of the model. On the other hand, the limited receptive field of CNN will reduce the fidelity and naturalness of the reconstructed facial images, resulting in suboptimal reconstructed images. In this work, we propose an efficient CNN-Transformer Cooperation Network (CTCNet) for face super-resolution tasks, which uses the multi-scale connected encoder-decoder architecture as the backbone. Specifically, we first devise a novel Local-Global Feature Cooperation Module (LGCM), which is composed of a Facial Structure Attention Unit (FSAU) and a Transformer block, to promote the consistency of local facial detail and global facial structure restoration simultaneously. Then, we design an efficient Feature Refinement Module (FRM) to enhance the encoded features. Finally, to further improve the restoration of fine facial details, we present a Multi-scale Feature Fusion Unit (MFFU) to adaptively fuse the features from different stages in the encoder procedure. Extensive evaluations on various datasets have assessed that the proposed CTCNet can outperform other state-of-the-art methods significantly. Source code will be available at https://github.com/IVIPLab/CTCNet.", "authors": ["Guangwei Gao", "Zixiang Xu", "Juncheng Li", "Jian Yang", "Tieyong Zeng", "Guo-Jun Qi"], "year": 2023, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 151, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Computer vision", "Face (sociological concept)", "Image resolution"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4406457474", "doi": "https://doi.org/10.1109/tcsvt.2025.3530090", "title": "VmambaIR: Visual State Space Model for Image Restoration", "abstract": "Image restoration is a critical task in low-level computer vision, aiming to restore high-quality images from degraded inputs. Various models, such as convolutional neural networks (CNNs), generative adversarial networks (GANs), transformers, and diffusion models (DMs), have been employed to address this problem with significant impact. However, CNNs have limitations in capturing long-range dependencies. DMs require large prior models and computationally intensive denoising steps. Transformers have powerful modeling capabilities but face challenges due to quadratic complexity with input image size. To tackle these challenges, we propose VmambaIR, one of the first works to introduce State Space Models (SSMs) with linear complexity into comprehensive image restoration tasks. Specifically, we utilize a Unet architecture to stack our proposed Omni Selective Scan (OSS) blocks, consisting of an OSS module and an Efficient Feed-Forward Network (EFFN). Our proposed omni selective scan mechanism overcomes the unidirectional modeling limitation of SSMs by efficiently modeling image information flows in all six directions to better exploit surrounding restoration information. Furthermore, we conducted a comprehensive evaluation of our VmambaIR across multiple image restoration tasks, including image deraining, single image super-resolution, and real-world image super-resolution. Extensive experimental results demonstrate that our proposed VmambaIR achieves state-of-the-art (SOTA) performance with much fewer computational resources and parameters. Our research highlights the potential of state space models as promising alternatives to the transformer and CNN architectures in serving as foundational frameworks for next-generation low-level visual tasks.", "authors": ["Yuan Shi", "Bin Xia", "Xiaoyu Jin", "Xing Wang", "Tianyu Zhao", "Xin Xia", "Xuefeng Xiao", "Wenming Yang"], "year": 2025, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 93, "type": "article", "concepts": ["Image restoration", "Computer vision", "Computer science", "Artificial intelligence", "Image (mathematics)"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W2984522085", "doi": "https://doi.org/10.1109/tci.2019.2911881", "title": "Deep Spatial–Spectral Representation Learning for Hyperspectral Image Denoising", "abstract": "Deep learning has found successful applications in restoration of two-dimensional (2-D) images including denoising, dehazing, and superresolution. However, existing deep convolutional neural network (DCNN) architecture cannot fully exploit spatial-spectral correlations in three-dimensional (3-D) hyperspectral images (HSIs) (directly extending 2-D DCNN into 3-D will significantly increase computational complexity); meantime, unlike 2-D images, there is an obstacle caused by the shortage of training data for HSIs. To meet those challenges, we present a novel, deep-learning framework for 3-D HSI denoising with the following contributions. First, inspired by the success of U-net in low-dose current-transformer denoising, we propose a novel approach of encoding rich multi-scale information of HSIs by a modified 3-D U-net. Second, we present a computationally efficient implementation of 3-D U-net based on the strategy of separable filtering. By decomposing 3-D filtering into 2-D spatial filtering and 1-D spectral filtering, we can achieve substantial savings on the number of network parameters to keep the computational complexity low. Third, we have developed a transfer learning approach of synthetically generating HSIs from RGB images as supplementary training data. The synthesized HSIs are used for the initial training of the modified 3-D U-net denoising network, which will be fine-tuned on real HSI images. Experimental results have shown that the proposed 3-D U-net denoising method significantly outperforms existing model-based HSI denoising methods.", "authors": ["Weisheng Dong", "Huan Wang", "Fangfang Wu", "Guangming Shi", "Xin Li"], "year": 2019, "venue": "IEEE Transactions on Computational Imaging", "cited_by_count": 127, "type": "article", "concepts": ["Hyperspectral imaging", "Artificial intelligence", "Noise reduction", "Computer science", "Deep learning"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4404654752", "doi": "https://doi.org/10.1007/978-3-031-72995-9_22", "title": "When Fast Fourier Transform Meets Transformer for Image Restoration", "abstract": "", "authors": ["Xingyu Jiang", "Xiuhui Zhang", "Ning Gao", "Yue Deng"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 36, "type": "book-chapter", "concepts": ["Computer science", "Fourier transform", "Image restoration", "Transformer", "Computer vision"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4404687984", "doi": "https://doi.org/10.1109/tip.2024.3501855", "title": "MWFormer: Multi-Weather Image Restoration Using Degradation-Aware Transformers", "abstract": "Restoring images captured under adverse weather conditions is a fundamental task for many computer vision applications. However, most existing weather restoration approaches are only capable of handling a specific type of degradation, which is often insufficient in real-world scenarios, such as rainy-snowy or rainy-hazy weather. Towards being able to address these situations, we propose a multi-weather Transformer, or MWFormer for short, which is a holistic vision Transformer that aims to solve multiple weather-induced degradations using a single, unified architecture. MWFormer uses hyper-networks and feature-wise linear modulation blocks to restore images degraded by various weather types using the same set of learned parameters. We first employ contrastive learning to train an auxiliary network that extracts content-independent, distortion-aware feature embeddings that efficiently represent predicted weather types, of which more than one may occur. Guided by these weather-informed predictions, the image restoration Transformer adaptively modulates its parameters to conduct both local and global feature processing, in response to multiple possible weather. Moreover, MWFormer allows for a novel way of tuning, during application, to either a single type of weather restoration or to hybrid weather restoration without any retraining, offering greater controllability than existing methods. Our experimental results on multi-weather restoration benchmarks show that MWFormer achieves significant performance improvements compared to existing state-of-the-art methods, without requiring much computational cost. Moreover, we demonstrate that our methodology of using hyper-networks can be integrated into various network architectures to further boost their performance. The code is available at: https://github.com/taco-group/MWFormer.", "authors": ["Ruoxi Zhu", "Zhengzhong Tu", "Jiaming Liu", "Alan C. Bovik", "Yibo Fan"], "year": 2024, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 28, "type": "article", "concepts": ["Image restoration", "Computer science", "Image processing", "Degradation (telecommunications)", "Computer vision"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4221151978", "doi": "https://doi.org/10.1145/3528223.3530127", "title": "Instant neural graphics primitives with a multiresolution hash encoding", "abstract": "Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.", "authors": ["Thomas Müller", "Alex Evans", "Christoph Schied", "Alexander Keller"], "year": 2022, "venue": "ACM Transactions on Graphics", "cited_by_count": 3366, "type": "article", "concepts": ["Computer science", "Hash function", "Speedup", "Rendering (computer graphics)", "Artificial neural network"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4372266706", "doi": "https://doi.org/10.1109/icassp49357.2023.10095242", "title": "Sandformer: CNN and Transformer under Gated Fusion for Sand Dust Image Restoration", "abstract": "Although Convolutional Neural Networks (CNN) have made good progress in image restoration, the intrinsic equivalence and locality of convolutions still constrain further improvements in image quality. Recent vision transformer and selfattention have achieved promising results on various computer vision tasks. However, directly utilizing Transformer for image restoration is a challenging task. In this paper, we introduce an effective hybrid architecture for sand image restoration tasks, which leverages local features from CNN and long-range dependencies captured by transformer to improve the results further. We propose an efficient hybrid structure for sand dust image restoration to solve the feature inconsistency issue between Transformer and CNN. The framework complements each representation by modulating features from the CNN-based and Transformer-based branches rather than simply adding or concatenating features. Experiments demonstrate that SandFormer achieves significant performance improvements in synthetic and real dust scenes compared to previous sand image restoration methods.", "authors": ["Jun Shi", "Bingcai Wei", "Gang Zhou", "Liye Zhang"], "year": 2023, "venue": "", "cited_by_count": 10, "type": "article", "concepts": ["Transformer", "Computer science", "Image restoration", "Convolutional neural network", "Locality"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4382173267", "doi": "https://doi.org/10.48550/arxiv.2306.13653", "title": "ProRes: Exploring Degradation-aware Visual Prompt for Universal Image Restoration", "abstract": "Image restoration aims to reconstruct degraded images, e.g., denoising or deblurring. Existing works focus on designing task-specific methods and there are inadequate attempts at universal methods. However, simply unifying multiple tasks into one universal architecture suffers from uncontrollable and undesired predictions. To address those issues, we explore prompt learning in universal architectures for image restoration tasks. In this paper, we present Degradation-aware Visual Prompts, which encode various types of image degradation, e.g., noise and blur, into unified visual prompts. These degradation-aware prompts provide control over image processing and allow weighted combinations for customized image restoration. We then leverage degradation-aware visual prompts to establish a controllable and universal model for image restoration, called ProRes, which is applicable to an extensive range of image restoration tasks. ProRes leverages the vanilla Vision Transformer (ViT) without any task-specific designs. Furthermore, the pre-trained ProRes can easily adapt to new tasks through efficient prompt tuning with only a few images. Without bells and whistles, ProRes achieves competitive performance compared to task-specific methods and experiments can demonstrate its ability for controllable restoration and adaptation for new tasks. The code and models will be released in \\url{https://github.com/leonmakise/ProRes}.", "authors": ["Jiaqi Ma", "Tianheng Cheng", "Guoli Wang", "Qian Zhang", "Xinggang Wang", "Lefei Zhang"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 14, "type": "preprint", "concepts": ["Deblurring", "Image restoration", "Computer science", "Artificial intelligence", "Leverage (statistics)"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4302013160", "doi": "https://doi.org/10.48550/arxiv.2210.01069", "title": "Dual-former: Hybrid Self-attention Transformer for Efficient Image Restoration", "abstract": "Recently, image restoration transformers have achieved comparable performance with previous state-of-the-art CNNs. However, how to efficiently leverage such architectures remains an open problem. In this work, we present Dual-former whose critical insight is to combine the powerful global modeling ability of self-attention modules and the local modeling ability of convolutions in an overall architecture. With convolution-based Local Feature Extraction modules equipped in the encoder and the decoder, we only adopt a novel Hybrid Transformer Block in the latent layer to model the long-distance dependence in spatial dimensions and handle the uneven distribution between channels. Such a design eliminates the substantial computational complexity in previous image restoration transformers and achieves superior performance on multiple image restoration tasks. Experiments demonstrate that Dual-former achieves a 1.91dB gain over the state-of-the-art MAXIM method on the Indoor dataset for single image dehazing while consuming only 4.2% GFLOPs as MAXIM. For single image deraining, it exceeds the SOTA method by 0.1dB PSNR on the average results of five datasets with only 21.5% GFLOPs. Dual-former also substantially surpasses the latest desnowing method on various datasets, with fewer parameters.", "authors": ["Sixiang Chen", "Ye Tian", "Yun Liu", "Erkang Chen"], "year": 2022, "venue": "arXiv (Cornell University)", "cited_by_count": 11, "type": "preprint", "concepts": ["FLOPS", "Computer science", "Transformer", "Encoder", "Leverage (statistics)"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W3155072588", "doi": "https://doi.org/10.1109/tpami.2022.3204461", "title": "Image Super-Resolution Via Iterative Refinement", "abstract": "We present SR3, an approach to image Super-Resolution via Repeated Refinement. SR3 adapts denoising diffusion probabilistic models (Ho et al. 2020), (Sohl-Dickstein et al. 2015) to image-to-image translation, and performs super-resolution through a stochastic iterative denoising process. Output images are initialized with pure Gaussian noise and iteratively refined using a U-Net architecture that is trained on denoising at various noise levels, conditioned on a low-resolution input image. SR3 exhibits strong performance on super-resolution tasks at different magnification factors, on faces and natural images. We conduct human evaluation on a standard 8× face super-resolution task on CelebA-HQ for which SR3 achieves a fool rate close to 50%, suggesting photo-realistic outputs, while GAN baselines do not exceed a fool rate of 34%. We evaluate SR3 on a 4× super-resolution task on ImageNet, where SR3 outperforms baselines in human evaluation and classification accuracy of a ResNet-50 classifier trained on high-resolution images. We further show the effectiveness of SR3 in cascaded image generation, where a generative model is chained with super-resolution models to synthesize high-resolution images with competitive FID scores on the class-conditional 256×256 ImageNet generation challenge.", "authors": ["Chitwan Saharia", "Jonathan Ho", "William Chan", "Tim Salimans", "David J. Fleet", "Mohammad Norouzi"], "year": 2022, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 1551, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Pattern recognition (psychology)", "Image resolution", "Computer vision"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4391667544", "doi": "https://doi.org/10.48550/arxiv.2402.04139", "title": "U-shaped Vision Mamba for Single Image Dehazing", "abstract": "Currently, Transformer is the most popular architecture for image dehazing, but due to its large computational complexity, its ability to handle long-range dependency is limited on resource-constrained devices. To tackle this challenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficient single-image dehazing network. Inspired by the State Space Sequence Models (SSMs), a new deep sequence model known for its power to handle long sequences, we design a Bi-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies. Extensive experimental results demonstrate the effectiveness of our method. Our method provides a more highly efficient idea of long-range dependency modeling for image dehazing as well as other image restoration tasks. The URL of the code is \\url{https://github.com/zzr-idam/UVM-Net}. Our method takes only \\textbf{0.009} seconds to infer a $325 \\times 325$ resolution image (100FPS) without I/O handling time.", "authors": ["Zhuoran Zheng", "Chen Wu"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 15, "type": "preprint", "concepts": ["Computer vision", "Image (mathematics)", "Artificial intelligence", "Computer science", "Geology"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4391417547", "doi": "https://doi.org/10.48550/arxiv.2401.15235", "title": "CascadedGaze: Efficiency in Global Context Extraction for Image Restoration", "abstract": "Image restoration tasks traditionally rely on convolutional neural networks. However, given the local nature of the convolutional operator, they struggle to capture global information. The promise of attention mechanisms in Transformers is to circumvent this problem, but it comes at the cost of intensive computational overhead. Many recent studies in image restoration have focused on solving the challenge of balancing performance and computational cost via Transformer variants. In this paper, we present CascadedGaze Network (CGNet), an encoder-decoder architecture that employs Global Context Extractor (GCE), a novel and efficient way to capture global information for image restoration. The GCE module leverages small kernels across convolutional layers to learn global dependencies, without requiring self-attention. Extensive experimental results show that our computationally efficient approach performs competitively to a range of state-of-the-art methods on synthetic image denoising and single image deblurring tasks, and pushes the performance boundary further on the real image denoising task.", "authors": ["Amirhosein Ghasemabadi", "Mohammad Salameh", "Muhammad Kamran Janjua", "Chunhua Zhou", "Fengyu Sun", "Di Niu"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 8, "type": "preprint", "concepts": ["Image restoration", "Context (archaeology)", "Extraction (chemistry)", "Image (mathematics)", "Computer science"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4399747822", "doi": "https://doi.org/10.1016/j.compag.2024.109169", "title": "Low-light wheat image enhancement using an explicit inter-channel sparse transformer", "abstract": "", "authors": ["Yu Wang", "Fei Wang", "Kun Li", "Xuping Feng", "Wenhui Hou", "Lu Liu", "Liqing Chen", "Yong He", "Yuwei Wang", "Yuwei Wang", "Yuwei Wang"], "year": 2024, "venue": "Computers and Electronics in Agriculture", "cited_by_count": 14, "type": "article", "concepts": ["Transformer", "Artificial intelligence", "Computer science", "Computer vision", "Pattern recognition (psychology)"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4377971563", "doi": "https://doi.org/10.2139/ssrn.4458244", "title": "Towards an Effective and Efficient Transformer for Rain-by-Snow Weather Removal", "abstract": "", "authors": ["Tao Gao", "Yuanbo Wen", "Kaihao Zhang", "Peng Cheng", "Ting Chen"], "year": 2023, "venue": "SSRN Electronic Journal", "cited_by_count": 8, "type": "preprint", "concepts": ["Snow", "Rain and snow mixed", "Environmental science", "Meteorology", "Transformer"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W2979040987", "doi": "https://doi.org/10.1109/access.2019.2945545", "title": "Comprehensive Review of Artificial Neural Network Applications to Pattern Recognition", "abstract": "The era of artificial neural network (ANN) began with a simplified application in many fields and remarkable success in pattern recognition (PR) even in manufacturing industries. Although significant progress achieved and surveyed in addressing ANN application to PR challenges, nevertheless, some problems are yet to be resolved like whimsical orientation (the unknown path that cannot be accurately calculated due to its directional position). Other problem includes; object classification, location, scaling, neurons behavior analysis in hidden layers, rule, and template matching. Also, the lack of extant literature on the issues associated with ANN application to PR seems to slow down research focus and progress in the field. Hence, there is a need for state-of-the-art in neural networks application to PR to urgently address the above-highlights problems for more successes. The study furnishes readers with a clearer understanding of the current, and new trend in ANN models that effectively addresses PR challenges to enable research focus and topics. Similarly, the comprehensive review reveals the diverse areas of the success of ANN models and their application to PR. In evaluating the performance of ANN models, some statistical indicators for measuring the performance of the ANN model in many studies were adopted. Such as the use of mean absolute percentage error (MAPE), mean absolute error (MAE), root mean squared error (RMSE), and variance of absolute percentage error (VAPE). The result shows that the current ANN models such as GAN, SAE, DBN, RBM, RNN, RBFN, PNN, CNN, SLP, MLP, MLNN, Reservoir computing, and Transformer models are performing excellently in their application to PR tasks. Therefore, the study recommends the research focus on current models and the development of new models concurrently for more successes in the field.", "authors": ["Oludare Isaac Abiodun", "Muhammad Ubale Kiru", "Aman Jantan", "Abiodun Esther Omolara", "Kemi Victoria Dada", "Abubakar Malah Umar", "Okafor Uchenwa Linus", "Humaira Arshad", "Abdullahi Aminu Kazaure", "Usman M. Gana"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 688, "type": "article", "concepts": ["Mean squared error", "Artificial neural network", "Computer science", "Mean absolute percentage error", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4401824304", "doi": "https://doi.org/10.3847/1538-4357/ad5954", "title": "Deeper, Sharper, Faster: Application of Efficient Transformer to Galaxy Image Restoration", "abstract": "Abstract The Transformer architecture has revolutionized the field of deep learning over the past several years in diverse areas, including natural language processing, code generation, image recognition, and time-series forecasting. We propose to apply Zamir et al.'s efficient transformer to perform deconvolution and denoising to enhance astronomical images. We conducted experiments using pairs of high-quality images and their degraded versions, and our deep learning model demonstrates exceptional restoration of photometric, structural, and morphological information. When compared with the ground-truth James Webb Space Telescope images, the enhanced versions of our Hubble Space Telescope–quality images reduce the scatter of isophotal photometry, Sérsic index, and half-light radius by factors of 4.4, 3.6, and 4.7, respectively, with Pearson correlation coefficients approaching unity. The performance is observed to degrade when input images exhibit correlated noise, point-like sources, and artifacts. We anticipate that this deep learning model will prove valuable for a number of scientific applications, including precision photometry, morphological analysis, and shear calibration.", "authors": ["Hyosun Park", "Yongsik Jo", "Seokun Kang", "T. Kim", "M. James Jee"], "year": 2024, "venue": "The Astrophysical Journal", "cited_by_count": 8, "type": "article", "concepts": ["Physics", "Galaxy", "Astronomy", "Astrophysics", "Transformer"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4295122555", "doi": "https://doi.org/10.3390/app12188972", "title": "Deep Residual Learning for Image Recognition: A Survey", "abstract": "Deep Residual Networks have recently been shown to significantly improve the performance of neural networks trained on ImageNet, with results beating all previous methods on this dataset by large margins in the image classification task. However, the meaning of these impressive numbers and their implications for future research are not fully understood yet. In this survey, we will try to explain what Deep Residual Networks are, how they achieve their excellent results, and why their successful implementation in practice represents a significant advance over existing techniques. We also discuss some open questions related to residual learning as well as possible applications of Deep Residual Networks beyond ImageNet. Finally, we discuss some issues that still need to be resolved before deep residual learning can be applied on more complex problems.", "authors": ["Muhammad Shafiq", "Zhaoquan Gu"], "year": 2022, "venue": "Applied Sciences", "cited_by_count": 838, "type": "article", "concepts": ["Residual", "Deep learning", "Computer science", "Artificial intelligence", "Deep neural networks"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4392884081", "doi": "https://doi.org/10.1016/j.jvcir.2024.104117", "title": "GoLDFormer: A global–local deformable window transformer for efficient image restoration", "abstract": "", "authors": ["Quan Chen", "Bolun Zheng", "Chenggang Yan", "Zunjie Zhu", "Tingyu Wang", "Greg Slabaugh", "Shanxin Yuan"], "year": 2024, "venue": "Journal of Visual Communication and Image Representation", "cited_by_count": 4, "type": "article", "concepts": ["Transformer", "Computer science", "Computation", "Window (computing)", "Computer vision"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4391944774", "doi": "https://doi.org/10.1007/s11042-024-18550-z", "title": "Underwater image enhancement using lightweight vision transformer", "abstract": "", "authors": ["Muneeba Daud", "Hammad Afzal", "Khawir Mahmood"], "year": 2024, "venue": "Multimedia Tools and Applications", "cited_by_count": 6, "type": "article", "concepts": ["Computer science", "Underwater", "Artificial intelligence", "Transformer", "Computer vision"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4382240242", "doi": "https://doi.org/10.1609/aaai.v37i3.25364", "title": "Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method", "abstract": "As the quality of optical sensors improves, there is a need for processing large-scale images. In particular, the ability of devices to capture ultra-high definition (UHD) images and video places new demands on the image processing pipeline. In this paper, we consider the task of low-light image enhancement (LLIE) and introduce a large-scale database consisting of images at 4K and 8K resolution. We conduct systematic benchmarking studies and provide a comparison of current LLIE algorithms. As a second contribution, we introduce LLFormer, a transformer-based low-light enhancement method. The core components of LLFormer are the axis-based multi-head self-attention and cross-layer attention fusion block, which significantly reduces the linear complexity. Extensive experiments on the new dataset and existing public datasets show that LLFormer outperforms state-of-the-art methods. We also show that employing existing LLIE methods trained on our benchmark as a pre-processing step significantly improves the performance of downstream tasks, e.g., face detection in low-light conditions. The source code and pre-trained models are available at https://github.com/TaoWangzj/LLFormer.", "authors": ["Tao Wang", "Kaihao Zhang", "Tianrun Shen", "Wenhan Luo", "Björn Stenger", "Tong Lu"], "year": 2023, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 359, "type": "article", "concepts": ["Computer science", "Benchmarking", "Benchmark (surveying)", "Artificial intelligence", "Transformer"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4366091323", "doi": "https://doi.org/10.1007/s10462-023-10466-8", "title": "Deep learning modelling techniques: current progress, applications, advantages, and challenges", "abstract": "Abstract Deep learning (DL) is revolutionizing evidence-based decision-making techniques that can be applied across various sectors. Specifically, it possesses the ability to utilize two or more levels of non-linear feature transformation of the given data via representation learning in order to overcome limitations posed by large datasets. As a multidisciplinary field that is still in its nascent phase, articles that survey DL architectures encompassing the full scope of the field are rather limited. Thus, this paper comprehensively reviews the state-of-art DL modelling techniques and provides insights into their advantages and challenges. It was found that many of the models exhibit a highly domain-specific efficiency and could be trained by two or more methods. However, training DL models can be very time-consuming, expensive, and requires huge samples for better accuracy. Since DL is also susceptible to deception and misclassification and tends to get stuck on local minima, improved optimization of parameters is required to create more robust models. Regardless, DL has already been leading to groundbreaking results in the healthcare, education, security, commercial, industrial, as well as government sectors. Some models, like the convolutional neural network (CNN), generative adversarial networks (GAN), recurrent neural network (RNN), recursive neural networks, and autoencoders, are frequently used, while the potential of other models remains widely unexplored. Pertinently, hybrid conventional DL architectures have the capacity to overcome the challenges experienced by conventional models. Considering that capsule architectures may dominate future DL models, this work aimed to compile information for stakeholders involved in the development and use of DL models in the contemporary world.", "authors": ["Shams Forruque Ahmed", "Md. Sakib Bin Alam", "Maruf Hassan", "Mahtabin Rodela Rozbu", "Taoseef Ishtiak", "Nazifa Rafa", "M. Mofijur", "A. B. M. Shawkat Ali", "Amir H. Gandomi"], "year": 2023, "venue": "Artificial Intelligence Review", "cited_by_count": 790, "type": "article", "concepts": ["Computer science", "Deep learning", "Artificial intelligence", "Machine learning", "Field (mathematics)"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4408456561", "doi": "https://doi.org/10.3390/s25061803", "title": "Adaptive Vectorial Restoration from Dynamic Speckle Patterns Through Biological Scattering Media Based on Deep Learning", "abstract": "Imaging technologies based on vector optical fields hold significant potential in the biomedical field, particularly for non-invasive scattering imaging of anisotropic biological tissues. However, the dynamic and anisotropic nature of biological tissues poses severe challenges to the propagation and reconstruction of vector optical fields due to light scattering. To address this, we propose a deep learning-based polarization-resolved restoration method aimed at achieving the efficient and accurate imaging reconstruction from speckle patterns generated after passing through anisotropic and dynamic time-varying biological scattering media. By innovatively leveraging the two orthogonal polarization components of vector optical fields, our approach significantly enhances the robustness of imaging reconstruction in dynamic and anisotropic biological scattering media, benefiting from the additional information dimension of vectorial optical fields and the powerful learning capacity of a deep neural network. For the first time, a hybrid network model is designed that integrates convolutional neural networks (CNN) with a Transformer architecture for capturing local and global features of a speckle image, enabling adaptive vectorial restoration of dynamically time-varying speckle patterns. The experimental results demonstrate that the model exhibits excellent robustness and generalization capabilities in reconstructing the two orthogonal polarization components from dynamic speckle patterns behind anisotropic biological media. This study not only provides an efficient solution for scattering imaging of dynamic anisotropic biological tissues but also advances the application of vector optical fields in dynamic scattering environments through the integration of deep learning and optical technologies.", "authors": ["Yu–Chen Chen", "Shixuan Mi", "Yaping Tian", "Xiaobo Hu", "Qiangqiang Yuan", "Khian‐Hooi Chew", "Rui‐Pin Chen"], "year": 2025, "venue": "Sensors", "cited_by_count": 5, "type": "article", "concepts": ["Speckle pattern", "Robustness (evolution)", "Computer science", "Artificial intelligence", "Scattering"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W2923477440", "doi": "https://doi.org/10.3390/inventions4010022", "title": "Internet of Things in Smart Grid: Architecture, Applications, Services, Key Technologies, and Challenges", "abstract": "Internet of Things (IoT) is a connection of people and things at any time, in any place, with anyone and anything, using any network and any service. Thus, IoT is a huge dynamic global network infrastructure of Internet-enabled entities with web services. One of the most important applications of IoT is the Smart Grid (SG). SG is a data communications network which is integrated with the power grid to collect and analyze data that are acquired from transmission lines, distribution substations, and consumers. In this paper, we talk about IoT and SG and their relationship. Some IoT architectures in SG, requirements for using IoT in SG, IoT applications and services in SG, and challenges and future work are discussed.", "authors": ["Alireza Ghasempour"], "year": 2019, "venue": "Inventions", "cited_by_count": 629, "type": "article", "concepts": ["Internet of Things", "Smart grid", "Computer science", "Key (lock)", "Architecture"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4392642845", "doi": "https://doi.org/10.1109/access.2024.3375360", "title": "Decomformer: Decompose Self-Attention of Transformer for Efficient Image Restoration", "abstract": "A transformer architecture achieves outstanding performance in computer vision tasks based on the ability to capture long-range dependencies. However, a quadratic increase in complexity with respect to spatial resolution makes it impractical to apply for image restoration tasks. In this paper, we propose a Decomformer that efficiently captures global relationship by decomposing self-attention into linear combination of vectors and coefficients to reduce the heavy computational cost. This approximation not only reduces the complexity linearly, but also preserves the globality of the vanilla self-attention properly. Moreover, we apply a linear simple gate to represent the complex self-attention mechanism as the proposed decomposition directly. To show the effectiveness of our approach, we apply it to image restoration tasks including denoising, deblurring and deraining. The proposed decomposing scheme for self-attention in the Transformer achieves better or comparable results with state-of-the-arts as well as much more efficiency than most of previous approaches.", "authors": ["Eunho Lee", "Youngbae Hwang"], "year": 2024, "venue": "IEEE Access", "cited_by_count": 3, "type": "article", "concepts": ["Deblurring", "Computer science", "Image restoration", "Transformer", "Globality"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4403754946", "doi": "https://doi.org/10.48550/arxiv.2409.13094", "title": "DenoMamba: A fused state-space model for low-dose CT denoising", "abstract": "Low-dose computed tomography (LDCT) lower potential risks linked to radiation exposure while relying on advanced denoising algorithms to maintain diagnostic quality in reconstructed images. The reigning paradigm in LDCT denoising is based on neural network models that learn data-driven image priors to separate noise evoked by dose reduction from underlying tissue signals. Naturally, the fidelity of these priors depend on the model's ability to capture the broad range of contextual features evident in CT images. Earlier convolutional neural networks (CNN) are highly adept at efficiently capturing short-range spatial context, but their limited receptive fields reduce sensitivity to interactions over longer distances. Although transformers based on self-attention mechanisms have recently been posed to increase sensitivity to long-range context, they can suffer from suboptimal performance and efficiency due to elevated model complexity, particularly for high-resolution CT images. For high-quality restoration of LDCT images, here we introduce DenoMamba, a novel denoising method based on state-space modeling (SSM), that efficiently captures short- and long-range context in medical images. Following an hourglass architecture with encoder-decoder stages, DenoMamba employs a spatial SSM module to encode spatial context and a novel channel SSM module equipped with a secondary gated convolution network to encode latent features of channel context at each stage. Feature maps from the two modules are then consolidated with low-level input features via a convolution fusion module (CFM). Comprehensive experiments on LDCT datasets with 25\\% and 10\\% dose reduction demonstrate that DenoMamba outperforms state-of-the-art denoisers with average improvements of 1.4dB PSNR, 1.1% SSIM, and 1.6% RMSE in recovered image quality.", "authors": ["Şaban Öztürk", "Özge Duran", "Tolga Çukur"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 7, "type": "preprint", "concepts": ["Noise reduction", "Space (punctuation)", "State space", "State (computer science)", "Nuclear medicine"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4410729663", "doi": "https://doi.org/10.1007/s00371-025-03947-0", "title": "An asymmetric calibrated transformer network for underwater image restoration", "abstract": "", "authors": ["Xiaojiao Guo", "Shenghong Luo", "Yihang Dong", "Zexiao Liang", "Zimeng Li", "Xiujun Zhang", "Xuhang Chen"], "year": 2025, "venue": "The Visual Computer", "cited_by_count": 2, "type": "article", "concepts": ["Underwater", "Transformer", "Computer graphics", "Computer science", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4367055910", "doi": "https://doi.org/10.1038/s41746-023-00811-0", "title": "Self-supervised learning for medical image classification: a systematic review and implementation guidelines", "abstract": "", "authors": ["Shih-Cheng Huang", "Anuj Pareek", "Malte Jensen", "Matthew P. Lungren", "Serena Yeung", "Akshay Chaudhari"], "year": 2023, "venue": "npj Digital Medicine", "cited_by_count": 356, "type": "review", "concepts": ["Artificial intelligence", "Computer science", "Machine learning", "Deep learning", "Supervised learning"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4406030314", "doi": "https://doi.org/10.1007/s11760-024-03798-7", "title": "Multi-scale representation for image deraining with state space model", "abstract": "", "authors": ["Yufeng Li", "Chuanlong Xie", "Hongming Chen"], "year": 2025, "venue": "Signal Image and Video Processing", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Feature (linguistics)", "Convolutional neural network", "Block (permutation group theory)"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4404275081", "doi": "https://doi.org/10.2139/ssrn.5018208", "title": "Joint Multi-Dimensional Dynamic Attention and Transformer for General Image Restoration", "abstract": "", "authors": ["Huan Zhang", "Xu Zhang", "Nian Cai", "Jianglei Di", "Yun Zhang"], "year": 2024, "venue": "SSRN Electronic Journal", "cited_by_count": 2, "type": "preprint", "concepts": ["Joint (building)", "Transformer", "Image restoration", "Computer science", "Computer vision"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4283801824", "doi": "https://doi.org/10.1038/s41551-022-00898-y", "title": "Shifting machine learning for healthcare from development to deployment and from models to data", "abstract": "In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance.", "authors": ["Angela Zhang", "Lei Xing", "James Zou", "Joseph C. Wu"], "year": 2022, "venue": "Nature Biomedical Engineering", "cited_by_count": 373, "type": "review", "concepts": ["Software deployment", "Computer science", "Artificial intelligence", "Health care", "Machine learning"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4411899995", "doi": "https://doi.org/10.1007/s00521-025-11440-x", "title": "LDFormer: lightweight dehazing transformer", "abstract": "", "authors": ["D. Pushpalatha", "P. Prithvi"], "year": 2025, "venue": "Neural Computing and Applications", "cited_by_count": 3, "type": "article", "concepts": ["Computational Science and Engineering", "Computer science", "Transformer", "Machine learning", "Electrical engineering"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4382568119", "doi": "https://doi.org/10.2139/ssrn.4495224", "title": "Blind Face Restoration: Benchmark Datasets and a Baseline Model", "abstract": "", "authors": ["Puyang Zhang", "Kaihao Zhang", "Wenhan Luo", "Changsheng Li", "Guoren Wang"], "year": 2023, "venue": "SSRN Electronic Journal", "cited_by_count": 5, "type": "preprint", "concepts": ["Benchmark (surveying)", "Baseline (sea)", "Computer science", "Face (sociological concept)", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4205129187", "doi": "https://doi.org/10.1109/access.2022.3142859", "title": "Particle Swarm Optimization: A Comprehensive Survey", "abstract": "Particle swarm optimization (PSO) is one of the most well-regarded swarm-based algorithms in the literature. Although the original PSO has shown good optimization performance, it still severely suffers from premature convergence. As a result, many researchers have been modifying it resulting in a large number of PSO variants with either slightly or significantly better performance. Mainly, the standard PSO has been modified by four main strategies: modification of the PSO controlling parameters, hybridizing PSO with other well-known meta-heuristic algorithms such as genetic algorithm (GA) and differential evolution (DE), cooperation and multi-swarm techniques. This paper attempts to provide a comprehensive review of PSO, including the basic concepts of PSO, binary PSO, neighborhood topologies in PSO, recent and historical PSO variants, remarkable engineering applications of PSO, and its drawbacks. Moreover, this paper reviews recent studies that utilize PSO to solve feature selection problems. Finally, eight potential research directions that can help researchers further enhance the performance of PSO are provided.", "authors": ["Tareq M. Shami", "Ayman A. El‐Saleh", "Mohammed Alswaitti", "Qasem Al-Tashi", "Mhd Amen Summakieh", "Seyedali Mirjalili"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 1158, "type": "article", "concepts": ["Particle swarm optimization", "Premature convergence", "Computer science", "Swarm behaviour", "Mathematical optimization"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4409019412", "doi": "https://doi.org/10.1109/jsen.2025.3554650", "title": "Weather-Robust Spatial-Frequency Decoupling Transformer for Crack Segmentation", "abstract": "Using edge devices such as drones for road inspections is critical for monitoring the structural integrity of transportation infrastructure. However, the limited resources of these devices constrain the deployment of high-performance models, while dynamic weather conditions require greater model stability. To address the challenge of efficient crack detection across various environments, we propose the spatial-frequency decoupling transformer (SFDFormer). Our model integrates an all-inone restoration module and a frequency decoupling module. The restoration module, combining AdverseGAN and stacked attention-integrated iterative recovery (AIIR) modules, restores images degraded by adverse weather. The frequency decoupling module employs a lightweight parallel network architecture to establish a correspondence between frequency-domain components and spatial-domain pixels, enabling direct extraction of crack edges and region information from the raw image. This approach effectively leverages semantic details from the frequency domain for pixel-level crack segmentation. Extensive experiments across six benchmark datasets demonstrate that SFDFormer consistently outperforms existing models, setting a new standard for crack detection on edge devices under harsh weather conditions.", "authors": ["Senyang Li", "Siqi Cai", "Siohong Teng", "Siwei Wei", "Jingling Yuan", "Xian Zhong"], "year": 2025, "venue": "IEEE Sensors Journal", "cited_by_count": 3, "type": "article", "concepts": ["Decoupling (probability)", "Transformer", "Segmentation", "Computer science", "Electronic engineering"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4285065952", "doi": "https://doi.org/10.1109/access.2022.3179517", "title": "A Review of Wavelet Analysis and Its Applications: Challenges and Opportunities", "abstract": "As a general and rigid mathematical tool, wavelet theory has found many applications and is constantly developing. This article reviews the development history of wavelet theory, from the construction method to the discussion of wavelet properties. Then it focuses on the design and expansion of wavelet transform. The main models and algorithms of wavelet transform are discussed. The construction of rational wavelet transform (RWT) is provided by examples emphasizing the advantages of RWT over traditional wavelet transform through a review of the literature. The combination of wavelet theory and neural networks is one of the key points of the review. The review covers the evolution of Wavelet Neural Network (WNN), the system architecture and algorithm implementation. The review of the literature indicates the advantages and a clear trend of fast development inWNNthat can be combined with existing neural network algorithms. This article also introduces the categories of wavelet-based applications. The advantages of wavelet analysis are summarized in terms of application scenarios with a comparison of results. Through the review, new research challenges and gaps have been clarified, which will serve as a guide for potential wavelet-based applications and new system designs.", "authors": ["Tiantian Guo", "Tongpo Zhang", "Eng Gee Lim", "Miguel López‐Benítez", "Fei Ma", "Limin Yu"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 446, "type": "review", "concepts": ["Wavelet", "Wavelet transform", "Lifting scheme", "Computer science", "Wavelet packet decomposition"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4393150006", "doi": "https://doi.org/10.1609/aaai.v38i2.27907", "title": "Omni-Kernel Network for Image Restoration", "abstract": "Image restoration aims to reconstruct a high-quality image from a degraded low-quality observation. Recently, Transformer models have achieved promising performance on image restoration tasks due to their powerful ability to model long-range dependencies. However, the quadratically growing complexity with respect to the input size makes them inapplicable to practical applications. In this paper, we develop an efficient convolutional network for image restoration by enhancing multi-scale representation learning. To this end, we propose an omni-kernel module that consists of three branches, i.e., global, large, and local branches, to learn global-to-local feature representations efficiently. Specifically, the global branch achieves a global perceptive field via the dual-domain channel attention and frequency-gated mechanism. Furthermore, to provide multi-grained receptive fields, the large branch is formulated via different shapes of depth-wise convolutions with unusually large kernel sizes. Moreover, we complement local information using a point-wise depth-wise convolution. Finally, the proposed network, dubbed OKNet, is established by inserting the omni-kernel module into the bottleneck position for efficiency. Extensive experiments demonstrate that our network achieves state-of-the-art performance on 11 benchmark datasets for three representative image restoration tasks, including image dehazing, image desnowing, and image defocus deblurring. The code is available at https://github.com/c-yn/OKNet.", "authors": ["Yuning Cui", "Wenqi Ren", "Alois Knoll"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 183, "type": "article", "concepts": ["Image restoration", "Kernel (algebra)", "Computer science", "Artificial intelligence", "Image (mathematics)"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W4375827355", "doi": "https://doi.org/10.1007/978-3-031-31417-9_40", "title": "A Transformer-Based U-Net Architecture for Fast and Efficient Image Demoireing", "abstract": "", "authors": ["Densen Puthussery", "P. S. Hrishikesh", "C. V. Jiji"], "year": 2023, "venue": "Communications in computer and information science", "cited_by_count": 1, "type": "book-chapter", "concepts": ["Deblurring", "Computer science", "Transformer", "Architecture", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W2997150500", "doi": "https://doi.org/10.1609/aaai.v34i07.6693", "title": "Channel Attention Is All You Need for Video Frame Interpolation", "abstract": "Prevailing video frame interpolation techniques rely heavily on optical flow estimation and require additional model complexity and computational cost; it is also susceptible to error propagation in challenging scenarios with large motion and heavy occlusion. To alleviate the limitation, we propose a simple but effective deep neural network for video frame interpolation, which is end-to-end trainable and is free from a motion estimation network component. Our algorithm employs a special feature reshaping operation, referred to as PixelShuffle, with a channel attention, which replaces the optical flow computation module. The main idea behind the design is to distribute the information in a feature map into multiple channels and extract motion information by attending the channels for pixel-level frame synthesis. The model given by this principle turns out to be effective in the presence of challenging motion and occlusion. We construct a comprehensive evaluation benchmark and demonstrate that the proposed approach achieves outstanding performance compared to the existing models with a component for optical flow computation.", "authors": ["Myungsub Choi", "Heewon Kim", "Bohyung Han", "Ning Xu", "Kyoung Mu Lee"], "year": 2020, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 325, "type": "article", "concepts": ["Computer science", "Optical flow", "Interpolation (computer graphics)", "Channel (broadcasting)", "Motion interpolation"], "search_query": "image restoration transformer architecture efficient"}
{"openalex_id": "https://openalex.org/W3133049266", "doi": "https://doi.org/10.1109/jstsp.2021.3053364", "title": "Editorial: Introduction to the Issue on Deep Learning for Image/Video Restoration and Compression", "abstract": "The papers in this special issue focus on deep learning for image/video restoration and compression. The huge success of deep-learning-based approaches in computer vision has inspired research in learned solutions to classic image/video processing problems, such as denoising, deblurring, dehazing, deraining, super-resolution (SR), and compression. Hence, learning-based methods have emerged as a promising nonlinear signal-processing framework for image/ video restoration and compression. Recent works have shown that learned models can achieve significant performance gains, especially in terms of perceptual quality measures, over traditional methods. Hence, the state of the art in image restoration and compression is getting redefined. This special issue covers the state of the art in learned image/video restoration and compression to promote further progress in innovative architectures and training methods for effective and efficient networks for image/video restoration and compression.", "authors": ["A. Murat Tekalp", "Michele Covell", "Radu Timofte", "Chao Dong"], "year": 2021, "venue": "IEEE Journal of Selected Topics in Signal Processing", "cited_by_count": 7, "type": "editorial", "concepts": ["Deblurring", "Image restoration", "Computer science", "Compression artifact", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4389599809", "doi": "https://doi.org/10.48550/arxiv.2312.05038", "title": "Prompt-In-Prompt Learning for Universal Image Restoration", "abstract": "Image restoration, which aims to retrieve and enhance degraded images, is fundamental across a wide range of applications. While conventional deep learning approaches have notably improved the image quality across various tasks, they still suffer from (i) the high storage cost needed for various task-specific models and (ii) the lack of interactivity and flexibility, hindering their wider application. Drawing inspiration from the pronounced success of prompts in both linguistic and visual domains, we propose novel Prompt-In-Prompt learning for universal image restoration, named PIP. First, we present two novel prompts, a degradation-aware prompt to encode high-level degradation knowledge and a basic restoration prompt to provide essential low-level information. Second, we devise a novel prompt-to-prompt interaction module to fuse these two prompts into a universal restoration prompt. Third, we introduce a selective prompt-to-feature interaction module to modulate the degradation-related feature. By doing so, the resultant PIP works as a plug-and-play module to enhance existing restoration models for universal image restoration. Extensive experimental results demonstrate the superior performance of PIP on multiple restoration tasks, including image denoising, deraining, dehazing, deblurring, and low-light enhancement. Remarkably, PIP is interpretable, flexible, efficient, and easy-to-use, showing promising potential for real-world applications. The code is available at https://github.com/longzilicart/pip_universal.", "authors": ["Zilong Li", "Yiming Lei", "Chenglong Ma", "Junping Zhang", "Hongming Shan"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 6, "type": "preprint", "concepts": ["Deblurring", "Computer science", "Image restoration", "Flexibility (engineering)", "Feature (linguistics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4385667669", "doi": "https://doi.org/10.1007/s11263-023-01843-5", "title": "Pyramid Attention Network for Image Restoration", "abstract": "", "authors": ["Yiqun Mei", "Yuchen Fan", "Yulun Zhang", "Jiahui Yu", "Yuqian Zhou", "Ding Liu", "Yun Fu", "Thomas S. Huang", "Humphrey Shi"], "year": 2023, "venue": "International Journal of Computer Vision", "cited_by_count": 112, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Pyramid (geometry)", "Computer vision", "Image restoration"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4323022514", "doi": "https://doi.org/10.1109/access.2023.3250616", "title": "A Comprehensive Review of Deep Learning-Based Real-World Image Restoration", "abstract": "Real-world imagery does not always exhibit good visibility and clean content, but often suffers from various kinds of degradations (e.g., noise, blur, rain drops, fog, color distortion, etc.), which severely affect vision-driven tasks (e.g., image classification, target recognition, and tracking, etc.). Thus, restoring the true scene from such degraded images is of significance. In recent years, a large body of deep learning-based image processing works has been exploited due to the advances in deep neural networks. This paper aims to make a comprehensive review of real-world image restoration algorithms and beyond. More specifically, this review provides overviews of critical benchmark datasets, image quality assessment methods, and four major categories of deep learning-based image restoration methods, i.e., based on convolutional neural network (CNN), generative adversarial network (GAN), Transformer, and multi-layer perceptron (MLP). The paper highlights the latest developments and advances in each category of network architecture to provide an up-to-date overview. Moreover, the representative state-of-the-art image restoration methods are compared visually and numerically. Finally, for real-world image restoration, the current situations are objectively assessed, challenges are discussed, and future directions and trends are presented.", "authors": ["Lujun Zhai", "Yonghui Wang", "Suxia Cui", "Yu Zhou"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 62, "type": "review", "concepts": ["Computer science", "Image restoration", "Artificial intelligence", "Convolutional neural network", "Deep learning"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4400238700", "doi": "https://doi.org/10.3390/app14135683", "title": "A Survey on Visual Mamba", "abstract": "State space models (SSM) with selection mechanisms and hardware-aware architectures, namely Mamba, have recently shown significant potential in long-sequence modeling. Since the complexity of transformers’ self-attention mechanism is quadratic with image size, as well as increasing computational demands, researchers are currently exploring how to adapt Mamba for computer vision tasks. This paper is the first comprehensive survey that aims to provide an in-depth analysis of Mamba models within the domain of computer vision. It begins by exploring the foundational concepts contributing to Mamba’s success, including the SSM framework, selection mechanisms, and hardware-aware design. Then, we review these vision Mamba models by categorizing them into foundational models and those enhanced with techniques including convolution, recurrence, and attention to improve their sophistication. Furthermore, we investigate the widespread applications of Mamba in vision tasks, which include their use as a backbone in various levels of vision processing. This encompasses general visual tasks, medical visual tasks (e.g., 2D/3D segmentation, classification, image registration, etc.), and remote sensing visual tasks. In particular, we introduce general visual tasks from two levels: high/mid-level vision (e.g., object detection, segmentation, video classification, etc.) and low-level vision (e.g., image super-resolution, image restoration, visual generation, etc.). We hope this endeavor will spark additional interest within the community to address current challenges and further apply Mamba models in computer vision.", "authors": ["Hanwei Zhang", "Ying Zhu", "Dan Wang", "Lijun Zhang", "Tianxiang Chen", "Ziyang Wang", "Zi Ye"], "year": 2024, "venue": "Applied Sciences", "cited_by_count": 132, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Sophistication", "Computer vision", "Segmentation"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4221160948", "doi": "https://doi.org/10.1109/jbhi.2022.3187103", "title": "RFormer: Transformer-Based Generative Adversarial Network for Real Fundus Image Restoration on a New Clinical Benchmark", "abstract": "Ophthalmologists have used fundus images to screen and diagnose eye diseases. However, different equipments and ophthalmologists pose large variations to the quality of fundus images. Low-quality (LQ) degraded fundus images easily lead to uncertainty in clinical screening and generally increase the risk of misdiagnosis. Thus, real fundus image restoration is worth studying. Unfortunately, real clinical benchmark has not been explored for this task so far. In this paper, we investigate the real clinical fundus image restoration problem. Firstly, We establish a clinical dataset, Real Fundus (RF), including 120 low- and high-quality (HQ) image pairs. Then we propose a novel Transformer-based Generative Adversarial Network (RFormer) to restore the real degradation of clinical fundus images. The key component in our network is the Window-based Self-Attention Block (WSAB) which captures non-local self-similarity and long-range dependencies. To produce more visually pleasant results, a Transformer-based discriminator is introduced. Extensive experiments on our clinical benchmark show that the proposed RFormer significantly outperforms the state-of-the-art (SOTA) methods. In addition, experiments of downstream tasks such as vessel segmentation and optic disc/cup detection demonstrate that our proposed RFormer benefits clinical fundus image analysis and applications.", "authors": ["Zhuo Deng", "Yuanhao Cai", "Lu Chen", "Zheng Gong", "Qiqi Bao", "Xue Yao", "Fang Dong", "Wenming Yang", "Shaochong Zhang", "Lan Ma"], "year": 2022, "venue": "IEEE Journal of Biomedical and Health Informatics", "cited_by_count": 76, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Discriminator", "Fundus (uterus)", "Benchmark (surveying)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W3154672751", "doi": "https://doi.org/10.1155/2021/5541134", "title": "Deep CNN and Deep GAN in Computational Visual Perception‐Driven Image Analysis", "abstract": "Computational visual perception, also known as computer vision, is a field of artificial intelligence that enables computers to process digital images and videos in a similar way as biological vision does. It involves methods to be developed to replicate the capabilities of biological vision. The computer vision’s goal is to surpass the capabilities of biological vision in extracting useful information from visual data. The massive data generated today is one of the driving factors for the tremendous growth of computer vision. This survey incorporates an overview of existing applications of deep learning in computational visual perception. The survey explores various deep learning techniques adapted to solve computer vision problems using deep convolutional neural networks and deep generative adversarial networks. The pitfalls of deep learning and their solutions are briefly discussed. The solutions discussed were dropout and augmentation. The results show that there is a significant improvement in the accuracy using dropout and data augmentation. Deep convolutional neural networks’ applications, namely, image classification, localization and detection, document analysis, and speech recognition, are discussed in detail. In‐depth analysis of deep generative adversarial network applications, namely, image‐to‐image translation, image denoising, face aging, and facial attribute editing, is done. The deep generative adversarial network is unsupervised learning, but adding a certain number of labels in practical applications can improve its generating ability. However, it is challenging to acquire many data labels, but a small number of data labels can be acquired. Therefore, combining semisupervised learning and generative adversarial networks is one of the future directions. This article surveys the recent developments in this direction and provides a critical review of the related significant aspects, investigates the current opportunities and future challenges in all the emerging domains, and discusses the current opportunities in many emerging fields such as handwriting recognition, semantic mapping, webcam‐based eye trackers, lumen center detection, query‐by‐string word, intermittently closed and open lakes and lagoons, and landslides.", "authors": ["R. Abirami", "P. M. Durai Raj Vincent", "Kathiravan Srinivasan", "Usman Tariq", "Chuan‐Yu Chang"], "year": 2021, "venue": "Complexity", "cited_by_count": 77, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Image (mathematics)", "Perception", "Deep learning"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4283820866", "doi": "https://doi.org/10.1609/aaai.v36i2.20033", "title": "Close the Loop: A Unified Bottom-Up and Top-Down Paradigm for Joint Image Deraining and Segmentation", "abstract": "In this work, we focus on a very practical problem: image segmentation under rain conditions. Image deraining is a classic low-level restoration task, while image segmentation is a typical high-level understanding task. Most of the existing methods intuitively employ the bottom-up paradigm by taking deraining as a preprocessing step for subsequent segmentation. However, our statistical analysis indicates that not only deraining would benefit segmentation (bottom-up), but also segmentation would further improve deraining performance (top-down) in turn. This motivates us to solve the rainy image segmentation task within a novel top-down and bottom-up unified paradigm, in which two sub-tasks are alternatively performed and collaborated with each other. Specifically, the bottom-up procedure yields both clearer images and rain-robust features from both image and feature domains, so as to ease the segmentation ambiguity caused by rain streaks. The top-down procedure adopts semantics to adaptively guide the restoration for different contents via a novel multi-path semantic attentive module (SAM). Thus the deraining and segmentation could boost the performance of each other cooperatively and progressively. Extensive experiments and ablations demonstrate that the proposed method outperforms the state-of-the-art on rainy image segmentation.", "authors": ["Yi Li", "Yi Chang", "Chang‐Feng Yu", "Luxin Yan"], "year": 2022, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 28, "type": "article", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Task (project management)", "Scale-space segmentation"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W3033307992", "doi": "https://doi.org/10.1109/access.2020.2999750", "title": "MSGAN: Generative Adversarial Networks for Image Seasonal Style Transfer", "abstract": "Although Generative Adversarial Networks (GANs) have shown remarkable successes in various computer vision tasks, they still face challenges in image season style transfer task. In this paper, we propose a multi-season Generative Adversarial Networks (MSGANs) aimed to transfer input images into other season styles. To improve the quality of the simulated images generated by the proposed MSGAN, we propose a novel loss function to guide the optimization direction of the network. Besides, we adopt the saliency information to guide the seasonal style transformation task, so as to ensure that different image contents can have different optimization weights in MSGAN. The experimental results show that the proposed MSGAN can generate high-quality simulated images from real images, and is superior to other latest methods. Not only that, the synthetic image generated by the proposed method also be used to perform depth estimation task so that prove that the synthetic images can be well applied to other computer vision tasks.", "authors": ["Fuquan Zhang", "Chuansheng Wang"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 24, "type": "article", "concepts": ["Computer science", "Task (project management)", "Artificial intelligence", "Adversarial system", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4393153879", "doi": "https://doi.org/10.1609/aaai.v38i6.28412", "title": "Learning from History: Task-agnostic Model Contrastive Learning for Image Restoration", "abstract": "Contrastive learning has emerged as a prevailing paradigm for high-level vision tasks, which, by introducing properly negative samples, has also been exploited for low-level vision tasks to achieve a compact optimization space to account for their ill-posed nature. However, existing methods rely on manually predefined and task-oriented negatives, which often exhibit pronounced task-specific biases. To address this challenge, our paper introduces an innovative method termed 'learning from history', which dynamically generates negative samples from the target model itself. Our approach, named Model Contrastive Learning for Image Restoration (MCLIR), rejuvenates latency models as negative models, making it compatible with diverse image restoration tasks. We propose the Self-Prior guided Negative loss (SPN) to enable it. This approach significantly enhances existing models when retrained with the proposed model contrastive paradigm. The results show significant improvements in image restoration across various tasks and architectures. For example, models retrained with SPN outperform the original FFANet and DehazeFormer by 3.41 and 0.57 dB on the RESIDE indoor dataset for image dehazing. Similarly, they achieve notable improvements of 0.47 dB on SPA-Data over IDT for image deraining and 0.12 dB on Manga109 for a 4x scale super-resolution over lightweight SwinIR, respectively. Code and retrained models are available at https://github.com/Aitical/MCLIR.", "authors": ["Gang Wu", "Junjun Jiang", "Kui Jiang", "Xianming Liu"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 11, "type": "article", "concepts": ["Task (project management)", "Computer science", "Artificial intelligence", "Image (mathematics)", "Image restoration"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W3043357501", "doi": "https://doi.org/10.1109/access.2020.3008324", "title": "FastDerainNet: A Deep Learning Algorithm for Single Image Deraining", "abstract": "Existing neural network-based methods for de-raining single images exhibit dissatisfactory results owing to the inefficient propagation of features when objects with sizes and shapes similar to those of rain streaks are present in images. Furthermore, existing methods do not consider that the abundant information included in rain streaked images could interfere with the training process. To overcome these limitations, in this paper, we propose a deep residual learning algorithm called FastDerainNet for removing rain streaks from single images. We design a deep convolutional neural network architecture, based on a deep residual network called the share-source residual module (SSRM), by substituting the origins of all shortcut connections for one point. To further improve the de-raining performance, we adopt the SSRM as the parameter layers in FastDerainNet and use image decomposition to modify the loss function. Finally, we train FastDerainNet on a synthetic dataset. By learning the residual mapping between rainy and clean image detail layers, it is able to reduce the mapping range and simplify the training process. Experiments on both synthetic and real-world images demonstrate that the proposed method achieves increased performance with regard to de-raining, in addition to preserving original details, in comparison with other state-of-the-art methods.", "authors": ["Xiuwen Wang", "Zhiwei Li", "Hongtao Shan", "Zhiyuan Tian", "Yuanhong Ren", "Wuneng Zhou"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 17, "type": "article", "concepts": ["Computer science", "Residual", "Convolutional neural network", "Deep learning", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W2971374671", "doi": "https://doi.org/10.1109/access.2019.2939578", "title": "Color Filter Array Demosaicking Using Densely Connected Residual Network", "abstract": "Deep convolutional neural networks have been used extensively in recent image processing research, exhibiting drastically improved performance. In this study, we apply convolutional neural networks to color filter array demosaicking, which plays an essential role in single-sensor digital cameras. Contrary to conventional convolutional neural network-based demosaicking models, the proposed model does not require any initial interpolation step for mosaicked input images, which increases the computational complexity. Using a mosaicked image as input, the proposed model is trained in an end-to-end manner to generate demosaicked images outputs. Many deep neural networks experience vanishing-gradient problem, which makes models hard to be trained. To solve this problem, we apply residual learning and densely connected convolutional neural network. Moreover, we apply block-wise convolutional neural networks to consider local features. Finally, we apply a sub-pixel interpolation layer to generate demosaicked output images more efficiently and accurately. Experimental results show that our proposed model outperforms conventional solutions and state-of-the-art models.", "authors": ["Bumjun Park", "Jechang Jeong"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 16, "type": "article", "concepts": ["Demosaicing", "Convolutional neural network", "Computer science", "Artificial intelligence", "Residual"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W2949349317", "doi": "https://doi.org/10.48550/arxiv.1609.07769", "title": "Deep Joint Rain Detection and Removal from a Single Image", "abstract": "In this paper, we address a rain removal problem from a single image, even in the presence of heavy rain and rain streak accumulation. Our core ideas lie in the new rain image models and a novel deep learning architecture. We first modify an existing model comprising a rain streak layer and a background layer, by adding a binary map that locates rain streak regions. Second, we create a new model consisting of a component representing rain streak accumulation (where individual streaks cannot be seen, and thus visually similar to mist or fog), and another component representing various shapes and directions of overlapping rain streaks, which usually happen in heavy rain. Based on the first model, we develop a multi-task deep learning architecture that learns the binary rain streak map, the appearance of rain streaks, and the clean background, which is our ultimate output. The additional binary map is critically beneficial, since its loss function can provide additional strong information to the network. To handle rain streak accumulation (again, a phenomenon visually similar to mist or fog) and various shapes and directions of overlapping rain streaks, we propose a recurrent rain detection and removal network that removes rain streaks and clears up the rain accumulation iteratively and progressively. In each recurrence of our method, a new contextualized dilated network is developed to exploit regional contextual information and outputs better representation for rain detection. The evaluation on real images, particularly on heavy rain, shows the effectiveness of our novel models and architecture, outperforming the state-of-the-art methods significantly. Our codes and data sets will be publicly available.", "authors": ["Wenhan Yang", "Robby T. Tan", "Jiashi Feng", "Jiaying Liu", "Zongming Guo", "Shuicheng Yan"], "year": 2016, "venue": "arXiv (Cornell University)", "cited_by_count": 10, "type": "preprint", "concepts": ["Streak", "Computer science", "Mist", "Binary number", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4321594307", "doi": "https://doi.org/10.48550/arxiv.2302.09554", "title": "Mixed Hierarchy Network for Image Restoration", "abstract": "Image restoration is a long-standing low-level vision problem, e.g., deblurring and deraining. In the process of image restoration, it is necessary to consider not only the spatial details and contextual information of restoration to ensure the quality, but also the system complexity. Although many methods have been able to guarantee the quality of image restoration, the system complexity of the state-of-the-art (SOTA) methods is increasing as well. Motivated by this, we present a mixed hierarchy network that can balance these competing goals. Our main proposal is a mixed hierarchy architecture, that progressively recovers contextual information and spatial details from degraded images while we design intra-blocks to reduce system complexity. Specifically, our model first learns the contextual information using encoder-decoder architectures, and then combines them with high-resolution branches that preserve spatial detail. In order to reduce the system complexity of this architecture for convenient analysis and comparison, we replace or remove the nonlinear activation function with multiplication and use a simple network structure. In addition, we replace spatial convolution with global self-attention for the middle block of encoder-decoder. The resulting tightly interlinked hierarchy architecture, named as MHNet, delivers strong performance gains on several image restoration tasks, including image deraining, and deblurring.", "authors": ["Hu Gao", "Depeng Dang"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 7, "type": "preprint", "concepts": ["Deblurring", "Computer science", "Image restoration", "Hierarchy", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4361208495", "doi": "https://doi.org/10.3389/fpls.2023.1154176", "title": "All-in-one aerial image enhancement network for forest scenes", "abstract": "Drone monitoring plays an irreplaceable and significant role in forest firefighting due to its characteristics of wide-range observation and real-time messaging. However, aerial images are often susceptible to different degradation problems before performing high-level visual tasks including but not limited to smoke detection, fire classification, and regional localization. Recently, the majority of image enhancement methods are centered around particular types of degradation, necessitating the memory unit to accommodate different models for distinct scenarios in practical applications. Furthermore, such a paradigm requires wasted computational and storage resources to determine the type of degradation, making it difficult to meet the real-time and lightweight requirements of real-world scenarios. In this paper, we propose an All-in-one Image Enhancement Network (AIENet) that can restore various degraded images in one network. Specifically, we design a new multi-scale receptive field image enhancement block, which can better reconstruct high-resolution details of target regions of different sizes. In particular, this plug-and-play module enables it to be embedded in any learning-based model. And it has better flexibility and generalization in practical applications. This paper takes three challenging image enhancement tasks encountered in drone monitoring as examples, whereby we conduct task-specific and all-in-one image enhancement experiments on a synthetic forest dataset. The results show that the proposed AIENet outperforms the state-of-the-art image enhancement algorithms quantitatively and qualitatively. Furthermore, extra experiments on high-level vision detection also show the promising performance of our method compared with some recent baselines.", "authors": ["Zhaoqi Chen", "Chuansheng Wang", "Fuquan Zhang", "Ling Zhang", "Antoni Grau", "Edmundo Guerra"], "year": 2023, "venue": "Frontiers in Plant Science", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Drone", "Aerial image", "Block (permutation group theory)", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4387490618", "doi": "https://doi.org/10.1109/tcsvt.2023.3323483", "title": "Joint Pixel and Frequency Feature Learning and Fusion via Channel-Wise Transformer for High-Efficiency Learned In-Loop Filter in VVC", "abstract": "Block-based video codecs such as Versatile Video Coding (VVC)/H.266, High Efficiency Video Coding (HEVC)/H.265, Advanced Video Coding (AVC)/H.264 etc. inherently introduces compression artifacts. Although these codecs have in-loop filters to correct these distortions, they are not always effective due to the complexity of the noise. Recently, deep-learning approaches emerged as a promising solution for in-loop filtering. However, most of the previous approaches were designed solely for learning from images and neglected the high-frequency signals present in the reconstructed video frames. Furthermore, some previous methods employed a multi-level feature-extraction and feature-fusion strategy to enhance performance. However, they utilized complex feature-extractors while relying on naive feature-fusion methods. In this article, we propose a novel framework called <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> , which jointly learns from both the pixel (spatial) and frequency-decomposed information and through powerful capability of a channel-wise transformer, it fuses both these information to improve performance. Our approach deviates from previous approaches by employing a simple feature-extractor coupled with an advanced transformer-based feature-fusion module. Simultaneously, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> introduces a few fundamental modifications in the multi-head self-attention module of the channel-wise transformer to make it computationally efficient. Our experimental results show that the proposed <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> achieves a Bjøntegaard Delta (BD) - bitrate saving of up to 10.258% for the luma (Y) component under all-intra (AI) profile outperforming the VVC baseline and other state-of-the-art methods. Moreover, the proposed <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> with an efficient channel-wise transformer is twice as efficient as <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> with a vanilla channel-wise transformer.", "authors": ["Birendra Kathariya", "Zhu Li", "Geert Van der Auwera"], "year": 2023, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 20, "type": "article", "concepts": ["Computer science", "Feature extraction", "Artificial intelligence", "Feature learning", "Transformer"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4320713067", "doi": "https://doi.org/10.1109/access.2023.3245150", "title": "Blind Text Image Deblurring Algorithm Based on Multi-Scale Fusion and Sparse Priors", "abstract": "The goal of blind text image deblurring is to obtain a clean text image from the given blurry text image without knowing the blur kernel. Sparsity-based methods have been shown their effectiveness in various blind text image deblurring models. However, the blur kernel estimation methods based on sparse priors lack of the consideration for the brightness information about the blur kernel, which will affect the restoration effect of the blur kernel. Besides, previous methods seldom apply sparse priors to both spatial domain and transform domain information. We propose a novel blind text image deblurring model based on multi-scale fusion and sparse priors. Besides the sparse gradient prior on the latent clean text image, we add the sparse prior on the high-frequency wavelet coefficients of the latent text image, which will better constrain the solution space and obtain good clean images. The semi-quadratic splitting method is used to alternately optimize the blur kernel and the latent clean image. Meanwhile, we consider the influence of the brightness feature of the restored blur kernel. By multi-scale fusion technique on the basis of Laplacian weight and saliency weight, we fuse the computed blur kernels in three channels to improve the quality of blur kernel. The experimental results show that our algorithm has good results in the restoration of blur kernels and text images.", "authors": ["Zhe Li", "Ming Yang", "Libo Cheng", "Xiaoning Jia"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 10, "type": "article", "concepts": ["Deblurring", "Computer science", "Artificial intelligence", "Image fusion", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W3189012752", "doi": "https://doi.org/10.1109/access.2021.3101319", "title": "A Model-Driven Deep Dehazing Approach by Learning Deep Priors", "abstract": "Photos taken in hazy weather are usually covered with white masks and lose important details. Haze removal is a fundamental task and a prerequisite to many other vision tasks. Single image dehazing is an ill-posed inverse problem that has attracted much attention in recent years. Generally, current single dehazing methods can be categorized into the traditional prior-based methods and the data-driven deep learning methods that respectively investigate haze-related image priors and deep architectures. In this paper, we propose a novel model-driven deep learning approach that combines the advantages of both kinds of methods. First, we build an energy model for single image dehazing with physical constraints in both color image space and haze-related feature space (implemented as dark channel space in this work), regularized by haze-related image priors. Then, we design an iterative optimization algorithm for solving the proposed dehazing energy model based on the half-quadratic splitting algorithm, and the priors are transformed to their corresponding proximal operators. Finally, inspired by the optimization algorithm, we design a deep dehazing neural network, dubbed as proximal dehaze-net, by learning the proximal operators for haze-related image priors using CNNs. Our network incorporates physical model constraints of hazes and haze-related prior learning into a novel deep architecture. Extensive experiments show that our method achieves promising performance for single image dehazing.", "authors": ["Dong Yang", "Jian Sun"], "year": 2021, "venue": "IEEE Access", "cited_by_count": 14, "type": "article", "concepts": ["Prior probability", "Computer science", "Deep learning", "Artificial intelligence", "Inpainting"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4382814212", "doi": "https://doi.org/10.1155/2023/4506331", "title": "Two‐Step Unsupervised Approach for Sand‐Dust Image Enhancement", "abstract": "In sand‐dust environments, light is scattered and absorbed, and sand‐dust images thus suffer from severe image degradation problems, such as color shifts, low contrast, and blurred details. To address these problems, we propose a two‐step unsupervised sand‐dust image enhancement algorithm. In the first step, a convenient and competent color correction method is put forward to solve the color shift problem. Considering the wavelength attenuation features of sand‐dust images, a linear stretching and blue channel compensation method is designed, and an adaptive color shift correction factor is developed to remove the color shift. In the second step, to enhance the clarity and details of the images, an unsupervised generative adversarial network is proposed, which does not require pairs of data for training. To reduce detail loss, the detail enhancement branch is designed, and the generator considers to more details through the constructed coarse‐grained and fine‐grained discriminators. The introduced multiscale perceptual loss promotes the image fidelity well. Experiments show that the proposed method achieves better color correction, enhances image details and clarity, has a better subjective effect, and outperforms existing sand‐dust image enhancement methods both quantitatively and qualitatively. Similarly, our method promotes the application capability of the target detection algorithm and also has a good enhancement effect on underwater images and haze images.", "authors": ["Guxue Gao", "Huicheng Lai", "Zhenhong Jia"], "year": 2023, "venue": "International Journal of Intelligent Systems", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Color balance", "Artificial intelligence", "Image (mathematics)", "Color correction"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4212954470", "doi": "https://doi.org/10.20944/preprints202202.0159.v1", "title": "Generative Adversarial Unsupervised Image Restoration in Hybrid Degradation Scenes", "abstract": "In this paper, we propose an unsupervised blind restoration model for images in hybrid degradation scenes. The proposed model encodes the content information and degradation information of images and then uses the attention module to disentangle the two kinds of information. It can improve the ability of disentangled presentation learning for a generative adversarial network (GAN) to restore the images in hybrid degradation scenes, enhance the detailed features of restored image and remove the artifact combining the adversarial loss, cycle-consistency loss, and perception loss. The experimental results on the DIV2K dataset and medical images show that the proposed method outperforms existing unsupervised image restoration algorithms in terms of peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and subjective visual evaluation.", "authors": ["Fan Tang", "Xinyu Zhu", "Jinrong Hu", "Juhong Tie", "Jiliu Zhou", "Ying Fu"], "year": 2022, "venue": "Preprints.org", "cited_by_count": 6, "type": "preprint", "concepts": ["Artificial intelligence", "Computer science", "Image restoration", "Degradation (telecommunications)", "Generative grammar"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4379255977", "doi": "https://doi.org/10.48550/arxiv.2306.00306", "title": "Low-Light Image Enhancement with Wavelet-based Diffusion Models", "abstract": "Diffusion models have achieved promising results in image restoration tasks, yet suffer from time-consuming, excessive computational resource consumption, and unstable restoration. To address these issues, we propose a robust and efficient Diffusion-based Low-Light image enhancement approach, dubbed DiffLL. Specifically, we present a wavelet-based conditional diffusion model (WCDM) that leverages the generative power of diffusion models to produce results with satisfactory perceptual fidelity. Additionally, it also takes advantage of the strengths of wavelet transformation to greatly accelerate inference and reduce computational resource usage without sacrificing information. To avoid chaotic content and diversity, we perform both forward diffusion and denoising in the training phase of WCDM, enabling the model to achieve stable denoising and reduce randomness during inference. Moreover, we further design a high-frequency restoration module (HFRM) that utilizes the vertical and horizontal details of the image to complement the diagonal information for better fine-grained restoration. Extensive experiments on publicly available real-world benchmarks demonstrate that our method outperforms the existing state-of-the-art methods both quantitatively and visually, and it achieves remarkable improvements in efficiency compared to previous diffusion-based methods. In addition, we empirically show that the application for low-light face detection also reveals the latent practical values of our method. Code is available at https://github.com/JianghaiSCU/Diffusion-Low-Light.", "authors": ["Hai Jiang", "Ao Luo", "Songchen Han", "Haoqiang Fan", "Shuaicheng Liu"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 16, "type": "preprint", "concepts": ["Computer science", "Wavelet", "Artificial intelligence", "Inference", "Image restoration"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4409366360", "doi": "https://doi.org/10.1609/aaai.v39i8.32905", "title": "Debiased All-in-one Image Restoration with Task Uncertainty Regularization", "abstract": "All-in-one image restoration is a fundamental low-level vision task with significant real-world applications. The primary challenge lies in addressing diverse degradations within a single model. While current methods primarily exploit task prior information to guide the restoration models, they typically employ uniform multi-task learning, overlooking the heterogeneity in model optimization across different degradation tasks. To eliminate the bias, we propose a task-aware optimization strategy, that introduces adaptive task-specific regularization for multi-task image restoration learning. Specifically, our method dynamically weights and balances losses for different restoration tasks during training, encouraging the implementation of the most reasonable optimization route. In this way, we can achieve more robust and effective model training. Notably, our approach can serve as a plug-and-play strategy to enhance existing models without requiring modifications during inference. Extensive experiments in diverse all-in-one restoration settings demonstrate the superiority and generalization of our approach. For example, AirNet retrained with TUR achieves average improvements of 1.16 dB on three distinct tasks and 1.81 dB on five distinct all-in-one tasks. These results underscore TUR's effectiveness in advancing the SOTAs in all-in-one image restoration, paving the way for more robust and versatile image restoration.", "authors": ["Gang Wu", "Junjun Jiang", "Yijun Wang", "Kui Jiang", "Xianming Liu"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 5, "type": "article", "concepts": ["Regularization (linguistics)", "Image restoration", "Image (mathematics)", "Artificial intelligence", "Task (project management)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4319302037", "doi": "https://doi.org/10.1007/s10462-023-10405-7", "title": "Deep learning: survey of environmental and camera impacts on internet of things images", "abstract": "Internet of Things (IoT) images are captivating growing attention because of their wide range of applications which requires visual analysis to drive automation. However, IoT images are predominantly captured from outdoor environments and thus are inherently impacted by the camera and environmental parameters which can adversely affect corresponding applications. Deep Learning (DL) has been widely adopted in the field of image processing and computer vision and can reduce the impact of these parameters on IoT images. Albeit, there are many DL-based techniques available in the current literature for analyzing and reducing the environmental and camera impacts on IoT images. However, to the best of our knowledge, no survey paper presents state-of-the-art DL-based approaches for this purpose. Motivated by this, for the first time, we present a Systematic Literature Review (SLR) of existing DL techniques available for analyzing and reducing environmental and camera lens impacts on IoT images. As part of this SLR, firstly, we reiterate and highlight the significance of IoT images in their respective applications. Secondly, we describe the DL techniques employed for assessing the environmental and camera lens distortion impacts on IoT images. Thirdly, we illustrate how DL can be effective in reducing the impact of environmental and camera lens distortion in IoT images. Finally, along with the critical reflection on the advantages and limitations of the techniques, we also present ways to address the research challenges of existing techniques and identify some further researches to advance the relevant research areas.", "authors": ["Roopdeep Kaur", "Gour Karmakar", "Feng Xia", "Muhammad Imran"], "year": 2023, "venue": "Artificial Intelligence Review", "cited_by_count": 13, "type": "article", "concepts": ["Computer science", "Internet of Things", "Artificial intelligence", "Field (mathematics)", "Automation"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W2901114637", "doi": "https://doi.org/10.48550/arxiv.1811.08575", "title": "Unsupervised Single Image Deraining with Self-supervised Constraints", "abstract": "Most existing single image deraining methods require learning supervised models from a large set of paired synthetic training data, which limits their generality, scalability and practicality in real-world multimedia applications. Besides, due to lack of labeled-supervised constraints, directly applying existing unsupervised frameworks to the image deraining task will suffer from low-quality recovery. Therefore, we propose an Unsupervised Deraining Generative Adversarial Network (UD-GAN) to tackle above problems by introducing self-supervised constraints from the intrinsic statistics of unpaired rainy and clean images. Specifically, we firstly design two collaboratively optimized modules, namely Rain Guidance Module (RGM) and Background Guidance Module (BGM), to take full advantage of rainy image characteristics: The RGM is designed to discriminate real rainy images from fake rainy images which are created based on outputs of the generator with BGM. Simultaneously, the BGM exploits a hierarchical Gaussian-Blur gradient error to ensure background consistency between rainy input and de-rained output. Secondly, a novel luminance-adjusting adversarial loss is integrated into the clean image discriminator considering the built-in luminance difference between real clean images and derained images. Comprehensive experiment results on various benchmarking datasets and different training settings show that UD-GAN outperforms existing image deraining methods in both quantitative and qualitative comparisons.", "authors": ["Xin Jin", "Zhibo Chen", "Jianxin Lin", "Zhikai Chen", "Wei Zhou"], "year": 2018, "venue": "arXiv (Cornell University)", "cited_by_count": 8, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Discriminator", "Image (mathematics)", "Pattern recognition (psychology)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4388878512", "doi": "https://doi.org/10.1109/access.2023.3335618", "title": "Delving Deeper Into Image Dehazing: A Survey", "abstract": "Images captured under foggy or hazy weather conditions are affected by the scattering of atmospheric particles, resulting in decreased contrast and color variation, thereby limiting their practical applications. In recent years, deep learning methods showcase significant advancements in image dehazing. However, the complexity and degradation factors in hazy images challenge the generalization capacity of dehazing methods. This paper comprehensively reviews the recent developments in single-image dehazing techniques based on deep learning. From the perspectives of Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN), different models are introduced and classified into four categories: Encoder-Decoder, Multi-Module, Multi-Branch, and Dual-Generative Adversarial Networks. The robustness and effectiveness of deep learning models are analyzed by comparing their performance and model complexity on public datasets. Additionally, limitations of current benchmark datasets and evaluation metrics are identified, and unresolved issues and future research directions are discussed. Our efforts in this paper will serve as a comprehensive reference for future research and call for further development in deep learning-based image dehazing.", "authors": ["Guohou Li", "Jia Li", "Gongchao Chen", "Zhibin Wang", "Songlin Jin", "Chang Ding", "Weidong Zhang"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Robustness (evolution)", "Deep learning", "Artificial intelligence", "Benchmark (surveying)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4221075701", "doi": "https://doi.org/10.3390/rs14061513", "title": "Unsupervised Remote Sensing Image Super-Resolution Guided by Visible Images", "abstract": "Remote sensing images are widely used in many applications. However, due to being limited by the sensors, it is difficult to obtain high-resolution (HR) images from remote sensing images. In this paper, we propose a novel unsupervised cross-domain super-resolution method devoted to reconstructing a low-resolution (LR) remote sensing image guided by an unpaired HR visible natural image. Therefore, an unsupervised visible image-guided remote sensing image super-resolution network (UVRSR) is built. The network is divided into two learnable branches: a visible image-guided branch (VIG) and a remote sensing image-guided branch (RIG). As HR visible images can provide rich textures and sufficient high-frequency information, the purpose of VIG is to treat them as targets and make full use of their advantages in reconstruction. Specially, we first use a CycleGAN to drag the LR visible natural images to the remote sensing domain; then, we apply an SR network to upscale these simulated remote sensing domain LR images. However, the domain gap between SR remote sensing images and HR visible targets is massive. To enforce domain consistency, we propose a novel domain-ruled discriminator in the reconstruction. Furthermore, inspired by the zero-shot super-resolution network (ZSSR) to explore the internal information of remote sensing images, we add a remote sensing domain inner study to train the SR network in RIG. Sufficient experimental works show UVRSR can achieve superior results with state-of-the-art unpaired and remote sensing SR methods on several challenging remote sensing image datasets.", "authors": ["Zili Zhang", "Yan Tian", "Jianxiang Li", "Yiping Xu"], "year": 2022, "venue": "Remote Sensing", "cited_by_count": 14, "type": "article", "concepts": ["Remote sensing", "Computer science", "Artificial intelligence", "Image (mathematics)", "Computer vision"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4366327759", "doi": "https://doi.org/10.48550/arxiv.2304.08291", "title": "Refusion: Enabling Large-Size Realistic Image Restoration with Latent-Space Diffusion Models", "abstract": "This work aims to improve the applicability of diffusion models in realistic image restoration. Specifically, we enhance the diffusion model in several aspects such as network architecture, noise level, denoising steps, training image size, and optimizer/scheduler. We show that tuning these hyperparameters allows us to achieve better performance on both distortion and perceptual scores. We also propose a U-Net based latent diffusion model which performs diffusion in a low-resolution latent space while preserving high-resolution information from the original input for the decoding process. Compared to the previous latent-diffusion model which trains a VAE-GAN to compress the image, our proposed U-Net compression strategy is significantly more stable and can recover highly accurate images without relying on adversarial optimization. Importantly, these modifications allow us to apply diffusion models to various image restoration tasks, including real-world shadow removal, HR non-homogeneous dehazing, stereo super-resolution, and bokeh effect transformation. By simply replacing the datasets and slightly changing the noise network, our model, named Refusion, is able to deal with large-size images (e.g., 6000 x 4000 x 3 in HR dehazing) and produces good results on all the above restoration problems. Our Refusion achieves the best perceptual performance in the NTIRE 2023 Image Shadow Removal Challenge and wins 2nd place overall.", "authors": ["Ziwei Luo", "Fredrik Gustafsson", "Zheng Zhao", "Jens Sjölund", "Thomas B. Schön"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 6, "type": "preprint", "concepts": ["Computer science", "Image restoration", "Artificial intelligence", "Distortion (music)", "Computer vision"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W3163628478", "doi": "https://doi.org/10.1371/journal.pone.0251337", "title": "An end-to-end sea fog removal network using multiple scattering model", "abstract": "An end-to-end sea fog removal network using multiple scattering model was proposed. In this network, the atmospheric multiple scattering model was re-formulated and used for sea fog removal. Compared with the atmospheric single scattering model, the atmospheric multiple scattering model could more comprehensively consider the effect of multiple scattering, which was important to the dense fog scenes, such as in ocean scene. Therefore, we used the atmospheric multiple scattering model to avoid image blurring. The model can directly generate the dehazing results, and unify the three parameters of the transmission map, the atmospheric light and the blur kernel into one formula. The latest smooth dilation and sub-pixel techniques were used in the network model. The latest techniques can avoid the gridding artifacts and the halo artifacts, the multi-scale sub-network was used to consider the features of multi-scale. In addition, multiple loss functions were used in end-to-end network. In the experimental results, the model was superior to the state-of-the-art models in terms of quantitatively and qualitatively.", "authors": ["Shunmin An", "Xixia Huang", "Zhangjing Zheng", "Linling Wang"], "year": 2021, "venue": "PLoS ONE", "cited_by_count": 8, "type": "article", "concepts": ["Scattering", "Halo", "Atmospheric model", "Computer science", "Diffuse sky radiation"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4385769398", "doi": "https://doi.org/10.3390/sym15081571", "title": "Symmetric Enhancement of Visual Clarity through a Multi-Scale Dilated Residual Recurrent Network Approach for Image Deraining", "abstract": "Images captured during rainy days present the challenge of maintaining a symmetrical balance between foreground elements (like rain streaks) and the background scenery. The interplay between these rain-obscured images is reminiscent of the principle of symmetry, where one element, the rain streak, overshadows or disrupts the visual quality of the entire image. The challenge lies not just in eradicating the rain streaks but in ensuring the background is symmetrically restored to its original clarity. Recently, numerous deraining algorithms that employ deep learning techniques have been proposed, demonstrating promising results. Yet, achieving a perfect symmetrical balance by effectively removing rain streaks from a diverse set of images, while also symmetrically restoring the background details, is a monumental task. To address this issue, we introduce an image-deraining algorithm that leverages multi-scale dilated residual recurrent networks. The algorithm begins by utilizing convolutional activation layers to symmetrically process both the foreground and background features. Then, to ensure the symmetrical dissemination of the characteristics of rain streaks and the background, it employs long short-term memory networks in conjunction with gated recurrent units across various stages. The algorithm then incorporates dilated residual blocks (DRB), composed of dilated convolutions with three distinct dilation factors. This integration expands the receptive field, facilitating the extraction of deep, multi-scale features of both the rain streaks and background information. Furthermore, considering the complex and diverse nature of rain streaks, a channel attention (CA) mechanism is incorporated to capture richer image features and enhance the model’s performance. Ultimately, convolutional layers are employed to fuse the image features, resulting in a derained image. An evaluation encompassing seven benchmark datasets, assessed using five quality metrics against various conventional and modern algorithms, confirms the robustness and flexibility of our approach.", "authors": ["Jameel Ahmed Bhutto", "Ruihong Zhang", "Zia-ur Rahman"], "year": 2023, "venue": "Symmetry", "cited_by_count": 7, "type": "article", "concepts": ["Computer science", "Residual", "Artificial intelligence", "Scale (ratio)", "Process (computing)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4309427392", "doi": "https://doi.org/10.48550/arxiv.2111.08892", "title": "SAPNet: Segmentation-Aware Progressive Network for Perceptual\\n Contrastive Deraining", "abstract": "Deep learning algorithms have recently achieved promising deraining\\nperformances on both the natural and synthetic rainy datasets. As an essential\\nlow-level pre-processing stage, a deraining network should clear the rain\\nstreaks and preserve the fine semantic details. However, most existing methods\\nonly consider low-level image restoration. That limits their performances at\\nhigh-level tasks requiring precise semantic information. To address this issue,\\nin this paper, we present a segmentation-aware progressive network (SAPNet)\\nbased upon contrastive learning for single image deraining. We start our method\\nwith a lightweight derain network formed with progressive dilated units (PDU).\\nThe PDU can significantly expand the receptive field and characterize\\nmulti-scale rain streaks without the heavy computation on multi-scale images. A\\nfundamental aspect of this work is an unsupervised background segmentation\\n(UBS) network initialized with ImageNet and Gaussian weights. The UBS can\\nfaithfully preserve an image's semantic information and improve the\\ngeneralization ability to unseen photos. Furthermore, we introduce a perceptual\\ncontrastive loss (PCL) and a learned perceptual image similarity loss (LPISL)\\nto regulate model learning. By exploiting the rainy image and groundtruth as\\nthe negative and the positive sample in the VGG-16 latent space, we bridge the\\nfine semantic details between the derained image and the groundtruth in a fully\\nconstrained manner. Comprehensive experiments on synthetic and real-world rainy\\nimages show our model surpasses top-performing methods and aids object\\ndetection and semantic segmentation with considerable efficacy. A Pytorch\\nImplementation is available at\\nhttps://github.com/ShenZheng2000/SAPNet-for-image-deraining.\\n", "authors": ["Shen Zheng", "Changjie Lu", "WU Yu-xiong", "Gaurav Gupta"], "year": 2021, "venue": "arXiv (Cornell University)", "cited_by_count": 4, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Segmentation", "Pattern recognition (psychology)", "Perception"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W3097097973", "doi": "https://doi.org/10.1109/access.2020.3034238", "title": "Wavelet Based Deep Recursive Pyramid Convolution Residual Network for Single Image Rain Removal", "abstract": "Image rain removal aims to separate the background image from the rainy image. During the past three years, the image rain removal with deep convolutional neural networks has achieved impressive performance. However, how to reach tradeoff between high de-raining performance and low model parameters is still a challenge. To address the issue, the paper is devoted to exploring a novel method based on wavelet deep recursive pyramid convolution residual network (WDRPRN), in which discrete wavelet transform is embedded to decompose the rainy image in different frequency domains, and the deep recursive pyramid convolution residual network (DRPRN) can well predict the residual coefficients between rainy image and clean image. In addition, compared with other neural networks, the DRPRN adopts recursive model that can cost fewer parameters. Plentiful of experiments on synthetic and real-world datasets show that the proposed method is significantly superior to the recent state-of-the-art algorithms.", "authors": ["Tian Tian Gong", "Jun Sheng Wang"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 3, "type": "article", "concepts": ["Residual", "Convolution (computer science)", "Computer science", "Pyramid (geometry)", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4206086042", "doi": "https://doi.org/10.1109/access.2021.3132148", "title": "Universal Framework for Joint Image Restoration and 3D Body Reconstruction", "abstract": "Recent works have demonstrated excellent state-of-the-art achievements in image restoration and 3D body reconstruction from an input image. The 3D body reconstruction task, however, relies heavily on the input image’s quality. A straightforward way to solve this issue is by generating vast degraded datasets and using them in a re-finetuned or newly-crafted body reconstruction network. However, in future usage, these datasets may become obsolete, leaving the newly-crafted network outdated. Unlike this approach, we design a universal framework that is able to utilize prior state-of-the-art restoration works and then self-boosts their performances during test-time while jointly carrying out the 3D body reconstruction. The self-boosting mechanism is adopted via test-time parameter adaptation capable of handling various types of degradation. To accommodate, we also propose a strategy that generates pseudo-data on the fly during test-time, allowing both restoration and reconstruction modules to be learned in a self-supervised manner. With this advantage, the universal framework intelligently enhances the performance without any new dataset or new neural network model involvement. Our experimental results show that using the proposed framework and pseudo-data strategies significantly improves the performances of both scenarios.", "authors": ["Jonathan Samuel Lumentut", "Matthew Marchellus", "Joshua Santoso", "Tae Hyun Kim", "Ju Yong Chang", "In Kyu Park"], "year": 2021, "venue": "IEEE Access", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Boosting (machine learning)", "Image restoration", "Artificial intelligence", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4308900645", "doi": "https://doi.org/10.48550/arxiv.2112.05147", "title": "Learning Deep Context-Sensitive Decomposition for Low-Light Image\\n Enhancement", "abstract": "Enhancing the quality of low-light images plays a very important role in many\\nimage processing and multimedia applications. In recent years, a variety of\\ndeep learning techniques have been developed to address this challenging task.\\nA typical framework is to simultaneously estimate the illumination and\\nreflectance, but they disregard the scene-level contextual information\\nencapsulated in feature spaces, causing many unfavorable outcomes, e.g.,\\ndetails loss, color unsaturation, artifacts, and so on. To address these\\nissues, we develop a new context-sensitive decomposition network architecture\\nto exploit the scene-level contextual dependencies on spatial scales. More\\nconcretely, we build a two-stream estimation mechanism including reflectance\\nand illumination estimation network. We design a novel context-sensitive\\ndecomposition connection to bridge the two-stream mechanism by incorporating\\nthe physical principle. The spatially-varying illumination guidance is further\\nconstructed for achieving the edge-aware smoothness property of the\\nillumination component. According to different training patterns, we construct\\nCSDNet (paired supervision) and CSDGAN (unpaired supervision) to fully evaluate\\nour designed architecture. We test our method on seven testing benchmarks to\\nconduct plenty of analytical and evaluated experiments. Thanks to our designed\\ncontext-sensitive decomposition connection, we successfully realized excellent\\nenhanced results, which fully indicates our superiority against existing\\nstate-of-the-art approaches. Finally, considering the practical needs for\\nhigh-efficiency, we develop a lightweight CSDNet (named LiteCSDNet) by reducing\\nthe number of channels. Further, by sharing an encoder for these two\\ncomponents, we obtain a more lightweight version (SLiteCSDNet for short).\\nSLiteCSDNet just contains 0.0301M parameters but achieves the almost same\\nperformance as CSDNet.\\n", "authors": ["Long Ma", "Risheng Liu", "Jiaao Zhang", "Xin Fan", "Zhongxuan Luo"], "year": 2021, "venue": "arXiv (Cornell University)", "cited_by_count": 5, "type": "preprint", "concepts": ["Computer science", "Context (archaeology)", "Artificial intelligence", "Deep learning", "Encoder"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4293499157", "doi": "https://doi.org/10.1109/access.2022.3202888", "title": "Single Image Raindrop Removal Using a Non-Local Operator and Feature Maps in the Frequency Domain", "abstract": "Taking a photo on a rainy day may result in a photo with raindrops. Images containing raindrops have a significant impact on the visual impression and accuracy when applied to image recognition systems. Thus, an automatic high-quality raindrop removal method is desired for outdoor image processing systems as well as for acquiring good-looking images. Several existing methods have been proposed to tackle this problem, but they often fail to keep global consistency and generate unnatural patterns. In this paper, we tackle this problem by introducing a non-local operator. The non-local operator combines features in distant locations with matrix multiplication and enables consistency in distant locations. In addition, high-frequency components such as edges are more affected in images with raindrops. Inspired by the nature that high-frequency components can be separated from other components in the frequency domain, we also propose to process feature maps in the frequency domain, which are obtained by the fast Fourier transform operation and processed by several convolution layers. Experimental results show that our method effectively removes raindrops and achieves state-of-the-art performance.", "authors": ["Shinya Ezumi", "Masaaki Ikehara"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 4, "type": "article", "concepts": ["Frequency domain", "Computer science", "Convolution (computer science)", "Operator (biology)", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4385849093", "doi": "https://doi.org/10.48550/arxiv.2308.06998", "title": "Mutual Information-driven Triple Interaction Network for Efficient Image Dehazing", "abstract": "Multi-stage architectures have exhibited efficacy in image dehazing, which usually decomposes a challenging task into multiple more tractable sub-tasks and progressively estimates latent hazy-free images. Despite the remarkable progress, existing methods still suffer from the following shortcomings: (1) limited exploration of frequency domain information; (2) insufficient information interaction; (3) severe feature redundancy. To remedy these issues, we propose a novel Mutual Information-driven Triple interaction Network (MITNet) based on spatial-frequency dual domain information and two-stage architecture. To be specific, the first stage, named amplitude-guided haze removal, aims to recover the amplitude spectrum of the hazy images for haze removal. And the second stage, named phase-guided structure refined, devotes to learning the transformation and refinement of the phase spectrum. To facilitate the information exchange between two stages, an Adaptive Triple Interaction Module (ATIM) is developed to simultaneously aggregate cross-domain, cross-scale, and cross-stage features, where the fused features are further used to generate content-adaptive dynamic filters so that applying them to enhance global context representation. In addition, we impose the mutual information minimization constraint on paired scale encoder and decoder features from both stages. Such an operation can effectively reduce information redundancy and enhance cross-stage feature complementarity. Extensive experiments on multiple public datasets exhibit that our MITNet performs superior performance with lower model complexity.The code and models are available at https://github.com/it-hao/MITNet.", "authors": ["Hao Shen", "Zhong‐Qiu Zhao", "Yulun Zhang", "Zhao Zhang"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Computer science", "Mutual information", "Redundancy (engineering)", "Encoder", "Interaction information"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W2768996629", "doi": "https://doi.org/10.1109/cvpr.2018.00258", "title": "xUnit: Learning a Spatial Activation Function for Efficient Image Restoration", "abstract": "In recent years, deep neural networks (DNNs) achieved unprecedented performance in many low-level vision tasks. However, state-of-the-art results are typically achieved by very deep networks, which can reach tens of layers with tens of millions of parameters. To make DNNs implementable on platforms with limited resources, it is necessary to weaken the tradeoff between performance and efficiency. In this paper, we propose a new activation unit, which is particularly suitable for image restoration problems. In contrast to the widespread per-pixel activation units, like ReLUs and sigmoids, our unit implements a learnable nonlinear function with spatial connections. This enables the net to capture much more complex features, thus requiring a significantly smaller number of layers in order to reach the same performance. We illustrate the effectiveness of our units through experiments with state-of-the-art nets for denoising, de-raining, and super resolution, which are already considered to be very small. With our approach, we are able to further reduce these models by nearly 50% without incurring any degradation in performance.", "authors": ["Idan Kligvasser", "Tamar Rott Shaham", "Tomer Michaeli"], "year": 2018, "venue": "", "cited_by_count": 4, "type": "preprint", "concepts": ["Computer science", "Image restoration", "Deep neural networks", "Pixel", "Activation function"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4405291967", "doi": "https://doi.org/10.3390/app142411565", "title": "MCIDN: Deblurring Network for Metal Corrosion Images", "abstract": "The analysis of corrosion images is crucial in materials science, where acquiring clear images is fundamental for subsequent analysis. The goal of deblurring metal corrosion images is to reconstruct clear images from degraded ones. To the best of our knowledge, this study introduces the first paired blurry-sharp image dataset specifically designed for the metal corrosion domain, filling a critical gap in the existing research. This innovative approach effectively addresses the unique challenges associated with deblurring metal corrosion images. We propose a novel metal corrosion images deblurring network (MCIDN) that employs a dual-domain attention mechanism, integrating both spatial and frequency domains to enhance image clarity. This innovative approach effectively addresses the unique challenges associated with deblurring metal corrosion images. While self-attention is widely used in visual tasks, its quadratic complexity often leads to high computational costs. To address this issue, we introduce a new spatial channel attention module (SCAM) that employs dynamic group convolutions to achieve self-attention, effectively integrating information from local regions and enhancing representation learning capabilities. Recognizing the critical role of frequency components in image restoration, we develop a frequency channel attention module (FCAM) that selectively focuses on different frequency components of images, thereby enhancing deblurring performance. These two attention modules are seamlessly integrated into our network. Compared to existing methods, our approach demonstrates superior performance on datasets of blurry metal corrosion images, achieving a peak signal-to-noise ratio (PSNR) of 32.8645 dB and a structural similarity (SSIM) of 0.9768. These metrics indicate that our method provides clearer and more detailed reconstructions, significantly enhancing the image quality.", "authors": ["Jiaxiang Wang", "Meng Wan", "Pufen Zhang", "Sijie Chang", "Hao Du", "Peng Shi", "Hongying Yu", "Dongbai Sun", "Jue Wang", "Yangang Wang"], "year": 2024, "venue": "Applied Sciences", "cited_by_count": 3, "type": "article", "concepts": ["Deblurring", "Materials science", "Computer science", "Artificial intelligence", "Image processing"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4403661836", "doi": "https://doi.org/10.48550/arxiv.2409.08510", "title": "CasDyF-Net: Image Dehazing via Cascaded Dynamic Filters", "abstract": "Image dehazing aims to restore image clarity and visual quality by reducing atmospheric scattering and absorption effects. While deep learning has made significant strides in this area, more and more methods are constrained by network depth. Consequently, lots of approaches have adopted parallel branching strategies. however, they often prioritize aspects such as resolution, receptive field, or frequency domain segmentation without dynamically partitioning branches based on the distribution of input features. Inspired by dynamic filtering, we propose using cascaded dynamic filters to create a multi-branch network by dynamically generating filter kernels based on feature map distribution. To better handle branch features, we propose a residual multiscale block (RMB), combining different receptive fields. Furthermore, we also introduce a dynamic convolution-based local fusion method to merge features from adjacent branches. Experiments on RESIDE, Haze4K, and O-Haze datasets validate our method's effectiveness, with our model achieving a PSNR of 43.21dB on the RESIDE-Indoor dataset. The code is available at https://github.com/dauing/CasDyF-Net.", "authors": ["Yinglong Wang", "Bin He"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Net (polyhedron)", "Image (mathematics)", "Computer science", "Computer vision", "Dynamic imaging"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4375957537", "doi": "https://doi.org/10.48550/arxiv.2305.03997", "title": "Dual Degradation Representation for Joint Deraining and Low-Light Enhancement in the Dark", "abstract": "Rain in the dark poses a significant challenge to deploying real-world applications such as autonomous driving, surveillance systems, and night photography. Existing low-light enhancement or deraining methods struggle to brighten low-light conditions and remove rain simultaneously. Additionally, cascade approaches like ``deraining followed by low-light enhancement'' or the reverse often result in problematic rain patterns or overly blurred and overexposed images. To address these challenges, we introduce an end-to-end model called L$^{2}$RIRNet, designed to manage both low-light enhancement and deraining in real-world settings. Our model features two main components: a Dual Degradation Representation Network (DDR-Net) and a Restoration Network. The DDR-Net independently learns degradation representations for luminance effects in dark areas and rain patterns in light areas, employing dual degradation loss to guide the training process. The Restoration Network restores the degraded image using a Fourier Detail Guidance (FDG) module, which leverages near-rainless detailed images, focusing on texture details in frequency and spatial domains to inform the restoration process. Furthermore, we contribute a dataset containing both synthetic and real-world low-light-rainy images. Extensive experiments demonstrate that our L$^{2}$RIRNet performs favorably against existing methods in both synthetic and complex real-world scenarios. All the code and dataset can be found in \\url{https://github.com/linxin0/Low_light_rainy}.", "authors": ["Xin Lin", "Jingtong Yue", "Chao Ren", "Chunle Guo", "Chongyi Li", "Yang, Ming-Hsuan"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 4, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Degradation (telecommunications)", "Pairwise comparison", "Feature (linguistics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4311728785", "doi": "https://doi.org/10.3390/s22249587", "title": "PRAGAN: Progressive Recurrent Attention GAN with Pretrained ViT Discriminator for Single-Image Deraining", "abstract": "Images captured in bad weather are not conducive to visual tasks. Rain streaks in rainy images will significantly affect the regular operation of imaging equipment; to solve this problem, using multiple neural networks is a trend. The ingenious integration of network structures allows for full use of the powerful representation and fitting abilities of deep learning to complete low-level visual tasks. In this study, we propose a generative adversarial network (GAN) with multiple attention mechanisms for image rain removal tasks. Firstly, to the best of our knowledge, we propose a pretrained vision transformer (ViT) as the discriminator in GAN for single-image rain removal for the first time. Secondly, we propose a neural network training method that can use a small amount of data for training while maintaining promising results and reliable visual quality. A large number of experiments prove the correctness and effectiveness of our method. Our proposed method achieves better results on synthetic and real image datasets than multiple state-of-the-art methods, even when using less training data.", "authors": ["Bingcai Wei", "Di Wang", "Zhuang Wang", "Liye Zhang"], "year": 2022, "venue": "Sensors", "cited_by_count": 3, "type": "article", "concepts": ["Discriminator", "Correctness", "Computer science", "Artificial intelligence", "Transformer"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W2985670408", "doi": "https://doi.org/10.48550/arxiv.2005.03155", "title": "NTIRE 2020 Challenge on Image Demoireing: Methods and Results", "abstract": "This paper reviews the Challenge on Image Demoireing that was part of the New Trends in Image Restoration and Enhancement (NTIRE) workshop, held in conjunction with CVPR 2020. Demoireing is a difficult task of removing moire patterns from an image to reveal an underlying clean image. The challenge was divided into two tracks. Track 1 targeted the single image demoireing problem, which seeks to remove moire patterns from a single image. Track 2 focused on the burst demoireing problem, where a set of degraded moire images of the same scene were provided as input, with the goal of producing a single demoired image as output. The methods were ranked in terms of their fidelity, measured using the peak signal-to-noise ratio (PSNR) between the ground truth clean images and the restored images produced by the participants' methods. The tracks had 142 and 99 registered participants, respectively, with a total of 14 and 6 submissions in the final testing stage. The entries span the current state-of-the-art in image and burst image demoireing problems.", "authors": ["Shanxin Yuan", "Radu Timofte", "Aleš Leonardis", "Greg Slabaugh", "Xiaotong Luo", "Jiangtao Zhang", "Yanyun Qu", "Ming Hong", "Yuan Xie", "Cuihua Li", "Dejia Xu", "Yihao Chu", "Qingyan Sun", "Shuai Liu", "Ziyao Zong", "Nan Nan", "Chenghua Li", "Sangmin Kim", "Hyungjoon Nam", "Jisu Kim", "Jechang Jeong", "Manri Cheon", "Sungjun Yoon", "Byungyeon Kang", "JunWoo Lee", "Bolun Zheng", "Xiaohong Liu", "Linhui Dai", "Jun Chen", "Xi Cheng", "Zhenyong Fu", "Jian Yang", "Chul Lee", "An Gia Vien", "Hyunkook Park", "Sabari Nathan", "M. Parisa Beham", "S. Mohamed Mansoor Roomi", "Florian Lemarchand", "Maxime Pelcat", "Erwan Nogues", "Densen Puthussery", "P. S. Hrishikesh", "C. V. Jiji", "Ashish Sinha", "Xuan Zhao"], "year": 2020, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Image (mathematics)", "Computer science", "Artificial intelligence", "Computer vision", "Fidelity"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4313328176", "doi": "https://doi.org/10.32604/cmc.2023.031444", "title": "CLGA Net: Cross Layer Gated Attention Network for Image Dehazing", "abstract": "In this paper, we propose an end-to-end cross-layer gated attention network (CLGA-Net) to directly restore fog-free images. Compared with the previous dehazing network, the dehazing model presented in this paper uses the smooth cavity convolution and local residual module as the feature extractor, combined with the channel attention mechanism, to better extract the restored features. A large amount of experimental data proves that the defogging model proposed in this paper is superior to previous defogging technologies in terms of structure similarity index (SSIM), peak signal to noise ratio (PSNR) and subjective visual quality. In order to improve the efficiency of decoding and encoding, we also describe a fusion residual module and conduct ablation experiments, which prove that the fusion residual is suitable for the dehazing problem. Therefore, we use fusion residual as a fixed module for encoding and decoding. In addition, we found that the traditional defogging model based on the U-net network may cause some information losses in space. We have achieved effective maintenance of low-level feature information through the cross-layer gating structure that better takes into account global and subtle features. We also present the application of our CLGA-Net in challenging scenarios where the best results in both quantity and quality can be obtained. Experimental results indicate that the present cross-layer gating module can be widely used in the same type of network.", "authors": ["Shengchun Wang", "Baoxuan Huang", "Tsz Ho Wong", "Huang Jin-gui", "Hong Deng"], "year": 2022, "venue": "Computers, materials & continua/Computers, materials & continua (Print)", "cited_by_count": 3, "type": "article", "concepts": ["Residual", "Computer science", "Decoding methods", "Encoding (memory)", "Layer (electronics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4385767441", "doi": "https://doi.org/10.21203/rs.3.rs-3240803/v1", "title": "A Hybrid CNN-Transformer Architecture with Frequency Domain Contrastive Learning for Image Deraining", "abstract": "Abstract Image deraining is a challenging task that involves restoring degraded images affected by rain streaks. While Convolutional Neural Networks (CNNs) have been commonly used for this task, existing approaches often rely on stacked convolutional basic blocks with limited performance and compromised spatial detail. Furthermore, the limited receptive field of convolutional layers leads to incomplete processing of non-uniform rain streaks. To address these concerns, we propose a novel image deraining network that combines CNNs and trans- formers. Our network comprises two stages: an encoder-decoder architecture with a triple attention mechanism to capture valuable features and residual dual branch transformer blocks that enhance local information modeling. To address the transformer’s lack of local information modeling capability, we intro- duce convolution in the self-attentive mechanism of the transformer block and feed-forward network. Additionally, we employ a frequency domain contrastive learning method to enhance contrastive sample information, ensuring that the restored image closely resembles the clear image in the frequency domain space, while still retaining a distinction from the rainy image. Extensive quantitative and qualitative experiments demonstrate that our proposed deraining network outperforms existing methods on public datasets.", "authors": ["Cheng Wang", "Wei Li"], "year": 2023, "venue": "Research Square (Research Square)", "cited_by_count": 2, "type": "preprint", "concepts": ["Computer science", "Transformer", "Convolutional neural network", "Encoder", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4295350396", "doi": "https://doi.org/10.1007/s40747-022-00865-9", "title": "Multi-scale progressive blind face deblurring", "abstract": "", "authors": ["Hao Zhang", "Canghong Shi", "Xian Zhang", "Linfeng Wu", "Xiaojie Li", "Jing Peng", "Xi Wu", "Jiancheng Lv"], "year": 2022, "venue": "Complex & Intelligent Systems", "cited_by_count": 3, "type": "article", "concepts": ["Deblurring", "Artificial intelligence", "Computer science", "Face (sociological concept)", "Computer vision"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4313008082", "doi": "https://doi.org/10.1109/access.2022.3213025", "title": "Deep Learning for Screen-Shot Image Demoiréing: A Survey", "abstract": "Image demoiréing is an important image processing technology in computer vision, used to remove the moiré from images and improve the image quality. In recent years, the image demoiréing technique based on the deep learning method has gained more attention and achieved good results, but it still has some limitations. This paper aims to provide a review and perspective on the recent advances in deep learning-based image demoiréing techniques. First, the definition and production principle of the image moiré pattern are given. Common datasets and image quality evalution methods in demoiréing studies are analyzed. Then two internationally famous competitions in image demoiréing are introduced. Second, the research status of the supervised demoiréing technique is summarized from four dimensions: sampling method, model network design, baseline model, and training learning strategy. Recent progress made by the mainstream model of unsupervised deep learning in the field of image demoiréing is summarized. The typical application of the image demoiréing technique in panel defect detection and digital radiography is analyzed. The performance and the image quality of the above mentioned models based on different data sets are evaluated in detail. Finally, this paper analyzes and forelocks the problems to be solved in the coming years.", "authors": ["Shouming Hou", "Yabing Wang", "Kai Li", "Yinggang Zhao", "Baoyun Lu", "Liya Fan"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 2, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Deep learning", "Image quality", "Field (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4409370074", "doi": "https://doi.org/10.1609/aaai.v39i3.32257", "title": "SIDL: A Real-World Dataset for Restoring Smartphone Images with Dirty Lenses", "abstract": "Smartphone cameras are ubiquitous in daily life, yet their performance can be severely impacted by dirty lenses, leading to degraded image quality. This issue is often overlooked in image restoration research, which assumes ideal or controlled lens conditions. To address this gap, we introduced SIDL (Smartphone Images with Dirty Lenses), a novel dataset designed to restore images captured through contaminated smartphone lenses. SIDL contains diverse real-world images taken under various lighting conditions and environments. These images feature a wide range of lens contaminants, including water drops, fingerprints, and dust. Each contaminated image is paired with a clean reference image, enabling supervised learning approaches for restoration tasks. To evaluate the challenge posed by SIDL, various state-of-the-art restoration models were trained and compared on this dataset. Their performances achieved some level of restoration but did not adequately address the diverse and realistic nature of the lens contaminants in SIDL. This challenge highlights the need for more robust and adaptable image restoration techniques for restoring images with dirty lenses.", "authors": ["Sooyoung Choi", "Sungyong Park", "Heewon Kim"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 1, "type": "article", "concepts": ["Smartphone application", "Computer science", "Smartphone app", "Computer vision", "Optometry"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4391909273", "doi": "https://doi.org/10.21597/jist.1328255", "title": "Enhance or Leave It: An Investigation of the Image Enhancement in Small Object Detection in Aerial Images", "abstract": "Recent years of object detection (OD), a fundamental task in computer vision, have witnessed the rise of numerous practical applications of this sub-field such as face detection, self-driving, security, and more. Although existing deep learning models show significant achievement in object detection, they are usually tested on datasets having mostly clean images. Thus, their performance levels were not measured on degraded images. In addition, images and videos in real-world scenarios often involve several natural artifacts such as noise, haze, rain, dust, and motion blur due to several factors such as insufficient light, atmospheric scattering, and faults in image sensors. This image acquisition-related problem becomes more severe when it comes to detecting small objects in aerial images. In this study, we investigate the small object identification performance of several state-of-the-art object detection models (Yolo 6/7/8) under three conditions (noisy, motion blurred, and rainy). Through this inspection, we evaluate the contribution of an image enhancement scheme so-called MPRNet. For this aim, we trained three OD algorithms with the original clean images of the VisDrone dataset. Followingly, we measured the detection performance of saved YOLO models against (1) clean, (2) degraded, and (3) enhanced counterparts. According to the results, MPRNet-based image enhancement promisingly contributes to the detection performance and YOLO8 outperforms its predecessors. We believe that this work presents useful findings for researchers studying aerial image-based vision tasks, especially under extreme weather and image acquisition conditions", "authors": ["Alpay Tekin", "Ahmet Selman Bozkır"], "year": 2024, "venue": "Iğdır Üniversitesi Fen Bilimleri Enstitüsü Dergisi", "cited_by_count": 3, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Computer vision", "Object detection", "Motion blur"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4361192474", "doi": "https://doi.org/10.21203/rs.3.rs-2717815/v1", "title": "DC-GAN with Feature Attention for Single Image Dehazing", "abstract": "<title>Abstract</title> In recent years, the frequent occurrence of smog weather has affected people's health and has also had a major impact on computer vision application systems. Images captured in hazy environments suffer from quality degradation and other issues such as color distortion, low contrast, and lack of detail. This study proposes an end-to-end, adversarial neural network-based dehazing technique called DC-GAN that combines Dense and Residual blocks efficiently for improved dehazing performance. In addition, it also consists of channel attention and pixel attention, which can offer more versatility when dealing with different forms of data. The Wasserstein Generative Adversarial Network with Gradient Penality(WGAN-GP) was used as an enhancement method to correct the shortcomings in the original GAN's cost function and create an improvised loss. On the basis of the experiment results, the algorithm used in this paper is able to generate sharp images with high image quality. The processed images were simultaneously analyzed using the objective evaluation metrics Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity (SSIM). The findings demonstrate that the dehazing effect is favorable compared to other state-of-the-art dehazing algorithms, achieving a PSNR and SSIM of 14.7 and 0.54 for the indoor images, and 16.54 and 0.54 for the outdoor images respectively using the NTIRE 2018 dataset. Using the SOTS dataset, the model achieved a PSNR and SSIM of 23.98 and 0.87 for the indoor images, and 19.88 and 0.83 for the outdoor images.", "authors": ["Tewodros Megabiaw Tassew", "Xuan Nie"], "year": 2023, "venue": "", "cited_by_count": 2, "type": "preprint", "concepts": ["Feature (linguistics)", "Image (mathematics)", "Computer science", "Materials science", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning"}
{"openalex_id": "https://openalex.org/W4390874575", "doi": "https://doi.org/10.1109/iccv51070.2023.00371", "title": "Segment Anything", "abstract": "We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive – often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at segment-anything.com to foster research into foundation models for computer vision. We recommend reading the full paper at: arxiv.org/abs/2304.02643.", "authors": ["Alexander M. Kirillov", "Eric Mintun", "Nikhila Ravi", "Hanzi Mao", "Chloe Rolland", "Laura Gustafson", "Tete Xiao", "Spencer Whitehead", "Alexander C. Berg", "Wan‐Yen Lo", "Piotr Dollár", "Ross Girshick"], "year": 2023, "venue": "", "cited_by_count": 7782, "type": "article", "concepts": ["Computer science", "Segmentation", "Task (project management)", "Artificial intelligence", "Shot (pellet)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4364383051", "doi": "https://doi.org/10.48550/arxiv.2304.04155", "title": "Segment Anything Model (SAM) for Digital Pathology: Assess Zero-shot Segmentation on Whole Slide Imaging", "abstract": "The segment anything model (SAM) was released as a foundation model for image segmentation. The promptable segmentation model was trained by over 1 billion masks on 11M licensed and privacy-respecting images. The model supports zero-shot image segmentation with various segmentation prompts (e.g., points, boxes, masks). It makes the SAM attractive for medical image analysis, especially for digital pathology where the training data are rare. In this study, we evaluate the zero-shot segmentation performance of SAM model on representative segmentation tasks on whole slide imaging (WSI), including (1) tumor segmentation, (2) non-tumor tissue segmentation, (3) cell nuclei segmentation. Core Results: The results suggest that the zero-shot SAM model achieves remarkable segmentation performance for large connected objects. However, it does not consistently achieve satisfying performance for dense instance object segmentation, even with 20 prompts (clicks/boxes) on each image. We also summarized the identified limitations for digital pathology: (1) image resolution, (2) multiple scales, (3) prompt selection, and (4) model fine-tuning. In the future, the few-shot fine-tuning with images from downstream pathological segmentation tasks might help the model to achieve better performance in dense object segmentation.", "authors": ["Ruining Deng", "Can Cui", "Quan Liu", "Tianyuan Yao", "Lucas W. Remedios", "Shunxing Bao", "Bennett A. Landman", "Lee Wheless", "Lori A. Coburn", "Keith T. Wilson", "Yaohong Wang", "Shilin Zhao", "Agnes B. Fogo", "Haichun Yang", "Yucheng Tang", "Yuankai Huo"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 96, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Scale-space segmentation", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4396996869", "doi": "https://doi.org/10.1145/3654704", "title": "Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM)", "abstract": "The advent of foundation models signals a new era in artificial intelligence. The Segment Anything Model (SAM) is the first foundation model for image segmentation. In this study, we evaluate SAM's ability to segment features from eye images recorded in virtual reality setups. The increasing requirement for annotated eye-image datasets presents a significant opportunity for SAM to redefine the landscape of data annotation in gaze estimation. Our investigation centers on SAM's zero-shot learning abilities and the effectiveness of prompts like bounding boxes or point clicks. Our results are consistent with studies in other domains, demonstrating that SAM's segmentation effectiveness can be on-par with specialized models depending on the feature, with prompts improving its performance, evidenced by an IoU of 93.34% for pupil segmentation in one dataset. Foundation models like SAM could revolutionize gaze estimation by enabling quick and easy image segmentation, reducing reliance on specialized models and extensive manual annotation.", "authors": ["Virmarie Maquiling", "Sean Anthony Byrne", "Diederick C. Niehorster", "Marcus Nyström", "Enkelejda Kasneci"], "year": 2024, "venue": "Proceedings of the ACM on Computer Graphics and Interactive Techniques", "cited_by_count": 10, "type": "article", "concepts": ["Shot (pellet)", "Segmentation", "Artificial intelligence", "Zero (linguistics)", "Computer science"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4385481295", "doi": "https://doi.org/10.1016/j.media.2023.102918", "title": "Segment anything model for medical image analysis: An experimental study", "abstract": "", "authors": ["Maciej A. Mazurowski", "Haoyu Dong", "Hanxue Gu", "Jichen Yang", "Nicholas Konz", "Yixin Zhang"], "year": 2023, "venue": "Medical Image Analysis", "cited_by_count": 623, "type": "article", "concepts": ["Artificial intelligence", "Image (mathematics)", "Computer science", "Computer vision", "Pattern recognition (psychology)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4391021462", "doi": "https://doi.org/10.1109/tgrs.2024.3356074", "title": "RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation Based on Visual Foundation Model", "abstract": "Leveraging the extensive training data from SA-1B, the Segment Anything Model (SAM) demonstrates remarkable generalization and zero-shot capabilities. However, as a category-agnostic instance segmentation method, SAM heavily relies on prior manual guidance, including points, boxes, and coarse-grained masks. Furthermore, its performance in remote sensing image segmentation tasks remains largely unexplored and unproven. In this paper, we aim to develop an automated instance segmentation approach for remote sensing images, based on the foundational SAM model and incorporating semantic category information. Drawing inspiration from prompt learning, we propose a method to learn the generation of appropriate prompts for SAM. This enables SAM to produce semantically discernible segmentation results for remote sensing images, a concept we have termed RSPrompter. We also propose several ongoing derivatives for instance segmentation tasks, drawing on recent advancements within the SAM community, and compare their performance with RSPrompter. Extensive experimental results, derived from the WHU building, NWPU VHR-10, and SSDD datasets, validate the effectiveness of our proposed method. The code for our method is publicly available at https://kychen.me/RSPrompter.", "authors": ["Keyan Chen", "Chenyang Liu", "Hao Chen", "Haotian Zhang", "Wenyuan Li", "Zhengxia Zou", "Zhenwei Shi"], "year": 2024, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 271, "type": "article", "concepts": ["Segmentation", "Computer science", "Generalization", "Artificial intelligence", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4388129777", "doi": "https://doi.org/10.1016/j.jag.2023.103540", "title": "The Segment Anything Model (SAM) for remote sensing applications: From zero to one shot", "abstract": "Segmentation is an essential step for remote sensing image processing. This study aims to advance the application of the Segment Anything Model (SAM), an innovative image segmentation model by Meta AI, in the field of remote sensing image analysis. SAM is known for its exceptional generalization capabilities and zero-shot learning, making it a promising approach to processing aerial and orbital images from diverse geographical contexts. Our exploration involved testing SAM across multi-scale datasets using various input prompts, such as bounding boxes, individual points, and text descriptors. To enhance the model’s performance, we implemented a novel automated technique that combines a text-prompt-derived general example with one-shot training. This adjustment resulted in an improvement in accuracy, underscoring SAM’s potential for deployment in remote sensing imagery and reducing the need for manual annotation. Despite the limitations, encountered with lower spatial resolution images, SAM exhibits promising adaptability to remote sensing data analysis. We recommend future research to enhance the model’s proficiency through integration with supplementary fine-tuning techniques and other networks. Furthermore, we provide the open-source code of our modifications on online repositories, encouraging further and broader adaptations of SAM to the remote sensing domain.", "authors": ["Lucas Prado Osco", "Qiusheng Wu", "Eduardo Lopes de Lemos", "Wesley Nunes Gonçalves", "Ana Paula Marques Ramos", "Jonathan Li", "José Marcato"], "year": 2023, "venue": "International Journal of Applied Earth Observation and Geoinformation", "cited_by_count": 261, "type": "article", "concepts": ["Zero (linguistics)", "Shot (pellet)", "Geography", "Computer science", "Cartography"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402727760", "doi": "https://doi.org/10.1109/cvpr52733.2024.01525", "title": "EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything", "abstract": "Segment Anything Model (SAM) has emerged as a powerful tool for numerous vision applications. A key component that drives the impressive performance for zero-shot trans-fer and high versatility is a super large Transformer model trained on the extensive high-quality SA -1 B dataset. While beneficial, the huge computation cost of SAM model has limited its applications to wider real-world applications. To address this limitation, we propose EfficientSAMs, light-weight SAM models that exhibits decent performance with largely reduced complexity. Our idea is based on leveraging masked image pretraining, SAMI, which learns to reconstruct features from SAM image encoder for effective visual representation learning. Further, we take SAMI-pretrained light-weight image encoders and mask decoder to build Effi-cientSAMs, and finetune the models on SA -1B for segment anything task. We perform evaluations on multiple vision tasks including image classification, object detection, in-stance segmentation, and semantic segmentation, and find that our proposed pretraining method, SAMI, consistently outperforms other masked image pretraining methods. On segment anything task such as zero-shot instance segmentation, our EfficientSAMs with SAMI-pretrained lightweight image encoders perform favorably with a significant gain (e.g., rv4 AP on COCOILVIS) over other fast SAM models. Our EfficientSAM code and models are available at here.", "authors": ["Yunyang Xiong", "Bala Varadarajan", "Lemeng Wu", "Xiaoyu Xiang", "Fanyi Xiao", "Chenchen Zhu", "Xiaoliang Dai", "Dilin Wang", "Fei Sun", "Forrest Iandola", "Raghuraman Krishnamoorthi", "Vikas Chandra"], "year": 2024, "venue": "", "cited_by_count": 168, "type": "article", "concepts": ["Computer science", "Image (mathematics)", "Artificial intelligence", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4379141755", "doi": "https://doi.org/10.3390/diagnostics13111947", "title": "Generalist Vision Foundation Models for Medical Imaging: A Case Study of Segment Anything Model on Zero-Shot Medical Segmentation", "abstract": "Medical image analysis plays an important role in clinical diagnosis. In this paper, we examine the recent Segment Anything Model (SAM) on medical images, and report both quantitative and qualitative zero-shot segmentation results on nine medical image segmentation benchmarks, covering various imaging modalities, such as optical coherence tomography (OCT), magnetic resonance imaging (MRI), and computed tomography (CT), as well as different applications including dermatology, ophthalmology, and radiology. Those benchmarks are representative and commonly used in model development. Our experimental results indicate that while SAM presents remarkable segmentation performance on images from the general domain, its zero-shot segmentation ability remains restricted for out-of-distribution images, e.g., medical images. In addition, SAM exhibits inconsistent zero-shot segmentation performance across different unseen medical domains. For certain structured targets, e.g., blood vessels, the zero-shot segmentation of SAM completely failed. In contrast, a simple fine-tuning of it with a small amount of data could lead to remarkable improvement of the segmentation quality, showing the great potential and feasibility of using fine-tuned SAM to achieve accurate medical image segmentation for a precision diagnostics. Our study indicates the versatility of generalist vision foundation models on medical imaging, and their great potential to achieve desired performance through fine-turning and eventually address the challenges associated with accessing large and diverse medical datasets in support of clinical diagnostics.", "authors": ["Peilun Shi", "Jianing Qiu", "Sai Mu Dalike Abaxi", "Wei Hao", "Frank P.-W. Lo", "Wu Yuan"], "year": 2023, "venue": "Diagnostics", "cited_by_count": 116, "type": "article", "concepts": ["Segmentation", "Medical imaging", "Optical coherence tomography", "Artificial intelligence", "Computer science"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4411124654", "doi": "https://doi.org/10.1016/j.bspc.2025.108086", "title": "SIT-SAM: A semantic-integration transformer that adapts the Segment Anything Model to zero-shot medical image semantic segmentation", "abstract": "", "authors": ["Wentao Shi", "Junjun He", "Yiqing Shen"], "year": 2025, "venue": "Biomedical Signal Processing and Control", "cited_by_count": 3, "type": "article", "concepts": ["Segmentation", "Computer science", "Transformer", "Artificial intelligence", "Zero (linguistics)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4386781846", "doi": "https://doi.org/10.3390/s23187884", "title": "Enhancing Agricultural Image Segmentation with an Agricultural Segment Anything Model Adapter", "abstract": "The Segment Anything Model (SAM) is a versatile image segmentation model that enables zero-shot segmentation of various objects in any image using prompts, including bounding boxes, points, texts, and more. However, studies have shown that the SAM performs poorly in agricultural tasks like crop disease segmentation and pest segmentation. To address this issue, the agricultural SAM adapter (ASA) is proposed, which incorporates agricultural domain expertise into the segmentation model through a simple but effective adapter technique. By leveraging the distinctive characteristics of agricultural image segmentation and suitable user prompts, the model enables zero-shot segmentation, providing a new approach for zero-sample image segmentation in the agricultural domain. Comprehensive experiments are conducted to assess the efficacy of the ASA compared to the default SAM. The results show that the proposed model achieves significant improvements on all 12 agricultural segmentation tasks. Notably, the average Dice score improved by 41.48% on two coffee-leaf-disease segmentation tasks.", "authors": ["Yaqin Li", "Dandan Wang", "Yuan Cao", "Hao Li", "Jing Hu"], "year": 2023, "venue": "Sensors", "cited_by_count": 70, "type": "article", "concepts": ["Adapter (computing)", "Segmentation", "Computer science", "Artificial intelligence", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4379474533", "doi": "https://doi.org/10.48550/arxiv.2306.01567", "title": "Segment Anything in High Quality", "abstract": "The recent Segment Anything Model (SAM) represents a big leap in scaling up segmentation models, allowing for powerful zero-shot capabilities and flexible prompting. Despite being trained with 1.1 billion masks, SAM's mask prediction quality falls short in many cases, particularly when dealing with objects that have intricate structures. We propose HQ-SAM, equipping SAM with the ability to accurately segment any object, while maintaining SAM's original promptable design, efficiency, and zero-shot generalizability. Our careful design reuses and preserves the pre-trained model weights of SAM, while only introducing minimal additional parameters and computation. We design a learnable High-Quality Output Token, which is injected into SAM's mask decoder and is responsible for predicting the high-quality mask. Instead of only applying it on mask-decoder features, we first fuse them with early and final ViT features for improved mask details. To train our introduced learnable parameters, we compose a dataset of 44K fine-grained masks from several sources. HQ-SAM is only trained on the introduced detaset of 44k masks, which takes only 4 hours on 8 GPUs. We show the efficacy of HQ-SAM in a suite of 10 diverse segmentation datasets across different downstream tasks, where 8 out of them are evaluated in a zero-shot transfer protocol. Our code and pretrained models are at https://github.com/SysCV/SAM-HQ.", "authors": ["Ke Lei", "Mingqiao Ye", "Martin Danelljan", "Yifan Liu", "Yu‐Wing Tai", "Chi–Keung Tang", "Fisher Yu"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 109, "type": "preprint", "concepts": ["Computer science", "Segmentation", "Security token", "Artificial intelligence", "Quality (philosophy)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4401819803", "doi": "https://doi.org/10.1016/j.media.2024.103310", "title": "MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation", "abstract": "", "authors": ["Cheng Chen", "Juzheng Miao", "Dufan Wu", "Aoxiao Zhong", "Zhiling Yan", "Sekeun Kim", "Jiang Hu", "Zhengliang Liu", "Lichao Sun", "Xiang Li", "Tianming Liu", "Pheng‐Ann Heng", "Quanzheng Li"], "year": 2024, "venue": "Medical Image Analysis", "cited_by_count": 146, "type": "article", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Encoder", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4391272787", "doi": "https://doi.org/10.48550/arxiv.2401.14159", "title": "Grounded SAM: Assembling Open-World Models for Diverse Visual Tasks", "abstract": "We introduce Grounded SAM, which uses Grounding DINO as an open-set object detector to combine with the segment anything model (SAM). This integration enables the detection and segmentation of any regions based on arbitrary text inputs and opens a door to connecting various vision models. As shown in Fig.1, a wide range of vision tasks can be achieved by using the versatile Grounded SAM pipeline. For example, an automatic annotation pipeline based solely on input images can be realized by incorporating models such as BLIP and Recognize Anything. Additionally, incorporating Stable-Diffusion allows for controllable image editing, while the integration of OSX facilitates promptable 3D human motion analysis. Grounded SAM also shows superior performance on open-vocabulary benchmarks, achieving 48.7 mean AP on SegInW (Segmentation in the wild) zero-shot benchmark with the combination of Grounding DINO-Base and SAM-Huge models.", "authors": ["Tianhe Ren", "Shilong Liu", "Ailing Zeng", "Jing Lin", "Kunchang Li", "He Cao", "Jiayu Chen", "Xinyu Huang", "Yukang Chen", "Feng Yan", "Zhaoyang Zeng", "Hao Zhang", "Feng Li", "Jie Yang", "Hongyang Li", "Qing Jiang", "Lei Zhang"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 88, "type": "preprint", "concepts": ["Pipeline (software)", "Computer science", "Segmentation", "Benchmark (surveying)", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4391991763", "doi": "https://doi.org/10.1109/tgrs.2024.3368168", "title": "Adapting Segment Anything Model for Change Detection in VHR Remote Sensing Images", "abstract": "Vision Foundation Models (VFMs) such as the Segment Anything Model (SAM) allow zero-shot or interactive segmentation of visual contents, thus they are quickly applied in a variety of visual scenes. However, their direct use in many Remote Sensing (RS) applications is often unsatisfactory due to the special imaging properties of RS images. In this work, we aim to utilize the strong visual recognition capabilities of VFMs to improve change detection (CD) in very high-resolution (VHR) remote sensing images (RSIs). We employ the visual encoder of FastSAM, a variant of the SAM, to extract visual representations in RS scenes. To adapt FastSAM to focus on some specific ground objects in RS scenes, we propose a convolutional adaptor to aggregate the task-oriented change information. Moreover, to utilize the semantic representations that are inherent to SAM features, we introduce a task-agnostic semantic learning branch to model the semantic latent in bi-temporal RSIs. The resulting method, SAM-CD, obtains superior accuracy compared to the SOTA fully-supervised CD methods and exhibits a sample-efficient learning ability that is comparable to semi-supervised CD methods. To the best of our knowledge, this is the first work that adapts VFMs to CD in VHR RS images.", "authors": ["Lei Ding", "Kun Zhu", "Daifeng Peng", "Hao Tang", "Kuiwu Yang", "Lorenzo Bruzzone"], "year": 2024, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 137, "type": "article", "concepts": ["Remote sensing", "Change detection", "Computer science", "Artificial intelligence", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4365816982", "doi": "https://doi.org/10.48550/arxiv.2304.05396", "title": "SAM.MD: Zero-shot medical image segmentation capabilities of the Segment Anything Model", "abstract": "Foundation models have taken over natural language processing and image generation domains due to the flexibility of prompting. With the recent introduction of the Segment Anything Model (SAM), this prompt-driven paradigm has entered image segmentation with a hitherto unexplored abundance of capabilities. The purpose of this paper is to conduct an initial evaluation of the out-of-the-box zero-shot capabilities of SAM for medical image segmentation, by evaluating its performance on an abdominal CT organ segmentation task, via point or bounding box based prompting. We show that SAM generalizes well to CT data, making it a potential catalyst for the advancement of semi-automatic segmentation tools for clinicians. We believe that this foundation model, while not reaching state-of-the-art segmentation performance in our investigations, can serve as a highly potent starting point for further adaptations of such models to the intricacies of the medical domain. Keywords: medical image segmentation, SAM, foundation models, zero-shot learning", "authors": ["Saikat Roy", "Tassilo Wald", "Gregor Koehler", "Maximilian Rokuss", "Nico Disch", "Julius C. Holzschuh", "David Zimmerer", "Klaus H. Maier-Hein"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 64, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Image (mathematics)", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402727436", "doi": "https://doi.org/10.1109/cvpr52733.2024.02636", "title": "SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation", "abstract": "Zero-shot 6D object pose estimation involves the detection of novel objects with their 6D poses in cluttered scenes, presenting significant challenges for model generalizability. Fortunately, the recent Segment Anything Model (SAM) has showcased remarkable zero-shot transfer performance, which provides a promising solution to tackle this task. Motivated by this, we introduce SAM-6D, a novel framework designed to realize the task through two steps, including instance segmentation and pose estimation. Given the target objects, SAM-6D employs two dedicated sub-networks, namely Instance Segmentation Model (ISM) and Pose Estimation Model (PEM), to perform these steps on cluttered RGB-D images. ISM takes SAM as an advanced starting point to generate all possible object proposals and selectively preserves valid ones through meticulously crafted object matching scores in terms of semantics, appearance and geometry. By treating pose estimation as a partial-to-partial point matching problem, PEM performs a two-stage point matching process featuring a novel design of background tokens to construct dense 3D-3D correspondence, ultimately yielding the pose estimates. Without bells and whistles, SAM-6D outperforms the existing methods on the seven core datasets of the BOP Benchmark for both instance segmentation and pose estimation of novel objects.", "authors": ["Jiehong Lin", "Lihua Liu", "Dekun Lu", "Kui Jia"], "year": 2024, "venue": "", "cited_by_count": 82, "type": "article", "concepts": ["Zero (linguistics)", "Computer vision", "Object (grammar)", "Computer science", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4390971106", "doi": "https://doi.org/10.1109/bibm58861.2023.10386032", "title": "Segment Anything Model (SAM) for Medical Image Segmentation: A Preliminary Review", "abstract": "Medical image segmentation is a critical component in a variety of clinical applications, facilitating accurate diagnosis and treatment planning. The Segment Anything Model (SAM), a deep learning architecture, has emerged as a promising solution to the challenges inherent in medical image segmentation. SAM’s superior zero-shot capability allows it to generalize effectively, even in the absence of task-specific segmentation samples. This unique characteristic broadens its application potential across various medical image modalities. This paper provides an in-depth review of SAM, focusing on its application in medical image segmentation. The review discusses the advantages of deep learning image segmentation over traditional methods, emphasizing the superior accuracy, efficiency, and automation that deep learning models offer. The paper also highlights the applications of SAM across various medical imaging modalities, demonstrating its versatility and adaptability. A taxonomy of SAM approaches in medical image segmentation is presented, categorizing them based on modality, dimension, organ, dataset, prompt, and performance. Despite the promising results of SAM, challenges remain in the field of medical image segmentation. The paper identifies these challenges and suggests potential directions for future research. In conclusion, this review aims to provide a comprehensive understanding of SAM and its potential to revolutionize medical image analysis and contribute to advancements in healthcare.", "authors": ["Leying Zhang", "Xiaokang Deng", "Lu Yu"], "year": 2023, "venue": "", "cited_by_count": 87, "type": "review", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Image segmentation", "Deep learning"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4393159543", "doi": "https://doi.org/10.1609/aaai.v38i7.28514", "title": "SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation", "abstract": "The Segment Anything Model (SAM) is a powerful foundation model that has revolutionised image segmentation. To apply SAM to surgical instrument segmentation, a common approach is to locate precise points or boxes of instruments and then use them as prompts for SAM in a zero-shot manner. However, we observe two problems with this naive pipeline: (1) the domain gap between natural objects and surgical instruments leads to inferior generalisation of SAM; and (2) SAM relies on precise point or box locations for accurate segmentation, requiring either extensive manual guidance or a well-performing specialist detector for prompt preparation, which leads to a complex multi-stage pipeline. To address these problems, we introduce SurgicalSAM, a novel end-to-end efficient-tuning approach for SAM to effectively integrate surgical-specific information with SAM’s pre-trained knowledge for improved generalisation. Specifically, we propose a lightweight prototype-based class prompt encoder for tuning, which directly generates prompt embeddings from class prototypes and eliminates the use of explicit prompts for improved robustness and a simpler pipeline. In addition, to address the low inter-class variance among surgical instrument categories, we propose contrastive prototype learning, further enhancing the discrimination of the class prototypes for more accurate class prompting. The results of extensive experiments on both EndoVis2018 and EndoVis2017 datasets demonstrate that SurgicalSAM achieves state-of-the-art performance while only requiring a small number of tunable parameters. The source code is available at https://github.com/wenxi-yue/SurgicalSAM.", "authors": ["Wenxi Yue", "Jing Zhang", "Kun Hu", "Yong Xia", "Jiebo Luo", "Zhiyong Wang"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 72, "type": "article", "concepts": ["Surgical instrument", "Class (philosophy)", "Artificial intelligence", "Computer vision", "Segmentation"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4404177154", "doi": "https://doi.org/10.1007/978-3-031-72855-6_14", "title": "IRSAM: Advancing Segment Anything Model for Infrared Small Target Detection", "abstract": "", "authors": ["Mingjin Zhang", "Yuchun Wang", "Jie Guo", "Yunsong Li", "Xinbo Gao", "Jing Zhang"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 115, "type": "book-chapter", "concepts": ["Computer science", "Infrared", "Artificial intelligence", "Computer vision", "Optics"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4388823372", "doi": "https://doi.org/10.1101/2023.11.17.567630", "title": "CellSAM: A Foundation Model for Cell Segmentation", "abstract": "Abstract Cells are a fundamental unit of biological organization, and identifying them in imaging data – cell segmentation – is a critical task for various cellular imaging experiments. While deep learning methods have led to substantial progress on this problem, most models are specialist models that work well for specific domains but cannot be applied across domains or scale well with large amounts of data. In this work, we present CellSAM, a universal model for cell segmentation that generalizes across diverse cellular imaging data. CellSAM builds on top of the Segment Anything Model (SAM) by developing a prompt engineering approach for mask generation. We train an object detector, CellFinder, to automatically detect cells and prompt SAM to generate segmentations. We show that this approach allows a single model to achieve human-level performance for segmenting images of mammalian cells, yeast, and bacteria collected across various imaging modalities. We show that CellSAM has strong zero-shot performance and can be improved with a few examples via few-shot learning. Additionally, we demonstrate how CellSAM can be applied across diverse bioimage analysis workflows. A deployed version of CellSAM is available at https://cellsam.deepcell.org/ .", "authors": ["Uriah Israel", "Markus Marks", "Rohit Dilip", "Qilin Li", "Changhua Yu", "Emily Laubscher", "Shenyi Li", "Morgan Schwartz", "Elora Pradhan", "Ada Ates", "Martin Abt", "Caitlin Brown", "Edward Pao", "Alexander Pearson-Goulart", "Pietro Perona", "Georgia Gkioxari", "Ross Barnowski", "Yisong Yue", "David Van Valen"], "year": 2023, "venue": "", "cited_by_count": 51, "type": "preprint", "concepts": ["Computer science", "Segmentation", "Workflow", "Artificial intelligence", "Market segmentation"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4394597311", "doi": "https://doi.org/10.1109/wacv57701.2024.00817", "title": "Segment anything, from space?", "abstract": "Recently, the first foundation model developed specifically for image segmentation tasks was developed, termed the \"Segment Anything Model\" (SAM). SAM can segment objects in input imagery based on cheap input prompts, such as one (or more) points, a bounding box, or a mask. The authors examined the zero-shot image segmentation accuracy of SAM on a large number of vision benchmark tasks and found that SAM usually achieved recognition accuracy similar to, or sometimes exceeding, vision models that had been trained on the target tasks. The impressive generalization of SAM for segmentation has major implications for vision researchers working on natural imagery. In this work, we examine whether SAM's performance extends to overhead imagery problems and help guide the community's response to its development. We examine SAM's performance on a set of diverse and widely studied benchmark tasks. We find that SAM does often generalize well to overhead imagery, although it fails in some cases due to the unique characteristics of overhead imagery and its common target objects. We report on these unique systematic failure cases for remote sensing imagery that may comprise useful future research for the community.", "authors": ["Simiao Ren", "Francesco Luzi", "Saad Lahrichi", "Kaleb Kassaw", "Leslie M. Collins", "Kyle Bradbury", "Jordan M. Malof"], "year": 2024, "venue": "", "cited_by_count": 58, "type": "article", "concepts": ["Space (punctuation)", "Computer science", "Operating system"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4388666409", "doi": "https://doi.org/10.1016/j.atech.2023.100367", "title": "The Segment Anything Model (SAM) for accelerating the smart farming revolution", "abstract": "Precision agriculture uses accurate identification and mapping of crop features by automated mechanisms. Using computer vision techniques implemented by supervised deep learning systems to solve many precision agricultural problems necessitates large-scale data collection and prolonged ground truth annotation by humans. The so-called foundation models in Artificial Intelligence (AI) are becoming increasingly significant. Meta AI Research is working on a project called Segment Anything to provide a base model for image segmentation. It can accomplish zero-shot generalisation to strange objects and images without additional training. This study evaluates the performance of the Segment Anything Model (SAM) for the problem of semantic segmentation of objects in the context of precision agriculture.", "authors": ["Alberto Carraro", "Marco Sozzi", "Francesco Marinello"], "year": 2023, "venue": "Smart Agricultural Technology", "cited_by_count": 51, "type": "article", "concepts": ["Computer science", "Segmentation", "Artificial intelligence", "Context (archaeology)", "Identification (biology)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4367692241", "doi": "https://doi.org/10.48550/arxiv.2305.00035", "title": "SAM on Medical Images: A Comprehensive Study on Three Prompt Modes", "abstract": "The Segment Anything Model (SAM) made an eye-catching debut recently and inspired many researchers to explore its potential and limitation in terms of zero-shot generalization capability. As the first promptable foundation model for segmentation tasks, it was trained on a large dataset with an unprecedented number of images and annotations. This large-scale dataset and its promptable nature endow the model with strong zero-shot generalization. Although the SAM has shown competitive performance on several datasets, we still want to investigate its zero-shot generalization on medical images. As we know, the acquisition of medical image annotation usually requires a lot of effort from professional practitioners. Therefore, if there exists a foundation model that can give high-quality mask prediction simply based on a few point prompts, this model will undoubtedly become the game changer for medical image analysis. To evaluate whether SAM has the potential to become the foundation model for medical image segmentation tasks, we collected more than 12 public medical image datasets that cover various organs and modalities. We also explore what kind of prompt can lead to the best zero-shot performance with different modalities. Furthermore, we find that a pattern shows that the perturbation of the box size will significantly change the prediction accuracy. Finally, Extensive experiments show that the predicted mask quality varied a lot among different datasets. And providing proper prompts, such as bounding boxes, to the SAM will significantly increase its performance.", "authors": ["Dongjie Cheng", "Ziyuan Qin", "Zekun Jiang", "Shaoting Zhang", "Qicheng Lao", "Kang Li"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 54, "type": "preprint", "concepts": ["Computer science", "Generalization", "Segmentation", "Artificial intelligence", "Modalities"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402915908", "doi": "https://doi.org/10.1109/cvprw63382.2024.00367", "title": "SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding", "abstract": "The landscape of publicly available vision foundation models (VFMs), such as CLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed with distinct capabilities stemming from their pre-training objectives. For instance, CLIP excels in semantic understanding, while SAM specializes in spatial understanding for segmentation. In this work, we introduce a simple recipe to efficiently merge VFMs into a unified model that absorbs their expertise. Our method integrates techniques of multitask learning, continual learning, and distillation. Further, it demands significantly less computational cost compared to traditional multi-task training from scratch, and it only needs a small fraction of the pre-training datasets that were initially used to train individual models. By applying our method to SAM and CLIP, we obtain SAM-CLIP : a unified model that combines the capabilities of SAM and CLIP into a single vision transformer. Compared with deploying SAM and CLIP independently, our merged model, SAM-CLIP, reduces storage and compute costs for inference, making it well-suited for edge device applications. We show that SAM-CLIP not only retains the foundational strengths of SAM and CLIP, but also introduces synergistic functionalities, notably in zero-shot semantic segmentation, where SAM-CLIP establishes new state-of-the-art results on 5 benchmarks. It outperforms previous models that are specifically designed for this task by a large margin, including +6.8% and +5.9% mean IoU improvement on Pascal-VOC and COCO-Stuff datasets, respectively.", "authors": ["Haoxiang Wang", "Pavan Kumar Anasosalu Vasu", "Fartash Faghri", "Raviteja Vemulapalli", "Mehrdad Farajtabar", "Sachin Mehta", "Mohammad Rastegari", "Oncel Tuzel", "Hadi Pouransari"], "year": 2024, "venue": "", "cited_by_count": 65, "type": "article", "concepts": ["Foundation (evidence)", "Computer science", "Artificial intelligence", "Information retrieval", "Geography"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4383180710", "doi": "https://doi.org/10.48550/arxiv.2307.01197", "title": "Segment Anything Meets Point Tracking", "abstract": "The Segment Anything Model (SAM) has established itself as a powerful zero-shot image segmentation model, enabled by efficient point-centric annotation and prompt-based models. While click and brush interactions are both well explored in interactive image segmentation, the existing methods on videos focus on mask annotation and propagation. This paper presents SAM-PT, a novel method for point-centric interactive video segmentation, empowered by SAM and long-term point tracking. SAM-PT leverages robust and sparse point selection and propagation techniques for mask generation. Compared to traditional object-centric mask propagation strategies, we uniquely use point propagation to exploit local structure information agnostic to object semantics. We highlight the merits of point-based tracking through direct evaluation on the zero-shot open-world Unidentified Video Objects (UVO) benchmark. Our experiments on popular video object segmentation and multi-object segmentation tracking benchmarks, including DAVIS, YouTube-VOS, and BDD100K, suggest that a point-based segmentation tracker yields better zero-shot performance and efficient interactions. We release our code that integrates different point trackers and video segmentation benchmarks at https://github.com/SysCV/sam-pt.", "authors": ["Frano Rajič", "Lei Ke", "Yu‐Wing Tai", "Chi–Keung Tang", "Martin Danelljan", "Fisher Yu"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 38, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Computer vision", "Artificial intelligence", "Benchmark (surveying)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4366457071", "doi": "https://doi.org/10.48550/arxiv.2304.08506", "title": "When SAM Meets Medical Images: An Investigation of Segment Anything Model (SAM) on Multi-phase Liver Tumor Segmentation", "abstract": "Learning to segmentation without large-scale samples is an inherent capability of human. Recently, Segment Anything Model (SAM) performs the significant zero-shot image segmentation, attracting considerable attention from the computer vision community. Here, we investigate the capability of SAM for medical image analysis, especially for multi-phase liver tumor segmentation (MPLiTS), in terms of prompts, data resolution, phases. Experimental results demonstrate that there might be a large gap between SAM and expected performance. Fortunately, the qualitative results show that SAM is a powerful annotation tool for the community of interactive medical image segmentation.", "authors": ["Chuanfei Hu", "Xinde Li", "Ju, Shenghong", "Li, Xinde"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 37, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Computer vision", "Image (mathematics)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4401008913", "doi": "https://doi.org/10.1016/j.atech.2024.100515", "title": "Leaf only SAM: A segment anything pipeline for zero-shot automated leaf segmentation", "abstract": "", "authors": ["Dominic Williams", "Fraser Macfarlane", "Avril Britten"], "year": 2024, "venue": "Smart Agricultural Technology", "cited_by_count": 38, "type": "article", "concepts": ["Shot (pellet)", "Pipeline (software)", "Segmentation", "Zero (linguistics)", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4388283708", "doi": "https://doi.org/10.1109/tmm.2023.3330047", "title": "FoodSAM: Any Food Segmentation", "abstract": "In this paper, we explore the zero-shot capability of the Segment Anything Model (SAM) for food image segmentation. To address the lack of class-specific information in SAM-generated masks, we propose a novel framework, called <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">FoodSAM</i> . This innovative approach integrates the coarse semantic mask with SAM-generated masks to enhance semantic segmentation quality. Besides, we recognize that the ingredients in food can be supposed as independent individuals, which motivated us to perform instance segmentation on food images. Furthermore, FoodSAM extends its zero-shot capability to encompass panoptic segmentation by incorporating an object detector, which renders FoodSAM to effectively capture non-food object information. Drawing inspiration from the recent success of promptable segmentation, we also extend FoodSAM to promptable segmentation, supporting various prompt variants. Consequently, FoodSAM emerges as an all-encompassing solution capable of segmenting food items at multiple levels of granularity. Remarkably, this pioneering framework stands as the first-ever work to achieve instance, panoptic, and promptable segmentation on food images. Extensive experiments demonstrate the feasibility and impressing performance of FoodSAM, validating SAM's potential as a prominent and influential tool within the domain of food image segmentation.", "authors": ["Xing Lan", "Jiayi Lyu", "Hanyu Jiang", "Kun Dong", "Zehai Niu", "Yi Zhang", "Jian Xue"], "year": 2023, "venue": "IEEE Transactions on Multimedia", "cited_by_count": 41, "type": "article", "concepts": ["Segmentation", "Computer science", "Market segmentation", "Artificial intelligence", "Scale-space segmentation"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4395015601", "doi": "https://doi.org/10.1088/1742-6596/2722/1/012012", "title": "All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning", "abstract": "The Segment Anything Model (SAM) is a recently proposed prompt-based segmentation model in a generic zero-shot segmentation approach. With the zero-shot segmentation capacity, SAM achieved impressive flexibility and precision on various segmentation tasks. However, the current pipeline requires manual prompts during the inference stage, which is still resource intensive for biomedical image segmentation. In this paper, instead of using prompts during the inference stage, we introduce a pipeline that utilizes the SAM, called all-in-SAM, through the entire AI development workflow (from annotation generation to model finetuning) without requiring manual prompts during the inference stage. Specifically, SAM is first employed to generate pixel-level annotations from weak prompts (e.g., points, bounding box). Then, the pixel-level annotations are used to finetune the SAM segmentation model rather than training from scratch. Our experimental results reveal two key findings: 1) the proposed pipeline surpasses the state-of-the-art methods in a nuclei segmentation task on the public Monuseg dataset, and 2) the utilization of weak and few annotations for SAM finetuning achieves competitive performance compared to using strong pixelwise annotated data.", "authors": ["Can Cui", "Ruining Deng", "Quan Liu", "Tianyuan Yao", "Shunxing Bao", "Lucas W. Remedios", "Bennett A. Landman", "Yucheng Tang", "Yuankai Huo"], "year": 2024, "venue": "Journal of Physics Conference Series", "cited_by_count": 35, "type": "article", "concepts": ["Annotation", "Segmentation", "Artificial intelligence", "Computer science", "Pixel"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4396825686", "doi": "https://doi.org/10.1016/j.conbuildmat.2024.136573", "title": "Fine-tuning vision foundation model for crack segmentation in civil infrastructures", "abstract": "", "authors": ["Kang Ge", "Chao Wang", "Yutao Guo", "Yutong Tang", "Zhen Hu", "Hongzhu Chen"], "year": 2024, "venue": "Construction and Building Materials", "cited_by_count": 45, "type": "article", "concepts": ["Foundation (evidence)", "Segmentation", "Artificial intelligence", "Computer science", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4403649753", "doi": "https://doi.org/10.1007/978-3-031-72390-2_60", "title": "MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation", "abstract": "", "authors": ["Taha Koleilat", "Hojat Asgariandehkordi", "Hassan Rivaz", "Yiming Xiao"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 33, "type": "book-chapter", "concepts": ["Bridging (networking)", "Computer science", "Image segmentation", "Computer vision", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402961794", "doi": "https://doi.org/10.1007/978-3-031-72775-7_24", "title": "Open-Vocabulary SAM: Segment and Recognize Twenty-Thousand Classes Interactively", "abstract": "", "authors": ["Haobo Yuan", "Xiangtai Li", "Chong Zhou", "Yining Li", "Kai Chen", "Chen Change Loy"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 34, "type": "book-chapter", "concepts": ["Computer science", "Vocabulary", "Artificial intelligence", "Natural language processing", "Computer graphics (images)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4391929768", "doi": "https://doi.org/10.1109/bibe60311.2023.00025", "title": "Zero-Shot Performance of the Segment Anything Model (SAM) in 2D Medical Imaging: A Comprehensive Evaluation and Practical Guidelines", "abstract": "This study evaluates the potential of the “Segment Anything Model” (SAM) as a robust alternative for medical imaging segmentation in a zero-shot learning context. We evaluate SAM's performance across six diverse medical imaging datasets spanning four different imaging modalities. By employing eight unique prompting strategies we reveal comprehensive insights into SAM's adaptability. The Bounding Box strategy, with its variations, matched or even outperformed existing benchmarks. On the Breast Ultrasound Images dataset, SAM notably outperformed SOTA models, attesting to its capability as a robust zero-shot segmentation tool. Conversely, challenges arose with datasets having indistinct boundaries and inconsistent annotations, as in skin lesion images. The study also establishes a practical set of guidelines aimed at optimizing SAM's clinical usage. The findings underscore SAM's potential as a powerful, versatile tool for medical imaging segmentation, alleviating the burden of manual segmentation and potentially improving ground truth masks for labeling new datasets. With its minimal resource requirements and promising results, SAM represents an exciting advancement in medical imaging analysis.", "authors": ["Christian Mattjie", "Luís Vinícius de Moura", "Rafaela Ravazio", "Lucas Silveira Kupssinskü", "Otávio Parraga", "Marcelo Mussi Delucis", "Rodrigo C. Barros"], "year": 2023, "venue": "", "cited_by_count": 33, "type": "article", "concepts": ["Zero (linguistics)", "Shot (pellet)", "Computer science", "Medical imaging", "Medical physics"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4389213248", "doi": "https://doi.org/10.1007/978-3-031-47401-9_23", "title": "SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation", "abstract": "", "authors": ["An Wang", "Mobarakol Islam", "Mengya Xu", "Yang Zhang", "Hongliang Ren"], "year": 2023, "venue": "Lecture notes in computer science", "cited_by_count": 38, "type": "book-chapter", "concepts": ["Computer science", "Robustness (evolution)", "Minimum bounding box", "Generalizability theory", "Bounding overwatch"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402916510", "doi": "https://doi.org/10.1109/cvprw63382.2024.00526", "title": "Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero-shot Medical Image Segmentation", "abstract": "The Segment Anything Model (SAM) and CLIP are remarkable vision foundation models (VFMs). SAM, a prompt-driven segmentation model, excels in segmentation tasks across diverse domains, while CLIP is renowned for its zero-shot recognition capabilities. However, their unified potential has not yet been explored in medical image segmentation. To adapt SAM, to medical imaging, existing methods primarily rely on tuning strategies that require extensive data or prior prompts tailored to the specific task, making it particularly challenging when only a limited number of data samples are available. This work presents an in-depth exploration of integrating SAM and CLIP into a unified framework for medical image segmentation. Specifically, we propose a simple unified framework, SaLIP, for organ segmentation. Initially, SAM is used for part-based segmentation within the image, followed by CLIP to retrieve the mask corresponding to the region of interest (ROI) from the pool of SAM’s generated masks. Finally, SAM is prompted by the retrieved ROI to segment a specific organ. Thus, SaLIP is training/fine-tuning free and does not rely on domain expertise or labeled data for prompt engineering. Our method shows substantial enhancements in zero-shot segmentation, showcasing notable improvements in DICE scores across diverse segmentation tasks like brain (63.46%), lung (50.11%), and fetal head (30.82%), when compared to un-prompted SAM. Code and text prompts are available at SaLIP.", "authors": ["Sidra Aleem", "Fangyijie Wang", "Mayug Maniparambil", "Eric Arazo", "Julia Dietlmeier", "Kathleen M. Curran", "Noel E. O’Connor", "Suzanne Little"], "year": 2024, "venue": "", "cited_by_count": 26, "type": "article", "concepts": ["Cascade", "Shot (pellet)", "Computer science", "Segmentation", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402781391", "doi": "https://doi.org/10.1109/cvpr52733.2024.01074", "title": "One-Prompt to Segment All Medical Images", "abstract": "Large foundation models, known for their strong zero-shot generalization, have excelled in visual and language applications. However, applying them to medical image segmentation, a domain with diverse imaging types and target labels, remains an open challenge. Current approaches, such as adapting interactive segmentation models like Segment Anything Model (SAM), require user prompts for each sample during inference. Alternatively, trans-fer learning methods like few/one-shot models demand la-beled samples, leading to high costs. This paper intro-duces a new paradigm toward the universal medical image segmentation, termed ‘One-Prompt Segmentation.’ One-Prompt Segmentation combines the strengths of one-shot and interactive methods. In the inference stage, with just one prompted sample, it can adeptly handle the un-seen task in a single forward pass. We train One-Prompt Model on 64 open-source medical datasets, accompanied by the collection of over 3,000 clinician-labeled prompts. Tested on 14 previously unseen datasets, the One-Prompt Model showcases superior zero-shot segmentation capabil-ities, outperforming a wide range of related methods. The code and data is released as https://github.com/KidsWithTokens/one-prompt.", "authors": ["Junde Wu", "Min Xu"], "year": 2024, "venue": "", "cited_by_count": 29, "type": "article", "concepts": ["Computer science", "Computer vision", "Medical imaging", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4409363472", "doi": "https://doi.org/10.1609/aaai.v39i19.34255", "title": "TinySAM: Pushing the Envelope for Efficient Segment Anything Model", "abstract": "Recently segment anything model (SAM) has shown powerful segmentation capability and has drawn great attention in computer vision fields. Massive following works have developed various applications based on the pre-trained SAM and achieved impressive performance on downstream vision tasks. However, SAM consists of heavy architectures and requires massive computational capacity, which hinders the further application of SAM on computation constrained edge devices. To this end, in this paper we propose a framework to obtain a tiny segment anything model (TinySAM) while maintaining the strong zero-shot performance. We first propose a full-stage knowledge distillation method with hard prompt sampling and hard mask weighting strategy to distill a lightweight student model. We also adapt the post-training quantization to the prompt-based segmentation task and further reduce the computational cost. Moreover, a hierarchical segmenting everything strategy is proposed to accelerate the everything inference by 2× with almost no performance degradation. With all these proposed methods, our TinySAM leads to orders of magnitude computational reduction and pushes the envelope for efficient segment anything task. Extensive experiments on various zero-shot transfer tasks demonstrate the significantly advantageous performance of our TinySAM against counterpart methods.", "authors": ["Han Shu", "Wenshuo Li", "Yehui Tang", "Yiman Zhang", "Yihao Chen", "Houqiang Li", "Yunhe Wang", "Xinghao Chen"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 20, "type": "article", "concepts": ["Envelope (radar)", "Computer science", "Telecommunications", "Radar"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4392154986", "doi": "https://doi.org/10.3390/rs16050797", "title": "Segment Anything Model Can Not Segment Anything: Assessing AI Foundation Model’s Generalizability in Permafrost Mapping", "abstract": "This paper assesses trending AI foundation models, especially emerging computer vision foundation models and their performance in natural landscape feature segmentation. While the term foundation model has quickly garnered interest from the geospatial domain, its definition remains vague. Hence, this paper will first introduce AI foundation models and their defining characteristics. Built upon the tremendous success achieved by Large Language Models (LLMs) as the foundation models for language tasks, this paper discusses the challenges of building foundation models for geospatial artificial intelligence (GeoAI) vision tasks. To evaluate the performance of large AI vision models, especially Meta’s Segment Anything Model (SAM), we implemented different instance segmentation pipelines that minimize the changes to SAM to leverage its power as a foundation model. A series of prompt strategies were developed to test SAM’s performance regarding its theoretical upper bound of predictive accuracy, zero-shot performance, and domain adaptability through fine-tuning. The analysis used two permafrost feature datasets, ice-wedge polygons and retrogressive thaw slumps because (1) these landform features are more challenging to segment than man-made features due to their complicated formation mechanisms, diverse forms, and vague boundaries; (2) their presence and changes are important indicators for Arctic warming and climate change. The results show that although promising, SAM still has room for improvement to support AI-augmented terrain mapping. The spatial and domain generalizability of this finding is further validated using a more general dataset EuroCrops for agricultural field mapping. Finally, we discuss future research directions that strengthen SAM’s applicability in challenging geospatial domains.", "authors": ["Wenwen Li", "Chia-Yu Hsu", "Sizhe Wang", "Yezhou Yang", "Hyunho Lee", "Anna Liljedahl", "Chandi Witharana", "Yili Yang", "Brendan M. Rogers", "Samantha T. Arundel", "Matthew B. Jones", "Kenton McHenry", "Patricia Solís"], "year": 2024, "venue": "Remote Sensing", "cited_by_count": 28, "type": "article", "concepts": ["Generalizability theory", "Permafrost", "Foundation (evidence)", "Geology", "Oceanography"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4391109864", "doi": "https://doi.org/10.1038/s41467-024-44824-z", "title": "Segment anything in medical images", "abstract": "", "authors": ["Jun Ma", "Yuting He", "Feifei Li", "Lin Han", "Chenyu You", "Bo Wang"], "year": 2024, "venue": "Nature Communications", "cited_by_count": 1973, "type": "article", "concepts": ["Computer science", "Computational biology", "Medicine", "Biology"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4397001004", "doi": "https://doi.org/10.1016/j.compag.2024.109045", "title": "An innovative segment anything model for precision poultry monitoring", "abstract": "", "authors": ["Xiao Yang", "Haixing Dai", "Zihao Wu", "Ramesh Bahadur Bist", "Sachin Subedi", "Jin Sun", "Guoyu Lu", "Changying Li", "Tianming Liu", "Lilong Chai"], "year": 2024, "venue": "Computers and Electronics in Agriculture", "cited_by_count": 23, "type": "article", "concepts": ["Computer science", "Engineering", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4390190003", "doi": "https://doi.org/10.1109/iccvw60793.2023.00184", "title": "Semantic Segmentation using Foundation Models for Cultural Heritage: an Experimental Study on Notre-Dame de Paris", "abstract": "The zero-shot performance of foundation models has captured a lot of attention. Specifically, the Segment Anything Model (SAM) has gained popularity in computer vision due to its label-free segmentation capabilities. Our study proposes using SAM on cultural heritage data, specifically images of Notre-Dame de Paris, with a controlled vocabulary. SAM can successfully identify objects within the cathedral. To further improve segmentation, we utilized Grounding DINO to detect objects and CLIP to automatically add labels from the segmentation masks generated by SAM. Our study demonstrates the usefulness of foundation models for zero-shot semantic segmentation of cultural heritage data.", "authors": ["Kévin Réby", "Anaïs Guilhelm", "Livio De Luca"], "year": 2023, "venue": "", "cited_by_count": 16, "type": "article", "concepts": ["Segmentation", "Foundation (evidence)", "Popularity", "Computer science", "Cultural heritage"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4382319386", "doi": "https://doi.org/10.48550/arxiv.2306.13731", "title": "How to Efficiently Adapt Large Segmentation Model(SAM) to Medical Images", "abstract": "The emerging scale segmentation model, Segment Anything (SAM), exhibits impressive capabilities in zero-shot segmentation for natural images. However, when applied to medical images, SAM suffers from noticeable performance drop. To make SAM a real ``foundation model\" for the computer vision community, it is critical to find an efficient way to customize SAM for medical image dataset. In this work, we propose to freeze SAM encoder and finetune a lightweight task-specific prediction head, as most of weights in SAM are contributed by the encoder. In addition, SAM is a promptable model, while prompt is not necessarily available in all application cases, and precise prompts for multiple class segmentation are also time-consuming. Therefore, we explore three types of prompt-free prediction heads in this work, include ViT, CNN, and linear layers. For ViT head, we remove the prompt tokens in the mask decoder of SAM, which is named AutoSAM. AutoSAM can also generate masks for different classes with one single inference after modification. To evaluate the label-efficiency of our finetuning method, we compare the results of these three prediction heads on a public medical image segmentation dataset with limited labeled data. Experiments demonstrate that finetuning SAM significantly improves its performance on medical image dataset, even with just one labeled volume. Moreover, AutoSAM and CNN prediction head also has better segmentation accuracy than training from scratch and self-supervised learning approaches when there is a shortage of annotations.", "authors": ["Xinrong Hu", "Xiaowei Xu", "Yiyu Shi"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 29, "type": "preprint", "concepts": ["Computer science", "Segmentation", "Artificial intelligence", "Encoder", "Inference"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402753822", "doi": "https://doi.org/10.1109/cvpr52733.2024.02207", "title": "Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation", "abstract": "The success of large language models has inspired the computer vision community to explore image segmentation foundation model that is able to zero/few-shot generalize through prompt engineering. Segment-Anything (SAM), among others, is the state-of-the-art image segmentation foundation model demonstrating strong zero/few-shot generalization. Despite the success, recent studies reveal the weakness of SAM under strong distribution shift. In particular, SAM performs awkwardly on corrupted natural images, camouflaged images, medical images, etc. Motivated by the observations, we aim to develop a self-training based strategy to adapt SAM to target distribution. Given the unique challenges of large source dataset, high computation cost and incorrect pseudo label, we propose a weakly supervised self-training architecture with anchor regularization and low-rank finetuning to improve the robustness and computation efficiency of adaptation. We validate the effectiveness on 5 types of downstream segmentation tasks including natural clean/corrupted images, medical images, camouflaged images and robotic images. Our proposed method is task-agnostic in nature and outperforms pre-trained SAM and state-of-the-art domain adaptation methods on almost all downstream tasks with the same testing prompt inputs.", "authors": ["Haojie Zhang", "Yongyi Su", "Xun Xu", "Kui Jia"], "year": 2024, "venue": "", "cited_by_count": 24, "type": "article", "concepts": ["Generalization", "Foundation (evidence)", "Segmentation", "Adaptation (eye)", "Computer science"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4405594810", "doi": "https://doi.org/10.1016/j.rineng.2024.103784", "title": "Tea leaf disease detection using segment anything model and deep convolutional neural networks", "abstract": "", "authors": ["A. Balasundaram", "Puma Sundaresan", "Arnav Bhavsar", "Mishti Mattu", "Muthu Subash Kavitha", "Ayesha Shaik"], "year": 2024, "venue": "Results in Engineering", "cited_by_count": 28, "type": "article", "concepts": ["Convolutional neural network", "Artificial intelligence", "Computer science", "Pattern recognition (psychology)"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4386987615", "doi": "https://doi.org/10.1016/j.icarus.2023.115797", "title": "A flexible deep learning crater detection scheme using Segment Anything Model (SAM)", "abstract": "Craters are one of the most important morphological features in planetary exploration. To that extent, detecting, mapping and counting craters is a mainstream process in planetary science, done primarily manually, which is a very laborious, time-consuming and inconsistent process. Recently, machine learning (ML) and computer vision have been successfully applied for both detecting craters and estimating their size. Existing ML models for automated crater detection have been trained in specific types of data e.g. digital elevation model (DEM), images and associated metadata from orbiters such as the Lunar Reconnaissance Orbiter Camera (LROC) etc.. Due to that, each of the resulting ML schemes is applicable and reliable only to the type of data used during the training process. Data from different sources, angles and setups can compromise the reliability of these ML schemes. In this paper we present a flexible crater detection scheme that is based on the recently proposed Segment Anything Model (SAM) from META AI. SAM is a prompt-able segmentation system with zero-shot generalization to unfamiliar objects and images without the need for additional training. Using SAM, without additional training and fine-tuning, we can successfully identify crater-looking objects in various types of data (e,g, raw satellite images Level-1 and 2 products, DEMs etc.) for different setups (e.g. Lunar, Mars) and different capturing angles. Moreover, using shape indexes, we only keep the segmentation masks of crater-like features. These masks are subsequently fitted with a circle or an ellipse, recovering both the location and the size/geometry of the detected craters.", "authors": ["Iraklis Giannakis", "Anshuman Bhardwaj", "Lydia Sam", "Georgios Leontidis"], "year": 2023, "venue": "Icarus", "cited_by_count": 39, "type": "article", "concepts": ["Impact crater", "Orbiter", "Computer science", "Artificial intelligence", "Contouring"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4406322219", "doi": "https://doi.org/10.1109/tgrs.2025.3529031", "title": "PointSAM: Pointly-Supervised Segment Anything Model for Remote Sensing Images", "abstract": "Segment anything model (SAM) is an advanced foundational model for image segmentation, which is gradually being applied to remote sensing images (RSIs). Due to the domain gap between RSIs and natural images, traditional methods typically use SAM as a source pretrained model and fine-tune it with fully supervised masks. Unlike these methods, our work focuses on fine-tuning SAM using more convenient and challenging point annotations. Leveraging SAM’s zero-shot capability, we adopt a self-training framework that iteratively generates pseudolabels. However, noisy labels in pseudolabels can cause error accumulation. To address this, we introduce prototype-based regularization (PBR), where target prototypes are extracted from the dataset and matched to predicted prototypes using the Hungarian algorithm to guide learning in the correct direction. In addition, RSIs have complex backgrounds and densely packed objects, making it possible for point prompts to mistakenly group multiple objects as one. To resolve this, we propose a negative prompt calibration (NPC) method based on the nonoverlapping nature of instance masks, where overlapping masks are used as negative signals to refine segmentation. Combining these techniques, we present a novel pointly-supervised SAM (PointSAM). We conduct experiments on three RSI datasets, including WHU, HRSID, and NWPU VHR-10, showing that our method significantly outperforms direct testing with SAM, SAM2, and other comparison methods. In addition, PointSAM can act as a point-to-box converter for oriented object detection, achieving promising results and indicating its potential for other point-supervised tasks. The code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/Lans1ng/PointSAM</uri>.", "authors": ["Nanqing Liu", "Xun Xu", "Yongyi Su", "Haojie Zhang", "Heng-Chao Li"], "year": 2025, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 38, "type": "article", "concepts": ["Remote sensing", "Computer science", "Computer vision", "Artificial intelligence", "Geology"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4402980275", "doi": "https://doi.org/10.1109/icme57554.2024.10687602", "title": "PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation", "abstract": "The Segment Anything Model (SAM) has exhibited outstanding performance in various image segmentation tasks. Despite being trained with over a billion masks, SAM faces challenges in mask prediction quality in numerous scenarios, especially in real-world contexts. In this paper, we introduce a novel prompt-driven adapter into SAM, namely Prompt Adapter Segment Anything Model (PA-SAM), aiming to enhance the segmentation mask quality of the original SAM. By exclusively training the prompt adapter, PA-SAM extracts detailed information from images and optimizes the mask decoder feature at both sparse and dense prompt levels, improving the segmentation performance of SAM to produce high-quality masks. Experimental results demonstrate that our PA-SAM outperforms other SAM-based methods in high-quality, zero-shot, and open-set segmentation. We’re making the source code and models available at https://github.com/xzz2/pa-sam.", "authors": ["Zhaozhi Xie", "Bochen Guan", "Weihao Jiang", "Muyang Yi", "Yue Ding", "Hongtao Lu", "Lei Zhang"], "year": 2024, "venue": "", "cited_by_count": 15, "type": "article", "concepts": ["Adapter (computing)", "Computer science", "Artificial intelligence", "Computer vision", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation"}
{"openalex_id": "https://openalex.org/W4382462760", "doi": "https://doi.org/10.1609/aaai.v37i2.25353", "title": "Exploring CLIP for Assessing the Look and Feel of Images", "abstract": "Measuring the perception of visual content is a long-standing problem in computer vision. Many mathematical models have been developed to evaluate the look or quality of an image. Despite the effectiveness of such tools in quantifying degradations such as noise and blurriness levels, such quantification is loosely coupled with human language. When it comes to more abstract perception about the feel of visual content, existing methods can only rely on supervised models that are explicitly trained with labeled data collected via laborious user study. In this paper, we go beyond the conventional paradigms by exploring the rich visual language prior encapsulated in Contrastive Language-Image Pre-training (CLIP) models for assessing both the quality perception (look) and abstract perception (feel) of images without explicit task-specific training. In particular, we discuss effective prompt designs and show an effective prompt pairing strategy to harness the prior. We also provide extensive experiments on controlled datasets and Image Quality Assessment (IQA) benchmarks. Our results show that CLIP captures meaningful priors that generalize well to different perceptual assessments.", "authors": ["Jianyi Wang", "Kelvin C. K. Chan", "Chen Change Loy"], "year": 2023, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 461, "type": "article", "concepts": ["Computer science", "Perception", "Task (project management)", "Quality (philosophy)", "Prior probability"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2067404301", "doi": "https://doi.org/10.1111/j.1365-2648.2007.04569.x", "title": "The qualitative content analysis process", "abstract": "Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon or when it is fragmented. A deductive approach is useful if the general aim was to test a previous theory in a different situation or to compare categories at different time periods.", "authors": ["Satu Elo", "Helvi Kyngäs"], "year": 2008, "venue": "Journal of Advanced Nursing", "cited_by_count": 21175, "type": "article", "concepts": ["Operationalization", "Content analysis", "Phenomenon", "Computer science", "Content (measure theory)"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4402704606", "doi": "https://doi.org/10.1109/cvpr52733.2024.02408", "title": "Q-Instruct: Improving Low-Level Visual Abilities for Multi-Modality Foundation Models", "abstract": "Multi-modality large language models (MLLMs), as represented by GPT-4V, have introduced a paradigm shift for visual perception and understanding tasks, that a variety of abilities can be achieved within one foundation model. While current MLLMs demonstrate primary low-level visual abilities from the identification of low-level visual attributes (e.g., clarity, brightness) to the evaluation on image quality, there's still an imperative to further improve the accuracy of MLLMs to substantially alleviate human burdens. To address this, we collect the first dataset consisting of human natural language feedback on low-level vision. Each feedback offers a comprehensive description of an image's low-level visual attributes, culminating in an overall quality assessment. The constructed Q-Pathway dataset includes 58K detailed human feedbacks on 18,973 multi-sourced images with diverse low-level appearance. To ensure MLLMs can adeptly handle diverse queries, we further propose a GPT-participated transformation to convert these feedbacks into a rich set of 200K instruction-response pairs, termed Q-Instruct. Experimental results indicate that the Q-Instruct consistently elevates various low-level visual capabilities across multiple base models. We anticipate that our datasets can pave the way for a future that foundation models can assist humans on low-level visual tasks.", "authors": ["Haoning Wu", "Zicheng Zhang", "Erli Zhang", "Chaofeng Chen", "Liang Liao", "Annan Wang", "Kaixin Xu", "Chunyi Li", "Jingwen Hou", "Guangtao Zhai", "Geng Xue", "Wenxiu Sun", "Qiong Yan", "Weisi Lin"], "year": 2024, "venue": "", "cited_by_count": 62, "type": "article", "concepts": ["Modality (human–computer interaction)", "Foundation (evidence)", "Computer science", "Artificial intelligence", "Human–computer interaction"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2137295153", "doi": "https://doi.org/10.1137/1114019", "title": "Non-Parametric Estimation of a Multivariate Probability Density", "abstract": "Previous article Next article Non-Parametric Estimation of a Multivariate Probability DensityV. A. EpanechnikovV. A. Epanechnikovhttps://doi.org/10.1137/1114019PDFBibTexSections ToolsAdd to favoritesExport CitationTrack CitationsEmail SectionsAbout[1] Emanuel Parzen, On estimation of a probability density function and mode, Ann. Math. Statist., 33 (1962), 1065–1076 MR0143282 0116.11302 CrossrefGoogle Scholar[2] Murray Rosenblatt, Remarks on some nonparametric estimates of a density function, Ann. Math. Statist., 27 (1956), 832–837 MR0079873 0073.14602 CrossrefGoogle Scholar[3] G. M. Manija, Remarks on non-parametric estimates of a two-dimensional density function, Soobšč. Akad. Nauk Gruzin. SSR, 27 (1961), 385–390 MR0143303 Google Scholar[4] E. A. Nadaraya, Estimation of a bivariate probability density, Soobshch. Akad. Nauk Gruz. SSR, 36 (1964), 267–268 Google Scholar[5] R. E. Bellman, , I. Glicksberg and , O. A. Gross, Some aspects of the mathematical theory of control processes, Rand Corporation, Santa Monica, Calif., Rep. No. R-313, 1958rm xix+244 MR0094281 0086.11703 Google Scholar Previous article Next article FiguresRelatedReferencesCited byDetails Kernel-based learning of birth process from evolving spatiotemporal RFS data stream in SMC CPHD filter for multi-target trackingSignal Processing, Vol. 203 Cross Ref Assessing spatial connectivity effects on daily streamflow forecasting using Bayesian-based graph neural networkScience of The Total Environment, Vol. 855 Cross Ref Joint Source-Channel Decoding of Polar Codes for HEVC-Based Video StreamingACM Transactions on Multimedia Computing, Communications, and Applications, Vol. 18, No. 4 Cross Ref A novel structure adaptive new information priority discrete grey prediction model and its application in renewable energy generation forecastingApplied Energy, Vol. 325 Cross Ref A novel structure adaptive fractional discrete grey forecasting model and its application in China’s crude oil production predictionExpert Systems with Applications, Vol. 207 Cross Ref Age-varying effects of repeated emergency department presentations for children in Canada6 May 2022 | Journal of Health Services Research & Policy, Vol. 27, No. 4 Cross Ref Probabilistic adaptive power pinch analysis for islanded hybrid energy storage systemsJournal of Energy Storage, Vol. 54 Cross Ref Should I stay or should I fly? Migration phenology, individual-based migration decision and seasonal changes in foraging behaviour of Common Woodpigeons17 August 2022 | The Science of Nature, Vol. 109, No. 5 Cross Ref Machine learning and optimization based decision-support tool for seed variety selection24 September 2022 | Annals of Operations Research, Vol. 65 Cross Ref Estimating regional income indicators under transformations and access to limited population auxiliary information16 September 2022 | Journal of the Royal Statistical Society: Series A (Statistics in Society), Vol. 37 Cross Ref Automated calibration of model-driven reconstructions in atom probe tomography1 July 2022 | Journal of Physics D: Applied Physics, Vol. 55, No. 37 Cross Ref Point and interval forecasting of ultra-short-term wind power based on a data-driven method and hybrid deep learning modelEnergy, Vol. 254 Cross Ref Deep attention ConvLSTM-based adaptive fusion of clear-sky physical prior knowledge and multivariable historical information for probabilistic prediction of photovoltaic powerExpert Systems with Applications, Vol. 202 Cross Ref The Taxonomy of Mineral Occurrence Rarity and Endemicity21 October 2022 | The Canadian Mineralogist, Vol. 60, No. 5 Cross Ref Estimation of wind speed distribution with time window and new kernel functionJournal of Renewable and Sustainable Energy, Vol. 14, No. 5 Cross Ref Future crop risk estimation due to drought, extreme temperature, hail, lightning, and tornado at the census tract level in louisiana23 August 2022 | Frontiers in Environmental Science, Vol. 10 Cross Ref Translocation detection from Hi‐C data via scan statistics10 August 2022 | Biometrics, Vol. 8 Cross Ref Does restricting therapeutic antibiotics use influence efficiency of pig farms? Evidence from Denmark’s Yellow Card Initiative18 May 2022 | European Review of Agricultural Economics, Vol. 49, No. 4 Cross Ref Computational approach to modeling microbiome landscapes associated with chronic human disease progression4 August 2022 | PLOS Computational Biology, Vol. 18, No. 8 Cross Ref Spillovers between exchange rate pressure and CDS bid-ask spreads, reserve assets and oil prices using the quantile ARDL modelInternational Economics, Vol. 170 Cross Ref Liability Structure and Risk Taking: Evidence from the Money Market Fund Industry18 June 2021 | Journal of Financial and Quantitative Analysis, Vol. 57, No. 5 Cross Ref Security risk assessment of wind integrated power system using Parzen window density estimation6 January 2022 | Electrical Engineering, Vol. 104, No. 4 Cross Ref Predator or prey? Effects of farm growth on neighbouring farms25 July 2022 | Journal of Agricultural Economics, Vol. 4 Cross Ref Multimodel Errors and Emergence Times in Climate Attribution StudiesJournal of Climate, Vol. 35, No. 14 Cross Ref The hierarchical structure of galactic haloes: generalized N -dimensional clustering with C lu STAR-ND20 June 2022 | Monthly Notices of the Royal Astronomical Society, Vol. 514, No. 4 Cross Ref Effective End-to-End Learning Framework for Economic DispatchIEEE Transactions on Network Science and Engineering, Vol. 9, No. 4 Cross Ref 4-D Gesture Sensing Using Reconfigurable Virtual Array Based on a 60-GHz FMCW MIMO Radar SensorIEEE Transactions on Microwave Theory and Techniques, Vol. 70, No. 7 Cross Ref Estimation of drift and diffusion functions from unevenly sampled time-series data27 July 2022 | Physical Review E, Vol. 106, No. 1 Cross Ref Detecting space–time patterns of disease risk under dynamic background population20 April 2022 | Journal of Geographical Systems, Vol. 24, No. 3 Cross Ref Wind power prediction based on PSO-KalmanEnergy Reports, Vol. 8 Cross Ref Visual cluster separation using high-dimensional sharpened dimensionality reduction21 April 2022 | Information Visualization, Vol. 21, No. 3 Cross Ref Interval Wind-Speed Forecasting Model Based on Quantile Regression Bidirectional Minimal Gated Memory Network and Kernel Density Estimation17 June 2022 | Arabian Journal for Science and Engineering, Vol. 4 Cross Ref Spatio-temporal process monitoring using exponentially weighted spatial LASSO2 June 2022 | Journal of Quality Technology, Vol. 58 Cross Ref Bridge deformation prediction based on SHM data using improved VMD and conditional KDEEngineering Structures, Vol. 261 Cross Ref Nonparametric extrapolation of extreme quantiles: a comparison study7 October 2021 | Stochastic Environmental Research and Risk Assessment, Vol. 36, No. 6 Cross Ref Schedule Performance as a Baseline for the Experimental Analysis of Coordinated Behavior: Same or Different Units of Analysis?24 February 2022 | The Psychological Record, Vol. 72, No. 2 Cross Ref Rainfall intensity and catchment size control storm runoff in a gullied blanket peatlandJournal of Hydrology, Vol. 609 Cross Ref Creating a Healthy Environment for Children: GIS Tools for Improving the Quality of the Social Welfare Management System10 June 2022 | International Journal of Environmental Research and Public Health, Vol. 19, No. 12 Cross Ref Conditional catheter‐related thrombosis free probability and risk‐adapted choices of catheter for lung cancer13 May 2022 | Thoracic Cancer, Vol. 13, No. 12 Cross Ref Search for an anomalous excess of charged-current quasielastic νe interactions with the MicroBooNE experiment using Deep-Learning-based reconstruction13 June 2022 | Physical Review D, Vol. 105, No. 11 Cross Ref Spatio-temporal wind speed prediction based on Clayton Copula function with deep learning fusionRenewable Energy, Vol. 192 Cross Ref Dynamic disease screening by joint modelling of survival and longitudinal data27 May 2022 | Journal of the Royal Statistical Society: Series C (Applied Statistics), Vol. 23 Cross Ref Uncertainties in the Assessment of COVID-19 Risk: A Study of People’s Exposure to High-Risk Environments Using Individual-Level Activity Data20 September 2021 | Annals of the American Association of Geographers, Vol. 112, No. 4 Cross Ref Incremental software product line verification - A performance analysis with dead variable code17 March 2022 | Empirical Software Engineering, Vol. 27, No. 3 Cross Ref Theory of evolutionary spectra for heteroskedasticity and autocorrelation robust inference in possibly misspecified and nonstationary modelsJournal of Econometrics, Vol. 117 Cross Ref An Unconventional Technique for Choosing the Kernel Function Blur Coefficients in Nonparametric Regression18 August 2022 | Measurement Techniques, Vol. 65, No. 2 Cross Ref Specificities of ERD lateralization during motion execution Cross Ref Kernel density estimation for circular data: a Fourier series-based plug-in approach for bandwidth selection21 April 2022 | Journal of Nonparametric Statistics, Vol. 34, No. 2 Cross Ref Concurrent Effects between Geomagnetic Storms and Magnetospheric Substorms6 April 2022 | Universe, Vol. 8, No. 4 Cross Ref Deep non-crossing probabilistic wind speed forecasting with multi-scale featuresEnergy Conversion and Management, Vol. 257 Cross Ref Efficient and robust propensity‐score‐based methods for population inference using epidemiologic cohorts6 September 2021 | International Statistical Review, Vol. 90, No. 1 Cross Ref Estimation of a Nonlinear Functional of the Probability Density of a Three-Dimensional Random Variable to Improve the Computational Efficiency of Nonparametric Decision Rules28 August 2022 | Optoelectronics, Instrumentation and Data Processing, Vol. 58, No. 2 Cross Ref The relation between belief in a just world and early processing of deserved and undeserved outcomes: An ERP study13 February 2022 | Social Neuroscience, Vol. 17, No. 2 Cross Ref Mutual information scaling for tensor network machine learning20 January 2022 | Machine Learning: Science and Technology, Vol. 3, No. 1 Cross Ref Automatically extracting surfaces of reinforced concrete bridges from terrestrial laser scanning point cloudsAutomation in Construction, Vol. 135 Cross Ref OnlineSTLProceedings of the VLDB Endowment, Vol. 15, No. 7 Cross Ref On the application of generative adversarial networks for nonlinear modal analysisMechanical Systems and Signal Processing, Vol. 166 Cross Ref Interval Prediction Method for Solar Radiation Based on Kernel Density Estimation and Machine LearningComplexity, Vol. 2022 Cross Ref A three-step local smoothing approach for estimating the mean and covariance functions of spatio-temporal Data20 March 2021 | Annals of the Institute of Statistical Mathematics, Vol. 74, No. 1 Cross Ref Phase I monitoring of serially correlated nonparametric profiles by mixed‐effects modeling28 July 2021 | Quality and Reliability Engineering International, Vol. 38, No. 1 Cross Ref Data-driven prosumer-centric energy scheduling using convolutional neural networksApplied Energy, Vol. 308 Cross Ref The (un)predictable magnetosphere: the role of the internal dynamics3 March 2022 | Journal of Plasma Physics, Vol. 88, No. 1 Cross Ref Quick Selecting Kernel Blur Coefficients to Estimate Probability Density for Independent Random Variables8 July 2022 | Optoelectronics, Instrumentation and Data Processing, Vol. 58, No. 1 Cross Ref Robust analogs to the coefficient of variation20 August 2020 | Journal of Applied Statistics, Vol. 49, No. 2 Cross Ref Nonparametric Mass Imputation for Data Integration17 November 2020 | Journal of Survey Statistics and Methodology, Vol. 10, No. 1 Cross Ref Regional wind power probabilistic forecasting based on an improved kernel density estimation, regular vine copulas, and ensemble learningEnergy, Vol. 238 Cross Ref Probabilistic Revenue Analysis of Microgrid Considering Source-Load and Forecast UncertaintiesIEEE Access, Vol. 10 Cross Ref Data-Enhancement Strategies in Weather-Related Health Studies14 January 2022 | International Journal of Environmental Research and Public Health, Vol. 19, No. 2 Cross Ref Model-based techniques for traffic congestion detection Cross Ref Object-based cluster validation with densitiesPattern Recognition, Vol. 121 Cross Ref Towards Robust Waveform-Based Acoustic ModelsIEEE/ACM Transactions on Audio, Speech, and Language Processing, Vol. 30 Cross Ref Nonparametric Survival Analysis20 July 2022 Cross Ref A Combined Approach for Monitoring Monthly Surface Water/Ice Dynamics of Lesser Slave Lake Via Earth Observation DataIEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, Vol. 15 Cross Ref Structural characterisation of nanoalloys for (photo)catalytic applications with the Sapphire library1 January 2022 | Faraday Discussions, Vol. 8 Cross Ref Joint modeling of multivariate nonparametric longitudinal data and survival data: A local smoothing approach25 September 2021 | Statistics in Medicine, Vol. 40, No. 29 Cross Ref Shock Reduction Technique on Thin Plate Structure by Wave Refraction Using an Elastic PatchShock and Vibration, Vol. 2021 Cross Ref Persistent meanders and eddies lead to quasi-steady Lagrangian transport patterns in a weak western boundary current12 January 2021 | Scientific Reports, Vol. 11, No. 1 Cross Ref Caenorhabditis elegans exhibits positive gravitaxis14 September 2021 | BMC Biology, Vol. 19, No. 1 Cross Ref Niche partitioning among social clusters of a resident estuarine apex predator15 November 2021 | Behavioral Ecology and Sociobiology, Vol. 75, No. 12 Cross Ref Study of the Method for Verification of the Hypothesis on Independence of Two-Dimensional Random Quantities Using a Nonparametric Classifier13 May 2022 | Optoelectronics, Instrumentation and Data Processing, Vol. 57, No. 6 Cross Ref Epanechnikov kernel for PDF estimation applied to equalization and blind source separationSignal Processing, Vol. 189 Cross Ref Age-coherent extensions of the Lee–Carter model29 April 2021 | Scandinavian Actuarial Journal, Vol. 2021, No. 10 Cross Ref compaso : A new halo finder for competitive assignment to spherical overdensities19 October 2021 | Monthly Notices of the Royal Astronomical Society, Vol. 509, No. 1 Cross Ref Nonparametric Multivariate Density Estimation: Case Study of Cauchy Mixture Model26 October 2021 | Mathematics, Vol. 9, No. 21 Cross Ref A method of sequentially generating a set of components of a multidimensional random variable using a nonparametric pattern recognition algorithm1 November 2021 | Computer Optics, Vol. 45, No. 6 Cross Ref Year-round spatial distribution and migration phenology of a rapidly declining trans-Saharan migrant—evidence of winter movements and breeding site fidelity in European turtle doves13 October 2021 | Behavioral Ecology and Sociobiology, Vol. 75, No. 11 Cross Ref Efficiency of European universities: A comparison of peersResearch Policy, Vol. 50, No. 9 Cross Ref Heads Or Tails: A Framework To Model Supply Chain Heterogeneous Messages Cross Ref Research of Wind Power Generation Characteristics in Southern China Based on Improved Non-Parametric Kernel Density Estimation Cross Ref Fast multivariate empirical cumulative distribution function with connection to kernel density estimationComputational Statistics & Data Analysis, Vol. 162 Cross Ref Some confidence intervals and insights for the proportion below the relative poverty line13 October 2021 | SN Business & Economics, Vol. 1, No. 10 Cross Ref The HARPS search for southern extra-solar planets18 October 2021 | Astronomy & Astrophysics, Vol. 654 Cross Ref The sectorally heterogeneous and time-varying price elasticities of energy demand in ChinaEnergy Economics, Vol. 102 Cross Ref Outlier accommodation with semiparametric density processes: A study of Antarctic snow density modelling29 September 2021 | Statistical Modelling, Vol. 124 Cross Ref SAFE-STOP System: Tactical Intention Awareness Based Emergency Collision Avoidance for Malicious Cut-in of Surrounding Vehicle Cross Ref Violin graphs to supervise the energy performance of PV arrays Cross Ref Application of a novel structure-adaptative grey model with adjustable time power item for nuclear energy consumption forecastingApplied Energy, Vol. 298 Cross Ref The continuous wavelet derived by smoothing function and its application in cosmology5 August 2021 | Communications in Theoretical Physics, Vol. 73, No. 9 Cross Ref Inertial Sensor Algorithms to Characterize Turning in Neurological Patients With Turn HesitationsIEEE Transactions on Biomedical Engineering, Vol. 68, No. 9 Cross Ref Consistent inference for predictive regressions in persistent economic systemsJournal of Econometrics, Vol. 224, No. 1 Cross Ref Identifying convergence in nitrogen oxides emissions from motor vehicles in China: A spatial panel data approachJournal of Cleaner Production, Vol. 316 Cross Ref Estimating parameters of a stochastic cell invasion model with fluorescent cell cycle labelling using approximate Bayesian computation22 September 2021 | Journal of The Royal Society Interface, Vol. 18, No. 182 Cross Ref Nonparametric pattern recognition algorithm for testing a hypothesis of the independence of random variables1 September 2021 | Computer Optics, Vol. 5, No. 45 Cross Ref Noise and error analysis and optimization in particle-based kinetic plasma simulationsJournal of Computational Physics, Vol. 440 Cross Ref Unsupervised Learning Methods for Molecular Simulation Data4 May 2021 | Chemical Reviews, Vol. 121, No. 16 Cross Ref A robust dynamic screening system by estimation of the longitudinal data distribution26 May 2020 | Journal of Quality Technology, Vol. 53, No. 4 Cross Ref Ellipsoidal one-class constraint acquisition for quadratically constrained programmingEuropean Journal of Operational Research, Vol. 293, No. 1 Cross Ref Uncertainty quantification for Multiphase-CFD simulations of bubbly flows: a machine learning-based Bayesian approach supported by high-resolution experimentsReliability Engineering & System Safety, Vol. 212 Cross Ref Effective disease surveillance by using covariate information30 July 2021 | Statistics in Medicine, Vol. 59 Cross Ref Quasi‐maximum likelihood and the kernel block bootstrap for nonlinear dynamic models6 January 2021 | Journal of Time Series Analysis, Vol. 42, No. 4 Cross Ref between and to the of level and in the of in Research, Vol. 68, No. 2 Cross Ref energy demand spatio-temporal data Vol. Cross Ref Learning for Statistical of June 2021 | Vol. 29 Cross Ref joint distribution analysis of the under semiparametric distribution for the in of Engineering and Science, Vol. No. 2 Cross Ref model of Econometrics, Vol. No. 2 Cross Ref of Based on and Network with the Quantile May 2021 | Applied Vol. 11, No. 11 Cross Ref An to multivariate probabilistic and Vol. 4 Cross Ref based on deep learning model with attention for hybrid system under Energy, Vol. 170 Cross Ref and March 2022 | Mathematics, Vol. No. 1 Cross Ref Uncertainty Analysis of Wind Power Based on Data Cross Ref kernel density estimation Systems with Applications, Vol. Cross Ref network modelling of the of a with the Physics Vol. Cross Ref March 2021 | Journal of Computational and Vol. No. 2 Cross Ref modeling of for July 2020 | Reviews, Vol. 40, No. 3 Cross Ref for Cross Ref on the size of February 2021 | of the of Vol. No. 9 Cross Ref Uncertainty analysis of wind power probability density forecasting based on and quantile Vol. Cross Ref of Methods in Data of March 2021 | International Journal of Vol. 10, No. 3 Cross Ref Dynamic spatial analysis of China: and spatial convergence Research, Vol. No. 3 Cross Ref the Hypothesis of the Independence of Two-Dimensional Random Using a Nonparametric for August 2021 | Optoelectronics, Instrumentation and Data Processing, Vol. 57, No. 2 Cross Ref A Study of Nonparametric Kernel with of Vol. No. 1 Cross Ref Fast Modelling, Vol. Cross Ref for of Coefficients for Kernel of Probability March 2021 | Measurement Techniques, Vol. No. 11 Cross Ref of laser fusion Vol. Cross Ref A of density based clustering September 2020 | Frontiers of Computer Science, Vol. 15, No. 1 Cross Ref of Information and Regression for of Acoustic Data during on Structural and Construction, Vol. No. 1 Cross Ref of Heterogeneous in January 2021 | Research Vol. No. 2 Cross Ref for Time Series of Cross Ref Data-driven Kernel-based Probabilistic for Time Series Reduction Cross Ref The for Robust Energy Estimation Cross Ref from August 2020 Cross Ref during Chain for Detecting Using from 2020 | Vol. No. 1 Cross Ref Method for of in Using and 2020 | Remote Sensing, Vol. 13, No. 1 Cross Ref of a Framework for Environmental of 2020 | Journal of Science and Engineering, Vol. 9, No. 1 Cross Ref a for kernel density estimation, and of Vol. No. Cross Ref Analysis of the of the mean of the kernel probability density estimation in the of and random variables1 January 2021 | No. 3 Cross Ref Energy Management of April 2021 Cross Ref for Detecting of July 2021 Cross Ref of a Analysis Method to the of COVID-19 Kernel Density Estimation Using July 2021 Cross Ref On generative as the for August 2021 | Engineering, Vol. 2 Cross Ref and in the January 2021 | Journal of Vol. 27, No. 1 Cross Ref The in January 2021 | Vol. No. 5 Cross Ref Kernel Based for MIMO Radar in Access, Vol. 9 Cross Ref The diffusion of diffusion and Computational Analysis, Vol. Cross Ref of of components of a multidimensional random variable based on a nonparametric pattern recognition algorithm1 January 2021 | No. 9 Cross Ref in energy efficiency of and its for performance Journal of and Engineering, Vol. Cross Ref of Nonlinear Systems with Cross Ref Probability density forecasting of wind power based on quantile neural Systems, Vol. Cross Ref Hypothesis testing based on a of of Econometrics, Vol. No. 2 Cross Ref Analysis of distribution human in the of Lake in Vol. Cross Ref in and May 2020 | Scientific Reports, Vol. 10, No. 1 Cross Ref Assessment of regressions for in the insights from and historical June 2020 | Vol. 17, No. 12 Cross Ref hybrid and for September 2020 | Journal on Communications and Vol. No. 1 Cross Ref of March 2021 | Physics of Vol. No. 12 Cross Ref price and July 2020 | European Review of Agricultural Economics, Vol. No. 5 Cross Ref A of | Applied Vol. 27, No. Cross Ref Risk Estimation to and in November 2020 | Frontiers in Earth Science, Vol. 8 Cross Ref Learning to a A Transactions on Systems Technology, Vol. No. 6 Cross Ref for cell lung Analysis based on and Radiation Vol. Cross Ref Fast for the of the Kernel Density April 2021 | Optoelectronics, Instrumentation and Data Processing, Vol. No. 6 Cross Ref Using Deep Learning: With Systems and November 2020 | Journal of in Earth Systems, Vol. No. 11 Cross Ref search in the A Research Vol. Cross Ref A new algorithm based on and algorithm to the optimization Computing, Vol. Cross Ref of data methods and clustering model in the of of of Vol. No. 3 Cross Ref Energy Efficient in of Cross Ref Statistical of and for July 2020 | Journal International, Vol. No. 1 Cross Ref Unsupervised of Deep Bayesian Cross Ref for Visual of Data Cross Ref nonlinear of covariance Annals of Statistics, Vol. No. 5 Cross Ref modeling and prediction approach for using deep Journal of and Mass Vol. Cross Ref in model for May 2020 | Structural and Vol. No. 4 Cross Ref A Kernel Outlier August | Review, Vol. No. 5 Cross Ref emissions in China: spatial patterns and Research, Vol. 11, No. 9 Cross Ref A Analysis of the Effects of on the Performance of Transactions on Applications, Vol. No. 5 Cross Ref during A for the of based on September 2020 | Journal of and Management, Vol. No. 3 Cross Ref Dynamic risk assessment with network and clustering Engineering & System Safety, Vol. Cross Ref with exchange and Some from Modelling, Vol. Cross Ref A probabilistic verification application of random", "authors": ["V. A. Epanechnikov"], "year": 1969, "venue": "Theory of Probability and Its Applications", "cited_by_count": 1799, "type": "article", "concepts": ["Multivariate statistics", "Mathematics", "Multivariate kernel density estimation", "Estimation", "Density estimation"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4409383105", "doi": "https://doi.org/10.1016/j.isprsjprs.2025.03.028", "title": "RSGPT: A remote sensing vision language model and benchmark", "abstract": "", "authors": ["Yuan Hu", "Jianlong Yuan", "Congcong Wen", "Xiao‐Nan Lu", "Yu Liu", "Li Xiang"], "year": 2025, "venue": "ISPRS Journal of Photogrammetry and Remote Sensing", "cited_by_count": 64, "type": "article", "concepts": ["Benchmark (surveying)", "Computer science", "Remote sensing", "Artificial intelligence", "Computer vision"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2952481429", "doi": "https://doi.org/10.1038/s41598-017-17204-5", "title": "QuPath: Open source software for digital pathology image analysis", "abstract": "", "authors": ["Peter Bankhead", "Maurice B. Loughrey", "José A. Fernández", "Yvonne Dombrowski", "Darragh G. McArt", "Philip D. Dunne", "Stephen McQuaid", "Ronan T. Gray", "Liam Murray", "Helen G. Coleman", "Jacqueline A. James", "Manuel Salto‐Tellez", "Peter W. Hamilton"], "year": 2017, "venue": "Scientific Reports", "cited_by_count": 7975, "type": "article", "concepts": ["Computer science", "Scripting language", "Software", "Digital pathology", "Extensibility"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W1480729244", "doi": "https://doi.org/10.1159/000369778", "title": "Aspirin plus Clopidogrel as Secondary Prevention after Stroke or Transient Ischemic Attack: A Systematic Review and Meta-Analysis", "abstract": "Compared with monotherapy, short-term aspirin in combination with clopidogrel is more effective as secondary prevention of stroke or TIA without increasing the risk of hemorrhagic stroke and major bleeding events. Long-term combination therapy does not reduce the risk of stroke recurrence, and is associated with increased major bleeding events. The clinical applicability of the findings of this systematic review, however, needs to be confirmed in future clinical trials.", "authors": ["Qinghua Zhang", "Chao Wang", "Maoyong Zheng", "Yanxia Li", "Jincun Li", "Liping Zhang", "Xiao Shang", "Chuanzhu Yan"], "year": 2014, "venue": "Cerebrovascular Diseases", "cited_by_count": 11545, "type": "review", "concepts": ["Medicine", "Clopidogrel", "Aspirin", "Internal medicine", "Stroke (engine)"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W3107527779", "doi": "https://doi.org/10.1093/nar/gkaa1074", "title": "The STRING database in 2021: customizable protein–protein networks, and functional characterization of user-uploaded gene/measurement sets", "abstract": "Cellular life depends on a complex web of functional associations between biomolecules. Among these associations, protein-protein interactions are particularly important due to their versatility, specificity and adaptability. The STRING database aims to integrate all known and predicted associations between proteins, including both physical interactions as well as functional associations. To achieve this, STRING collects and scores evidence from a number of sources: (i) automated text mining of the scientific literature, (ii) databases of interaction experiments and annotated complexes/pathways, (iii) computational interaction predictions from co-expression and from conserved genomic context and (iv) systematic transfers of interaction evidence from one organism to another. STRING aims for wide coverage; the upcoming version 11.5 of the resource will contain more than 14 000 organisms. In this update paper, we describe changes to the text-mining system, a new scoring-mode for physical interactions, as well as extensive user interface features for customizing, extending and sharing protein networks. In addition, we describe how to query STRING with genome-wide, experimental data, including the automated detection of enriched functionalities and potential biases in the user's query data. The STRING resource is available online, at https://string-db.org/.", "authors": ["Damian Szklarczyk", "Annika L. Gable", "Katerina Nastou", "David Lyon", "Rebecca Kirsch", "Sampo Pyysalo", "Nadezhda T. Doncheva", "Marc Legeay", "Tao Fang", "Peer Bork", "Lars Juhl Jensen", "Christian von Mering"], "year": 2020, "venue": "Nucleic Acids Research", "cited_by_count": 8221, "type": "article", "concepts": ["Biology", "Upload", "Gene", "String (physics)", "Computational biology"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4400070365", "doi": "https://doi.org/10.1109/lsp.2024.3420083", "title": "Vision-Language Consistency Guided Multi-Modal Prompt Learning for Blind AI Generated Image Quality Assessment", "abstract": "Recently, textual prompt tuning has shown inspirational performance in adapting Contrastive Language-Image Pre-training (CLIP) models to natural image quality assessment. However, such uni-modal prompt learning method only tunes the language branch of CLIP models. This is not enough for adapting CLIP models to AI generated image quality assessment (AGIQA) since AGIs visually differ from natural images. In addition, the consistency between AGIs and user input text prompts, which correlates with the perceptual quality of AGIs, is not investigated to guide AGIQA. In this letter, we propose vision-language consistency guided multi-modal prompt learning for blind AGIQA, dubbed CLIP-AGIQA. Specifically, we introduce learnable textual and visual prompts in language and vision branches of CLIP models, respectively. Moreover, we design a text-to-image alignment quality prediction task, whose learned vision-language consistency knowledge is used to guide the optimization of the above multi-modal prompts. Experimental results on two public AGIQA datasets demonstrate that the proposed method outperforms state-of-the-art quality assessment models.", "authors": ["Jun Fu", "Wei Zhou", "Qiuping Jiang", "Hantao Liu", "Guangtao Zhai"], "year": 2024, "venue": "IEEE Signal Processing Letters", "cited_by_count": 24, "type": "article", "concepts": ["Computer science", "Consistency (knowledge bases)", "Artificial intelligence", "Image quality", "Quality (philosophy)"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2089739736", "doi": "https://doi.org/10.1097/00006324-200111000-00006", "title": "Customized Corneal Ablation: the Quest for Supervision", "abstract": "Customized Corneal Ablation: the Quest for Supervision. Scott M. MacRae, Ronald R. Krueger, Raymond A. Applegate. Thorofare, NJ: Slack Inc, 2001. Pages: 416. Price: $205.00. ISBN 1-55642-488-4. Mohan Merchea , College of Optometry , The Ohio State University , Columbus, Ohio Occasionally clinicians and scientists are fortunate enough to experience the evolution of innovative concepts in vision science. The introduction of wavefront aberration measurement in the human visual system was such an event. It was not a novel concept when Liang and colleagues designed a rapid and repeatable method of measuring higher order aberrations in the human eye; rather it was a concept that evolved in conjunction with technological advances in other fields, including adaptive optics, refractive surgery, and contact lens manufacturing. The excitement generated by this developing topic was apparent at the 2000 Academy Research Symposium and by the numerous abstracts and papers presented at the AAO and ARVO annual meetings. This is the first textbook devoted to the emerging science of aberration detection, image quality, and customized refractive therapy. The title of this textbook implies a focus solely on the surgical management of refractive error by corneal photoablation; rather, the contents of this book provide a great breadth of information on ocular image degradation by optical limits such as aberrations and diffraction, neural limits to visual function, and retinal photoreceptor imaging. In chapter 2 of the introductory subsection, the reader is provided with a detailed review of several seminal research papers on the optical and neural limits of human vision and the benefits realized by monochromatic and chromatic aberration correction. Additional factors that affect aberration measurements such as accommodation, decentration, and temporal effects are also addressed here, but the role of tear film stability on wavefront measurement is not mentioned. Chapter 3 presents the reader with a brief historical review of the development of objective and subjective instruments for wavefront detection, including interferometric and the ray tracing methods on which most modern instruments are based. Chapter 4 describes the fundamentals of an adaptive optics ophthalmoscope for photoreceptor imaging. Although the chapter seems unrelated in a text on custom correction of refractive error, the reader is fortunately provided with insight into another application of wavefront sensing in the ophthalmic field. This section concludes with a description of how whole-eye wavefront aberrations or corneal topography aberrations are used to guide corneal ablation and the brief review of the physics of lasers. Section 2, Wavefront Guided Custom Ablation, is divided into basic and clinical science sections. The basic science section primarily contains several chapters that I felt would be more appropriately placed in the introductory section. The chapters covering the assessment of optical quality, visual performance assessment, corneal biomechanics, and technology requirements are relevant to any customized refractive treatment wavefront or topography guided ablation. Chapters 6, 7, and 8 provide the language of traditional methods of optical image quality: PSF, LSF, MTF, PTF, and OTF with which the reader needs to be familiar to interpret wavefront aberration maps in relation to traditional image quality assessments. Zernike polynomial wavefront quantification is also introduced in this section, and the importance of a standardized method of data presentation is highlighted. Chapter 9 provides an extensive review of changes in corneal shape and power that occur with any refractive surgical procedure, ablative or incisional. Roberts and Dupps propose a biomechanical model for changes in the corneal structure in chapter 9. They emphasize that current customized ablation techniques being developed do not address changes in the cornea that occur during surgical procedures. Chapters 10 and 11 cover the technological requirements for custom treatment, including laser attributes, topography and wavefront resolution, and eye tracking. The basic science subsection of part 2 is appropriate reading for anyone interested in whole-eye or corneal aberration changes from refractive surgery. The clinical science subsection is a thorough review of the clinical instruments being developed to measure ocular wavefront aberration. Several techniques, including Hartmann-Shack, Tscherning, Tracey ray tracing, Spatially Resolved Refractometer, and a Scanning Slit Refractometer are described in detail in chapters 12 through 17. Section 3, Corneal Topography Guided Ablations, is similarly divided into basic and clinical subsections. How topography instruments are used to estimate corneal curvature and height is reviewed, and how this data is used to estimate the wavefront error of the cornea is presented. Also, the advantages over wavefront-guided procedures are provided. Chapter 20 describes the limitations of corneal wavefront error for custom ablation based on factors, including arbitrary reference surface calculation, a lack of biomechanical modeling, and ignoring aberrations induced from other ocular components. The clinical science subsection provides a summary of the current instruments available using software for topography-guided custom ablation, including Topolink, Corneal Interactive Programmed Topographic Ablation (CIPTA), Topographic Simulated Customized Ablation (TOSCA), and Contoured Ablation Patterns (CAP). Section 4, Surgeon Guided Customized Ablation, presents management strategies for decentered ablations, including masking techniques and eccentric ablations and for steep central islands. Chapter 27 describes how ablation zone diameter can influence symptoms such as glare. This section concludes with a description of cross-cylinder and bitoric ablation profiles. Section 5 addresses the future of customization. The final section in this insightful text provides a positive outlook for the development of alternative techniques for custom refractive correction, including contact lenses and intraocular lenses. The authors were thoughtful enough to include the Standards for Reporting the Optical Aberrations of Eyes from the Optical Society of America, which includes recommendations for reference axis selection, Zernike polynomial indexing standards, and a description of a standard aberrator for calibration of wavefront-sensing instruments. Also included in the appendices are the American National Standards Institute (ANSI) Standards in Corneal Topography. The index covers most topics and will allow readers to easily locate the desired information. Labeling errors of some figures through the text are a very minor complaint. Overall, the figures and tables were of high quality and easily understood. In summary, this textbook will be a valuable reference to clinicians and vision scientists who are interested in familiarizing themselves with optical image quality measurement techniques and the current instruments available for customized refractive surgery. FIGUREFigure", "authors": ["Mohan Merchea"], "year": 2001, "venue": "Optometry and Vision Science", "cited_by_count": 87, "type": "article", "concepts": ["Ablation", "Optometry", "Ophthalmology", "Computer science", "Medicine"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4404536559", "doi": "https://doi.org/10.1007/978-3-031-72904-1_9", "title": "A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment", "abstract": "", "authors": ["Tianhe Wu", "Kede Ma", "Jie Liang", "Yujiu Yang", "Lei Zhang"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 24, "type": "book-chapter", "concepts": ["Computer science", "Quality (philosophy)", "Natural language processing", "Image quality", "Artificial intelligence"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2116634113", "doi": "https://doi.org/10.1093/bioinformatics/btg405", "title": "affy—analysis of <i>Affymetrix GeneChip</i> data at the probe level", "abstract": "The affy package is an R package of functions and classes for the analysis of oligonucleotide arrays manufactured by Affymetrix. The package is currently in its second release, affy provides the user with extreme flexibility when carrying out an analysis and make it possible to access and manipulate probe intensity data. In this paper, we present the main classes and functions in the package and demonstrate how they can be used to process probe-level data. We also demonstrate the importance of probe-level analysis when using the Affymetrix GeneChip platform.", "authors": ["Laurent Gautier", "Leslie Cope", "Benjamin M. Bolstad", "Rafael A. Irizarry"], "year": 2004, "venue": "Bioinformatics", "cited_by_count": 5349, "type": "article", "concepts": ["Computer science", "Gene chip analysis", "R package", "Flexibility (engineering)", "Data mining"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4402448026", "doi": "https://doi.org/10.3390/hydrology11090148", "title": "The Implementation of Multimodal Large Language Models for Hydrological Applications: A Comparative Study of GPT-4 Vision, Gemini, LLaVa, and Multimodal-GPT", "abstract": "Large Language Models (LLMs) combined with visual foundation models have demonstrated significant advancements, achieving intelligence levels comparable to human capabilities. This study analyzes the latest Multimodal LLMs (MLLMs), including Multimodal-GPT, GPT-4 Vision, Gemini, and LLaVa, with a focus on hydrological applications such as flood management, water level monitoring, agricultural water discharge, and water pollution management. We evaluated these MLLMs on hydrology-specific tasks, testing their response generation and real-time suitability in complex real-world scenarios. Prompts were designed to enhance the models’ visual inference capabilities and contextual comprehension from images. Our findings reveal that GPT-4 Vision demonstrated exceptional proficiency in interpreting visual data, providing accurate assessments of flood severity and water quality. Additionally, MLLMs showed potential in various hydrological applications, including drought prediction, streamflow forecasting, groundwater management, and wetland conservation. These models can optimize water resource management by predicting rainfall, evaporation rates, and soil moisture levels, thereby promoting sustainable agricultural practices. This research provides valuable insights into the potential applications of advanced AI models in addressing complex hydrological challenges and improving real-time decision-making in water resource management", "authors": ["Likith Kadiyala", "Omer Mermer", "R. Dinesh Jackson Samuel", "Yusuf Sermet", "İbrahim Demir"], "year": 2024, "venue": "Hydrology", "cited_by_count": 35, "type": "article", "concepts": ["Computer science", "Multimodal therapy", "Environmental science", "Remote sensing", "Geology"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4413146669", "doi": "https://doi.org/10.1109/cvpr52734.2025.02245", "title": "Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis", "abstract": "In the quest for artificial general intelligence, Multi-modal Large Language Models (MLLMs) have emerged as a focal point in recent advancements. However, the predominant focus remains on developing their capabilities in static image understanding. The potential of MLLMs to process sequential visual data is still insufficiently explored, highlighting the lack of a comprehensive, high-quality assessment of their performance. In this paper, we introduce Video-MME, the first-ever full-spectrum, Multi-Modal Evaluation benchmark of MLLMs in Video analysis. Our work distinguishes from existing benchmarks through four key features: 1) Diversity in video types, spanning 6 primary visual domains with 30 subfields to ensure broad scenario generalizability; 2) Duration in temporal dimension, encompassing both short-, medium-, and long-term videos, ranging from 11 seconds to 1 hour, for robust contextual dynamics; 3) Breadth in data modalities, integrating multi-modal inputs besides video frames, including subtitles and audios, to unveil the all-round capabilities of MLLMs; 4) Quality in annotations, utilizing rigorous manual labeling by expert annotators to facilitate precise and reliable model assessment. With Video-MME, we extensively evaluate various state-of-the-art MLLMs, and reveal that Gemini 1.5 Pro is the best-performing commercial model, significantly outperforming the open-source models with an average accuracy of 75%, compared to 71.9% for GPT-4o. The results also demonstrate that Video-MME is a universal benchmark that applies to both image and video MLLMs. Further analysis indicates that subtitle and audio information could significantly enhance video understanding. Besides, a decline in MLLM performance is observed as video duration increases for all models. Our dataset along with these findings underscores the need for further improvements in handling longer sequences and multi-modal data, shedding light on future MLLM development. Project page: https://video-mme.github.io.", "authors": ["Chaoyou Fu", "Yuhan Dai", "Yongdong Luo", "Lei Li", "Shuhuai Ren", "Renrui Zhang", "Zihan Wang", "Chenyu Zhou", "Yunhang Shen", "Mengdan Zhang", "Peixian Chen", "Yanwei Li", "Shaohui Lin", "Sirui Zhao", "Ke Li", "Tong Xu", "Xiawu Zheng", "Enhong Chen", "Caifeng Shan", "Ran He", "Xing Sun"], "year": 2025, "venue": "", "cited_by_count": 38, "type": "article", "concepts": ["Benchmark (surveying)", "Computer science", "Modal", "Artificial intelligence", "Geography"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2809254203", "doi": "https://doi.org/10.1007/s13244-018-0639-9", "title": "Convolutional neural networks: an overview and application in radiology", "abstract": "", "authors": ["Rikiya Yamashita", "Mizuho Nishio", "Richard Kinh Gian", "Kaori Togashi"], "year": 2018, "venue": "Insights into Imaging", "cited_by_count": 4417, "type": "review", "concepts": ["Convolutional neural network", "Computer science", "Artificial intelligence", "Leverage (statistics)", "Overfitting"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4387076386", "doi": "https://doi.org/10.48550/arxiv.2309.14181", "title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision", "abstract": "The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models. Nevertheless, there is still an inadequacy in assessing the abilities of MLLMs on low-level visual perception and understanding. To address this gap, we present Q-Bench, a holistic benchmark crafted to systematically evaluate potential abilities of MLLMs on three realms: low-level visual perception, low-level visual description, and overall visual quality assessment. a) To evaluate the low-level perception ability, we construct the LLVisionQA dataset, consisting of 2,990 diverse-sourced images, each equipped with a human-asked question focusing on its low-level attributes. We then measure the correctness of MLLMs on answering these questions. b) To examine the description ability of MLLMs on low-level information, we propose the LLDescribe dataset consisting of long expert-labelled golden low-level text descriptions on 499 images, and a GPT-involved comparison pipeline between outputs of MLLMs and the golden descriptions. c) Besides these two tasks, we further measure their visual quality assessment ability to align with human opinion scores. Specifically, we design a softmax-based strategy that enables MLLMs to predict quantifiable quality scores, and evaluate them on various existing image quality assessment (IQA) datasets. Our evaluation across the three abilities confirms that MLLMs possess preliminary low-level visual skills. However, these skills are still unstable and relatively imprecise, indicating the need for specific enhancements on MLLMs towards these abilities. We hope that our benchmark can encourage the research community to delve deeper to discover and enhance these untapped potentials of MLLMs. Project Page: https://q-future.github.io/Q-Bench.", "authors": ["Haoning Wu", "Zicheng Zhang", "Erli Zhang", "Chaofeng Chen", "Liang Liao", "Annan Wang", "Chunyi Li", "Wenxiu Sun", "Qiong Yan", "Guangtao Zhai", "Weisi Lin"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 20, "type": "preprint", "concepts": ["Perception", "Computer science", "Benchmark (surveying)", "Construct (python library)", "Correctness"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2166667242", "doi": "https://doi.org/10.1017/s0140525x01003922", "title": "The magical number 4 in short-term memory: A reconsideration of mental storage capacity", "abstract": "Miller (1956) summarized evidence that people can remember about seven chunks in short-term memory (STM) tasks. However, that number was meant more as a rough estimate and a rhetorical device than as a real capacity limit. Others have since suggested that there is a more precise capacity limit, but that it is only three to five chunks. The present target article brings together a wide variety of data on capacity limits suggesting that the smaller capacity limit is real. Capacity limits will be useful in analyses of information processing only if the boundary conditions for observing them can be carefully described. Four basic conditions in which chunks can be identified and capacity limits can accordingly be observed are: (1) when information overload limits chunks to individual stimulus items, (2) when other steps are taken specifically to block the recording of stimulus items into larger chunks, (3) in performance discontinuities caused by the capacity limit, and (4) in various indirect effects of the capacity limit. Under these conditions, rehearsal and long-term memory cannot be used to combine stimulus items into chunks of an unknown size; nor can storage mechanisms that are not capacity-limited, such as sensory memory, allow the capacity-limited storage mechanism to be refilled during recall. A single, central capacity limit averaging about four chunks is implicated along with other, noncapacity-limited sources. The pure STM capacity limit expressed in chunks is distinguished from compound STM limits obtained when the number of separately held chunks is unclear. Reasons why pure capacity estimates fall within a narrow range are discussed and a capacity limit for the focus of attention is proposed.", "authors": ["Nelson Cowan"], "year": 2001, "venue": "Behavioral and Brain Sciences", "cited_by_count": 6665, "type": "article", "concepts": ["Mental capacity", "Limit (mathematics)", "Stimulus (psychology)", "Computer science", "Short-term memory"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W3120387768", "doi": "https://doi.org/10.1016/s0140-6736(20)32656-8", "title": "RETRACTED: 6-month consequences of COVID-19 in patients discharged from hospital: a cohort study", "abstract": "", "authors": ["Chaolin Huang", "Lixue Huang", "Yeming Wang", "Xia Li", "Lili Ren", "Xiaoying Gu", "Liang Kang", "Li Guo", "Min Liu", "Xing Zhou", "Jianfeng Luo", "Zhenghui Huang", "Shengjin Tu", "Yue Zhao", "Li Chen", "Decui Xu", "Yanping Li", "Caihong Li", "Peng Lü", "Yong Li", "Wuxiang Xie", "Dan Cui", "Lianhan Shang", "Guohui Fan", "Jiuyang Xu", "Geng Wang", "Ying Wang", "Jingchuan Zhong", "Chen Wang", "Jianwei Wang", "Dingyu Zhang", "Bin Cao"], "year": 2021, "venue": "The Lancet", "cited_by_count": 4238, "type": "article", "concepts": ["Medicine", "Cohort", "Pneumonia", "Logistic regression", "Emergency medicine"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W1787224781", "doi": "https://doi.org/10.1371/journal.pone.0130140", "title": "On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation", "abstract": "Understanding and interpreting classification decisions of automated image classification systems is of high value in many applications, as it allows to verify the reasoning of the system and provides additional information to the human expert. Although machine learning methods are solving very successfully a plethora of tasks, they have in most cases the disadvantage of acting as a black box, not providing any information about what made them arrive at a particular decision. This work proposes a general solution to the problem of understanding classification decisions by pixel-wise decomposition of nonlinear classifiers. We introduce a methodology that allows to visualize the contributions of single pixels to predictions for kernel-based classifiers over Bag of Words features and for multilayered neural networks. These pixel contributions can be visualized as heatmaps and are provided to a human expert who can intuitively not only verify the validity of the classification decision, but also focus further analysis on regions of potential interest. We evaluate our method for classifiers trained on PASCAL VOC 2009 images, synthetic image data containing geometric shapes, the MNIST handwritten digits data set and for the pre-trained ImageNet model available as part of the Caffe open source package.", "authors": ["Sebastian Bach", "Alexander Binder", "Grégoire Montavon", "Frederick Klauschen", "Klaus‐Robert Müller", "Wojciech Samek"], "year": 2015, "venue": "PLoS ONE", "cited_by_count": 4413, "type": "article", "concepts": ["MNIST database", "Computer science", "Artificial intelligence", "Pixel", "Pascal (unit)"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4390193237", "doi": "https://doi.org/10.4274/dir.2023.232496", "title": "Educating the next generation of radiologists: a comparative report of ChatGPT and e-learning resources", "abstract": "Rapid technological advances have transformed medical education, particularly in radiology, which depends on advanced imaging and visual data. Traditional electronic learning (e-learning) platforms have long served as a cornerstone in radiology education, offering rich visual content, interactive sessions, and peer-reviewed materials. They excel in teaching intricate concepts and techniques that necessitate visual aids, such as image interpretation and procedural demonstrations. However, Chat Generative Pre-Trained Transformer (ChatGPT), an artificial intelligence (AI)-powered language model, has made its mark in radiology education. It can generate learning assessments, create lesson plans, act as a round-the-clock virtual tutor, enhance critical thinking, translate materials for broader accessibility, summarize vast amounts of information, and provide real-time feedback for any subject, including radiology. Concerns have arisen regarding ChatGPT's data accuracy, currency, and potential biases, especially in specialized fields such as radiology. However, the quality, accessibility, and currency of e-learning content can also be imperfect. To enhance the educational journey for radiology residents, the integration of ChatGPT with expert-curated e-learning resources is imperative for ensuring accuracy and reliability and addressing ethical concerns. While AI is unlikely to entirely supplant traditional radiology study methods, the synergistic combination of AI with traditional e-learning can create a holistic educational experience.", "authors": ["İsmail Meşe", "Ceylan Altıntaş Taşlıçay", "Beyza Nur Kuzan", "Taha Yusuf Kuzan", "Ali Kemal Sivrioğlu"], "year": 2023, "venue": "Diagnostic and Interventional Radiology", "cited_by_count": 23, "type": "article", "concepts": ["Medicine", "Multimedia", "Flexibility (engineering)", "Chatbot", "Learning styles"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4387969352", "doi": "https://doi.org/10.1145/3581783.3611969", "title": "AesCLIP: Multi-Attribute Contrastive Learning for Image Aesthetics Assessment", "abstract": "Image aesthetics assessment (IAA) aims at predicting the aesthetic quality of images. Recently, large pre-trained vision-language models, like CLIP, have shown impressive performances on various visual tasks. When it comes to IAA, a straightforward way is to finetune the CLIP image encoder using aesthetic images. However, this can only achieve limited success without considering the uniqueness of multimodal data in the aesthetics domain. People usually assess image aesthetics according to fine-grained visual attributes, e.g., color, light and composition. However, how to learn aesthetics-aware attributes from CLIP-based semantic space has not been addressed before. With this motivation, this paper presents a CLIP-based multi-attribute contrastive learning framework for IAA, dubbed AesCLIP. Specifically, AesCLIP consists of two major components, i.e., aesthetic attribute-based comment classification and attribute-aware learning. The former classifies the aesthetic comments into different attribute categories. Then the latter learns an aesthetic attribute-aware representation by contrastive learning, aiming to mitigate the domain shift from the general visual domain to the aesthetics domain. Extensive experiments have been done by using the pre-trained AesCLIP on four popular IAA databases, and the results demonstrate the advantage of AesCLIP over the state-of-the-arts. The source code will be public at https://github.com/OPPOMKLab/AesCLIP.", "authors": ["Xiangfei Sheng", "Leida Li", "Pengfei Chen", "Jinjian Wu", "Weisheng Dong", "Yuzhe Yang", "Liwu Xu", "Yaqian Li", "Guangming Shi"], "year": 2023, "venue": "", "cited_by_count": 26, "type": "article", "concepts": ["Computer science", "Domain (mathematical analysis)", "Artificial intelligence", "Representation (politics)", "Image (mathematics)"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4401726215", "doi": "https://doi.org/10.1109/tpami.2024.3445770", "title": "Q-Bench+: A Benchmark for Multi-Modal Foundation Models on Low-Level Vision From Single Images to Pairs", "abstract": "The rapid development of Multi-modality Large Language Models (MLLMs) has navigated a paradigm shift in computer vision, moving towards versatile foundational models. However, evaluating MLLMs in low-level visual perception and understanding remains a yet-to-explore domain. To this end, we design benchmark settings to emulate human language responses related to low-level vision: the low-level visual perception (A1) via visual question answering related to low-level attributes (e.g. clarity, lighting); and the low-level visual description (A2), on evaluating MLLMs for low-level text descriptions. Furthermore, given that pairwise comparison can better avoid ambiguity of responses and has been adopted by many human experiments, we further extend the low-level perception-related questionanswering and description evaluations of MLLMs from single images to image pairs. Specifically, for perception (A1), we carry out the LLVisionQA+ dataset, comprising 2,990 single images and 1,999 image pairs each accompanied by an open-ended question about its low-level features; for description (A2), we propose the LLDescribe+ dataset, evaluating MLLMs for low-level descriptions on 499 single images and 450 pairs. Additionally, we evaluate MLLMs on assessment (A3) ability, i.e. predicting score, by employing a softmax-based approach to enable all MLLMs to generate quantifiable quality ratings, tested against human opinions in 7 image quality assessment (IQA) datasets. With 24 MLLMs under evaluation, we demonstrate that several MLLMs have decent low-level visual competencies on single images, but only GPT-4V exhibits higher accuracy on pairwise comparisons than single image evaluations (like humans). We hope that our benchmark will motivate further research into uncovering and enhancing these nascent capabilities of MLLMs. Datasets will be available at https://github.com/Q-Future/Q-Bench.", "authors": ["Zicheng Zhang", "Haoning Wu", "Erli Zhang", "Guangtao Zhai", "Weisi Lin"], "year": 2024, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 17, "type": "article", "concepts": ["Modal", "Artificial intelligence", "Benchmark (surveying)", "Computer science", "Foundation (evidence)"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4312219151", "doi": "https://doi.org/10.1145/3573891", "title": "Dynamic Convolution-based Encoder-Decoder Framework for Image Captioning in Hindi", "abstract": "In sequence-to-sequence modeling tasks, such as image captioning, machine translation, and visual question answering, encoder-decoder architectures are state of the art. An encoder, convolutional neural network (CNN) encodes input images into fixed dimensional vector representation in the image captioning task, whereas a decoder, a recurrent neural network, performs language modeling and generates the target descriptions. Recent CNNs use the same operation over every pixel; however, all the image pixels are not equally important. To address this, the proposed method uses a dynamic convolution-based encoder for image encoding or feature extraction, Long-Short-Term-Memory as a decoder for language modeling, and X-Linear attention to make the system robust. Encoders, attentions, and decoders are important aspects of the image captioning task; therefore, we experiment with various encoders, decoders, and attention mechanisms. Most of the works for image captioning have been carried out for the English language in the existing literature. We propose a novel approach for caption generation from images in Hindi. Hindi, widely spoken in South Asia and India, is the fourth most-spoken language globally; it is India’s official language. The proposed method utilizes dynamic convolution operation on the encoder side to obtain a better image encoding quality. The Hindi image captioning dataset is manually created by translating the popular MSCOCO dataset from English to Hindi. In terms of BLEU scores, the performance of the proposed method is compared with other baselines, and the results obtained show that the proposed method outperforms different baselines. Manual human assessment in terms of adequacy and fluency of the captions generated further determines the efficacy of the proposed method in generating good-quality captions.", "authors": ["Santosh Kumar Mishra", "Sushant Sinha", "Sriparna Saha", "Pushpak Bhattacharyya"], "year": 2022, "venue": "ACM Transactions on Asian and Low-Resource Language Information Processing", "cited_by_count": 19, "type": "article", "concepts": ["Closed captioning", "Computer science", "Hindi", "Encoder", "Artificial intelligence"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4319662928", "doi": "https://doi.org/10.1371/journal.pdig.0000198", "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models", "abstract": "We evaluated the performance of a large language model called ChatGPT on the United States Medical Licensing Exam (USMLE), which consists of three exams: Step 1, Step 2CK, and Step 3. ChatGPT performed at or near the passing threshold for all three exams without any specialized training or reinforcement. Additionally, ChatGPT demonstrated a high level of concordance and insight in its explanations. These results suggest that large language models may have the potential to assist with medical education, and potentially, clinical decision-making.", "authors": ["Tiffany H. Kung", "Morgan Cheatham", "Arielle Medenilla", "Czarina Sillos", "Lorie De Leon", "Camille Elepaño", "Maria Madriaga", "Rimel Aggabao", "Giezel Diaz-Candido", "James Maningo", "Victor Tseng"], "year": 2023, "venue": "PLOS Digital Health", "cited_by_count": 3279, "type": "article", "concepts": ["Concordance", "United States Medical Licensing Examination", "Medical education", "Computer science", "Licensure"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4390987121", "doi": "https://doi.org/10.57197/jdr-2023-0051", "title": "Empowering the Visually Impaired: Translating Handwritten Digits into Spoken Language with HRNN-GOA and Haralick Features", "abstract": "Visual impairment poses significant challenges to individuals in their daily lives, limiting their access to information encoded in the visual domain. This paper presents a novel approach to empower the visually impaired by developing a system capable of translating handwritten digits into spoken language. The proposed system leverages a combination of advanced deep learning (DL) architecture, Hopfield Recurrent Neural Network-Grasshopper Optimization Algorithm (HRNN-GOA), and traditional image-processing techniques such as Haralick features. The system employs HRNN-GOA as the core model for handwritten digit recognition. HRNN-GOA exhibits superior sequential learning capabilities, capturing intricate patterns in the handwritten digits. Additionally, Haralick features are extracted from the input images, providing complementary texture-based information. The fusion of DL and traditional features aims to enhance the robustness and accuracy of the recognition process. The experimental results demonstrate the effectiveness of the proposed approach in accurately recognising handwritten digits. The HRNN-GOA model achieves state-of-the-art performance in digit classification tasks, while the incorporation of Haralick features further refines the recognition process, especially in cases with complex textures or variations in writing styles. The simulation results are compared against state-of-the-art strategies in terms of many metrics, including accuracy, precision, recall, specificity, area under the curve, F1-score, and false-positive rate. The proposed system has the potential to significantly improve the independence and quality of life for individuals with visual impairments by providing seamless access to numerical information in a spoken format. Future endeavours could explore the extension of this framework to recognise and translate more complex handwritten symbols or characters. Additionally, user experience studies and real-world deployment assessments will be crucial for refining the system and ensuring its practical utility in diverse scenarios.", "authors": ["Mohammed Alshehri", "Sunil Kumar Sharma", "Priya Gupta", "Sapna Ratan Shah"], "year": 2024, "venue": "Journal of Disability Research", "cited_by_count": 24, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Robustness (evolution)", "Speech recognition", "Feature extraction"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4405016353", "doi": "https://doi.org/10.1007/978-3-031-78125-4_4", "title": "CLIP-AGIQA: Boosting the Performance of AI-Generated Image Quality Assessment with CLIP", "abstract": "", "authors": ["Zhenchen Tang", "Zichuan Wang", "Bo Peng", "Jing Dong"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 10, "type": "book-chapter", "concepts": ["Computer science", "Boosting (machine learning)", "Image quality", "Artificial intelligence", "Quality assessment"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2115609473", "doi": "https://doi.org/10.1002/mpr.168", "title": "The World Mental Health (WMH) Survey Initiative version of the World Health Organization (WHO) Composite International Diagnostic Interview (CIDI)", "abstract": "This paper presents an overview of the World Mental Health (WMH) Survey Initiative version of the World Health Organization (WHO) Composite International Diagnostic Interview (CIDI) and a discussion of the methodological research on which the development of the instrument was based. The WMH-CIDI includes a screening module and 40 sections that focus on diagnoses (22 sections), functioning (four sections), treatment (two sections), risk factors (four sections), socio-demographic correlates (seven sections), and methodological factors (two sections). Innovations compared to earlier versions of the CIDI include expansion of the diagnostic sections, a focus on 12-month as well as lifetime disorders in the same interview, detailed assessment of clinical severity, and inclusion of information on treatment, risk factors, and consequences. A computer-assisted version of the interview is available along with a direct data entry software system that can be used to keypunch responses to the paper-and-pencil version of the interview. Computer programs that generate diagnoses are also available based on both ICD-10 and DSM-IV criteria. Elaborate CD-ROM-based training materials are available to teach interviewers how to administer the interview as well as to teach supervisors how to monitor the quality of data collection.", "authors": ["Ronald C. Kessler", "T. Bedirhan Üstün"], "year": 2004, "venue": "International Journal of Methods in Psychiatric Research", "cited_by_count": 4759, "type": "article", "concepts": ["CIDI", "Mental health", "Medical diagnosis", "Psychology", "Focus group"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2128030851", "doi": "https://doi.org/10.1093/brain/awr179", "title": "Sensitivity of revised diagnostic criteria for the behavioural variant of frontotemporal dementia", "abstract": "Based on the recent literature and collective experience, an international consortium developed revised guidelines for the diagnosis of behavioural variant frontotemporal dementia. The validation process retrospectively reviewed clinical records and compared the sensitivity of proposed and earlier criteria in a multi-site sample of patients with pathologically verified frontotemporal lobar degeneration. According to the revised criteria, 'possible' behavioural variant frontotemporal dementia requires three of six clinically discriminating features (disinhibition, apathy/inertia, loss of sympathy/empathy, perseverative/compulsive behaviours, hyperorality and dysexecutive neuropsychological profile). 'Probable' behavioural variant frontotemporal dementia adds functional disability and characteristic neuroimaging, while behavioural variant frontotemporal dementia 'with definite frontotemporal lobar degeneration' requires histopathological confirmation or a pathogenic mutation. Sixteen brain banks contributed cases meeting histopathological criteria for frontotemporal lobar degeneration and a clinical diagnosis of behavioural variant frontotemporal dementia, Alzheimer's disease, dementia with Lewy bodies or vascular dementia at presentation. Cases with predominant primary progressive aphasia or extra-pyramidal syndromes were excluded. In these autopsy-confirmed cases, an experienced neurologist or psychiatrist ascertained clinical features necessary for making a diagnosis according to previous and proposed criteria at presentation. Of 137 cases where features were available for both proposed and previously established criteria, 118 (86%) met 'possible' criteria, and 104 (76%) met criteria for 'probable' behavioural variant frontotemporal dementia. In contrast, 72 cases (53%) met previously established criteria for the syndrome (P < 0.001 for comparison with 'possible' and 'probable' criteria). Patients who failed to meet revised criteria were significantly older and most had atypical presentations with marked memory impairment. In conclusion, the revised criteria for behavioural variant frontotemporal dementia improve diagnostic accuracy compared with previously established criteria in a sample with known frontotemporal lobar degeneration. Greater sensitivity of the proposed criteria may reflect the optimized diagnostic features, less restrictive exclusion features and a flexible structure that accommodates different initial clinical presentations. Future studies will be needed to establish the reliability and specificity of these revised diagnostic guidelines.", "authors": ["Katya Rascovsky", "John R. Hodges", "David S. Knopman", "Mario F. Mendez", "Joel H. Kramer", "John Neuhaus", "John C. van Swieten", "Harro Seelaar", "Elise G.P. Dopper", "Chiadi U. Onyike", "Argye E. Hillis", "Keith A. Josephs", "Bradley F. Boeve", "Andrew Kertesz", "William W. Seeley", "Katherine P. Rankin", "Julene K. Johnson", "Maria-Luisa Gorno-Tempini", "Howard J. Rosen", "Caroline E. Prioleau-Latham", "Albert Lee", "Christopher Kipps", "Patricia Lillo", "Olivier Piguet", "Jonathan D. Rohrer", "Martin N. Rossor", "Jason D. Warren", "Nick C. Fox", "Douglas Galasko", "David P. Salmon", "Sandra E. Black", "Marsel Mesulam", "Sandra Weıntraub", "Brad C. Dickerson", "Janine Diehl‐Schmid", "Florence Pasquier", "Vincent Deramecourt", "Florence Lebert", "Yolande A.L. Pijnenburg", "Tiffany W. Chow", "Facundo Manes", "Jordan Grafman", "Stefano F. Cappa", "Morris Freedman", "Murray Grossman", "Bruce L. Miller"], "year": 2011, "venue": "Brain", "cited_by_count": 5104, "type": "article", "concepts": ["Frontotemporal dementia", "Frontotemporal lobar degeneration", "Apathy", "Dementia", "Psychology"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2050788534", "doi": "https://doi.org/10.1044/jshr.0103.227", "title": "Myoelastic-Aerodynamic Theory of Voice Production", "abstract": "No AccessJournal of Speech and Hearing ResearchResearch Article1 Sep 1958Myoelastic-Aerodynamic Theory of Voice Production Janwillem van den Berg Janwillem van den Berg Google Scholar https://doi.org/10.1044/jshr.0103.227 SectionsAboutPDF ToolsAdd to favoritesDownload CitationTrack Citations ShareFacebookTwitterLinked In Additional Resources FiguresReferencesRelatedDetailsCited by The Journal of the Acoustical Society of America153:5 (2803)1 May 2023 Effect of functional electric stimulation on phonation in an ex vivo aged ovine model Bernhard Jakubaß, Gregor Peters, Stefan Kniesburges, Marion Semmler, Andrijana Kirsch, Claus Gerstenberger, Markus Gugatschka and Michael Döllinger Journal of Voice37:3 (305-313)1 May 2023Integrative Insights into the Myoelastic-Aerodynamic Theory and Acoustics of Phonation. Scientific Tribute to Donald G. MillerJan G. Švec, Harm K. Schutte, C. Julian Chen and Ingo R. Titze Maryam Naghibolhosseini, Ahmed M Yousef, Mohsen Zayernouri, Stephanie RC Zacharias and Dimitar D Deliyski (2023) Deep Learning for High-Speed Laryngeal Imaging Analysis 2023 International Conference on Computational Intelligence and Knowledge Economy (ICCIKE)10.1109/ICCIKE58312.2023.10131757979-8-3503-3826-3 Journal of Voice1 Mar 2023Mechanical Parameters Based on High-Speed Videoendoscopy of the Vocal Folds in Patients With Ectodermal DysplasiaFranziska Pelka, Maria Ensthaler, Olaf Wendler, Stefan Kniesburges, Anne Schützenberger and Marion Semmler Journal of Mammalian Evolution30:1 (79-94)1 Mar 2023The vocal apparatus: An understudied tool to reconstruct the evolutionary history of echolocation in bats?Nicolas L. M. Brualla, Laura A. B. Wilson, Michael Doube, Richard T. Carter, Alan G. McElligott and Daisuke Koyabu Journal of Voice1 Feb 2023Dynamic System Coupling in Voice ProductionChristian T. Herbst, Coen P.H. Elemans, Isao T. Tokuda, Vasileios Chatziioannou and Jan G. Švec Journal of Voice1 Nov 2022Empirical Evaluation of the Role of Vocal Fold Collision on Relative Fundamental Frequency in Voicing OffsetMatti D. Groll, Sean D. Peterson, Matías Zañartu, Jennifer M. Vojtech and Cara E. Stepp Research Studies in Music Education44:3 (491-508)1 Oct 2022Exploring perceptions and experiences of female secondary school singers in Aotearoa New ZealandCalvin P Baker, Te Oti Rakena and Suzanne C Purdy Current Opinion in Behavioral Sciences46 (101140)1 Aug 2022Selection levels on vocal individuality: strategic use or byproductMegan T Wyman, Britta Walkenhorst and Marta B. Manser Chaos, Solitons & Fractals159 (112188)1 Jun 2022Controlling chaotic oscillations in a symmetric two-mass model of the vocal foldsOriol Guasch, Annemie Van Hirtum, A. Inés Fernández and Marc Arnela Transgender Health31 May 2022Gender-Affirming Voice Modification for Transgender Women: Characteristics and OutcomesMichelle Adessa, Zoe Weston, Jeremy Ruthberg and Paul C. Bryson Psychology of Music50:3 (933-944)1 May 2022Augmented visual-feedback of airflow: Immediate effects on voice-source characteristics of students of singingFilipa Martins Batista Lã, Johan Sundberg and Svante Granqvist Journal of Voice36:3 (335-343)1 May 2022Multiparameter Voice Assessment in Dysphonics: Correlation Between Objective and Perceptual ParametersSV Narasimhan and Rajesh Rashmi International Journal of Head and Neck Surgery12:4 (125-130)15 Apr 2022Anatomy and Physiology of PhonationCandace Hrelec and Emily Zhang Brain Sciences12:4 (427)23 Mar 2022Phonetic Effects in the Perception of VOT in a Prevoicing LanguageViktor Kharlamov Journal of Phonetics91 (101138)1 Mar 2022Voicing in Qaqet: Prenasalization and language contactMarija Tabain, Marc Garellek, Birgit Hellwig, Adele Gregory and Richard Beare Tissue Engineering Part B: Reviews28:1 (182-205)1 Feb 2022Bioreactors for Vocal Fold Tissue EngineeringAna M. Gracioso Martins, Andreea Biehl, Daphne Sze and Donald O. Freytes Rostam D. Farhadieh, Ajay R. Sud, Edwin Morrison, and Wayne A.J. Morrison (2022) Pharyngeal Reconstruction Plastic Surgery - Principles and Practice10.1016/B978-0-323-65381-7.00026-5 Markus Gugatschka, David Hortobagyi and Liang Ker (2022) Anatomy and Microanatomy of the Larynx Textbook of Surgery of Larynx and Trachea10.1007/978-3-031-09621-1_3 Aude Lagier and Antoine Giovanni (2022) Physiology of the Larynx Textbook of Surgery of Larynx and Trachea10.1007/978-3-031-09621-1_1 EURASIP Journal on Advances in Signal Processing2021:11 Dec 2021Voice production model based on phonation biophysicsRaissa Bezerra Rocha, Wamberto José Lira de Queiroz and Marcelo Sampaio de Alencar Journal of Voice1 Oct 2021Multiparametric Analysis of Speaking Fundamental Frequency in Genetically Related Speakers Using Different Speech Materials: Some Forensic ImplicationsJulio Cesar Cavalcanti, Anders Eriksson and Plinio A. Barbosa Journal of Voice1 Aug 2021Influence of Reduced Saliva Production on Phonation in Patients With Ectodermal DysplasiaMarion Semmler, Stefan Kniesburges, Franziska Pelka, Maria Ensthaler, Olaf Wendler and Anne Schützenberger Phonetica78:2 (113-140)27 Apr 20211 Apr 2021Voice onset time and constriction duration in Warlpiri stops (Australia)Rikke L. Bundgaard-Nielsen and Carmel O'Shannessy Journal of Speech, Language, and Hearing Research64:4 (1197-1209)14 Apr 2021The Relationship Between Voice Onset Time and Increase in Vocal Effort and Fundamental FrequencyMatti D. Groll, Surbhi Hablani and Cara E. Stepp The Journal of the Acoustical Society of America149:3 (1657-1673)1 Mar 2021 Fluid-structure-acoustic interactions in an ex vivo porcine phonation model Marion Semmler, David A. Berry, Anne Schützenberger and Michael Döllinger Scientific Reports11:18 Jan 2021Subglottal pressure oscillations in anechoic and resonant conditions and their influence on excised larynx phonationsHugo Lehoux, Vít Hampala and Jan G. Švec Alberto Bolletta, Samir Mardini and Hung-Chi Chen (2021) Recipient Vessels: Voice Reconstruction Recipient Vessels in Reconstructive Microsurgery10.1007/978-3-030-75389-4_8 Frontiers in Zoology17:11 Dec 2020Vocal tract anatomy of king penguins: morphological traits of two-voiced sound productionHannah Joy Kriesell, Céline Le Bohec, Alexander F. Cerwenka, Moritz Hertel, Jean-Patrice Robin, Bernhard Ruthensteiner, Manfred Gahr, Thierry Aubin and Daniel Normen Düring Journal of Voice1 Dec 2020Effect of Ventricular Folds on Vocalization Fundamental Frequency in Domestic Pigs (Sus scrofa domesticus)Christian T. Herbst, Takeshi Nishimura, Maxime Garcia, Kishin Migimatsu and Isao T. Tokuda The Journal of the Acoustical Society of America148:1 (EL65-EL71)1 Jul 2020Effects of consonantal constrictions on voice qualityAdam J. Chong, Megan Risdal, Ann Aly, Jesse Zymet and Patricia Keating Proceedings of the National Academy of Sciences117:9 (4718-4723)3 Mar 2020High-fidelity continuum modeling predicts avian voiced sound productionWeili Jiang, Jeppe H. Rasmussen, Qian Xue, Ming Ding, Xudong Zheng and Coen P. H. Elemans Trends in Neurosciences43:2 (115-126)1 Feb 2020A Hierarchy of Autonomous Systems for Vocal ProductionYisi S. Zhang and Asif A. Ghazanfar EMC - Otorrinolaringología49:1 (1-16)1 Feb 2020Uso forzado de la vozL. Crevier Buchman, A. Mattei and A. Giovanni The Journal of the Acoustical Society of America147:1 (245-259)1 Jan 2020Longer vowel duration correlates with greater tongue root advancement at vowel offset: Acoustic and articulatory data from Italian and PolishStefano Coretta Takeshi Nishimura (2020) Primate Vocal Anatomy and Physiology: Similarities and Differences Between Humans and Nonhuman Primates The Origins of Language Revisited10.1007/978-981-15-4250-3_2 Lisa Bartha-Doering, Peter Birkholz, Cori Casanova, Felix de Jong, Wivine Decoster, Ilter Denizoglu, Rolf Dierichs, Christian Dobel, Michèle Kaufmann-Meyer, Malte Kob, Anders Löfqvist, Dirk Mürbe, Christiane Neuschaefer-Rube, Christo Pantev, Bernhard Richter, Ken Roßlau, Oskar Schindler, Harm K. Schutte, Ad Snik, Claudia Spahn, Kurt Stephan and Jürgen Wendler (2020) Basics of Phoniatrics Phoniatrics I10.1007/978-3-662-46780-0_1 Sid M. Khosla and Hayley Born (2020) Laryngeal Physiology Neurologic and Neurodegenerative Diseases of the Larynx10.1007/978-3-030-28852-5_2 Matthew R. Hoffman, Maia N. Braden and J. Scott McMurray (2020) Physiology of Voice Production Multidisciplinary Management of Pediatric Voice and Swallowing Disorders10.1007/978-3-030-26191-7_6 The Journal of the Acoustical Society of America146:5 (3184-3202)1 Nov 2019Refining algorithmic estimation of relative fundamental frequency: Accounting for sample characteristics and fundamental frequency estimation methodJennifer M. Vojtech, Roxanne K. Segina, Daniel P. Buckley, Katharine R. Kolin, Monique C. Tardif, J. Pieter Noordzij and Cara E. Stepp Journal of Voice1 Sep 2019Acoustic and Aerodynamic Comparisons of Voice Qualities Produced After Voice TrainingNicholas A. Barone, Christy L. Ludlow and Cari M. Tellis Audiology and Speech Research15:3 (223-231)31 Jul 2019Effect of Speech Stimulus, Gender, and Age on Phonation Threshold Measures in Korean AdultsJu Eun Park, Seong Hee Choi, Kyoung Jae Lee and Chul-Hee Choi Head & Neck41:7 (2324-2331)1 Jul 2019Predicting glottal closure insufficiency using fundamental frequency contour analysisJacob T. Cohen, Alma Cohen, Limor Benyamini, Yossi Adi and Joseph Keshet The Anatomical Record302:5 (703-717)1 May 2019Anatomy and Functional Morphology of the Mysticete Rorqual Whale Larynx: Phonation Positions of the U‐FoldJULIETTE DAMIEN, OLIVIER ADAM, DORIAN CAZAU, PAUL WHITE, JEFFREY T. LAITMAN and JOY S. REIDENBERG Movement Disorders Clinical Practice6:3 (243-249)1 Mar 2019Relationship Between Respiratory Sensory Perception, Speech, and Swallow in Parkinson's DiseaseKaren W. Hegland, Michelle Troche and Alexandra Brandimore Journal of Phonetics72 (52-65)1 Jan 2019Voice onset time and beyond: Exploring laryngeal contrast in 19 languagesTaehong Cho, D.H. Whalen and Gerard Docherty Journal of Voice1 Jan 2019In Vivo Quantification of the Intraglottal Pressure: Modal Phonation and Voice OnsetPhilippe H. DeJonckere and Jean Lebacq (2018) Speech Articulation Phonetics10.1017/9781108289849.002 Ratree Wayland (2020) Phonetics Journal of Mechanics34:6 (791-800)1 Dec 2018Three Dimensional FSI Modelling of Sulcus Vocalis Disorders of Vocal FoldsA. Vazifehdoostsaleh, N. Fatouraee, M. Navidbakhsh and F. Izadi The Laryngoscope128:10 (2367-2374)1 Oct 2018Clinical relevance of endoscopic three-dimensional imaging for quantitative assessment of phonationMarion Semmler, Michael Döllinger, Rita R. Patel, Anke Ziethe and Anne Schützenberger The Journal of Experimental Biology221:16 (jeb172247)15 Aug 2018 Quantifying syringeal dynamics in vitro using electroglottography Jeppe H. Rasmussen, Christian T. Herbst and Coen P. H. Elemans The Journal of Experimental Biology221:12 (jeb171801)15 Jun 2018Japanese macaque phonatory physiologyChristian T. Herbst, Hiroki Koda, Takumi Kunieda, Juri Suzuki, Maxime Garcia, W. Tecumseh Fitch and Takeshi Nishimura Computer Methods in Biomechanics and Biomedical Engineering21:8 (532-540)11 Jun 2018Numerical analysis and comparison of flow fields in normal larynx and larynx with unilateral vocal fold paralysisAmirhossein Bagheri Sarvestani, Ebrahim Goshtasbi Rad and Kamyar Iravani Journal of Medical Devices12:11 Mar 2018Design and Evaluation of a Mechanically Driven Artificial Speech DeviceTyler G. Tuttle and Byron D. Erath Annual Review of Linguistics4:1 (255-279)14 Jan 2018The Biology and Evolution of Speech: A Comparative AnalysisW. Tecumseh Fitch Anthropological Science126:1 (3-8)The descended larynx and the descending larynxTAKESHI NISHIMURA Anthropological Science126:1 (19-27)Non-invasive documentation of primate voice production using electroglottographyCHRISTIAN T. HERBST and JACOB C. DUNN Anthropological Science126:1 (9-17)Excised larynx experimentation: history, current developments, and prospects for bioacoustic researchMAXIME GARCIA and CHRISTIAN T. HERBST Procedia Computer Science126 (423-430)Voice source modelling using modified LF model with reduced parametersAnis Ben Aicha Scientific Reports7:112 Sep 2017In situ vocal fold properties and pitch prediction by dynamic actuation of the songbird syrinxDaniel N. Düring, Benjamin J. Knörlein and Coen P. H. Elemans Scientific Reports7:15 Sep 2017Acoustic allometry revisited: morphological determinants of fundamental frequency in primate vocal productionMaxime Garcia, Christian T. Herbst, Daniel L. Bowling, Jacob C. Dunn and W. Tecumseh Fitch Tissue and Cell49:3 (427-434)1 Jun 2017Structurally and functionally characterized in vitro model of rabbit vocal fold epitheliumMasanobu Mizuta, Takashi Kurita, Emily E. Kimball and Bernard Rousseau Journal of Voice31:3 (378.e1-378.e11)1 May 2017Metabolic Mechanisms of Vocal FatigueChayadevie Nanjundeswaran, Jessie VanSwearingen and Katherine Verdolini Abbott The Laryngoscope127:5 (1102-1108)1 May 2017A New Conceptual Approach for Voice Feminization: 12 Years of ExperienceHyung‐Tae Kim International Journal of Pharma and Bio Sciences8:26 Apr 2017Creation of voice database, acoustic analysis and standardisation of normal indian voicesLATHADEVI H T, MALIPATIL SR and S P GUGGARI GOUDAR The Journal of the Acoustical Society of America141:3 (1715-1725)1 Mar 2017Relations among subglottal pressure, breathing, and acoustic parameters of sentence-level prominence in GermanCaterina Petrone, Susanne Fuchs and Laura L. Koenig Nowa Audiofonologia6:4 (16-20)26 Oct 2020Process of voice production – an overview of the current literaturePaulina Krasnodębska, Tomasz Wolak and Agata Szkiełkowska Pattern Recognition and Image Analysis27:1 (139-151)1 Jan 2017Determination of a vocal source by the spectral ratio methodV. N. Sorokin and A. S. Leonov Journal of Voice31:1 (116.e1-116.e5)1 Jan 2017The Potential Role of Subglottal Convergence Angle and MeasurementXinlin Xu, Jingan Wang, Erin E. Devine, Yong Wang, Hua Zhong, Maxwell R. Courtright, Li Zhou, PeiYun Zhuang and Jack J. Jiang Petr Hájek, Pavel Švancara, Jaromír Horáček and Jan G. Švec (2017) Numerical Simulation of the Self-oscillating Vocal Folds in Interaction with Vocal Tract Shaped for Particular Czech Vowels Recent Global Research and Education: Technological Challenges10.1007/978-3-319-46490-9_43 MOJ Clinical & Medical Case Reports5:39 Dec 2016Management of Laryngo Tracheal Injury Our ExperienceSanjeev Mohanty The Journal of the Acoustical Society of America140:4 (2614-2635)1 Oct 2016Mechanics of human voice production and controlZhaoyan Zhang Journal of Speech, Language, and Hearing Research59:5 (1002-1017)1 Oct 2016Exploring the Clinical Utility of Relative Fundamental Frequency as an Objective Measure of Vocal HyperfunctionNelson Roy, Rebecca A. Fetrow, Ray M. Merrill and Christopher Dromey The Laryngoscope126:7 (1589-1594)1 Jul 2016Nonstimulated rabbit phonation model: Cricothyroid approximationCarolyn K. Novaleski, Tsuyoshi Kojima, Siyuan Chang, Haoxiang Luo, Carla V. Valenzuela and Bernard Rousseau PLOS Computational Biology12:6 (e1004907)16 Jun 2016Predicting Achievable Fundamental Frequency Ranges in Vocalization Across SpeciesIngo Titze, Tobias Riede, Ted Mau and Frédéric E. Theunissen Computer Speech & Language36 (365-394)1 Mar 2016Nonlinear interactive source-filter models for speechTurgay Koc and Tolga Ciloglu Journal of Biomechanical Science and Engineering11:4 (16-00414-16-00414)A possible common physical principle that underlies animal vocalization: theoretical considerations with an unsteady airflow-structure interaction modelShinji DEGUCHI Cells Tissues Organs202:5-6 (355-368)Evaluation of Dying Vocal Fold Epithelial Cells by Ultrastructural Features and TUNEL MethodCarolyn K. Novaleski, Masanobu Mizuta and Bernard Rousseau Christian T. Herbst (2016) Biophysics of Vocal Production in Mammals Vertebrate Sound Production and Acoustic Communication10.1007/978-3-319-27721-9_6 Daniel N. Düring and Coen P. H. Elemans (2016) Embodied Motor Control of Avian Vocal Production Vertebrate Sound Production and Acoustic Communication10.1007/978-3-319-27721-9_5 W. Tecumseh Fitch (2016) Vertebrate Bioacoustics: Prospects and Open Problems Vertebrate Sound Production and Acoustic Communication10.1007/978-3-319-27721-9_10 W. Tecumseh Fitch and Roderick A. Suthers (2016) Vertebrate Vocal Production: An Introductory Overview Vertebrate Sound Production and Acoustic Communication10.1007/978-3-319-27721-9_1 Communication Sciences & Disorders20:4 (607-616)31 Dec 2016Pattern Analysis of Voice Onset and Offset in Normal Adults Using High-Speed Digital Imaging: The Role of Arytenoid Cartilage MovementsSeong Hee Choi, Chi-Sun Oh and Chul-Hee Choi Nature Communications6:11 Dec 2015Universal mechanisms of sound production and control in birds and mammalsC.P.H Elemans, J.H. Rasmussen, C.T. Herbst, D.N. Düring, S.A. Zollinger, H. Brumm, K. Srivastava, N. Svane, M. Ding, O.N. Larsen, S.J. Sober and J.G. Švec Journal of Phonetics52 (35-45)1 Sep 2015Assessing respiratory contributions to f 0 declination in German across varying speech tasks and respiratory demandsSusanne Fuchs, Caterina Petrone, Amélie Rochet-Capellan, Uwe D. Reichel and Laura L. Koenig Ross D. Farhadieh and Wayne A.J. Morrison (2015) Pharyngeal reconstruction Plastic and reconstructive surgery10.1002/9781118655412.ch28 Journal of Experimental Biology218:7 (991-998)1 Apr 2015 Functional morphology of the Alligator mississippiensis larynx with implications for vocal production Tobias Riede, Zhiheng Li, Isao T. Tokuda and Colleen G. Farmer Brad H. Story (2015) Mechanisms of Voice Production The Handbook of Speech Production10.1002/9781118584156.ch3 The Journal of the Acoustical Society of America137:3 (1493-1502)1 Mar 2015Three speech sounds, one motor action: Evidence for speech-motor disparity from English flap productionDonald Derrick, Ian Stavness and Bryan Gick Cancer Research75:1 (31-39)1 Jan 2015A Noninvasive Procedure for Early-Stage Discrimination of Malignant and Precancerous Vocal Fold Lesions Based on Laryngeal Dynamics AnalysisJakob Unger, Jörg Lohscheller, Maximilian Reiter, Christian S. and Maria Computer Methods in Biomechanics and Biomedical Dec of in vocal fold and The Journal of the Acoustical Society of Nov of the of pressure on vocal fold H. and Zhang Journal of Nov of Vocal Fold A Review K. Computer Speech & Sep source analysis to and Journal of Jul Fold Dynamics for Frequency Journal of and Jul of a model of and Jul International Journal of & Jun a Larynx: A in Clinical and The Apr of and fields in excised Jun and The Journal of the Acoustical Society of Jan and in Sid Khosla and Peters, R. J. Van K. Van and The Jan of and laryngeal D. Journal of Experimental Nov in an T. Herbst, Jan G. Švec, Jörg Lohscheller, S. and W. Tecumseh Fitch Medical Engineering & Aug dynamics of vocal using normal P. and Journal of Jul and Acoustic of Vocal A. and Brad H. Story Audiology - Communication de Carla José and of Biomedical Dec in Vocal Fold the of E. and W. Journal of Nov of Differences in Using High-Speed Videoendoscopy and F. Maria E. and Dimitar D. Deliyski Aug Production of T. Herbst, S. Jörg Lohscheller, Ingo R. Titze, and W. Tecumseh Fitch Research in Jun the Voicing of English Voicing Voicing and Journal of Mar Voice in Digital Signal Mar of dynamics of vocal using and P. David E. D. José C. and The Feb of on acoustic characteristics of A. N. E. and Acoustical Science and of on the of flow the Control in and Speech of Paul and L. T. V. Aerodynamic and Acoustic Theory of Voice Production Forensic The Journal of the Acoustical Society of Dec acoustic correlates of human vocal fold modeling and laryngeal D. Matías Zañartu, F. Dimitar D. Deliyski and E. Oct analysis of speech and Journal of Experimental Sep Subglottal pressure and fundamental frequency control in of Alligator mississippiensis Tobias Riede, Isao T. Tokuda and C. G. Farmer of Voice The Journal of the Acoustical Society of Apr the and as phonation onset Zhang Mar of and Threshold Biomechanical for Voice and The Journal of the Acoustical Society of Mar acoustic model of the subglottal for speech C. Matías and R. Medical Engineering & Mar of the glottal into a C. M. and M. Döllinger The Journal of & Feb S Donald F. of for Phonation and J. of the Respiratory System Journal of the International Dec acoustic correlates of the contrast in M. T. and Journal of Speech, Language, and Hearing Oct of Vocal on Relative Fundamental Frequency Voicing Offset and E. E. and T. Brain and Oct mechanisms for vocal production in birds – and to human speech and and Journal of Experimental Sep and of vocal Tobias Plastic and Reconstructive Aug of the and Christopher J. F. Kim and Hung-Chi Chen on Voice and Voice Jul of Voice R. The Journal of the Acoustical Society of Mar of the glottal and Laryngeal and Pharyngeal - Head and Neck and and of the vocal Handbook of Mammalian Vocalization - An S. and Jennifer L. of the larynx and production of Handbook of Mammalian Vocalization - An The comparison of properties using F. J. and Jack J. Jiang Journal of Jul with vocal properties of their vocal Riede, J. and Ingo R. Titze Tissue Engineering Part B: Sep Engineering for the Vocal Fold K. and Ken Feb tract in and and Journal of Jan of of on acoustic correlates of the contrast in B. Speech Physiology to Journal of Nov and Aerodynamic for Voicing of A L. C. and W. The Oct of Voice in the by an S. and J. Mar in A. P. A. and Paul F. Acoustical Science and the interaction of the flow the of Oct in unilateral laryngeal theoretical Richard and Antoine Giovanni Journal of Sep as a The use of in a J. The Journal of the Acoustical Society of Jul of modeling of and voice with excised larynx T. Tokuda, Jan G. Švec and of & Feb Voice in by Laryngeal of M. and J. The Journal of the Acoustical Society of Feb of acoustic on an model of the vocal Zañartu, and R. Research Mar of voiced using models of the vocal and subglottal R. and EMC - Jan de la and The Journal of the Acoustical Society of Oct", "authors": ["Janwillem van den Berg"], "year": 1958, "venue": "Journal of Speech and Hearing Research", "cited_by_count": 511, "type": "article", "concepts": ["Aerodynamics", "Production (economics)", "Speech production", "Computer science", "Speech recognition"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4404515348", "doi": "https://doi.org/10.1016/j.inffus.2024.102790", "title": "TextFusion: Unveiling the power of textual semantics for controllable image fusion", "abstract": "", "authors": ["Chunyang Cheng", "Tianyang Xu", "Xiaojun Wu", "Hui Li", "Xi Li", "Zhangyong Tang", "Josef Kittler"], "year": 2024, "venue": "Information Fusion", "cited_by_count": 25, "type": "article", "concepts": ["Computer science", "Semantics (computer science)", "Image (mathematics)", "Power (physics)", "Fusion"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2582406074", "doi": "https://doi.org/10.1186/s12913-017-2031-8", "title": "Acceptability of healthcare interventions: an overview of reviews and development of a theoretical framework", "abstract": "", "authors": ["Mandeep Sekhon", "Martin Cartwright", "Jill Francis"], "year": 2017, "venue": "BMC Health Services Research", "cited_by_count": 3572, "type": "article", "concepts": ["Nursing research", "Health informatics", "Health administration", "Medicine", "Public health"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W1909740415", "doi": "https://doi.org/10.1186/s12880-015-0068-x", "title": "Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool", "abstract": "", "authors": ["Abdel Aziz Taha", "Allan Hanbury"], "year": 2015, "venue": "BMC Medical Imaging", "cited_by_count": 2601, "type": "article", "concepts": ["Computer science", "Segmentation", "Metric (unit)", "Scale-space segmentation", "Image segmentation"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4220959955", "doi": "https://doi.org/10.1002/cl2.1230", "title": "<i>PRISMA2020</i> : An R package and Shiny app for producing PRISMA 2020‐compliant flow diagrams, with interactivity for optimised digital transparency and Open Synthesis", "abstract": "We have developed a user-friendly tool for producing PRISMA 2020-compliant flow diagrams for users with coding experience and, importantly, for users without prior experience in coding by making use of Shiny (https://estech.shinyapps.io/prisma_flowdiagram/). This free-to-use tool will make it easier to produce clear and PRISMA 2020-compliant systematic review flow diagrams. Significantly, users can also produce interactive flow diagrams for the first time, allowing readers of their reviews to smoothly and swiftly explore and navigate to further details of the methods and results of a review. We believe this tool will increase use of PRISMA flow diagrams, improve the compliance and quality of flow diagrams, and facilitate strong science communication of the methods and results of systematic reviews by making use of interactivity. We encourage the systematic review community to make use of the tool, and provide feedback to streamline and improve their usability and efficiency.", "authors": ["Neal Haddaway", "Matthew J. Page", "Chris C. Pritchard", "Luke A. McGuinness"], "year": 2022, "venue": "Campbell Systematic Reviews", "cited_by_count": 2683, "type": "article", "concepts": ["Interactivity", "Transparency (behavior)", "Computer science", "World Wide Web", "Computer security"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2048505725", "doi": "https://doi.org/10.1016/j.jalz.2014.01.001", "title": "A conceptual framework for research on subjective cognitive decline in preclinical Alzheimer's disease", "abstract": "There is increasing evidence that subjective cognitive decline (SCD) in individuals with unimpaired performance on cognitive tests may represent the first symptomatic manifestation of Alzheimer's disease (AD). The research on SCD in early AD, however, is limited by the absence of common standards. The working group of the Subjective Cognitive Decline Initiative (SCD-I) addressed this deficiency by reaching consensus on terminology and on a conceptual framework for research on SCD in AD. In this publication, research criteria for SCD in pre-mild cognitive impairment (MCI) are presented. In addition, a list of core features proposed for reporting in SCD studies is provided, which will enable comparability of research across different settings. Finally, a set of features is presented, which in accordance with current knowledge, increases the likelihood of the presence of preclinical AD in individuals with SCD. This list is referred to as SCD plus.", "authors": ["Frank Jessen", "Rebecca E. Amariglio", "Martin P.J. van Boxtel", "Monique M.B. Breteler", "Mathieu Ceccaldi", "Gaël Chételat", "Bruno Dubois", "Carole Dufouil", "Kathryn A. Ellis", "Wiesje M. van der Flier", "Lidia Glodzik", "Argonde C. van Harten", "Mony J. de Leon", "Pauline McHugh", "Michelle M. Mielke", "José Luís Molinuevo", "Lisa Mosconi", "Ricardo S. Osorio", "Audrey Perrotin", "Ronald C. Petersen", "Laura A. Rabin", "Lorena Rami", "‌Barry Reisberg", "Dorene M. Rentz", "Perminder S. Sachdev", "Vincent de La Sayette", "Andrew J. Saykin", "Philip Scheltens", "Melanie Shulman", "Melissa J. Slavin", "Reisa A. Sperling", "Robert Stewart", "Olga Uspenskaya", "Bruno Vellas", "Pieter Jelle Visser", "Michael Wagner", "Subjective Cognitive Decline Initiative (SCD‐I) Working Group"], "year": 2014, "venue": "Alzheimer s & Dementia", "cited_by_count": 2885, "type": "review", "concepts": ["Comparability", "Cognitive decline", "Terminology", "Disease", "Cognition"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2510708214", "doi": "https://doi.org/10.2337/dc13-s011", "title": "Standards of Medical Care in Diabetes—2013", "abstract": "Clear evidence from well-conducted, generalizable RCTs that are adequately powered, including: c Evidence from a well-conducted multicenter trial c Evidence from a meta-analysis that incorporated quality ratings in the analysis Compelling nonexperimental evidence, i.e., \"all or none\" rule developed by the Centre for Evidence-Based Medicine at the University of Oxford Supportive evidence from well-conducted RCTs that are adequately powered, including:", "authors": [], "year": 2012, "venue": "Diabetes Care", "cited_by_count": 4416, "type": "article", "concepts": ["Medicine", "Diabetes mellitus", "MEDLINE", "Family medicine", "Endocrinology"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W4401990587", "doi": "https://doi.org/10.1109/icmew63481.2024.10645451", "title": "Q-Boost: On Visual Quality Assessment Ability of Low-Level Multi-Modality Foundation Models", "abstract": "Recent advancements in Multi-modality Large Language Models (MLLMs) have demonstrated remarkable capabilities in complex high-level vision tasks. However, the exploration of MLLM potential in visual quality assessment, a vital aspect of low-level vision, remains limited. To address this gap, we introduce Q-Boost, a novel strategy designed to enhance low-level MLLMs in image quality assessment (IQA) and video quality assessment (VQA) tasks, which is structured around two pivotal components: 1) Triadic-Tone Integration: Ordinary prompt design simply oscillates between the binary extremes of positive and negative. Q-Boost innovates by incorporating a ‘middle ground’ approach through neutral prompts, allowing for a more balanced and detailed assessment. 2) Multi-Prompt Ensemble: Multiple quality-centric prompts are used to mitigate bias and acquire more accurate evaluation. The experimental results show that the low-level MLLMs exhibit outstanding zeros-shot performance on the IQA/VQA tasks equipped with Q-Boost strategy.", "authors": ["Zicheng Zhang", "Haoning Wu", "Zhongpeng Ji", "Chunyi Li", "Erli Zhang", "Wei Sun", "Xiaohong Liu", "Xiongkuo Min", "Fengyu Sun", "Shangling Jui", "Weisi Lin", "Guangtao Zhai"], "year": 2024, "venue": "", "cited_by_count": 13, "type": "article", "concepts": ["Modality (human–computer interaction)", "Foundation (evidence)", "Computer science", "Quality (philosophy)", "Artificial intelligence"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2150353123", "doi": "https://doi.org/10.2196/jmir.8.2.e9", "title": "eHealth Literacy: Essential Skills for Consumer Health in a Networked World", "abstract": "Electronic health tools provide little value if the intended users lack the skills to effectively engage them. With nearly half the adult population in the United States and Canada having literacy levels below what is needed to fully engage in an information-rich society, the implications for using information technology to promote health and aid in health care, or for eHealth, are considerable. Engaging with eHealth requires a skill set, or literacy, of its own. The concept of eHealth literacy is introduced and defined as the ability to seek, find, understand, and appraise health information from electronic sources and apply the knowledge gained to addressing or solving a health problem. In this paper, a model of eHealth literacy is introduced, comprised of multiple literacy types, including an outline of a set of fundamental skills consumers require to derive direct benefits from eHealth. A profile of each literacy type with examples of the problems patient-clients might present is provided along with a resource list to aid health practitioners in supporting literacy improvement with their patient-clients across each domain. Facets of the model are illustrated through a set of clinical cases to demonstrate how health practitioners can address eHealth literacy issues in clinical or public health practice. Potential future applications of the model are discussed.", "authors": ["Cameron D. Norman", "Harvey A. Skinner"], "year": 2006, "venue": "Journal of Medical Internet Research", "cited_by_count": 2380, "type": "review", "concepts": ["eHealth", "Health literacy", "Literacy", "Health care", "Information literacy"], "search_query": "visual language model image quality assessment"}
{"openalex_id": "https://openalex.org/W2566149141", "doi": "https://doi.org/10.1109/jstsp.2016.2639328", "title": "Fully Deep Blind Image Quality Predictor", "abstract": "In general, owing to the benefits obtained from original information, full-reference image quality assessment (FR-IQA) achieves relatively higher prediction accuracy than no-reference image quality assessment (NR-IQA). By fully utilizing reference images, conventional FR-IQA methods have been investigated to produce objective scores that are close to subjective scores. In contrast, NR-IQA does not consider reference images; thus, its performance is inferior to that of FR-IQA. To alleviate this accuracy discrepancy between FR-IQA and NR-IQA methods, we propose a blind image evaluator based on a convolutional neural network (BIECON). To imitate FR-IQA behavior, we adopt the strong representation power of a deep convolutional neural network to generate a local quality map, similar to FR-IQA. To obtain the best results from the deep neural network, replacing hand-crafted features with automatically learned features is necessary. To apply the deep model to the NR-IQA framework, three critical problems must be resolved: 1) lack of training data; 2) absence of local ground truth targets; and 3) different purposes of feature learning. BIECON follows the FR-IQA behavior using the local quality maps as intermediate targets for conventional neural networks, which leads to NR-IQA prediction accuracy that is comparable with that of state-of-the-art FR-IQA methods.", "authors": ["Jongyoo Kim", "Sanghoon Lee"], "year": 2016, "venue": "IEEE Journal of Selected Topics in Signal Processing", "cited_by_count": 455, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Convolutional neural network", "Image quality", "Pattern recognition (psychology)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2797079651", "doi": "https://doi.org/10.1016/j.patcog.2018.04.016", "title": "Blind image quality prediction by exploiting multi-level deep representations", "abstract": "", "authors": ["Fei Gao", "Jun Yu", "Suguo Zhu", "Qingming Huang", "Qi Tian"], "year": 2018, "venue": "Pattern Recognition", "cited_by_count": 120, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Pattern recognition (psychology)", "Image (mathematics)", "Quality (philosophy)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2971622202", "doi": "https://doi.org/10.1109/access.2019.2938900", "title": "A Survey of DNN Methods for Blind Image Quality Assessment", "abstract": "Blind image quality assessment (BIQA) methods aim to predict quality of images as perceived by humans without access to a reference image. Recently, deep learning methods have gained substantial attention in the research community and have proven useful for BIQA. Although previous study of deep neural networks (DNN) methods is presented, some novelty DNN methods, which are recently proposed, are not summarized for BIQA. In this paper, we provide a survey covering various DNN methods for BIQA. First, we systematically analyze the existing DNN-based quality assessment methods according to the role of DNN. Then, we compare the prediction performance of various DNN methods on the synthetic databases (LIVE, TID2013, CSIQ, LIVE multiply distorted) and authentic databases (LIVE challenge), providing important information that can help understand the underlying properties between different DNN methods for BIQA. Finally, we describe some emerging challenges in designing and training DNN-based BIQA, along with few directions that are worth further investigations in the future.", "authors": ["Xiaohan Yang", "Fan Li", "Hantao Liu"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 73, "type": "article", "concepts": ["Novelty", "Computer science", "Artificial intelligence", "Artificial neural network", "Image quality"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2083704334", "doi": "https://doi.org/10.1109/icip.2014.7025102", "title": "Deep learning network for blind image quality assessment", "abstract": "Nowadays, blind image quality assessment (BIQA) has been intensively studied with machine learning, such as support vector machine (SVM) and k-means. Existing BIQA metrics, however, do not perform robust for various kinds of distortion types. We believe this problem is because those frequently used traditional machine learning techniques exploit shallow architectures, which only contain one single layer of nonlinear feature transformation, and thus cannot highly mimic the mechanism of human visual perception to image quality. The recent advance of deep neural network (DNN) can help to solve this problem, since the DNN is found to better capture the essential attributes of images. We in this paper therefore introduce a new Deep learning based Image Quality Index (DIQI) for blind quality assessment. Extensive studies are conducted on the new TID2013 database and confirm the effectiveness of our DIQI relative to classical full-reference and state-of-the-art reduced- and no-reference IQA approaches.", "authors": ["Ke Gu", "Guangtao Zhai", "Xiaokang Yang", "Wenjun Zhang"], "year": 2014, "venue": "", "cited_by_count": 61, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Distortion (music)", "Support vector machine", "Machine learning"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3193517049", "doi": "https://doi.org/10.1109/iccv48922.2021.01008", "title": "Learning Conditional Knowledge Distillation for Degraded-Reference Image Quality Assessment", "abstract": "An important scenario for image quality assessment (IQA) is to evaluate image restoration (IR) algorithms. The state-of-the-art approaches adopt a full-reference paradigm that compares restored images with their corresponding pristine-quality images. However, pristine-quality images are usually unavailable in blind image restoration tasks and real-world scenarios. In this paper, we propose a practical solution named degraded-reference IQA (DR-IQA), which exploits the inputs of IR models, degraded images, as references. Specifically, we extract reference information from degraded images by distilling knowledge from pristine-quality images. The distillation is achieved through learning a reference space, where various degraded images are encouraged to share the same feature statistics with pristine-quality images. And the reference space is optimized to capture deep image priors that are useful for quality assessment. Note that pristine-quality images are only used during training. Our work provides a powerful and differentiable metric for blind IRs, especially for GAN-based methods. Extensive experiments show that our results can even be close to the performance of full-reference settings.", "authors": ["Heliang Zheng", "Huan Yang", "Jianlong Fu", "Zheng-Jun Zha", "Jiebo Luo"], "year": 2021, "venue": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "cited_by_count": 52, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Metric (unit)", "Image quality", "Quality (philosophy)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2963833613", "doi": "https://doi.org/10.1016/j.mri.2018.07.003", "title": "A machine-learning framework for automatic reference-free quality assessment in MRI", "abstract": "", "authors": ["Thomas Küstner", "Sergios Gatidis", "Annika Liebgott", "Martin Schwartz", "Lars Mauch", "Petros Martirosian", "H. R. Schmidt", "NF Schwenzer", "Konstantin Nikolaou", "Fabian Bamberg", "Bin Yang", "Fritz Schick"], "year": 2018, "venue": "Magnetic Resonance Imaging", "cited_by_count": 61, "type": "article", "concepts": ["Computer science", "Image quality", "Artificial intelligence", "Quality assurance", "Scanner"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3016917677", "doi": "https://doi.org/10.1016/j.ins.2020.04.030", "title": "Blind quality assessment for image superresolution using deep two-stream convolutional networks", "abstract": "", "authors": ["Wei Zhou", "Qiuping Jiang", "Yuwang Wang", "Zhibo Chen", "Weiping Li"], "year": 2020, "venue": "Information Sciences", "cited_by_count": 77, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Discriminative model", "Convolutional neural network", "Pattern recognition (psychology)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2752223497", "doi": "https://doi.org/10.48550/arxiv.1708.08190", "title": "A Probabilistic Quality Representation Approach to Deep Blind Image Quality Prediction", "abstract": "Blind image quality assessment (BIQA) remains a very challenging problem due to the unavailability of a reference image. Deep learning based BIQA methods have been attracting increasing attention in recent years, yet it remains a difficult task to train a robust deep BIQA model because of the very limited number of training samples with human subjective scores. Most existing methods learn a regression network to minimize the prediction error of a scalar image quality score. However, such a scheme ignores the fact that an image will receive divergent subjective scores from different subjects, which cannot be adequately represented by a single scalar number. This is particularly true on complex, real-world distorted images. Moreover, images may broadly differ in their distributions of assigned subjective scores. Recognizing this, we propose a new representation of perceptual image quality, called probabilistic quality representation (PQR), to describe the image subjective score distribution, whereby a more robust loss function can be employed to train a deep BIQA model. The proposed PQR method is shown to not only speed up the convergence of deep model training, but to also greatly improve the achievable level of quality prediction accuracy relative to scalar quality score regression methods. The source code is available at https://github.com/HuiZeng/BIQA_Toolbox.", "authors": ["Hui Zeng", "Lei Zhang", "Alan C. Bovik"], "year": 2017, "venue": "arXiv (Cornell University)", "cited_by_count": 61, "type": "preprint", "concepts": ["Probabilistic logic", "Artificial intelligence", "Quality (philosophy)", "Computer science", "Representation (politics)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2296265007", "doi": "https://doi.org/10.1109/icip.2015.7351221", "title": "Difference of Gaussian statistical features based blind image quality assessment: A deep learning approach", "abstract": "Nowadays, natural scene statistics (NSS) based blind image quality assessment (BIQA) models trained by machine learning, tend to achieve excellent performance. However, BIQA is still a very challenging research topic due to the lack of reference images. The key of further improvement lies in feature mining and pooling strategy decision. In this work, a new BIQA model is proposed to utilize local normalized multi-scale difference of Gaussian (DoG) response in distorted images as features which show a high correlation with perceptual quality. Then, a three-step-framework based deep neural network (DNN) is designed and employed as the pooling strategy. Compared with the support vector machine (SVM), the proposed three-step-framework DNN can excavate better feature representation, leading to more accurate predictions and stronger generalization ability. The proposed model achieves state-of-the-art performance on two authoritative databases and excellent generalization ability in cross database experiments.", "authors": ["Yaqi Lv", "Gangyi Jiang", "Mei Yu", "Haiyong Xu", "Feng Shao", "Shanshan Liu"], "year": 2015, "venue": "", "cited_by_count": 45, "type": "article", "concepts": ["Pooling", "Computer science", "Support vector machine", "Artificial intelligence", "Generalization"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2925250639", "doi": "https://doi.org/10.1109/access.2019.2905615", "title": "No-Reference Quality Assessment for Pansharpened Images via Opinion-Unaware Learning", "abstract": "The high-quality pansharpened image with both high spatial resolution and high spectral fidelity is highly desirable in various applications. However, existing pansharpening methods may lead to spatial distortion and spectral distortion. To measure the degrees of distortion caused by the pansharpening methods, we conduct in-deep studies on the subjective and objective quality assessment of pansharpened images. We built a subjective database consisting of 360 images generated from 20 couples of panchromatic (PAN)/multispectral (MS) images using 18 pansharpening methods. Based on the database, we proposed a no-reference quality assessment method to blindly predict the quality of pansharpened images via opinion-unaware learning. The proposed method first extracted features from the MS images' spectral bands and typical information indexes which comprehensively reflect spatial distortion, spectral distortion, and the effects of pansharpening on applications. Based on the features extracted from the pristine MS image training dataset, a benchmark multivariate Gaussian (MVG) model is learned. The distance between the benchmark MVG and the MVG fitted on the test image is calculated to measure the quality. The experimental results show the superiority of our method on our database.", "authors": ["Bingzhong Zhou", "Feng Shao", "Xiangchao Meng", "Randi Fu", "Yo‐Sung Ho"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 21, "type": "article", "concepts": ["Panchromatic film", "Multispectral image", "Computer science", "Artificial intelligence", "Distortion (music)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2793583884", "doi": "https://doi.org/10.1109/icip.2017.8296869", "title": "Deep blind image quality assessment by employing FR-IQA", "abstract": "In this paper, we propose a convolutional neural network (CNN)-based no-reference image quality assessment (NR-IQA). Though deep learning has yielded superior performance in a number of computer vision studies, applying the deep CNN to the NR-IQA framework is not straightforward, since we face a few critical problems: 1) lack of training data; 2) absence of local ground truth targets. To alleviate these problems, we employ the full-reference image quality assessment (FR-IQA) metrics as intermediate training targets of the CNN. In addition, we incorporate the pooling stage in the training stage, so that the whole parameters of the model can be optimized in an end-to-end framework. The proposed model, named as a blind image evaluator based on a convolutional neural network (BIECON), achieves state-of-the-art prediction accuracy that is comparable with that of FR-IQA methods.", "authors": ["Jongyoo Kim", "Sanghoon Lee"], "year": 2017, "venue": "", "cited_by_count": 21, "type": "article", "concepts": ["Computer science", "Convolutional neural network", "Pooling", "Artificial intelligence", "Deep learning"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4292559719", "doi": "https://doi.org/10.1016/j.imed.2022.08.001", "title": "Automated assessment of transthoracic echocardiogram image quality using deep neural networks", "abstract": "", "authors": ["Robert B. Labs", "Apostolos Vrettos", "Jonathan Loo", "Massoud Zolgharni"], "year": 2022, "venue": "Intelligent Medicine", "cited_by_count": 20, "type": "article", "concepts": ["Image quality", "Computer science", "Artificial intelligence", "Transthoracic echocardiogram", "Deep learning"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3149775056", "doi": "https://doi.org/10.1109/tpami.2021.3071759", "title": "Active Fine-Tuning from gMAD Examples Improves Blind Image Quality Assessment", "abstract": "The research in image quality assessment (IQA) has a long history, and significant progress has been made by leveraging recent advances in deep neural networks (DNNs). Despite high correlation numbers on existing IQA datasets, DNN-based models may be easily falsified in the group maximum differentiation (gMAD) competition. Here we show that gMAD examples can be used to improve blind IQA (BIQA) methods. Specifically, we first pre-train a DNN-based BIQA model using multiple noisy annotators, and fine-tune it on multiple synthetically distorted images, resulting in a \"top-performing\" baseline model. We then seek pairs of images by comparing the baseline model with a set of full-reference IQA methods in gMAD. The spotted gMAD examples are most likely to reveal the weaknesses of the baseline, and suggest potential ways for refinement. We query human quality annotations for the selected images in a well-controlled laboratory environment, and further fine-tune the baseline on the combination of human-rated images from gMAD and existing databases. This process may be iterated, enabling active fine-tuning from gMAD examples for BIQA. We demonstrate the feasibility of our active learning scheme on a large-scale unlabeled image set, and show that the fine-tuned quality model achieves improved generalizability in gMAD, without destroying performance on previously seen databases.", "authors": ["Zhihua Wang", "Kede Ma"], "year": 2021, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 30, "type": "article", "concepts": ["Computer science", "Generalizability theory", "Artificial intelligence", "Set (abstract data type)", "Image quality"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3212793811", "doi": "https://doi.org/10.1109/tcsvt.2021.3128014", "title": "Multi-Angle Projection Based Blind Omnidirectional Image Quality Assessment", "abstract": "Most of the existing blind omnidirectional image quality assessment (BOIQA) methods are based on data-driven approach where the end-to-end neural network or deep learning tools are mainly used for feature extraction. However, it usually lacks interpretability and is difficult to discover the perceptual mechanism behind. In this paper, from the perspective of perception modeling, we propose a novel multi-angle projection based BOIQA (MP-BOIQA) method. Considering the omnibearing and near eye display characteristics with head mounted display, multiple color cubemap projection images with respect to different viewpoints are grouped as the color omnidirectional distortion (COD) units so as to simulate the user’s viewing behavior in subjective quality assessment. In the designed multi-angle projection based feature extractor, tensor decomposition is implemented on each COD unit for dimensionality reduction, and piecewise exponential fitting is used to get the distribution of mean subtracted contrast normalized coefficients of the unit’s feature matrices in tensor domain. Finally, the extracted features are pooled with random forest. The experimental results on three omnidirectional image quality datasets show that the MP-BOIQA method can deliver highly competitive performance compared with some representative full-reference quality assessment methods, as well as some state-of-the-art BOIQA methods.", "authors": ["Hao Jiang", "Gangyi Jiang", "Mei Yu", "Ting Luo", "Haiyong Xu"], "year": 2021, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 21, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Computer vision", "Projection (relational algebra)", "Feature extraction"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4210559218", "doi": "https://doi.org/10.1007/s00500-021-06662-9", "title": "Deep ensembling for perceptual image quality assessment", "abstract": "", "authors": ["Nisar Ahmed", "Hafiz Muhammad Shahzad Asif", "Abdul Rauf Bhatti", "Atif Khan"], "year": 2022, "venue": "Soft Computing", "cited_by_count": 20, "type": "article", "concepts": ["Computer science", "Benchmark (surveying)", "Artificial intelligence", "Distortion (music)", "Generalization"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4206481149", "doi": "https://doi.org/10.1016/s0140-6736(21)00218-x", "title": "Parkinson's disease", "abstract": "", "authors": ["Bastiaan R. Bloem", "Michael S. Okun", "Christine Klein"], "year": 2021, "venue": "The Lancet", "cited_by_count": 3263, "type": "review", "concepts": ["Disease", "Parkinson's disease", "Medicine", "Parkinsonism", "Levodopa"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2922226472", "doi": "https://doi.org/10.1109/istel.2018.8661024", "title": "No-Reference Image Quality Assessment using Transfer Learning", "abstract": "With the recent advancements in deep learning, high performance neural networks have been introduced. These neural networks also can be used to solve similar problems in a transfer learning approach. Recently, several state-of-the-art Convolutional Neural Networks (CNNs) are proposed for computer vision tasks. On the other hand, in-the-wild No-Reference (Blind) Image Quality Assessment (NR-IQA) problem is known as a challenging human perceptual problem. In this paper, a transfer learning approach is used to solve the problem of in-the-wild NR-IQA. With a few training times, the proposed neural network exceeds all the previous methods which are not using deep neural networks. Further, the proposed method predicts the opinion score distribution in its output which has more valuable information than single Mean Opinion Score (MOS). Moreover, the proposed method can accept arbitrary image size in its input which is often not applicable in the most CNNs which have a certain output size.", "authors": ["Hatef Otroshi Shahreza", "Arash Amini", "Hamid Behroozi"], "year": 2018, "venue": "", "cited_by_count": 17, "type": "article", "concepts": ["Transfer of learning", "Convolutional neural network", "Computer science", "Artificial intelligence", "Artificial neural network"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4385574853", "doi": "https://doi.org/10.1109/tmm.2023.3301276", "title": "Going the Extra Mile in Face Image Quality Assessment: A Novel Database and Model", "abstract": "An accurate computational model for image quality assessment (IQA) benefits many vision applications, such as image filtering, image processing, and image generation. Although the study of face images is an important subfield in computer vision research, the lack of face IQA data and models limits the precision of current IQA metrics on face image processing tasks such as face superresolution, face enhancement, and face editing. To narrow this gap, in this article, we first introduce the largest annotated IQA database developed to date, which contains 20,000 human faces – an order of magnitude larger than all existing rated datasets of faces – of diverse individuals in highly varied circumstances. Based on the database, we further propose a novel deep learning model to accurately predict face image quality, which, for the first time, explores the use of generative priors for IQA. By taking advantage of rich statistics encoded in well pretrained off-the-shelf generative models, we obtain generative prior information and use it as latent references to facilitate blind IQA. The experimental results demonstrate both the value of the proposed dataset for face IQA and the superior performance of the proposed model.", "authors": ["Shaolin Su", "Hanhe Lin", "Vlad Hosu", "Oliver Wiedemann", "Jinqiu Sun", "Yu Zhu", "Hantao Liu", "Yanning Zhang", "Dietmar Saupe"], "year": 2023, "venue": "IEEE Transactions on Multimedia", "cited_by_count": 19, "type": "article", "concepts": ["Computer science", "Face (sociological concept)", "Artificial intelligence", "Image quality", "Generative model"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3217519524", "doi": "https://doi.org/10.1016/j.image.2021.116576", "title": "QL-IQA: Learning distance distribution from quality levels for blind image quality assessment", "abstract": "", "authors": ["Rui Gao", "Ziqing Huang", "Shiguang Liu"], "year": 2021, "venue": "Signal Processing Image Communication", "cited_by_count": 14, "type": "article", "concepts": ["Quality Score", "Image quality", "Artificial intelligence", "Computer science", "Distortion (music)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4327946446", "doi": "https://doi.org/10.3390/healthcare11060887", "title": "ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns", "abstract": "ChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and development); (3) benefits in health care practice (streamlining the workflow, cost saving, documentation, personalized medicine, and improved health literacy); and (4) benefits in health care education including improved personalized learning and the focus on critical thinking and problem-based learning. Concerns regarding ChatGPT use were stated in 58/60 (96.7%) records including ethical, copyright, transparency, and legal issues, the risk of bias, plagiarism, lack of originality, inaccurate content with risk of hallucination, limited knowledge, incorrect citations, cybersecurity issues, and risk of infodemics. The promising applications of ChatGPT can induce paradigm shifts in health care education, research, and practice. However, the embrace of this AI chatbot should be conducted with extreme caution considering its potential limitations. As it currently stands, ChatGPT does not qualify to be listed as an author in scientific articles unless the ICMJE/COPE guidelines are revised or amended. An initiative involving all stakeholders in health care education, research, and practice is urgently needed. This will help to set a code of ethics to guide the responsible use of ChatGPT among other LLMs in health care and academia.", "authors": ["Malik Sallam"], "year": 2023, "venue": "Healthcare", "cited_by_count": 2517, "type": "review", "concepts": ["Health care", "Documentation", "MEDLINE", "Context (archaeology)", "Medical education"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3147474004", "doi": "https://doi.org/10.1109/tmm.2021.3068561", "title": "Motion Blur Removal With Quality Assessment Guidance", "abstract": "Non-uniform blind motion deblurring is a challenging yet fundamental task in the computer vision field, which aims to restore the latent sharp image from the blurry input. Recently, deep-learning-based methods have made significant improvement and progress, on the metric of PSNR. They achieve good results mainly because they adopt Mean Squared Error (MSE) as the optimization objective, in addition to their good model design. However, simple adoption of the PSNR metric and the MSE loss, has non-ignorable disadvantages. PSNR cannot always succeed in assessing the deblurred quality in accordance with the human visual system (HVS), and MSE guides the network to generate over-smoothed images. To address these problems, we are the first to propose the deep-learning-based multi-scale non-reference quality assessment network (Deep DEBLUR-IQA) for assessing the quality of deblurred results. Moreover, a deblurring network of high efficiency is presented. It is more than 50 times faster than other SOTA multi-scale Convolution Neural Network (CNN) methods, with the newly propose Residual Dilated Block (RDB) and Light ResBlock (LRB). The deblurring network's performance can be further boosted with Multiple Dilation Block (MDB), with an acceptable speed decrease. Finally, and most importantly, we are the first to let Deep DEBLUR-IQA guide the deblurring network's optimization. This IQA-guided enhancement paradigm can significantly improve the deblurring results’ subjective quality while achieving excellent PSNR. Experimental results demonstrate that the proposed method performs favorably against state-of-the-art methods quantitatively and qualitatively.", "authors": ["Jichun Li", "Bo Yan", "Qing Lin", "Ang Li", "Chenxi Ma"], "year": 2021, "venue": "IEEE Transactions on Multimedia", "cited_by_count": 17, "type": "article", "concepts": ["Deblurring", "Computer science", "Artificial intelligence", "Residual", "Metric (unit)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2974196484", "doi": "https://doi.org/10.1016/j.ophtha.2019.09.014", "title": "An Ophthalmologist's Guide to Deciphering Studies in Artificial Intelligence", "abstract": "", "authors": ["Daniel Shu Wei Ting", "Aaron Lee", "Tien Yin Wong"], "year": 2019, "venue": "Ophthalmology", "cited_by_count": 54, "type": "editorial", "concepts": ["Artificial intelligence", "Scopus", "Deep learning", "Medicine", "Scheimpflug principle"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2751069891", "doi": "https://doi.org/10.1038/sdata.2017.117", "title": "Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features", "abstract": "", "authors": ["Spyridon Bakas", "Hamed Akbari", "Aristeidis Sotiras", "Michel Bilello", "Martin Rozycki", "Justin Kirby", "John Freymann", "Keyvan Farahani", "Christos Davatzikos"], "year": 2017, "venue": "Scientific Data", "cited_by_count": 2781, "type": "article", "concepts": ["Glioma", "Segmentation", "Neuroradiologist", "Glioblastoma", "Magnetic resonance imaging"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2952218014", "doi": "https://doi.org/10.1109/taslp.2019.2915167", "title": "Conv-TasNet: Surpassing Ideal Time–Frequency Magnitude Masking for Speech Separation", "abstract": "Single-channel, speaker-independent speech separation methods have recently seen great progress. However, the accuracy, latency, and computational cost of such methods remain insufficient. The majority of the previous methods have formulated the separation problem through the time-frequency representation of the mixed signal, which has several drawbacks, including the decoupling of the phase and magnitude of the signal, the suboptimality of time-frequency representation for speech separation, and the long latency of the entire system. To address these shortcomings, we propose a fully-convolutional time-domain audio separation network (Conv-TasNet), a deep learning framework for end-to-end time-domain speech separation. Conv-TasNet uses a linear encoder to generate a representation of the speech waveform optimized for separating individual speakers. Speaker separation is achieved by applying a set of weighting functions (masks) to the encoder output. The modified encoder representations are then inverted back to the waveforms using a linear decoder. The masks are found using a temporal convolutional network (TCN) consisting of stacked 1-D dilated convolutional blocks, which allows the network to model the long-term dependencies of the speech signal while maintaining a small model size. The proposed Conv-TasNet system significantly outperforms previous time-frequency masking methods in separating two- and three-speaker mixtures. Additionally, Conv-TasNet surpasses several ideal time-frequency magnitude masks in two-speaker speech separation as evaluated by both objective distortion measures and subjective quality assessment by human listeners. Finally, Conv-TasNet has a significantly smaller model size and a much shorter minimum latency, making it a suitable solution for both offline and real-time speech separation applications. This study therefore represents a major step toward the realization of speech separation systems for real-world speech processing technologies.", "authors": ["Yi Luo", "Nima Mesgarani"], "year": 2019, "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing", "cited_by_count": 1952, "type": "article", "concepts": ["Magnitude (astronomy)", "Ideal (ethics)", "Masking (illustration)", "Separation (statistics)", "Speech recognition"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4384071683", "doi": "https://doi.org/10.1038/s41586-023-06291-2", "title": "Large language models encode clinical knowledge", "abstract": "", "authors": ["Karan Singhal", "Shekoofeh Azizi", "Tao Tu", "S. Sara Mahdavi", "Jason Lee", "Hyung Won Chung", "Nathan Scales", "Ajay Kumar Tanwani", "Heather Cole-Lewis", "Stephen Pfohl", "Perry W. Payne", "Martin Seneviratne", "Paul Gamble", "Christopher Kelly", "Abubakr Babiker", "Nathanael Schärli", "Aakanksha Chowdhery", "P. Mansfield", "Dina Demner‐Fushman", "Blaise Agüera y Arcas", "Dale R. Webster", "Greg S. Corrado", "Yossi Matias", "Katherine Chou", "Juraj Gottweis", "Nenad Tomašev", "Yun Liu", "Alvin Rajkomar", "Joëlle Barral", "Christopher Semturs", "Alan Karthikesalingam", "Vivek Natarajan"], "year": 2023, "venue": "Nature", "cited_by_count": 2617, "type": "article", "concepts": ["Computer science", "Benchmark (surveying)", "Language model", "Comprehension", "Artificial intelligence"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4324046518", "doi": "https://doi.org/10.1080/14703297.2023.2190148", "title": "Chatting and cheating: Ensuring academic integrity in the era of ChatGPT", "abstract": "The use of artificial intelligence in academia is a hot topic in the education field. ChatGPT is an AI tool that offers a range of benefits, including increased student engagement, collaboration, and accessibility. However, is also raises concerns regarding academic honesty and plagiarism. This paper examines the opportunities and challenges of using ChatGPT in higher education, and discusses the potential risks and rewards of these tools. The paper also considers the difficulties of detecting and preventing academic dishonesty, and suggests strategies that universities can adopt to ensure ethical and responsible use of these tools. These strategies include developing policies and procedures, providing training and support, and using various methods to detect and prevent cheating. The paper concludes that while the use of AI in higher education presents both opportunities and challenges, universities can effectively address these concerns by taking a proactive and ethical approach to the use of these tools.", "authors": ["Debby Cotton", "Peter A. Cotton", "J. Reuben Shipway"], "year": 2023, "venue": "Innovations in Education and Teaching International", "cited_by_count": 1714, "type": "article", "concepts": ["Cheating", "Academic dishonesty", "Academic integrity", "Honesty", "Engineering ethics"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2077663753", "doi": "https://doi.org/10.1371/journal.pmed.1001744", "title": "Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies: The CHARMS Checklist", "abstract": "Carl Moons and colleagues provide a checklist and background explanation for critically appraising and extracting data from systematic reviews of prognostic and diagnostic prediction modelling studies. Please see later in the article for the Editors' Summary.", "authors": ["Karel G. M. Moons", "Joris A. H. de Groot", "Walter Bouwmeester", "Yvonne Vergouwe", "Susan Mallett", "Douglas G. Altman", "Johannes B. Reitsma", "Gary S. Collins"], "year": 2014, "venue": "PLoS Medicine", "cited_by_count": 1804, "type": "article", "concepts": ["Checklist", "Critical appraisal", "Data extraction", "Systematic review", "MEDLINE"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2891125414", "doi": "https://doi.org/10.1016/s2214-109x(18)30386-3", "title": "High-quality health systems in the Sustainable Development Goals era: time for a revolution", "abstract": "", "authors": ["Margaret E. Kruk", "Anna Gage", "Catherine Arsenault", "Keely Jordan", "Hannah H. Leslie", "Sanam Roder‐DeWan", "Olusoji Adeyi", "Pierre Barker", "Bernadette Daelmans", "Svetlana V. Doubova", "Mike English", "Ezequiel García‐Elorrio", "Frederico Guanais", "Oye Gureje", "Lisa R. Hirschhorn", "Lixin Jiang", "Edward Kelley", "Ephrem Tekle Lemango", "Jerker Liljestrand", "Address Malata", "Tanya Marchant", "Malebona Precious Matsoso", "John G. Meara", "Manoj Mohanan", "Youssoupha Ndiaye", "Ole Frithjof Norheim", "K. Srinath Reddy", "Alexander K. Rowe", "Joshua A. Salomon", "Gagan Thapa", "Nana Twum-Danso", "Muhammad Ali Pate"], "year": 2018, "venue": "The Lancet Global Health", "cited_by_count": 3583, "type": "review", "concepts": ["Sustainable development", "Quality (philosophy)", "MEDLINE", "Environmental health", "Business"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2766166720", "doi": "https://doi.org/10.1053/j.gastro.2017.10.026", "title": "Will Computer-Aided Detection and Diagnosis Revolutionize Colonoscopy?", "abstract": "", "authors": ["Michael F. Byrne", "Neal Shahidi", "Douglas K. Rex"], "year": 2017, "venue": "Gastroenterology", "cited_by_count": 74, "type": "editorial", "concepts": ["Colonoscopy", "Medicine", "Colorectal cancer", "Colorectal Polyp", "Adenoma"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3043135743", "doi": "https://doi.org/10.1371/journal.pbio.3000411", "title": "Reporting animal research: Explanation and elaboration for the ARRIVE guidelines 2.0", "abstract": "Improving the reproducibility of biomedical research is a major challenge. Transparent and accurate reporting is vital to this process; it allows readers to assess the reliability of the findings and repeat or build upon the work of other researchers. The ARRIVE guidelines (Animal Research: Reporting In Vivo Experiments) were developed in 2010 to help authors and journals identify the minimum information necessary to report in publications describing in vivo experiments. Despite widespread endorsement by the scientific community, the impact of ARRIVE on the transparency of reporting in animal research publications has been limited. We have revised the ARRIVE guidelines to update them and facilitate their use in practice. The revised guidelines are published alongside this paper. This explanation and elaboration document was developed as part of the revision. It provides further information about each of the 21 items in ARRIVE 2.0, including the rationale and supporting evidence for their inclusion in the guidelines, elaboration of details to report, and examples of good reporting from the published literature. This document also covers advice and best practice in the design and conduct of animal studies to support researchers in improving standards from the start of the experimental design process through to publication.", "authors": ["Nathalie Percie du Sert", "Amrita Ahluwalia", "Sabina Alam", "Marc T. Avey", "Monya Baker", "William J. Browne", "Alejandra Clark", "Innes C. Cuthill", "Ulrich Dirnagl", "Michael Emerson", "Paul Garner", "Stephen T. Holgate", "David W. Howells", "Viki Hurst", "Natasha A. Karp", "Stanley E. Lazic", "Katie Lidster", "Catriona MacCallum", "Malcolm Macleod", "Esther J. Pearl", "Ole H. Petersen", "Frances Rawle", "Penny S. Reynolds", "Kieron Rooney", "Emily S. Sena", "Shai D. Silberberg", "Thomas Steckler", "Hanno Würbel"], "year": 2020, "venue": "PLoS Biology", "cited_by_count": 2635, "type": "article", "concepts": ["Elaboration", "Transparency (behavior)", "Process (computing)", "Reliability (semiconductor)", "Computer science"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3005342638", "doi": "https://doi.org/10.1109/icivc47709.2019.8981378", "title": "Towards Content Independent No-reference Image Quality Assessment Using Deep Learning", "abstract": "The study of image quality assessment (IQA) is divided on natural scene and document images which are processed using different models and quality metrics. This casts challenges for the development of content-independent no-reference (NR) IQA models which can operate on different types of images without requiring information regarding the content of the images. In this paper we propose a unified no-reference image quality assessment (UIQA) model using a deep learning approach, where a generalization of NR IQA across natural scene and document images is achieved using a deep convolutional neural network (DCNN). Without having to discriminate the type of the images, the proposed model can assess the quality of natural scene and document images in a blind and uniform manner. Testing results on two benchmarking datasets demonstrate that the proposed model achieves promising performances competitive with the state-of-the-art simultaneously on natural scene and document images.", "authors": ["Tan Lu", "Ann Dooms"], "year": 2019, "venue": "", "cited_by_count": 7, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Convolutional neural network", "Generalization", "Deep learning"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2888424632", "doi": "https://doi.org/10.1038/s41746-018-0040-6", "title": "Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices", "abstract": "", "authors": ["Michael D. Abràmoff", "Philip T. Lavin", "Michele Birch", "Nilay Shah", "James C. Folk"], "year": 2018, "venue": "npj Digital Medicine", "cited_by_count": 1387, "type": "article", "concepts": ["Medicine", "Diabetic retinopathy", "Fundus photography", "Specialty", "Optometry"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4231972505", "doi": "https://doi.org/10.1136/annrheumdis-2019-216655", "title": "EULAR recommendations for the management of rheumatoid arthritis with synthetic and biological disease-modifying antirheumatic drugs: 2019 update", "abstract": "", "authors": ["Josef S Smolen", "Robert Landewé", "J. W. J. Bijlsma", "Gerd R Burmester", "Maxime Dougados", "Andreas Kerschbaumer", "Iain B. McInnes", "Alexandre Sepriano", "Ronald van Vollenhoven", "Maarten de Wit", "Daniel Aletaha", "Martin Aringer", "Johan Askling", "Alejandro Balsa", "Maarten Boers", "Alfons A den Broeder", "Maya H Buch", "Frank Buttgereit", "Roberto Caporali", "Myrna Cardiel", "Diederik De Cock", "Cătălin Codreanu", "Maurizio Cutolo", "Christopher J Edwards", "Yvonne van Eijk‐Hustings", "Paul Emery", "Axel Finckh", "Laure Gossec", "Jacques‐Eric Gottenberg", "Merete Lund Hetland", "T. Huizinga", "Marios Koloumas", "Zhanguo Li", "Xavier Mariette", "Ulf Müller‐Ladner", "Eduardo Mysler", "José António Pereira da Silva", "Gyula Poór", "Janet Pope", "Andrea Rubbert‐Roth", "Adeline Ruyssen‐Witrand", "Kenneth G. Saag", "Anja Strangfeld", "Tsutomu Takeuchi", "Marieke Voshaar", "René Westhovens", "Désirée van der Heijde"], "year": 2020, "venue": "Annals of the Rheumatic Diseases", "cited_by_count": 2633, "type": "article", "concepts": ["Medicine", "Antirheumatic drugs", "Rheumatoid arthritis", "Antirheumatic Agents", "Disease management"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4297148103", "doi": "https://doi.org/10.3390/app12199567", "title": "A Visual Saliency-Based Neural Network Architecture for No-Reference Image Quality Assessment", "abstract": "Deep learning has recently been used to study blind image quality assessment (BIQA) in great detail. Yet, the scarcity of high-quality algorithms prevents from developing them further and being used in a real-time scenario. Patch-based techniques have been used to forecast the quality of an image, but they typically award the picture quality score to an individual patch of the image. As a result, there would be a lot of misleading scores coming from patches. Some regions of the image are important and can contribute highly toward the right prediction of its quality. To prevent outlier regions, we suggest a technique with a visual saliency module which allows the only important region to bypass to the neural network and allows the network to only learn the important information required to predict the quality. The neural network architecture used in this study is Inception-ResNet-v2. We assess the proposed strategy using a benchmark database (KADID-10k) to show its efficacy. The outcome demonstrates better performance compared with certain popular no-reference IQA (NR-IQA) and full-reference IQA (FR-IQA) approaches. This technique is intended to be utilized to estimate the quality of an image being acquired in real time from drone imagery.", "authors": ["Jihyoung Ryu"], "year": 2022, "venue": "Applied Sciences", "cited_by_count": 10, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Image quality", "Artificial neural network", "Benchmark (surveying)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2105932465", "doi": "https://doi.org/10.1002/hep.27210", "title": "Hepatic encephalopathy in chronic liver disease: 2014 Practice Guideline by the American Association for the Study Of Liver Diseases and the European Association for the Study of the Liver", "abstract": "The AASLD/EASL Practice Guideline Subcommittee on Hepatic Encephalopathy are: Jayant A. Talwalkar (Chair, AASLD), Hari S. Conjeevaram, Michael Porayko, Raphael B. Merriman, Peter L.M. Jansen, and Fabien Zoulim. This guideline has been approved by the American Association for the Study of Liver Diseases and the European Association for the Study of the Liver and represents the position of both associations. These recommendations provide a data-supported approach. They are based on the following: (1) formal review and analysis of the recently published world literature on the topic; (2) guideline policies covered by the American Association for the Study of Liver Diseases/European Association for the Study of the Liver (AASLD/EASL) Policy on the Joint Development and Use of Practice Guidelines; and (3) the experience of the authors in the specified topic. Intended for use by physicians, these recommendations suggest preferred approaches to the diagnostic, therapeutic, and preventive aspects of care. They are intended to be flexible, in contrast to standards of care, which are inflexible policies to be followed in every case. Specific recommendations are based on relevant published information. To more fully characterize the available evidence supporting the recommendations, the AASLD/EASL Practice Guidelines Subcommittee has adopted the classification used by the Grading of Recommendation Assessment, Development, and Evaluation (GRADE) workgroup, with minor modifications (Table 1). The classifications and recommendations are based on three categories: the source of evidence in levels I through III; the quality of evidence designated by high (A), moderate (B), or low quality (C); and the strength of recommendations classified as strong (1) or weak (2). The literature databases and search strategies are outlined below. The resulting literature database was available to all members of the writing group (i.e., the authors). They selected references within their field of expertise and experience and graded the references according to the GRADE system.1 The selection of references for the guideline was based on a validation of the appropriateness of the study design for the stated purpose, a relevant number of patients under study, and confidence in the participating centers and authors. References on original data were preferred and those that were found unsatisfactory in any of these respects were excluded from further evaluation. There may be limitations in this approach when recommendations are needed on rare problems or problems on which scant original data are available. In such cases, it may be necessary to rely on less-qualified references with a low grading. As a result of the important changes in the treatment of complications of cirrhosis (renal failure, infections, and variceal bleeding [VB]), studies performed more than 30 years ago have generally not been considered for these guidelines. Hepatic encephalopathy (HE) is a frequent complication and one of the most debilitating manifestations of liver disease, severely affecting the lives of patients and their caregivers. Furthermore, cognitive impairment associated with cirrhosis results in utilization of more health care resources in adults than other manifestations of liver disease.2 Progress in the area has been hindered by the complex pathogenesis that is not yet fully elucidated. Apart from such biological factors, there remains the larger obstacle that there are no universally accepted standards for the definition, diagnosis, classification, or treatment of HE, mostly as a result of insufficient clinical studies and standardized definitions. Clinical management tends to be dependent on local standards and personal views. This is an unfavorable situation for patients and contrasts with the severity of the condition and the high level of standardization in other complications of cirrhosis. The lack of consistency in the nomenclature and general standards renders comparisons among studies and patient populations difficult, introduces bias, and hinders progress in clinical research for HE. The latest attempts to standardize the nomenclature were published in 2002 and suggestions for the design of HE trials in 2011. Because there is an unmet need for recommendations on the clinical management of HE, the EASL and the AASLD jointly agreed to create these practice guidelines. It is beyond the scope of these guidelines to elaborate on the theories of pathogenesis of HE, as well as the management of encephalopathy resulting from acute liver failure (ALF), which has been published as guidelines recently. Rather, its aim is to present standardized terminology and recommendations to all health care workers who have patients with HE, regardless of their medical discipline, and focus on adult patients with chronic liver disease (CLD), which is, by far, the most frequent scenario. As these guidelines on HE were created, the authors found a limited amount of high-quality evidence to extract from the existing literature. There are many reasons for this; the elusive character of HE is among them, as well as the lack of generally accepted and utilized terms for description and categorization of HE. This makes a practice guideline all the more necessary for future improvement of clinical studies and, subsequently, the quality of management of patients with HE. With the existing body of evidence, these guidelines encompass the authors' best, carefully considered opinions. Although not all readers may necessarily agree with all aspects of the guidelines, their creation and adherence to them is the best way forward, with future adjustments when there is emergence of new evidence. Advanced liver disease and portosystemic shunting (PSS), far from being an isolated disorder of the liver, have well-known consequences on the body and, notably, on brain functioning. The alterations of brain functioning, which can produce behavioral, cognitive, and motor effects, were termed portosystemic encephalopathy (PSE)3 and later included in the term HE.4 Unless the underlying liver disease is successfully treated, HE is associated with poor survival and a high risk of recurrence.5, 6 Even in its mildest form, HE reduces health-related quality of life and is a risk factor for bouts of severe HE.7-9 Hepatic encephalopathy is a brain dysfunction caused by liver it as a of or from alterations to This definition, in with is based on the that are of brain and that the a to liver The and of HE are to the severity of the underlying liver and In patients with fully HE is an that the of the disease, such as or encephalopathy is in cirrhosis with The of HE may not be an clinical and there are used for its which the in the and The of the of of cirrhosis is in in those with and in patients with portosystemic The that in of those with cirrhosis their clinical and in the in most HE or HE in of patients with The of HE in is not well The risk for the of is within years cirrhosis diagnosis, on the of risk factors, such as other complications to cirrhosis or infections, or and and with a of were found to have a risk of and with have a risk of within 6 Even with cirrhosis and cognitive dysfunction or one of years of the of is and is by the patient selection data were by It an of the frequent of the health care by patients with HE that for in the in the European are not these are to be Furthermore, the of and cirrhosis is and more be to further the of HE. Hepatic encephalopathy a of and In its HE and as well as and other brain As HE such as and may be by the and alterations in and motor of the with are of the is may to and and acute with or and, The for Hepatic Encephalopathy and the of or as the of In patients with HE, motor such as and a can be In may and in can be can are in such as and of and with are in the of to or or is present in the to of HE that or and is, in not a a of of It is by that such as of the with or the of the can be in other such as the and is not of HE it can be in other the cognitive or and motor of HE may not be or not progress in in in the severity of HE. Hepatic is a of HE to by severe motor the of with and of with and or alterations have been and not to may with liver HE may present with with in which brain brain This condition was a term considered this is to and may be more than in patients with liver disease, in of Apart from these manifestations of HE, it is accepted in clinical practice that all of HE and their manifestations are and this is a for treatment research on HE patients and on patients of bouts of on the from those to other may and are later under of may be associated with in and Hepatic encephalopathy be classified according to all of the to the underlying disease, HE is to the severity of The that is HE has been clinical and research a of such is (Table classifications that to aim and and be used to its HE is to the of factors, HE is for standards and expertise lack of or of or or for to to classification, according to or not the patient has liver failure has recently been Although the and this classification is a research The the of of HE in a patient with severe liver who not have of brain The of for HE and the of HE. The the level of (Table Hepatic encephalopathy be classified according to the of underlying disease, severity of and 1). is other that can brain and HE 1). and of HE be and classified according to all factors, and this be relevant according to the clinical The recommendations are in and the severity of HE is as a The strategies in from clinical to and of the are for the The and according to the of the and the of The of is based on a clinical and a clinical Clinical are used to its Specific are needed in study The is the clinical are with limited for I HE, and a lack of can be in clinical In the of and has and are as of or have been used to the severity of In patients with the is and an cognitive dysfunction is not It can be from clinical as well as or The is to them to HE. this remains a of in this patient that is to resulting from of and disease (Table as of other by and for a patient with in HE is encephalopathy and is as the of or clinical of brain dysfunction in patients with who are not or The term that there is no clinical cognitive or of HE. The term and HE. strategies can be and Because the condition of cognitive functioning, which may not be to the the the use of on the local and and with one of the being more accepted as to as a for and is important it can poor quality of life and and patients and the The of and in patients with to be as high as every patient risk be this may be and the consequences of the are not and treatment is not approach may be to patients who have problems with their quality of life or in there are from the patients and their for or HE patients risk for Furthermore, of the available are for the and it is important to patients who not have factors, such as or be by a to that the the result is (i.e., for or in 6 has been of or not that the is a are not to to and are not in the best of both the patient and the local the of patients with HE on the consequences of their and, the is to the have the patient for In cases, the with the that have the expertise to and the to the Although the have been used to for and there is, most a poor them HE is a is with and it is HE a in the of these and of the results for further management need an of the and on the of HE are the of or by of the and one of the following: or or or In the clinical or may use for the severity of HE with which are that data are available and the have been for use in this patient levels not any diagnostic, or in HE patients with in an level is in a patient with and it is the of HE is in of may be to the There may be to which be is in or the relevant be are be when standards for or or other not or information. the risk of is in this patient and the may be a brain is of the of HE and on clinical of other Hepatic encephalopathy be as a from cognitive with through 1). The of HE is through of other of brain dysfunction 1). Hepatic encephalopathy be of the of and the need for care 1). encephalopathy is by clinical and can be graded according the and the 1). The and of and can be and that be performed by 1). for and be used in patients who most from such as those with quality of life or on or not any diagnostic, or for HE in patients with for 1). this is encephalopathy and as its is not on clinical and is by outlined in the its and can have a on a can there may be an to such a patient impairment in quality of or cognitive Liver is under the treatment recommendations for treatment of the following: of or be 1). an for HE is 1). for of of is not in patients with cirrhosis with a high risk to HE with liver failure, is an for approach to management of HE is of care for patients with of be and of and their of HE treatment with of HE who are risk or to their need more and are in an care of encephalopathy are not in patients with cirrhosis. other of encephalopathy are the of encephalopathy may not be termed HE. In the clinical is treatment of both HE and in the management of is of of patients can be with of the to this is the of HE In to the other of the approach to treatment of HE, treatment is of the have not been by studies and are utilized based on These such as and such as such as and other have been In the a can be used to in patients who are to or have an is generally used as treatment for of data not as a for treatment of for it not the and these to be used of of a clinical search for and for the brain it is that the being a that the of in the and of have an beyond the studies have not those In most trials on have been in to the in of In is preferred to based on of In populations with a high of the use of has been the to that and were to was The use of further The of be when the three of the approach are with of every or are the is to to three This be It is a that lack of of of is by larger There is a for of to such as and severe and can has been used for the of HE in a number of it with other and in These trials of that was or to the with with for patients with has been in three trials to and one in cognitive improvement and with patients bouts to the of the of data the use of have been used for treatment of HE, data to their use are or most of these can be used their limited of trials that the manifestations of HE or There is no of on the of These through their as in have been used for treatment of of the for many are available and present as has been for HE, further clinical are was in a on patients who or more of HE in the 6 and who were on The of HE and as well as to clinical studies on the are under way and, may to clinical on patients with HE improvement by in and with is study of or no in patients with cirrhosis who from HE found of HE in the or to were not There was no in of in any of the of the shunting the that may be by the of by the This has its and was used in the for HE it is a As has for its and these for This is not It in improvement on or The may be of in to the may be in by when or when is not have the of and no have been on this on patients on or no on of HE, was to and for HE 1). is the for treatment of 1). is an to for of 1). can be used as an or to patients to can be used as an or to patients to is an for treatment of is an for treatment of There are no trials of for of from it is and of of HE in patients with as of HE to to is the to in patients who have one or more bouts of on treatment their of was to complications of its to the of HE, or HE, was with severe HE as a complication of a a it was to use HE treatment to HE. one study that HE any than selection has the of severe HE it can the original for may important with to the of low a of can to HE, as There is a lack of on to aim to by or The is associated with more bouts of It is used to HE as with other of HE, the that be by of bouts of HE in patients with liver to a search for of such as can be successfully with of HE in a of patients in a liver the risk for is for of of HE the 1). as an to is for of of HE the 1). or is not for the of HE 1). There is a to treatment it has successfully a of The may be that the for is patients are high risk for This risk to as liver are bouts of from a well-known of a factor can be such as or variceal HE may not be a risk and HE can be Even more on the risk for further bouts of is liver and body patients a amount of liver and from the bouts of may well be to HE There are data on this for or HE patients risk for HE. the have been well (i.e., and or liver or may be Although it is not to for and studies have been performed of The of studies have been for than 6 and not the of the the from trials to studies from and studies have an improvement in the underlying cognitive the of has among of studies used relevant It was in an that can of the of the study to be in a larger study in a recommendations can be and have improvement in quality of and in have been the and of and them to as this Because of the used to and treatment and used in trials to treatment for is not this be on a that are approved for for patients with and I HE. of and is not from a 1). of is to the management of all of HE, and are guidelines for of patients with HE are is and of patients with HE from with of and is are than that of patients and are risk of and of is a risk factor for of HE and other cirrhosis has been to be an important in patients with HE patients an of by a with data and strength as of In the is to the the and are and Although body is the may be as well as the such as are for clinical The patient a by a or other The of HE patients for The is by moderate as below. the and a be with of may be the most available not be utilized as the be to patients that can by to patients who the and to other The be and The use of a is generally there are no data on the of and Specific is there are and is considered when HE. is of be and any of of be as to of in patients with cirrhosis. severe is this be There is that be for patients with HE. of may be in the of not be of or or with is to of may be used to HE and generally the of patients with for an of HE has no The studies on the of have been more and by a of the of these may to have more important on of of body than a on HE. be body 1). be 1). or the and a be 1). may to be and in patients of Liver remains the treatment for HE that not on any other is not its The management of these as in the has been published and European guidelines are under Hepatic encephalopathy by is not considered an for associated with poor liver HE severely the quality of life and be medical and who may be liver may and HE, be and considered or the severe be Hepatic encephalopathy it is important to HE from other of such as disease and and of the brain be and the patient be by an in and The and health be that may brain impairment and that not all manifestations of HE are fully by and not is the of a in the The search of the is difficult, and the may have with liver disease and those with HE are of are a frequent associated with and levels in of may be to associated with a search for or are not and the be from a clinical As outlined under the of HE is and more of HE be with being to for HE and to The patients with HE in the in of utilization for this group of patients is as a result of of and more complex and as well as a of There are no by from the be the and the and These are an care, and and the on the or were not The of is to in it from to and are by the the can the of based on that are as of and from in patients with or the of other to be the most The manifestations of HE are have to be considered as an source of dysfunction in any patient with important are and is bleeding and is an risk factor for of HE in patients with The of HE and the to with has been as a risk factor for of HE, in patients with the may be in other cirrhosis risk to HE has been in patients with cirrhosis with of the severity of cirrhosis. are in of patients with cirrhosis with and in of those with with cirrhosis not from patients cirrhosis their risk to brain dysfunction with it is that and with to the of HE. in patients with may as a of in cirrhosis of any The of and be as being the result of or by clinical In any of be the of the underlying liver disease on brain are for and difficult, may be the result of Even patients with disorder and no clinical disease have been to in and and and motor The cognitive dysfunction is more in those patients with disorder who are risk of encephalopathy as a result of or of the it remains the of brain in patients with is the result of HE, or There is evidence that is present and within the of patients chronic of the of their liver and patients with liver disease cognitive and patients with cirrhosis and may have severe and impairment of and of the of liver Because HE with all and underlying it is in the to the of HE and those resulting from other In cases, the and to may be the best of HE. As a level in a patient of HE for of the used present has been for their to HE and other of brain The not be by or may changes to those with HE in of or are to are to for these have been for their use in HE, the results are brain be in every patient with and of brain to In rare cases, by may be a for HE, the be This with research the management of HE. such research be based on research the of HE. It is necessary to more which liver are for of which alterations in and failure of these liver which brain are to the of the and, which this that result in the emergence of HE or the research and clinical management in result in new and treatment that need and clinical There is a severe and unmet need for clinical trials on treatment on all the of HE. clinical studies are the number of patients and their utilization is There are no data on which and patients the and research is needed to the of there is an insufficient for resources and policies management of HE. that were for HE ago were a of care is study of treatment for HE be or the of care. It is to to and The of recently is in the of and there is a need for trials on HE. There is an unmet need for research that is necessary to a for clinical The of and has it is not to results among studies and the be It may be to and HE that the of liver failure and with more than one important area of is the term which was to I of is and This to be by a approach. the isolated liver failure and HE be by clinical and brain brain is and are needed to the of that can be in patients with liver be more classified and based on and to the of clinical practice and studies in They be on the of HE on and to use and the in clinical (Table on and among on aspects on and with treatment studies on that can which patients may from Development of to when and to the on (i.e., and use on on for and of dysfunction on who from the for to and on cognitive improvement on to and be the to new which have been and are not a for studies The existing literature from a lack of and this makes of data or to consistency the field have been published by is a of the", "authors": ["Hendrik Vilstrup", "Piero Amodio", "Jasmohan S. Bajaj", "Juan Córdoba", "Péter Ferenci", "Kevin D. Mullen", "Karin Weißenborn", "Philip Wong"], "year": 2014, "venue": "Hepatology", "cited_by_count": 2000, "type": "article", "concepts": ["Guideline", "Medicine", "Grading (engineering)", "Liver disease", "Chronic liver disease"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3159728495", "doi": "https://doi.org/10.1038/s41586-021-03451-0", "title": "Towards complete and error-free genome assemblies of all vertebrate species", "abstract": "", "authors": ["Arang Rhie", "Shane McCarthy", "Olivier Fédrigo", "Joana Damas", "Giulio Formenti", "Sergey Koren", "Marcela Uliano‐Silva", "William Chow", "Arkarachai Fungtammasan", "Ju‐Wan Kim", "Chul Lee", "Byung June Ko", "Mark Chaisson", "Gregory Gedman", "Lindsey Cantin", "Françoise Thibaud‐Nissen", "Leanne Haggerty", "Iliana Bista", "Michelle Smith", "Bettina Haase", "Jacquelyn Mountcastle", "Sylke Winkler", "Sadye Paez", "Jason T. Howard", "Sonja C. Vernes", "Tanya M. Lama", "Frank Grützner", "Wesley C. Warren", "Christopher N. Balakrishnan", "David W. Burt", "Julia M. George", "Matthew T. Biegler", "David Iorns", "Andrew Digby", "Daryl Eason", "Bruce C. Robertson", "Taylor Edwards", "Mark Wilkinson", "George F. Turner", "Axel Meyer", "Andreas F. Kautt", "Paolo Franchini", "H. William Detrich", "Hannes Svardal", "Maximilian Wagner", "Gavin J. P. Naylor", "Martin Pippel", "Milan Malinsky", "Mark P. Mooney", "Maria Simbirsky", "Brett T. Hannigan", "Trevor Pesout", "Marlys L. Houck", "Ann Misuraca", "Sarah B. Kingan", "Richard Hall", "Zev Kronenberg", "Ivan Sović", "Christopher Dunn", "Zemin Ning", "Alex Hastie", "Joyce Lee", "Siddarth Selvaraj", "Richard E. Green", "Nicholas H. Putnam", "Marta Gut", "Jay Ghurye", "Erik Garrison", "Ying Sims", "Joanna Collins", "Sarah Pelan", "James Torrance", "Alan Tracey", "Jonathan Wood", "Robel E. Dagnew", "Dengfeng Guan", "Sarah E. London", "David F. Clayton", "Claudio V. Mello", "Samantha R. Friedrich", "Peter V. Lovell", "Ekaterina Osipova", "Farooq O. Al-Ajli", "Simona Secomandi", "Heebal Kim", "Constantina Theofanopoulou", "Michael Hiller", "Yang Zhou", "Robert S. Harris", "Kateryna D. Makova", "Paul Medvedev", "Jinna Hoffman", "Patrick Masterson", "Karen Clark", "Fergal J. Martin", "Kevin Howe", "Paul Flicek", "Brian P. Walenz", "Woori Kwak", "Hiram Clawson"], "year": 2021, "venue": "Nature", "cited_by_count": 2837, "type": "article", "concepts": ["Vertebrate", "Genome", "Evolutionary biology", "Biology", "Computational biology"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2612688942", "doi": "https://doi.org/10.1038/lsa.2017.141", "title": "Phase recovery and holographic image reconstruction using deep learning in neural networks", "abstract": "Phase recovery from intensity-only measurements forms the heart of coherent imaging techniques and holography. In this study, we demonstrate that a neural network can learn to perform phase recovery and holographic image reconstruction after appropriate training. This deep learning-based approach provides an entirely new framework to conduct holographic imaging by rapidly eliminating twin-image and self-interference-related spatial artifacts. This neural network-based method is fast to compute and reconstructs phase and amplitude images of the objects using only one hologram, requiring fewer measurements in addition to being computationally faster. We validated this method by reconstructing the phase and amplitude images of various samples, including blood and Pap smears and tissue sections. These results highlight that challenging problems in imaging science can be overcome through machine learning, providing new avenues to design powerful computational imaging systems.", "authors": ["Yair Rivenson", "Yibo Zhang", "Harun Günaydın", "Da Teng", "Aydogan Özcan"], "year": 2017, "venue": "Light Science & Applications", "cited_by_count": 1010, "type": "article", "concepts": ["Holography", "Computer science", "Artificial intelligence", "Deep learning", "Artificial neural network"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2754213847", "doi": "https://doi.org/10.1109/tip.2018.2831899", "title": "NIMA: Neural Image Assessment", "abstract": "Automatically learned quality assessment for images has recently become a hot topic due to its usefulness in a wide variety of applications such as evaluating image capture pipelines, storage techniques and sharing media. Despite the subjective nature of this problem, most existing methods only predict the mean opinion score provided by datasets such as AVA [1] and TID2013 [2]. Our approach differs from others in that we predict the distribution of human opinion scores using a convolutional neural network. Our architecture also has the advantage of being significantly simpler than other methods with comparable performance. Our proposed approach relies on the success (and retraining) of proven, state-of-the-art deep object recognition networks. Our resulting network can be used to not only score images reliably and with high correlation to human perception, but also to assist with adaptation and optimization of photo editing/enhancement algorithms in a photographic pipeline. All this is done without need for a \"golden\" reference image, consequently allowing for single-image, semantic- and perceptually-aware, no-reference quality assessment.", "authors": ["Hossein Talebi", "Peyman Milanfar"], "year": 2018, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 876, "type": "article", "concepts": [], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W3010973018", "doi": "https://doi.org/10.1117/12.2548953", "title": "Combined global and local information for blind CT image quality assessment via deep learning", "abstract": "Image quality assessment (IQA) is an important step to determine whether the computed tomography (CT) images are suitable for diagnosis. Since the high dose CT images are usually not accessible in clinical practice, no-reference (NR) CT IQA should be used. Most NR-IQA methods for CT images based on deep learning strategy focus on global information and ignores local performance, i.e., contrast, edge of local region. In this work, to address this issue, we presented a new NR-IQA framework combining global and local information for CT images. For simplicity, the NR-IQA framework is termed as NR-GL-IQA. In particular, the presented NR- GL-IQA adopts a convolutional neural network to predict entire image quality blindly without a reference image. In this stage, an elaborate strategy is used to automatically label the entire image quality for neural network training to cope with the problem of time-consuming in manually massive CT images annotation. Second, in the presented NR-GL-IQA method, Perception-based Image QUality Evaluator (PIQUE) is used to predict the local region quality because the PIQUE can adaptively capture the local region characteristics. Finally, the overall image quality is estimated by combining the global and local IQA together. The experimental results with Mayo dataset demonstrate that the presented NR-GL-IQA method can accurately predicts CT image quality and the combination of global and local IQA is closer to the radiologist assessment than that with only one single assessment.", "authors": ["Qi Gao", "Sui Li", "Manman Zhu", "Danyang Li", "Zhaoying Bian", "Qingwen Lv", "Dong Zeng", "Jianhua Ma"], "year": 2020, "venue": "", "cited_by_count": 7, "type": "article", "concepts": ["Image quality", "Computer science", "Artificial intelligence", "Convolutional neural network", "Image (mathematics)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4317910584", "doi": "https://doi.org/10.37074/jalt.2023.6.1.9", "title": "ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?", "abstract": "ChatGPT is the world’s most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI’s Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT’s functionality and a summary of its strengths and limitations, we focus on the technology’s implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment.", "authors": ["Jürgen Rudolph", "Samson Tan", "Shannon Tan"], "year": 2023, "venue": "Journal of Applied Learning & Teaching", "cited_by_count": 1568, "type": "article", "concepts": ["Chatbot", "Conversation", "Relevance (law)", "Context (archaeology)", "Higher education"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W2125107945", "doi": "https://doi.org/10.1007/s10029-009-0529-7", "title": "European Hernia Society guidelines on the treatment of inguinal hernia in adult patients", "abstract": "", "authors": ["M. P. Simons", "Theo Aufenacker", "Morten Bay‐Nielsen", "Jean‐Luc Bouillot", "Giampiero Campanelli", "J. Conze", "de Lange", "René H. Fortelny", "T. Heikkinen", "Andrew N. Kingsnorth", "Jan F. Kukleta", "Salvador Morales‐Conde", "Pär Nordin", "V. Schumpelick", "Sam Smedberg", "Maciej Śmietański", "G. Wéber", "Marc Miserez"], "year": 2009, "venue": "Hernia", "cited_by_count": 1569, "type": "article", "concepts": ["Medicine", "Inguinal hernia", "Hernia", "Randomized controlled trial", "General surgery"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4297474357", "doi": "https://doi.org/10.1016/j.jvcir.2022.103636", "title": "From synthetic to natural — single natural image dehazing deep networks using synthetic dataset domain randomization", "abstract": "", "authors": ["Abdul Fathaah Shamsuddin", "Krupasankari Ragunathan", "P. Abhijith", "Deepak Raja Sekar P.M.", "Praveen Sankaran"], "year": 2022, "venue": "Journal of Visual Communication and Image Representation", "cited_by_count": 5, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Visibility", "Margin (machine learning)", "Image (mathematics)"], "search_query": "image quality assessment no-reference blind deep learning"}
{"openalex_id": "https://openalex.org/W4408345706", "doi": "https://doi.org/10.1109/icassp49660.2025.10887587", "title": "Soft Knowledge Distillation with Multi-Dimensional Cross-Net Attention for Image Restoration Models Compression", "abstract": "Transformer-based encoder-decoder models have achieved remarkable success in image-to-image transfer tasks, particularly in image restoration. However, their high computational complexity—manifested in elevated FLOPs and parameter counts—limits their application in real-world scenarios. Existing knowledge distillation methods in image restoration typically employ lightweight student models that directly mimic the intermediate features and reconstruction results of the teacher, overlooking the implicit attention relationships between them. To address this, we propose a Soft Knowledge Distillation (SKD) strategy that incorporates a Multi-dimensional Cross-net Attention (MCA) mechanism for compressing image restoration models. This mechanism facilitates interaction between the student and teacher across both channel and spatial dimensions, enabling the student to implicitly learn the attention matrices. Additionally, we employ a Gaussian kernel function to measure the distance between student and teacher features in kernel space, ensuring stable and efficient feature learning. To further enhance the quality of reconstructed images, we replace the commonly used L1 or KL divergence loss with a contrastive learning loss at the image level. Experiments on three tasks—image deraining, deblurring, and denoising—demonstrate that our SKD strategy significantly reduces computational complexity while maintaining strong image restoration capabilities.", "authors": ["Yongheng Zhang", "Danfeng Yan"], "year": 2025, "venue": "", "cited_by_count": 2, "type": "article", "concepts": ["Distillation", "Computer science", "Image (mathematics)", "Compression (physics)", "Image restoration"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2607219512", "doi": "https://doi.org/10.14722/ndss.2018.23198", "title": "Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks", "abstract": "Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by adversarial examples that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, feature squeezing, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives.", "authors": ["Weilin Xu", "David Evans", "Yanjun Qi"], "year": 2018, "venue": "", "cited_by_count": 1796, "type": "preprint", "concepts": ["Adversarial system", "Feature (linguistics)", "Computer science", "Artificial intelligence", "Smoothing"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3101118213", "doi": "https://doi.org/10.18653/v1/2021.findings-emnlp", "title": "Findings of the Association for Computational Linguistics: EMNLP 2021", "abstract": "", "authors": ["Firoj Alam", "Shaden Shaar", "Fahim Dalvi", "Hassan Sajjad", "Alex Nikolov", "Hamdy Mubarak", "Giovanni Da", "San Martino", "Ahmed Abdelali", "Nadir Durrani", "Kareem Darwish", "Abdulaziz Al-Homaid", "Wajdi Za- Ghouani", "Tommaso Caselli", "Tianda Li", "Ahmad Rashid", "Aref Jafari", "Pranav Sharma", "Ali Ghodsi", "Mehdi Rezagholizadeh", "Thi-Nhung Nguyen", "Yimin Fan", "Yaobo Liang", "Alexandre Muzio", "Hany Hassan", "Houqiang Li", "Ming Zhou", "Nan Duan", "Shiyang Li", "Semih Yavuz", "Wenhu Chen", "Xifeng Yan", ";", "Weiwen Xu", "Yang Deng", "Huihui Zhang", "Deng Cai", "Wai Lam", ". . . . . . . . . . . . . . . . . . . . . ; Bowei", "Zhifeng Zou", "Manuel Li", "Jan-David Plank", "Terry Krieger", "Bela Ruas", "Akiko Gipp", "Aizawa", "Jiangnan Li", "Zheng Lin", "Peng Fu", "Weiping Wang ; Yanyan", "Hainan Zou", "Hongshen Zhang", "Zhuoye Chen", "Caixia Ding", "Xiaojie Yuan", "Wang", "Guoxin Yu", "Jiwei Li", "Ling Luo", "Yuxian Meng", "Xiang Ao", "Qing He", "Zixuan Zhang", "Hongwei Wang", "Han Zhao", "Hanghang Tong", "Heng Ji ; Guangrun", "Hang Wang", "Jiefeng Xu", "Bert", "Tong Overkill ; Bryan Mccann", "Nazneen Niu", "Rajani", "Shirish Nitish", "Thamar Keskar", "Solorio", "Shifeng Liu", "Yifang Sun", "Bing Li", "Wei Wang", "Florence Bourgeois", "Adam Dunn", ". ; Meishan", "Zhenghua Zhang", "Min ; Meng Li", "Oyvind Huang", "Chao Tafjord", "Zhao", "Yunlong Liang", "Fandong Meng", "Jinchao Zhang", "Yufeng Chen", "Jinan Xu", "Jie Zhou", "Yang Zhong", "Jingfeng Yang", "Wei Xu", "Diyi Yang ; Yuchen", "Chengyu Zhai", "Minghui Wang"], "year": 2021, "venue": "", "cited_by_count": 896, "type": "paratext", "concepts": ["Computational linguistics", "Computer science", "Association (psychology)", "Linguistics", "Natural language processing"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4413776565", "doi": "https://doi.org/10.2139/ssrn.5407564", "title": "Image Restoration Model Compression via Mamba-oriented Heterogeneous Knowledge Distillation", "abstract": "", "authors": ["Sai Yang", "Bin Hu", "Xiaoxin Wu", "Fan Liu", "Jun Zhou"], "year": 2025, "venue": "SSRN Electronic Journal", "cited_by_count": 0, "type": "preprint", "concepts": ["Image (mathematics)", "Compression (physics)", "Distillation", "Computer science", "Artificial intelligence"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4408352428", "doi": "https://doi.org/10.1109/icassp49660.2025.10889105", "title": "Knowledge Distillation for Image Restoration : Simultaneous Learning from Degraded and Clean Images", "abstract": "Model compression through knowledge distillation has seen extensive application in classification and segmentation tasks. However, its potential in image-to-image translation, particularly in image restoration, remains underexplored. To address this gap, we propose a Simultaneous Learning Knowledge Distillation (SLKD) framework tailored for model compression in image restoration tasks. SLKD employs a dual-teacher, single-student architecture with two distinct learning strategies: Degradation Removal Learning (DRL) and Image Reconstruction Learning (IRL), simultaneously. In DRL, the student encoder learns from Teacher A to focus on removing degradation factors, guided by a novel BRISQUE extractor. In IRL, the student decoder learns from Teacher B to reconstruct clean images, with the assistance of a proposed PIQE extractor. These strategies enable the student to learn from degraded and clean images simultaneously, ensuring high-quality compression of image restoration models. Experimental results across five datasets and three tasks demonstrate that SLKD achieves substantial reductions in FLOPs and parameters, exceeding 80%, while maintaining strong image restoration performance.", "authors": ["Yongheng Zhang", "Danfeng Yan"], "year": 2025, "venue": "", "cited_by_count": 2, "type": "article", "concepts": ["Distillation", "Computer science", "Image restoration", "Image (mathematics)", "Artificial intelligence"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W1904504745", "doi": "https://doi.org/10.1109/tsipn.2015.2448520", "title": "Joint Optimization of Radio and Computational Resources for Multicell Mobile-Edge Computing", "abstract": "Migrating computational intensive tasks from mobile devices to more resourceful cloud servers is a promising technique to increase the computational capacity of mobile devices while saving their battery energy. In this paper, we consider an MIMO multicell system where multiple mobile users (MUs) ask for computation offloading to a common cloud server. We formulate the offloading problem as the joint optimization of the radio resources-the transmit precoding matrices of the MUs-and the computational resources-the CPU cycles/second assigned by the cloud to each MU-in order to minimize the overall users' energy consumption, while meeting latency constraints. The resulting optimization problem is nonconvex (in the objective function and constraints). Nevertheless, in the single-user case, we are able to compute the global optimal solution in closed form. In the more challenging multiuser scenario, we propose an iterative algorithm, based on a novel successive convex approximation technique, converging to a local optimal solution of the original nonconvex problem. We then show that the proposed algorithmic framework naturally leads to a distributed and parallel implementation across the radio access points, requiring only a limited coordination/signaling with the cloud. Numerical results show that the proposed schemes outperform disjoint optimization algorithms.", "authors": ["Stefania Sardellitti", "Gesualdo Scutari", "Sergio Barbarossa"], "year": 2015, "venue": "IEEE Transactions on Signal and Information Processing over Networks", "cited_by_count": 907, "type": "article", "concepts": ["Computer science", "Cloud computing", "Mobile edge computing", "Optimization problem", "Server"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4408441573", "doi": "https://doi.org/10.3390/drones9030209", "title": "Simultaneous Learning Knowledge Distillation for Image Restoration: Efficient Model Compression for Drones", "abstract": "Deploying high-performance image restoration models on drones is critical for applications like autonomous navigation, surveillance, and environmental monitoring. However, the computational and memory limitations of drones pose significant challenges to utilizing complex image restoration models in real-world scenarios. To address this issue, we propose the Simultaneous Learning Knowledge Distillation (SLKD) framework, specifically designed to compress image restoration models for resource-constrained drones. SLKD introduces a dual-teacher, single-student architecture that integrates two complementary learning strategies: Degradation Removal Learning (DRL) and Image Reconstruction Learning (IRL). In DRL, the student encoder learns to eliminate degradation factors by mimicking Teacher A, which processes degraded images utilizing a BRISQUE-based extractor to capture degradation-sensitive natural scene statistics. Concurrently, in IRL, the student decoder reconstructs clean images by learning from Teacher B, which processes clean images, guided by a PIQE-based extractor that emphasizes the preservation of edge and texture features essential for high-quality reconstruction. This dual-teacher approach enables the student model to learn from both degraded and clean images simultaneously, achieving robust image restoration while significantly reducing computational complexity. Experimental evaluations across five benchmark datasets and three restoration tasks—deraining, deblurring, and dehazing—demonstrate that, compared to the teacher models, the SLKD student models achieve an average reduction of 85.4% in FLOPs and 85.8% in model parameters, with only a slight average decrease of 2.6% in PSNR and 0.9% in SSIM. These results highlight the practicality of integrating SLKD-compressed models into autonomous systems, offering efficient and real-time image restoration for aerial platforms operating in challenging environments.", "authors": ["Yongheng Zhang"], "year": 2025, "venue": "Drones", "cited_by_count": 0, "type": "article", "concepts": ["Drone", "Distillation", "Artificial intelligence", "Image (mathematics)", "Computer science"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4286277017", "doi": "https://doi.org/10.1109/iccia55271.2022.9828438", "title": "Color Restoration Method for Endoscope Image Using Multiscale Discriminator Based Model Compression Strategy", "abstract": "Color restoration of endoscopic images is an urgent clinical need during photodynamic surgery. In recent years, deep learning methods achieved notable results in the fields of image processing. The model compression algorithm and hardware performance enhancement improved the model inference speed. It is possible to apply deep learning methods to the task of endoscopic image color restoration during surgery. However, experiments show that model compression can lead to image deterioration. To solve this issue, we propose a fast color restoration method for endoscopic images, which use multiscale discriminator based on model compression. Initially, we train a CycleGAN teacher network with multiscale discriminator. Then, we obtain the student model through knowledge distillation and neural architecture search. We use the trained teacher discriminator to guide the student model and add feature matching loss to stabilize the training process. Experiments show that our method ameliorates the performance of compressed models.", "authors": ["Pengcheng Hao", "Danni Ai", "Liugeng Zang", "Jingfan Fan", "Jian Yang"], "year": 2022, "venue": "", "cited_by_count": 1, "type": "article", "concepts": ["Discriminator", "Computer science", "Artificial intelligence", "Feature (linguistics)", "Compression (physics)"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2963184668", "doi": "https://doi.org/10.1109/cvpr.2018.00357", "title": "Defense Against Universal Adversarial Perturbations", "abstract": "Recent advances in Deep Learning show the existence of image-agnostic quasi-imperceptible perturbations that when applied to 'any' image can fool a state-of-the-art network classifier to change its prediction about the image label. These 'Universal Adversarial Perturbations' pose a serious threat to the success of Deep Learning in practice. We present the first dedicated framework to effectively defend the networks against such perturbations. Our approach learns a Perturbation Rectifying Network (PRN) as 'pre-input' layers to a targeted model, such that the targeted model needs no modification. The PRN is learned from real and synthetic image-agnostic perturbations, where an efficient method to compute the latter is also proposed. A perturbation detector is separately trained on the Discrete Cosine Transform of the input-output difference of the PRN. A query image is first passed through the PRN and verified by the detector. If a perturbation is detected, the output of the PRN is used for label prediction instead of the actual image. A rigorous evaluation shows that our framework can defend the network classifiers against unseen adversarial perturbations in the real-world scenarios with up to 97.5% success rate. The PRN also generalizes well in the sense that training for one targeted network defends another network with a comparable success rate.", "authors": ["Naveed Akhtar", "Jian Liu", "Ajmal Mian"], "year": 2018, "venue": "", "cited_by_count": 209, "type": "article", "concepts": ["Adversarial system", "Computer science", "Artificial intelligence", "Perturbation (astronomy)", "Detector"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2898832590", "doi": "https://doi.org/10.3390/rs10111700", "title": "Deep Distillation Recursive Network for Remote Sensing Imagery Super-Resolution", "abstract": "Deep convolutional neural networks (CNNs) have been widely used and achieved state-of-the-art performance in many image or video processing and analysis tasks. In particular, for image super-resolution (SR) processing, previous CNN-based methods have led to significant improvements, when compared with shallow learning-based methods. However, previous CNN-based algorithms with simple direct or skip connections are of poor performance when applied to remote sensing satellite images SR. In this study, a simple but effective CNN framework, namely deep distillation recursive network (DDRN), is presented for video satellite image SR. DDRN includes a group of ultra-dense residual blocks (UDB), a multi-scale purification unit (MSPU), and a reconstruction module. In particular, through the addition of rich interactive links in and between multiple-path units in each UDB, features extracted from multiple parallel convolution layers can be shared effectively. Compared with classical dense-connection-based models, DDRN possesses the following main properties. (1) DDRN contains more linking nodes with the same convolution layers. (2) A distillation and compensation mechanism, which performs feature distillation and compensation in different stages of the network, is also constructed. In particular, the high-frequency components lost during information propagation can be compensated in MSPU. (3) The final SR image can benefit from the feature maps extracted from UDB and the compensated components obtained from MSPU. Experiments on Kaggle Open Source Dataset and Jilin-1 video satellite images illustrate that DDRN outperforms the conventional CNN-based baselines and some state-of-the-art feature extraction approaches.", "authors": ["Kui Jiang", "Zhongyuan Wang", "Peng Yi", "Junjun Jiang", "Jing Xiao", "Yuan Yao"], "year": 2018, "venue": "Remote Sensing", "cited_by_count": 134, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Convolutional neural network", "Convolution (computer science)", "Feature (linguistics)"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3112787034", "doi": "https://doi.org/10.1109/access.2020.3045078", "title": "Privacy and Security Issues in Deep Learning: A Survey", "abstract": "Deep Learning (DL) algorithms based on artificial neural networks have achieved remarkable success and are being extensively applied in a variety of application domains, ranging from image classification, automatic driving, natural language processing to medical diagnosis, credit risk assessment, intrusion detection. However, the privacy and security issues of DL have been revealed that the DL model can be stolen or reverse engineered, sensitive training data can be inferred, even a recognizable face image of the victim can be recovered. Besides, the recent works have found that the DL model is vulnerable to adversarial examples perturbed by imperceptible noised, which can lead the DL model to predict wrongly with high confidence. In this paper, we first briefly introduces the four types of attacks and privacy-preserving techniques in DL. We then review and summarize the attack and defense methods associated with DL privacy and security in recent years. To demonstrate that security threats really exist in the real world, we also reviewed the adversarial attacks under the physical condition. Finally, we discuss current challenges and open problems regarding privacy and security issues in DL.", "authors": ["Ximeng Liu", "Lehui Xie", "Yaopeng Wang", "Jian Zou", "Jinbo Xiong", "Zuobin Ying", "Athanasios V. Vasilakos"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 266, "type": "article", "concepts": ["Computer science", "Computer security", "Internet privacy", "Information privacy"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3168463823", "doi": "https://doi.org/10.1007/s00371-021-02166-7", "title": "A survey on deep multimodal learning for computer vision: advances, trends, applications, and datasets", "abstract": "", "authors": ["Khaled Bayoudh", "Raja Knani", "Fayçal Hamdaoui", "Abdellatif Mtibaa"], "year": 2021, "venue": "The Visual Computer", "cited_by_count": 389, "type": "article", "concepts": ["Deep learning", "Multimodal learning", "Computer science", "Artificial intelligence", "Modalities"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4413630552", "doi": "https://doi.org/10.1109/jstars.2025.3602477", "title": "Optimization Method for Remote Sensing Image-Based Photovoltaic Panel Segmentation via Perception-Driven Enhancement in Nonideal Environments", "abstract": "This research addresses the challenges of feature distortion, poor scale adaptability, and high model complexity in the segmentation of photovoltaic panels from remote sensing images under non-ideal conditions such as rain and fog. To tackle these issues, a DMFA-DeepLab model integrating perception-driven enhancement is proposed. First, a physical perception degradation data generation method is developed based on the CycleGAN framework to simulate optical degradation features caused by rain and fog, thereby enhancing the model's generalization capability in adverse environmental conditions. Second, a multi-scale convolutional attention module (MCAM) is designed, which captures cross-scale features through heterogeneous convolution branches with receptive fields of 3, 5, and 9. The module further incorporates a channel-spatial dual attention mechanism to dynamically focus on key regions while suppressing background interference. Based on MCAM, a multi-level feature aggregation network (MFA-Net) is constructed, which enhances boundary description through cross-level feature fusion. To achieve model lightweighting, a two-stage pruning–knowledge distillation strategy is introduced: initially, 30% of low-contribution channels are pruned based on the BN scaling factor through sparse training; after a second pruning of 20%, the cumulative compression rate reaches 44%. Finally, knowledge distillation is applied, where the original model serves as the teacher to guide the student model in performance restoration. Experimental results demonstrate that on the enhanced dataset simulating rain and fog environments, the complete model achieves an MIoU of 93.17%, representing an improvement of 7.04% over the baseline DeepLabV3+. The lightweight model DMFA-DeepLab, while reducing the parameter count by 44%, restores the MIoU to 92.96% and increases inference speed by 2.3 times. Compared with mainstream models such as U-Net and PSPNet, DMFA-DeepLab demonstrates significantly superior segmentation accuracy and robustness in complex environments, achieving an F1 score of 94.57%, which is 4.67 percentage points higher than the second-best model.", "authors": ["Xuewei Chao", "Lixin Zhang", "Yang Li", "Jing Nie", "Shuo Yang", "Sezai Erċışlı"], "year": 2025, "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "cited_by_count": 1, "type": "article", "concepts": ["Photovoltaic system", "Computer science", "Computer vision", "Artificial intelligence", "Image segmentation"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4321479797", "doi": "https://doi.org/10.53941/ijndi0201006", "title": "Deep Learning Attention Mechanism in Medical Image Analysis: Basics and Beyonds", "abstract": "Survey/review study Deep Learning Attention Mechanism in Medical Image Analysis: Basics and Beyonds Xiang Li 1, Minglei Li 1, Pengfei Yan 1, Guanyi Li 1, Yuchen Jiang 1, Hao Luo 1,*, and Shen Yin 2 1 Department of Control Science and Engineering, Harbin Institute of Technology, Harbin 150001, China 2 Department of Mechanical and Industrial Engineering, Faculty of Engineering, Norwegian University of Science and Technology, Trondheim 7034, Norway * Correspondence: hao.luo@hit.edu.cn Received: 16 October 2022 Accepted: 25 November 2022 Published: 27 March 2023 Abstract: With the improvement of hardware computing power and the development of deep learning algorithms, a revolution of \"artificial intelligence (AI) + medical image\" is taking place. Benefiting from diversified modern medical measurement equipment, a large number of medical images will be produced in the clinical process. These images improve the diagnostic accuracy of doctors, but also increase the labor burden of doctors. Deep learning technology is expected to realize an auxiliary diagnosis and improve diagnostic efficiency. At present, the method of deep learning technology combined with attention mechanism is a research hotspot and has achieved state-of-the-art results in many medical image tasks. This paper reviews the deep learning attention methods in medical image analysis. A comprehensive literature survey is first conducted to analyze the keywords and literature. Then, we introduce the development and technical characteristics of the attention mechanism. For its application in medical image analysis, we summarize the related methods in medical image classification, segmentation, detection, and enhancement. The remaining challenges, potential solutions, and future research directions are also discussed.", "authors": ["Xiang Li", "Minglei Li", "Pengfei Yan", "Guanyi Li", "Yuchen Jiang", "Hao Luo", "Shen Yin"], "year": 2023, "venue": "International Journal of Network Dynamics and Intelligence", "cited_by_count": 237, "type": "article", "concepts": ["Deep learning", "Artificial intelligence", "Computer science", "Mechanism (biology)", "Medical imaging"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2954717959", "doi": "https://doi.org/10.3390/foods8070245", "title": "Rapid Solid-Liquid Dynamic Extraction (RSLDE): A Powerful and Greener Alternative to the Latest Solid-Liquid Extraction Techniques", "abstract": "Traditionally, solid-liquid extractions are performed using organic and/or inorganic liquids and their mixtures as extractant solvents in contact with an insoluble solid matrix (e.g., the Soxhlet method) or using sequential atmospheric pressure systems that require long procedures, such as maceration or percolation. The objective of this procedure is the extraction of any compounds that can be carried out from the inner solid material to the outlet, resulting in a solution containing colorants, bioactive compounds, odorous substances, etc. Over the years, in the extraction techniques sector, there have been many important changes from the points of view of production, quality, and human and environmental safety due to improvements in technology. In more recent times, the interest of the scientific community has been aimed at the study of sustainable processes for the valorization of extracts from vegetables and food by-products, through the use of non-conventional (innovative) technologies that represent a valid alternative to conventional methods, generally through saving time and energy and the formation of fewer by-products. Therefore, with the development of principles based on the prevention of pollution, on a lower risk for human health, and on a low environmental impact, new systems have been implemented to reduce extraction times and solvent consumption, to improve efficiency, and to increase the productivity of the extracts. From this point of view, rapid solid-liquid dynamic extraction (RSLDE), performed using the Naviglio extractor, compared to traditional applications, is a technique that is able to reduce extraction times, generally leads to higher yields, does not require heating of the system, allows one to extract the active ingredients, and avoids their degradation. This technique is based on a new solid-liquid extraction principle named Naviglio's principle. In this review, after reviewing the latest extraction techniques, an overview of RSLDE applications in various research and production sectors over the past two decades is provided.", "authors": ["Daniele Naviglio", "Pierpaolo Scarano", "Martina Ciaravolo", "Monica Gallo"], "year": 2019, "venue": "Foods", "cited_by_count": 148, "type": "review", "concepts": ["Extraction (chemistry)", "Process engineering", "Extractor", "Biochemical engineering", "Pulp and paper industry"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2973184731", "doi": "https://doi.org/10.3390/s19183929", "title": "Survey of Deep-Learning Approaches for Remote Sensing Observation Enhancement", "abstract": "Deep Learning, and Deep Neural Networks in particular, have established themselves as the new norm in signal and data processing, achieving state-of-the-art performance in image, audio, and natural language understanding. In remote sensing, a large body of research has been devoted to the application of deep learning for typical supervised learning tasks such as classification. Less yet equally important effort has also been allocated to addressing the challenges associated with the enhancement of low-quality observations from remote sensing platforms. Addressing such channels is of paramount importance, both in itself, since high-altitude imaging, environmental conditions, and imaging systems trade-offs lead to low-quality observation, as well as to facilitate subsequent analysis, such as classification and detection. In this paper, we provide a comprehensive review of deep-learning methods for the enhancement of remote sensing observations, focusing on critical tasks including single and multi-band super-resolution, denoising, restoration, pan-sharpening, and fusion, among others. In addition to the detailed analysis and comparison of recently presented approaches, different research avenues which could be explored in the future are also discussed.", "authors": ["Grigorios Tsagkatakis", "Anastasia Aidini", "Konstantina Fotiadou", "Michalis Giannopoulos", "Anastasia Pentari", "Panagiotis Tsakalides"], "year": 2019, "venue": "Sensors", "cited_by_count": 142, "type": "review", "concepts": ["Deep learning", "Computer science", "Artificial intelligence", "Remote sensing", "Data science"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4405574099", "doi": "https://doi.org/10.1038/s41524-024-01493-2", "title": "DPA-2: a large atomic model as a multi-task learner", "abstract": "", "authors": ["Duo Zhang", "Xinzijian Liu", "Xiangyu Zhang", "Chengqian Zhang", "Chun Cai", "Hangrui Bi", "Yiming Du", "Xuejian Qin", "Anyang Peng", "Jiameng Huang", "Bowen Li", "Yifan Shan", "Jinzhe Zeng", "Yuzhi Zhang", "Siyuan Liu", "Yifan Li", "Junhan Chang", "Xinyan Wang", "Shuo Zhou", "Jianchuan Liu", "Xiaoshan Luo", "Zhenyu Wang", "Wanrun Jiang", "Jing Wu", "Yudi Yang", "Jiyuan Yang", "Manyi Yang", "Fu‐Qiang Gong", "Linshuang Zhang", "Mengchao Shi", "Fu‐Zhi Dai", "Darrin M. York", "Shi Liu", "Tong Zhu", "Zhicheng Zhong", "Jian Lv", "Jun Cheng", "Weile Jia", "Mohan Chen", "Guolin Ke", "E Weinan", "Linfeng Zhang", "Handong Wang"], "year": 2024, "venue": "npj Computational Materials", "cited_by_count": 95, "type": "article", "concepts": ["Bottleneck", "Computer science", "Task (project management)", "Process (computing)", "Generalization"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4367052490", "doi": "https://doi.org/10.3390/drones7050287", "title": "A Comprehensive Survey of Transformers for Computer Vision", "abstract": "As a special type of transformer, vision transformers (ViTs) can be used for various computer vision (CV) applications. Convolutional neural networks (CNNs) have several potential problems that can be resolved with ViTs. For image coding tasks such as compression, super-resolution, segmentation, and denoising, different variants of ViTs are used. In our survey, we determined the many CV applications to which ViTs are applicable. CV applications reviewed included image classification, object detection, image segmentation, image compression, image super-resolution, image denoising, anomaly detection, and drone imagery. We reviewed the state of the-art and compiled a list of available models and discussed the pros and cons of each model.", "authors": ["Sonain Jamil", "Md. Jalil Piran", "Oh‐Jin Kwon"], "year": 2023, "venue": "Drones", "cited_by_count": 86, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Computer vision", "Transformer", "Convolutional neural network"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4210511805", "doi": "https://doi.org/10.1109/ojits.2022.3142612", "title": "Countering Adversarial Attacks on Autonomous Vehicles Using Denoising Techniques: A Review", "abstract": "The evolution of automotive technology will eventually permit the automated driving system on the vehicle to handle all circumstances. Human occupants will be just passengers. This poses security issues that need to be addressed. This paper has two aims. The first one investigates strategies for robustifying scene analysis of adversarial road scenes. A taxonomy of the defense mechanisms for countering adversarial perturbations is initially presented, classifying those mechanisms in three major categories: those that modify the data, those that propose adding extra models, and those that focus on modifying the models deployed for scene analysis. Motivated by the limited number of surveys in the first category, we further analyze the approaches that utilize input transformation operations as countermeasures, further classifying them in supervised and unsupervised methods and highlighting both their strengths and weaknesses. The second aim of this paper is to publish CarlaScenes dataset produced using the CARLA simulator. An extensive evaluation study, on CarlaScenes, is performed testing the supervised deep learning approaches that have been either proposed for image restoration or adversarial noise removal. The study presents insights on the robustness of the aforementioned approaches in mitigating adversarial attacks in scene analysis operations.", "authors": ["Andreas Kloukiniotis", "Andreas G. Papandreou", "Aris S. Lalos", "Petros Kapsalas", "Duong-Van Nguyen", "Κωνσταντίνος Μουστάκας"], "year": 2022, "venue": "IEEE Open Journal of Intelligent Transportation Systems", "cited_by_count": 50, "type": "review", "concepts": ["Adversarial system", "Computer science", "Robustness (evolution)", "Artificial intelligence", "Publication"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2902609196", "doi": "https://doi.org/10.1186/s40643-018-0232-6", "title": "Novel application and industrial exploitation of winery by-products", "abstract": "", "authors": ["Εfstathia G. Kalli", "Iliada K. Lappa", "Pavlos Bouchagier", "Petros Α. Tarantilis", "Efstathia Skotti"], "year": 2018, "venue": "Bioresources and Bioprocessing", "cited_by_count": 174, "type": "article", "concepts": ["Winery", "Pomace", "Winemaking", "Business", "Wine"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4319925185", "doi": "https://doi.org/10.3390/s23041990", "title": "Research Challenges, Recent Advances, and Popular Datasets in Deep Learning-Based Underwater Marine Object Detection: A Review", "abstract": "Underwater marine object detection, as one of the most fundamental techniques in the community of marine science and engineering, has been shown to exhibit tremendous potential for exploring the oceans in recent years. It has been widely applied in practical applications, such as monitoring of underwater ecosystems, exploration of natural resources, management of commercial fisheries, etc. However, due to complexity of the underwater environment, characteristics of marine objects, and limitations imposed by exploration equipment, detection performance in terms of speed, accuracy, and robustness can be dramatically degraded when conventional approaches are used. Deep learning has been found to have significant impact on a variety of applications, including marine engineering. In this context, we offer a review of deep learning-based underwater marine object detection techniques. Underwater object detection can be performed by different sensors, such as acoustic sonar or optical cameras. In this paper, we focus on vision-based object detection due to several significant advantages. To facilitate a thorough understanding of this subject, we organize research challenges of vision-based underwater object detection into four categories: image quality degradation, small object detection, poor generalization, and real-time detection. We review recent advances in underwater marine object detection and highlight advantages and disadvantages of existing solutions for each challenge. In addition, we provide a detailed critical examination of the most extensively used datasets. In addition, we present comparative studies with previous reviews, notably those approaches that leverage artificial intelligence, as well as future trends related to this hot topic.", "authors": ["Meng Joo Er", "Jie Chen", "Yani Zhang", "Wenxiao Gao"], "year": 2023, "venue": "Sensors", "cited_by_count": 74, "type": "review", "concepts": ["Underwater", "Computer science", "Object detection", "Artificial intelligence", "Robustness (evolution)"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4385453417", "doi": "https://doi.org/10.1109/tpami.2023.3300470", "title": "Structured Knowledge Distillation for Accurate and Efficient Object Detection", "abstract": "Knowledge distillation, which aims to transfer the knowledge learned by a cumbersome teacher model to a lightweight student model, has become one of the most popular and effective techniques in computer vision. However, many previous knowledge distillation methods are designed for image classification and fail in more challenging tasks such as object detection. In this paper, we first suggest that the failure of knowledge distillation on object detection is mainly caused by two reasons: (1) the imbalance between pixels of foreground and background and (2) lack of knowledge distillation on the relation among different pixels. Then, we propose a structured knowledge distillation scheme, including attention-guided distillation and non-local distillation to address the two issues, respectively. Attention-guided distillation is proposed to find the crucial pixels of foreground objects with an attention mechanism and then make the students take more effort to learn their features. Non-local distillation is proposed to enable students to learn not only the feature of an individual pixel but also the relation between different pixels captured by non-local modules. Experimental results have demonstrated the effectiveness of our method on thirteen kinds of object detection models with twelve comparison methods for both object detection and instance segmentation. For instance, Faster RCNN with our distillation achieves 43.9 mAP on MS COCO2017, which is 4.1 higher than the baseline. Additionally, we show that our method is also beneficial to the robustness and domain generalization ability of detectors. Codes and model weights have been released on GitHub<sup>1</sup>.", "authors": ["Linfeng Zhang", "Kaisheng Ma"], "year": 2023, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 39, "type": "article", "concepts": ["Distillation", "Pixel", "Computer science", "Artificial intelligence", "Object (grammar)"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4406526284", "doi": "https://doi.org/10.3390/s25020531", "title": "A Comprehensive Survey of Deep Learning Approaches in Image Processing", "abstract": "The integration of deep learning (DL) into image processing has driven transformative advancements, enabling capabilities far beyond the reach of traditional methodologies. This survey offers an in-depth exploration of the DL approaches that have redefined image processing, tracing their evolution from early innovations to the latest state-of-the-art developments. It also analyzes the progression of architectural designs and learning paradigms that have significantly enhanced the ability to process and interpret complex visual data. Key advancements, such as techniques improving model efficiency, generalization, and robustness, are examined, showcasing DL's ability to address increasingly sophisticated image-processing tasks across diverse domains. Metrics used for rigorous model evaluation are also discussed, underscoring the importance of performance assessment in varied application contexts. The impact of DL in image processing is highlighted through its ability to tackle complex challenges and generate actionable insights. Finally, this survey identifies potential future directions, including the integration of emerging technologies like quantum computing and neuromorphic architectures for enhanced efficiency and federated learning for privacy-preserving training. Additionally, it highlights the potential of combining DL with emerging technologies such as edge computing and explainable artificial intelligence (AI) to address scalability and interpretability challenges. These advancements are positioned to further extend the capabilities and applications of DL, driving innovation in image processing.", "authors": ["Μαρία Τρίγκα", "Ηλίας Δρίτσας"], "year": 2025, "venue": "Sensors", "cited_by_count": 55, "type": "review", "concepts": ["Deep learning", "Image processing", "Artificial intelligence", "Computer science", "Data science"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4213246275", "doi": "https://doi.org/10.3390/bioengineering9020074", "title": "A New Wave of Industrialization of PHA Biopolyesters", "abstract": "The ever-increasing use of plastics, their fossil origin, and especially their persistence in nature have started a wave of new innovations in materials that are renewable, offer the functionalities of plastics, and are biodegradable. One such class of biopolymers, polyhydroxyalkanoates (PHAs), are biosynthesized by numerous microorganisms through the conversion of carbon-rich renewable resources. PHA homo- and heteropolyesters are intracellular products of secondary microbial metabolism. When isolated from microbial biomass, PHA biopolymers mimic the functionalities of many of the top-selling plastics of petrochemical origin, but biodegrade in soil, freshwater, and marine environments, and are both industrial- and home-compostable. Only a handful of PHA biopolymers have been studied in-depth, and five of these reliably match the desired material properties of established fossil plastics. Realizing the positive attributes of PHA biopolymers, several established chemical companies and numerous start-ups, brand owners, and converters have begun to produce and use PHA in a variety of industrial and consumer applications, in what can be described as the emergence of the \"PHA industry\". While this positive industrial and commercial relevance of PHA can hardly be described as the first wave in its commercial development, it is nonetheless a very serious one with over 25 companies and start-ups and 30+ brand owners announcing partnerships in PHA production and use. The combined product portfolio of the producing companies is restricted to five types of PHA, namely poly(3-hydroxybutyrate), poly(4-hydroxybutyrate), poly(3-hydroxybutyrate-<i>co</i>-3-hydroxyvalerate), poly(3-hydroxybutyrate-<i>co</i>-4-hydroxybutyrate), and poly(3-hydroxybutyrate-<i>co</i>-3-hydroxyhexanoate), even though PHAs as a class of polymers offer the potential to generate almost limitless combinations of polymers beneficial to humankind. To date, by varying the co-monomer type and content in these PHA biopolymers, their properties emulate those of the seven top-selling fossil plastics, representing 230 million t of annual plastics production. Capacity expansions of 1.5 million t over the next 5 years have been announced. Policymakers worldwide have taken notice and are encouraging industry to adopt biodegradable and compostable material solutions. This wave of commercialization of PHAs in single-use and in durable applications holds the potential to make the decisive quantum leap in reducing plastic pollution, the depletion of fossil resources, and the emission of greenhouse gases and thus fighting climate change. This review presents setbacks and success stories of the past 40 years and the current commercialization wave of PHA biopolymers, their properties, and their fields of application.", "authors": ["Martin Koller", "Anindya Mukherjee"], "year": 2022, "venue": "Bioengineering", "cited_by_count": 250, "type": "review", "concepts": ["Polyhydroxyalkanoates", "Petrochemical", "Bioplastic", "Biomass (ecology)", "Biodegradation"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2889495953", "doi": "https://doi.org/10.1109/les.2017.2774800", "title": "Securing Hardware Accelerators: A New Challenge for High-Level Synthesis", "abstract": "High-level synthesis (HLS) tools have made significant progress in the past few years, improving the design productivity for hardware accelerators and becoming mainstream in industry to create specialized system-on-chip architectures. Increasing the level of security of these heterogeneous architectures is becoming critical. However, state-of-the-art security countermeasures are still applied only to the code executing on the processor cores or manually implemented into the generated components, leading to suboptimal and sometimes even insecure designs. This letter discusses extensions to HLS tools for creating secure heterogeneous architectures.", "authors": ["Christian Pilato", "Siddharth Garg", "Kaijie Wu", "Ramesh Karri", "Francesco Regazzoni"], "year": 2017, "venue": "IEEE Embedded Systems Letters", "cited_by_count": 85, "type": "article", "concepts": ["Computer science", "High-level synthesis", "Embedded system", "Mainstream", "Computer architecture"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4323925779", "doi": "https://doi.org/10.1038/s41467-023-36017-x", "title": "Smartphone-based platforms implementing microfluidic detection with image-based artificial intelligence", "abstract": "The frequent outbreak of global infectious diseases has prompted the development of rapid and effective diagnostic tools for the early screening of potential patients in point-of-care testing scenarios. With advances in mobile computing power and microfluidic technology, the smartphone-based mobile health platform has drawn significant attention from researchers developing point-of-care testing devices that integrate microfluidic optical detection with artificial intelligence analysis. In this article, we summarize recent progress in these mobile health platforms, including the aspects of microfluidic chips, imaging modalities, supporting components, and the development of software algorithms. We document the application of mobile health platforms in terms of the detection objects, including molecules, viruses, cells, and parasites. Finally, we discuss the prospects for future development of mobile health platforms.", "authors": ["Bangfeng Wang", "Yiwei Li", "Mengfan Zhou", "Yulong Han", "Mingyu Zhang", "Zhaolong Gao", "Zetai Liu", "Peng Chen", "Wei Du", "Xingcai Zhang", "Xiaojun Feng", "Bi‐Feng Liu"], "year": 2023, "venue": "Nature Communications", "cited_by_count": 195, "type": "review", "concepts": ["Computer science", "Microfluidics", "Modalities", "Point-of-care testing", "Point of care"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4367665525", "doi": "https://doi.org/10.1109/access.2023.3271748", "title": "Deep Learning for Automatic Vision-Based Recognition of Industrial Surface Defects: A Survey", "abstract": "Automatic vision-based inspection systems have played a key role in product quality assessment for decades through the segmentation, detection, and classification of defects. Historically, machine learning frameworks, based on hand-crafted feature extraction, selection, and validation, counted on a combined approach of parameterized image processing algorithms and explicated human knowledge. The outstanding performance of deep learning (DL) for vision systems, in automatically discovering a feature representation suitable for the corresponding task, has exponentially increased the number of scientific articles and commercial products aiming at industrial quality assessment. In such a context, this article reviews more than 220 relevant articles from the related literature published until February 2023, covering the recent consolidation and advances in the field of fully-automatic DL-based surface defects inspection systems, deployed in various industrial applications. The analyzed papers have been classified according to a bi-dimensional taxonomy, that considers both the specific defect recognition task and the employed learning paradigm. The dependency on large and high-quality labeled datasets and the different neural architectures employed to achieve an overall perception of both well-visible and subtle defects, through the supervision of fine or/and coarse data annotations have been assessed. The results of our analysis highlight a growing research interest in defect representation power enrichment, especially by transferring pre-trained layers to an optimized network and by explaining the network decisions to suggest trustworthy retention or rejection of the products being evaluated.", "authors": ["Michela Prunella", "Roberto Maria Scardigno", "Domenico Buongiorno", "Antonio Brunetti", "Nicola Longo", "Raffaele Carli", "Mariagrazia Dotoli", "Vitoantonio Bevilacqua"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 78, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Machine learning", "Deep learning", "Feature extraction"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4387843838", "doi": "https://doi.org/10.3390/rs15205062", "title": "A Review of GAN-Based Super-Resolution Reconstruction for Optical Remote Sensing Images", "abstract": "High-resolution images have a wide range of applications in image compression, remote sensing, medical imaging, public safety, and other fields. The primary objective of super-resolution reconstruction of images is to reconstruct a given low-resolution image into a corresponding high-resolution image by a specific algorithm. With the emergence and swift advancement of generative adversarial networks (GANs), image super-resolution reconstruction is experiencing a new era of progress. Unfortunately, there has been a lack of comprehensive efforts to bring together the advancements made in the field of super-resolution reconstruction using generative adversarial networks. Hence, this paper presents a comprehensive overview of the super-resolution image reconstruction technique that utilizes generative adversarial networks. Initially, we examine the operational principles of generative adversarial networks, followed by an overview of the relevant research and background information on reconstructing remote sensing images through super-resolution techniques. Next, we discuss significant research on generative adversarial networks in high-resolution image reconstruction. We cover various aspects, such as datasets, evaluation criteria, and conventional models used for image reconstruction. Subsequently, the super-resolution reconstruction models based on generative adversarial networks are categorized based on whether the kernel blurring function is recognized and utilized during training. We provide a brief overview of the utilization of generative adversarial network models in analyzing remote sensing imagery. In conclusion, we present a prospective analysis of forthcoming research directions pertaining to super-resolution reconstruction methods that rely on generative adversarial networks.", "authors": ["Xuan Wang", "Lijun Sun", "Abdellah Chehri", "Yongchao Song"], "year": 2023, "venue": "Remote Sensing", "cited_by_count": 83, "type": "review", "concepts": ["Computer science", "Adversarial system", "Generative grammar", "Generative adversarial network", "Artificial intelligence"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3204491849", "doi": "https://doi.org/10.48550/arxiv.2109.14335", "title": "A Systematic Survey of Deep Learning-based Single-Image Super-Resolution", "abstract": "Single-image super-resolution (SISR) is an important task in image processing, which aims to enhance the resolution of imaging systems. Recently, SISR has made a huge leap and has achieved promising results with the help of deep learning (DL). In this survey, we give an overview of DL-based SISR methods and group them according to their design targets. Specifically, we first introduce the problem definition, research background, and the significance of SISR. Secondly, we introduce some related works, including benchmark datasets, upsampling methods, optimization objectives, and image quality assessment methods. Thirdly, we provide a detailed investigation of SISR and give some domain-specific applications of it. Fourthly, we present the reconstruction results of some classic SISR methods to intuitively know their performance. Finally, we discuss some issues that still exist in SISR and summarize some new trends and future directions. This is an exhaustive survey of SISR, which can help researchers better understand SISR and inspire more exciting research in this field. An investigation project for SISR is provided at https://github.com/CV-JunchengLi/SISR-Survey.", "authors": ["Juncheng Li", "Zehua Pei", "Tieyong Zeng", "Gao, Guangwei", "Wang, Longguang", "Wang, Yingqian", "Zeng, Tieyong"], "year": 2021, "venue": "arXiv (Cornell University)", "cited_by_count": 28, "type": "preprint", "concepts": ["Upsampling", "Computer science", "Benchmark (surveying)", "Field (mathematics)", "Artificial intelligence"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3120390034", "doi": "https://doi.org/10.1007/s10462-022-10224-2", "title": "A survey on deep reinforcement learning for audio-based applications", "abstract": "Abstract Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields including computer vision, natural language processing, healthcare, robotics, to name a few. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising applications in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together research studies across different but related areas in speech and music. We begin with an introduction to the general field of DL and reinforcement learning (RL), then progress to the main DRL methods and their applications in the audio domain. We conclude by presenting important challenges faced by audio-based DRL agents and by highlighting open areas for future research and investigation. The findings of this paper will guide researchers interested in DRL for the audio domain.", "authors": ["Siddique Latif", "Heriberto Cuayáhuitl", "Farrukh Pervez", "Fahad Shamshad", "Hafiz Shehbaz Ali", "Erik Cambria"], "year": 2022, "venue": "Artificial Intelligence Review", "cited_by_count": 96, "type": "article", "concepts": ["Reinforcement learning", "Computer science", "Field (mathematics)", "Domain (mathematical analysis)", "Artificial intelligence"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3166117684", "doi": "https://doi.org/10.1109/access.2021.3086530", "title": "Deep Neural Architectures for Medical Image Semantic Segmentation: Review", "abstract": "Deep learning has an enormous impact on medical image analysis. Many computer-aided diagnostic systems equipped with deep networks are rapidly reducing human intervention in healthcare. Among several applications, medical image semantic segmentation is one of the core areas of active research to delineate the anatomical structures and other regions of interest. It has a significant contribution to healthcare and provides guided interventions, radiotherapy, and improved radiological diagnostics. The underlying article provides a brief overview of deep convolutional neural architecture, the platforms and applications of deep neural networks, metrics used for empirical evaluation, state-of-the-art semantic segmentation architectures based on a foundational convolution concept, and a review of publicly available medical image datasets highlighting four distinct regions of interest. The article also analyzes the existing work and provides open-ended potential research directions in deep medical image semantic segmentation.", "authors": ["Muhammad Zubair Khan", "Mohan Kumar Gajendran", "Yugyung Lee", "Muazzam A. Khan"], "year": 2021, "venue": "IEEE Access", "cited_by_count": 94, "type": "article", "concepts": ["Computer science", "Deep learning", "Convolutional neural network", "Artificial intelligence", "Segmentation"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4391023335", "doi": "https://doi.org/10.3390/fi16010032", "title": "A Holistic Review of Machine Learning Adversarial Attacks in IoT Networks", "abstract": "With the rapid advancements and notable achievements across various application domains, Machine Learning (ML) has become a vital element within the Internet of Things (IoT) ecosystem. Among these use cases is IoT security, where numerous systems are deployed to identify or thwart attacks, including intrusion detection systems (IDSs), malware detection systems (MDSs), and device identification systems (DISs). Machine Learning-based (ML-based) IoT security systems can fulfill several security objectives, including detecting attacks, authenticating users before they gain access to the system, and categorizing suspicious activities. Nevertheless, ML faces numerous challenges, such as those resulting from the emergence of adversarial attacks crafted to mislead classifiers. This paper provides a comprehensive review of the body of knowledge about adversarial attacks and defense mechanisms, with a particular focus on three prominent IoT security systems: IDSs, MDSs, and DISs. The paper starts by establishing a taxonomy of adversarial attacks within the context of IoT. Then, various methodologies employed in the generation of adversarial attacks are described and classified within a two-dimensional framework. Additionally, we describe existing countermeasures for enhancing IoT security against adversarial attacks. Finally, we explore the most recent literature on the vulnerability of three ML-based IoT security systems to adversarial attacks.", "authors": ["Hassan Khazane", "Mohammed Ridouani", "Fatima Salahdine", "Naima Kaabouch"], "year": 2024, "venue": "Future Internet", "cited_by_count": 53, "type": "review", "concepts": ["Adversarial system", "Computer science", "Computer security", "Adversarial machine learning", "Attack surface"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3186023826", "doi": "https://doi.org/10.1109/access.2021.3100069", "title": "A Super Resolution Algorithm Based on Attention Mechanism and SRGAN Network", "abstract": "Image super-resolution reconstruction uses a specific algorithm to restore the low resolution blurred image in the same scene to a high resolution image. In recent years, with the vigorous development of deep learning, this technology has been widely used in many fields. In the field of image super-resolution reconstruction, more and more methods based on deep learning have been studied. According to the principle of GAN, a pseudo high-resolution image is generated by the generator, and then the discriminator calculates the difference between the image and the real high-resolution image to measure the authenticity of the image. Based on SRGAN (super resolution general adverse network), this paper mainly makes three improvements. First, it introduces the attention channel mechanism, that is, it adds Ca (channel attention) module to SRGAN network, and increases the network depth to better express high frequency features; Second, delete the original BN (batch normalization) layer to improve the network performance; Third, modify the loss function to reduce the impact of noise on the image. The experimental results show that the proposed method is superior to the current methods in both quantitative and qualitative indicators, and promotes the recovery of high-frequency detail information. The experimental results show that the proposed method improves the artifact problem and improves the PSNR (peak signal-to-noise ratio) on set5, set10 and bsd100 test sets.", "authors": ["Baozhong Liu", "Ji Chen"], "year": 2021, "venue": "IEEE Access", "cited_by_count": 46, "type": "article", "concepts": ["Discriminator", "Computer science", "Artificial intelligence", "Normalization (sociology)", "Image (mathematics)"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2116040783", "doi": null, "title": "PMU placement for power system observability using binary particle swarm optimization", "abstract": "A binary particle swarm optimization (BPSO) based methodology for the optimal placement of phasor measurement units (PMUs) for complete observability of a power system is presented in this paper. The objectives of the optimization problem are to minimize the total number of PMUs required, and to maximize the measurement redundancy at the power system buses. Simulation results on the IEEE 14-bus and 30-bus test systems are presented in this paper.", "authors": ["Saikat Chakrabarti", "Ganesh K. Venayagamoorthy", "Elias Kyriakides"], "year": 2008, "venue": "QUT ePrints (Queensland University of Technology)", "cited_by_count": 61, "type": "article", "concepts": ["Observability", "Phasor", "Particle swarm optimization", "Redundancy (engineering)", "Units of measurement"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4390873137", "doi": "https://doi.org/10.1109/tpami.2024.3350004", "title": "Face Generation and Editing With StyleGAN: A Survey", "abstract": "Our goal with this survey is to provide an overview of the state of the art deep learning methods for face generation and editing using StyleGAN. The survey covers the evolution of StyleGAN, from PGGAN to StyleGAN3, and explores relevant topics such as suitable metrics for training, different latent representations, GAN inversion to latent spaces of StyleGAN, face image editing, cross-domain face stylization, face restoration, and even Deepfake applications. We aim to provide an entry point into the field for readers that have basic knowledge about the field of deep learning and are looking for an accessible introduction and overview.", "authors": ["Andrew Melnik", "Maksim Miasayedzenkau", "Dzianis Makaravets", "Dzianis Pirshtuk", "Eren Akbulut", "Dennis Holzmann", "Tarek Renusch", "Gustav Reichert", "Helge Ritter"], "year": 2024, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 76, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Image editing", "Face (sociological concept)", "Deep learning"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4285193949", "doi": "https://doi.org/10.1109/ted.2022.3166716", "title": "Review of Quanta Image Sensors for Ultralow-Light Imaging", "abstract": "The quanta image sensor (QIS) is a photon-counting image sensor that has been implemented using different electron devices, including impact ionization-gain devices, such as the single-photon avalanche detectors (SPADs), and low-capacitance, high conversion-gain devices, such as modified CMOS image sensors (CIS) with deep subelectron read noise and/or low noise readout signal chains. This article primarily focuses on CIS QIS, but recent progress of both types is addressed. Signal processing progress, such as denoising, critical to improving apparent signal-to-noise ratio, is also reviewed as an enabling coinnovation.", "authors": ["Jiaju Ma", "Stanley H. Chan", "Eric R. Fossum"], "year": 2022, "venue": "IEEE Transactions on Electron Devices", "cited_by_count": 53, "type": "article", "concepts": ["Image sensor", "Noise (video)", "SIGNAL (programming language)", "Photon counting", "Capacitance"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4392948149", "doi": "https://doi.org/10.1016/j.eswa.2024.123732", "title": "DeepFake detection based on high-frequency enhancement network for highly compressed content", "abstract": "", "authors": ["Jie Gao", "Zhaoqiang Xia", "Gian Luca Marcialis", "Chen Dang", "Jing Dai", "Xiaoyi Feng"], "year": 2024, "venue": "Expert Systems with Applications", "cited_by_count": 39, "type": "article", "concepts": ["Computer science", "Compressed sensing", "Content (measure theory)", "Pattern recognition (psychology)", "Artificial intelligence"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4388018933", "doi": "https://doi.org/10.3390/app132111852", "title": "A Brief, In-Depth Survey of Deep Learning-Based Image Watermarking", "abstract": "This paper presents a comprehensive survey of deep learning-based image watermarking; this technique entails the invisible embedding and extraction of watermarks within a cover image, aiming for a seamless combination of robustness and adaptability. We navigate the complex landscape of this interdisciplinary domain, linking historical foundations, current innovations, and prospective developments. Unlike existing literature, our study concentrates exclusively on image watermarking with deep learning, delivering an in-depth, yet brief analysis enriched by three fundamental contributions. First, we introduce a refined categorization, segmenting the field into embedder–extractor, deep networks for feature transformation, and hybrid methods. This taxonomy, inspired by the varied roles of deep learning across studies, is designed to infuse clarity, offering readers technical insights and directional guidance. Second, our exploration dives into representative methodologies, encapsulating the diverse research directions and inherent challenges within each category to provide a consolidated perspective. Lastly, we venture beyond established boundaries, outlining emerging frontiers and providing detailed insights into prospective research avenues.", "authors": ["Xin Zhong", "Arjon Das", "Fahad Alrasheedi", "Abdullah Tanvir"], "year": 2023, "venue": "Applied Sciences", "cited_by_count": 33, "type": "article", "concepts": ["Deep learning", "Artificial intelligence", "Computer science", "Data science", "Adaptability"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4387230345", "doi": "https://doi.org/10.3390/jimaging9100207", "title": "Developments in Image Processing Using Deep Learning and Reinforcement Learning", "abstract": "The growth in the volume of data generated, consumed, and stored, which is estimated to exceed 180 zettabytes in 2025, represents a major challenge both for organizations and for society in general. In addition to being larger, datasets are increasingly complex, bringing new theoretical and computational challenges. Alongside this evolution, data science tools have exploded in popularity over the past two decades due to their myriad of applications when dealing with complex data, their high accuracy, flexible customization, and excellent adaptability. When it comes to images, data analysis presents additional challenges because as the quality of an image increases, which is desirable, so does the volume of data to be processed. Although classic machine learning (ML) techniques are still widely used in different research fields and industries, there has been great interest from the scientific community in the development of new artificial intelligence (AI) techniques. The resurgence of neural networks has boosted remarkable advances in areas such as the understanding and processing of images. In this study, we conducted a comprehensive survey regarding advances in AI design and the optimization solutions proposed to deal with image processing challenges. Despite the good results that have been achieved, there are still many challenges to face in this field of study. In this work, we discuss the main and more recent improvements, applications, and developments when targeting image processing applications, and we propose future research directions in this field of constant and fast evolution.", "authors": ["Jorge Valente", "João António", "Carlos León de Mora", "Sandra Jardim"], "year": 2023, "venue": "Journal of Imaging", "cited_by_count": 76, "type": "review", "concepts": ["Computer science", "Popularity", "Field (mathematics)", "Artificial intelligence", "Data science"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4391444806", "doi": "https://doi.org/10.1186/s13321-024-00808-1", "title": "DLM-DTI: a dual language model for the prediction of drug-target interaction with hint-based learning", "abstract": "The drug discovery process is demanding and time-consuming, and machine learning-based research is increasingly proposed to enhance efficiency. A significant challenge in this field is predicting whether a drug molecule's structure will interact with a target protein. A recent study attempted to address this challenge by utilizing an encoder that leverages prior knowledge of molecular and protein structures, resulting in notable improvements in the prediction performance of the drug-target interactions task. Nonetheless, the target encoders employed in previous studies exhibit computational complexity that increases quadratically with the input length, thereby limiting their practical utility. To overcome this challenge, we adopt a hint-based learning strategy to develop a compact and efficient target encoder. With the adaptation parameter, our model can blend general knowledge and target-oriented knowledge to build features of the protein sequences. This approach yielded considerable performance enhancements and improved learning efficiency on three benchmark datasets: BIOSNAP, DAVIS, and Binding DB. Furthermore, our methodology boasts the merit of necessitating only a minimal Video RAM (VRAM) allocation, specifically 7.7GB, during the training phase (16.24% of the previous state-of-the-art model). This ensures the feasibility of training and inference even with constrained computational resources.", "authors": ["Jonghyun Lee", "Dae Won Jun", "Ildae Song", "Yun Kim"], "year": 2024, "venue": "Journal of Cheminformatics", "cited_by_count": 37, "type": "article", "concepts": ["Computer science", "Machine learning", "Benchmark (surveying)", "Encoder", "Inference"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4394766673", "doi": "https://doi.org/10.1145/3657632", "title": "Visual Tuning", "abstract": "Fine-tuning visual models has been widely shown promising performance on many downstream visual tasks. With the surprising development of pre-trained visual foundation models, visual tuning jumped out of the standard modus operandi that fine-tunes the whole pre-trained model or just the fully connected layer. Instead, recent advances can achieve superior performance than full-tuning the whole pre-trained parameters by updating far fewer parameters, enabling edge devices and downstream applications to reuse the increasingly large foundation models deployed on the cloud. With the aim of helping researchers get the full picture and future directions of visual tuning, this survey characterizes a large and thoughtful selection of recent works, providing a systematic and comprehensive overview of existing work and models. Specifically, it provides a detailed background of visual tuning and categorizes recent visual tuning techniques into five groups: fine-tuning, prompt tuning, adapter tuning, parameter tuning, and remapping tuning. Meanwhile, it offers some exciting research directions for prospective pre-training and various interactions in visual tuning.", "authors": ["Bruce X. B. Yu", "Jianlong Chang", "Haixin Wang", "Lingbo Liu", "Shijie Wang", "Zhiyu Wang", "Junfan Lin", "Lingxi Xie", "Haojie Li", "Zhouchen Lin", "Qi Tian", "Chang Wen Chen"], "year": 2024, "venue": "ACM Computing Surveys", "cited_by_count": 25, "type": "review", "concepts": ["Computer science", "Fine-tuning", "Adapter (computing)", "Artificial intelligence", "Reuse"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4384341180", "doi": "https://doi.org/10.3390/rs15143534", "title": "Measurement of Total Dissolved Solids and Total Suspended Solids in Water Systems: A Review of the Issues, Conventional, and Remote Sensing Techniques", "abstract": "This study provides a comprehensive review of the efforts utilized in the measurement of water quality parameters (WQPs) with a focus on total dissolved solids (TDS) and total suspended solids (TSS). The current method used in the measurement of TDS and TSS includes conventional field and gravimetric approaches. These methods are limited due to the associated cost and labor, and limited spatial coverages. Remote Sensing (RS) applications have, however, been used over the past few decades as an alternative to overcome these limitations. Although they also present underlying atmospheric interferences in images, radiometric and spectral resolution issues. Studies of these WQPs with RS, therefore, require the knowledge and utilization of the best mechanisms. The use of RS for retrieval of TDS, TSS, and their forms has been explored in many studies using images from airborne sensors onboard unmanned aerial vehicles (UAVs) and satellite sensors such as those onboard the Landsat, Sentinel-2, Aqua, and Terra platforms. The images and their spectral properties serve as inputs for deep learning analysis and statistical, and machine learning models. Methods used to retrieve these WQP measurements are dependent on the optical properties of the inland water bodies. While TSS is an optically active parameter, TDS is optically inactive with a low signal–noise ratio. The detection of TDS in the visible, near-infrared, and infrared bands is due to some process that (usually) co-occurs with changes in the TDS that is affecting a WQP that is optically active. This study revealed significant improvements in incorporating RS and conventional approaches in estimating WQPs. The findings reveal that improved spatiotemporal resolution has the potential to effectively detect changes in the WQPs. For effective monitoring of TDS and TSS using RS, we recommend employing atmospheric correction mechanisms to reduce image atmospheric interference, exploration of the fusion of optical and microwave bands, high-resolution hyperspectral images, utilization of ML and deep learning models, calibration and validation using observed data measured from conventional methods. Further studies could focus on the development of new technology and sensors using UAVs and satellite images to produce real-time in situ monitoring of TDS and TSS. The findings presented in this review aid in consolidating understanding and advancement of TDS and TSS measurements in a single repository thereby offering stakeholders, researchers, decision-makers, and regulatory bodies a go-to information resource to enhance their monitoring efforts and mitigation of water quality impairments.", "authors": ["Godson Ebenezer Adjovu", "Haroon Stephen", "David E. James", "Sajjad Ahmad"], "year": 2023, "venue": "Remote Sensing", "cited_by_count": 208, "type": "review", "concepts": ["Total suspended solids", "Remote sensing", "Total dissolved solids", "Suspended solids", "Environmental science"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4385627173", "doi": "https://doi.org/10.1109/access.2023.3302692", "title": "DANS: Deep Attention Network for Single Image Super-Resolution", "abstract": "The current advancements in image super-resolution have explored different attention mechanisms to achieve better quantitative and perceptual results. The critical challenge recently is to utilize the potential of attention mechanisms to reconstruct high-resolution images from their low-resolution counterparts. This research proposes a novel method that combines inception blocks, non-local sparse attention, and a U-Net network architecture. The network incorporates the non-local sparse attention on the backbone of symmetric encoder-decoder U-Net structure, which helps to identify long-range dependencies and exploits contextual information while preserving global context. By incorporating skip connections, the network can leverage features at different scales, enhancing the reconstruction of high-frequency information. Additionally, we introduce inception blocks allowing the model to capture information at various levels of abstraction to enhance multi-scale representation learning further. Experimental findings show that our suggested approach produces superior quantitative measurements, such as peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), visual information fidelity (VIF), and visually appealing high-resolution image reconstructions.", "authors": ["Jagrati Talreja", "Supavadee Aramvith", "Takao Onoye"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 28, "type": "article", "concepts": ["Computer science", "Leverage (statistics)", "Artificial intelligence", "Encoder", "Context (archaeology)"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3159082513", "doi": "https://doi.org/10.1007/978-3-031-01233-4_1", "title": "Inspect, Understand, Overcome: A Survey of Practical Methods for AI Safety", "abstract": "", "authors": ["Sebastian Houben", "Stephanie Abrecht", "Maram Akila", "Andreas Bär", "Felix Brockherde", "Patrick Feifel", "Tim Fingscheidt", "Sujan Sai Gannamaneni", "Seyed Eghbal Ghobadi", "Ahmed Hammam", "Anselm Haselhoff", "Felix Hauser", "Christian Heinzemann", "Marco Hoffmann", "Nikhil Kapoor", "Falk Kappel", "Marvin Klingner", "Jan Kronenberger", "Fabian Küppers", "Jonas Löhdefink", "Michael Mlynarski", "Michael Möck", "Firas Mualla", "Svetlana Pavlitskaya", "Maximilian Poretschkin", "Alexander Pohl", "Varun Ravi-Kumar", "Julia Rosenzweig", "Matthias Rottmann", "Stefan Rüping", "Timo Sämann", "Ján Schneider", "Elena Schulz", "Gesina Schwalbe", "Joachim Sicking", "Toshika Srivastava", "Serin Varghese", "Michael Weber", "Sebastian Wirkert", "Tim Wirtz", "Matthias Woehrle"], "year": 2022, "venue": "", "cited_by_count": 46, "type": "book-chapter", "concepts": ["Psychology", "Computer science", "Engineering", "Engineering ethics"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2515253281", "doi": "https://doi.org/10.1039/c6cc06533c", "title": "Supramolecular metallogels with bulk self-healing properties prepared by in situ metal complexation", "abstract": "In this feature article, we discuss a series of contributions dealing with the in situ fabrication of supramolecular metallogels (i.e. using low molecular weight ligands and metal ions) that show self-healing properties of the bulk gel phase after complete physical segregation. Most of the advances in this area have taken place during the last three years and are mainly represented by organogels, whereas examples of hydrogels and organic-aqueous gels are still a minority. In situ gelation via metal-coordination of low molecular weight compounds is conceptually different from the use of premade (e.g. in solution) coordination polymers and polymeric structures as gelators and ligands, respectively. In the case of in situ gelation, the cooperative effects of all components of the mixture (i.e. ligand, metal ion, counterions and solvent molecules) in an appropriate ratio under well-defined experimental conditions play a crucial role in the gelation phenomenon and self-healing properties of the material.", "authors": ["Marleen Häring", "David Díaz Díaz"], "year": 2016, "venue": "Chemical Communications", "cited_by_count": 103, "type": "article", "concepts": ["Supramolecular chemistry", "Counterion", "Self-healing hydrogels", "Aqueous solution", "In situ"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W3215119337", "doi": "https://doi.org/10.1109/tmi.2021.3132291", "title": "Unpaired Cross-Modality Educed Distillation (CMEDL) for Medical Image Segmentation", "abstract": "Accurate and robust segmentation of lung cancers from CT, even those located close to mediastinum, is needed to more accurately plan and deliver radiotherapy and to measure treatment response. Therefore, we developed a new cross-modality educed distillation (CMEDL) approach, using unpaired CT and MRI scans, whereby an informative teacher MRI network guides a student CT network to extract features that signal the difference between foreground and background. Our contribution eliminates two requirements of distillation methods: (i) paired image sets by using an image to image (I2I) translation and (ii) pre-training of the teacher network with a large training set by using concurrent training of all networks. Our framework uses an end-to-end trained unpaired I2I translation, teacher, and student segmentation networks. Architectural flexibility of our framework is demonstrated using 3 segmentation and 2 I2I networks. Networks were trained with 377 CT and 82 T2w MRI from different sets of patients, with independent validation (N = 209 tumors) and testing (N = 609 tumors) datasets. Network design, methods to combine MRI with CT information, distillation learning under informative (MRI to CT), weak (CT to MRI) and equal teacher (MRI to MRI), and ablation tests were performed. Accuracy was measured using Dice similarity (DSC), surface Dice (sDSC), and Hausdorff distance at the 95<sup>th</sup> percentile (HD95). The CMEDL approach was significantly (p < 0.001) more accurate (DSC of 0.77 vs. 0.73) than non-CMEDL methods with an informative teacher for CT lung tumor, with a weak teacher (DSC of 0.84 vs. 0.81) for MRI lung tumor, and with equal teacher (DSC of 0.90 vs. 0.88) for MRI multi-organ segmentation. CMEDL also reduced inter-rater lung tumor segmentation variabilities.", "authors": ["Jue Jiang", "Andreas Rimner", "Joseph O. Deasy", "Harini Veeraraghavan"], "year": 2021, "venue": "IEEE Transactions on Medical Imaging", "cited_by_count": 21, "type": "article", "concepts": [], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4385633589", "doi": "https://doi.org/10.2147/ijn.s418534", "title": "Progress in Pluronic F127 Derivatives for Application in Wound Healing and Repair", "abstract": "Pluronic F127 hydrogel biomaterial has garnered considerable attention in wound healing and repair due to its remarkable properties including temperature sensitivity, injectability, biodegradability, and maintain a moist wound environment. This comprehensive review provides an in-depth exploration of the recent advancements in Pluronic F127-derived hydrogels, such as F127-CHO, F127-NH<sub>2</sub>, and F127-DA, focusing on their applications in the treatment of various types of wounds, ranging from burns and acute wounds to infected wounds, diabetic wounds, cutaneous tumor wounds, and uterine scars. Furthermore, the review meticulously examines the intricate interaction mechanisms employed by these hydrogels within the wound microenvironment. By elucidating the underlying mechanisms, discussing the strengths and weaknesses of Pluronic F127, analyzing the current state of wound healing development, and expanding on the trend of targeting mitochondria and cells with F127 as a nanomaterial. The review enhances our understanding of the therapeutic effects of these hydrogels aims to foster the development of effective and safe wound-healing modalities. The valuable insights provided this review have the potential to inspire novel ideas for clinical treatment and facilitate the advancement of innovative wound management approaches.", "authors": ["Shanshan Li", "Cheng Yang", "Junqiang Li", "Chao Zhang", "Liaoliao Zhu", "Yang Song", "Yongdong Guo", "Ronglin Wang", "Dongxue Gan", "Jingjie Shi", "Peixiang Ma", "Fei Gao", "Haichuan Su"], "year": 2023, "venue": "International Journal of Nanomedicine", "cited_by_count": 71, "type": "review", "concepts": ["Poloxamer", "Self-healing hydrogels", "Wound healing", "Biomaterial", "Tissue repair"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W4382138923", "doi": "https://doi.org/10.1109/jstars.2023.3289293", "title": "Transformer Meets Remote Sensing Video Detection and Tracking: A Comprehensive Survey", "abstract": "Transformer has shown excellent performance in remote sensing field with long-range modeling capabilities. Remote sensing video (RSV) moving object detection and tracking play indispensable roles in military activities as well as urban monitoring. However, transformers in these fields are still at the exploratory stage. In this survey, we comprehensively summarize the research prospects of transformers in RSV moving object detection and tracking. The core designs of remote sensing transformers and advanced transformers are first analyzed. It mainly includes the attention mechanism evolution for specific tasks, the fitting ability design of input mapping, diverse feature representation, model optimization, etc. The architectural characteristics of RSV detection and tracking are then described across two aspects. One is moving object detection for motion-based traditional background subtractions and appearance-based deep learning models. The other is object tracking for single and multi-targets. The research difficulties mainly include the blurred foreground in RSV data, the irregular objects movement in traditional background subtraction and the severe objects occlusion in object tracking. Following that, the potential significance of transformers is discussed according to some thorny problems in RSV. Finally, we summarize ten open challenges of transformers in RSV, which may be used as a reference for promoting future research.", "authors": ["Licheng Jiao", "Xin Zhang", "Xu Liu", "Fang Liu", "Shuyuan Yang", "Wenping Ma", "Lingling Li", "Puhua Chen", "Zhixi Feng", "Yuwei Guo", "Xu Tang", "Biao Hou", "Xiangrong Zhang", "Jing Bai", "Dou Quan", "Junpeng Zhang"], "year": 2023, "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "cited_by_count": 49, "type": "article", "concepts": ["Computer science", "Transformer", "Computer vision", "Artificial intelligence", "Object detection"], "search_query": "knowledge distillation model compression image restoration"}
{"openalex_id": "https://openalex.org/W2102091600", "doi": "https://doi.org/10.1109/72.822518", "title": "Weight assignment for adaptive image restoration by neural networks", "abstract": "This paper presents a scheme for adaptively training the weights, in terms of varying the regularization parameter, in a neural network for the restoration of digital images. The flexibility of neural-network-based image restoration algorithms easily allow the variation of restoration parameters such as blur statistics and regularization value spatially and temporally within the image. This paper focuses on spatial variation of the regularization parameter.We first show that the previously proposed neural-network method based on gradient descent can only find suboptimal solutions, and then introduce a regional processing approach based on local statistics. A method is presented to vary the regularization parameter spatially. This method is applied to a number of images degraded by various levels of noise, and the results are examined. The method is also applied to an image degraded by spatially variant blur. In all cases, the proposed method provides visually satisfactory results in an efficient way.", "authors": ["Stuart Perry", "Ling Guan"], "year": 2000, "venue": "IEEE Transactions on Neural Networks", "cited_by_count": 58, "type": "article", "concepts": ["Image restoration", "Computer science", "Artificial neural network", "Artificial intelligence", "Image (mathematics)"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W4382449856", "doi": "https://doi.org/10.1609/aaai.v37i1.25111", "title": "Hybrid CNN-Transformer Feature Fusion for Single Image Deraining", "abstract": "Since rain streaks exhibit diverse geometric appearances and irregular overlapped phenomena, these complex characteristics challenge the design of an effective single image deraining model. To this end, rich local-global information representations are increasingly indispensable for better satisfying rain removal. In this paper, we propose a lightweight Hybrid CNN-Transformer Feature Fusion Network (dubbed as HCT-FFN) in a stage-by-stage progressive manner, which can harmonize these two architectures to help image restoration by leveraging their individual learning strengths. Specifically, we stack a sequence of the degradation-aware mixture of experts (DaMoE) modules in the CNN-based stage, where appropriate local experts adaptively enable the model to emphasize spatially-varying rain distribution features. As for the Transformer-based stage, a background-aware vision Transformer (BaViT) module is employed to complement spatially-long feature dependencies of images, so as to achieve global texture recovery while preserving the required structure. Considering the indeterminate knowledge discrepancy among CNN features and Transformer features, we introduce an interactive fusion branch at adjacent stages to further facilitate the reconstruction of high-quality deraining results. Extensive evaluations show the effectiveness and extensibility of our developed HCT-FFN. The source code is available at https://github.com/cschenxiang/HCT-FFN.", "authors": ["Xiang Chen", "Jinshan Pan", "Jiyang Lu", "Zhentao Fan", "Hao Li"], "year": 2023, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 66, "type": "article", "concepts": ["Computer science", "Transformer", "Artificial intelligence", "Feature (linguistics)", "Source code"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W567999022", "doi": "https://doi.org/10.1201/b12693", "title": "Image Restoration", "abstract": "Image Denoising: Past, Present, and Future, X. Li Historical Review of Image Denoising First Episode: Local Wiener Filtering Second Episode: Understanding Transient Events Third Generation: Understanding Nonlocal Similarity Conclusions and Perspectives Fundamentals of Image Restoration, B.K. Gunturk Linear Shift-Invariant Degradation Model Image Restoration Methods Blind Image Restoration Other Methods of Image Restoration Super Resolution Image Restoration Regularization Parameter Estimation Beyond Linear Shift-Invariant Imaging Model Restoration in the Presence of Unknown Spatially Varying Blur, M. Sorel and F. Sroubek Blur models Space-Variant Super Resolution Image Denoising and Restoration Based on Nonlocal Means, P. van Beek, Y. Su, and J. Yang Image Denoising Based on the Nonlocal Means Image Deblurring Using Nonlocal Means Regularization Recent Nonlocal and Sparse Modeling Methods Reducing Computational Cost of NLM-Based Methods Sparsity-Regularized Image Restoration: Locality and Convexity Revisited, W. Dong and X. Li Historical Review of Sparse Representations From Local to Nonlocal Sparse Representations From Convex to Nonconvex Optimization Algorithms Reproducible Experimental Results Conclusions and Connections Resolution Enhancement Using Prior Information, H.M. Shieh, C.L. Byrne, and M.A. Fiddy Fourier Transform Estimation and Minimum L2-Norm Solution Minimum Weighted L2-Norm Solution Solution Sparsity and Data Sampling Minimum L1-Norm and Minimum Weighted L1-Norm Solutions Modification with Nonuniform Weights Summary and Conclusions Transform Domain-Based Learning for Super Resolution Restoration, P.P. Gajjar, M.V. Joshi, and K.P. Upla Introduction to Super Resolution Related Work Description of the Proposed Approach Transform Domain-Based Learning of the Initial HR Estimate Experimental Results Conclusions and Future Research Work Super Resolution for Multispectral Image Classification, F. Li, X. Jia, D. Fraser, and A. Lambert Methodology Experimental Results Color Image Restoration Using Vector Filtering Operators, R. Lukac Color Imaging Basics Color Space Conversions Color Image Filtering Color Image Quality Evaluation Document Image Restoration and Analysis as Separation of Mixtures of Patterns: From Linear to Nonlinear Models, A. Tonazzini, I. Gerace, and F. Martinelli Linear Instantaneous Data Model Linear Convolutional Data Model Nonlinear Convolutional Data Model for the Recto-Verso Case Conclusions and Future Prospects Correction of Spatially Varying Image and Video Motion Blur Using a Hybrid Camera, Y.-W. Tai and M.S. Brown Related Work Hybrid Camera System Optimization Framework Deblurring of Moving Objects Temporal Upsampling Results and Comparisons", "authors": [], "year": 2018, "venue": "", "cited_by_count": 45, "type": "book", "concepts": ["Image restoration", "Artificial intelligence", "Computer science", "Image (mathematics)", "Image processing"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2295936755", "doi": "https://doi.org/10.1145/344779.344972", "title": "Image inpainting", "abstract": "Inpainting, the technique of modifying an image in an undetectable form, is as ancient as art itself. The goals and applications of inpainting are numerous, from the restoration of damaged paintings and photographs to the removal/replacement of selected objects. In this paper, we introduce a novel algorithm for digital inpainting of still images that attempts to replicate the basic techniques used by professional restorators. After the user selects the regions to be restored, the algorithm automatically fills-in these regions with information surrounding them. The fill-in is done in such a way that isophote lines arriving at the regions' boundaries are completed inside. In contrast with previous approaches, the technique here introduced does not require the user to specify where the novel information comes from. This is automatically done (and in a fast way), thereby allowing to simultaneously fill-in numerous regions containing completely different structures and surrounding backgrounds. In addition, no limitations are imposed on the topology of the region to be inpainted. Applications of this technique include the restoration of old photographs and damaged film; removal of superimposed text like dates, subtitles, or publicity; and the removal of entire objects from the image like microphones or wires in special effects.", "authors": ["Marcelo Bertalmı́o", "Guillermo Sapiro", "V. Caselles", "Coloma Ballester"], "year": 2000, "venue": "", "cited_by_count": 3549, "type": "article", "concepts": ["Inpainting", "Computer science", "Artificial intelligence", "Computer vision", "Image restoration"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2127597920", "doi": "https://doi.org/10.1126/sciadv.1500052", "title": "Habitat fragmentation and its lasting impact on Earth’s ecosystems", "abstract": "We conducted an analysis of global forest cover to reveal that 70% of remaining forest is within 1 km of the forest's edge, subject to the degrading effects of fragmentation. A synthesis of fragmentation experiments spanning multiple biomes and scales, five continents, and 35 years demonstrates that habitat fragmentation reduces biodiversity by 13 to 75% and impairs key ecosystem functions by decreasing biomass and altering nutrient cycles. Effects are greatest in the smallest and most isolated fragments, and they magnify with the passage of time. These findings indicate an urgent need for conservation and restoration measures to improve landscape connectivity, which will reduce extinction rates and help maintain ecosystem services.", "authors": ["Nick M. Haddad", "Lars A. Brudvig", "Jean Clobert", "Kendi F. Davies", "Andrew Gonzalez", "Robert D. Holt", "Thomas Ε. Lovejoy", "Joe Sexton", "Mike P. Austin", "Cathy D. Collins", "William M. Cook", "Ellen I. Damschen", "Robert M. Ewers", "Bryan L. Foster", "Clinton N. Jenkins", "Andrew J. King", "William F. Laurance", "Douglas J. Levey", "Chris Margules", "Brett A. Melbourne", "Anthony Nicholls", "John L. Orrock", "Dan-Xia Song", "John Townshend"], "year": 2015, "venue": "Science Advances", "cited_by_count": 4277, "type": "article", "concepts": ["Biome", "Fragmentation (computing)", "Ecosystem", "Biodiversity", "Habitat fragmentation"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2074661552", "doi": "https://doi.org/10.1007/s00401-009-0619-8", "title": "Astrocytes: biology and pathology", "abstract": "", "authors": ["Michael V. Sofroniew", "Harry V. Vinters"], "year": 2009, "venue": "Acta Neuropathologica", "cited_by_count": 5027, "type": "review", "concepts": ["Astrogliosis", "Astrocyte", "Glial scar", "Biology", "Gliosis"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2156936307", "doi": "https://doi.org/10.1109/tip.2015.2446191", "title": "A Fast Single Image Haze Removal Algorithm Using Color Attenuation Prior", "abstract": "Single image haze removal has been a challenging problem due to its ill-posed nature. In this paper, we propose a simple but powerful color attenuation prior for haze removal from a single input hazy image. By creating a linear model for modeling the scene depth of the hazy image under this novel prior and learning the parameters of the model with a supervised learning method, the depth information can be well recovered. With the depth map of the hazy image, we can easily estimate the transmission and restore the scene radiance via the atmospheric scattering model, and thus effectively remove the haze from a single image. Experimental results show that the proposed approach outperforms state-of-the-art haze removal algorithms in terms of both efficiency and the dehazing effect.", "authors": ["Qingsong Zhu", "Jiaming Mai", "Ling Shao"], "year": 2015, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 2321, "type": "article", "concepts": ["Haze", "Radiance", "Artificial intelligence", "Computer science", "Computer vision"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W3108495343", "doi": "https://doi.org/10.1038/s41592-020-00990-8", "title": "Non-uniform refinement: adaptive regularization improves single-particle cryo-EM reconstruction", "abstract": "", "authors": ["Ali Punjani", "Haowei Zhang", "David J. Fleet"], "year": 2020, "venue": "Nature Methods", "cited_by_count": 1737, "type": "article", "concepts": ["Regularization (linguistics)", "Algorithm", "Computer science", "Particle (ecology)", "Computational biology"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2040385059", "doi": "https://doi.org/10.1159/000363582", "title": "Matrix Metalloproteinases and Other Matrix Proteinases in Relation to Cariology: The Era of ‘Dentin Degradomics'", "abstract": "Dentin organic matrix, with type I collagen as the main component, is exposed after demineralization in dentinal caries, erosion or acidic conditioning during adhesive composite restorative treatment. This exposed matrix is prone to slow hydrolytic degradation by host collagenolytic enzymes, matrix metalloproteinases (MMPs) and cysteine cathepsins. Here we review the recent findings demonstrating that inhibition of salivary or dentin endogenous collagenolytic enzymes may provide preventive means against progression of caries or erosion, just as they have been shown to retain the integrity and improve the longevity of resin composite filling bonding to dentin. This paper also presents the case that the organic matrix in caries-affected dentin may not be preserved as intact as previously considered. In partially demineralized dentin, MMPs and cysteine cathepsins with the ability to cleave off the terminal non-helical ends of collagen molecules (telopeptides) may lead to the gradual loss of intramolecular gap areas. This would seriously compromise the matrix ability for intrafibrillar remineralization, which is considered essential in restoring the dentin's mechanical properties. More detailed data of the enzymes responsible and their detailed function in dentin-destructive conditions may not only help to find new and better preventive means, but better preservation of demineralized dentin collagenous matrix may also facilitate true biological remineralization for the better restoration of tooth structural and mechanical integrity and mechanical properties.", "authors": ["Leo Tjäderhane", "Marília Afonso Rabelo Buzalaf", "Marcela Carrilho", "Catherine Chaussain"], "year": 2015, "venue": "Caries Research", "cited_by_count": 2307, "type": "review", "concepts": ["Adhesive", "Dentin", "Methacrylate", "Materials science", "Composite material"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2130761473", "doi": "https://doi.org/10.1111/1467-9876.00113", "title": "Model-Based Geostatistics", "abstract": "SUMMARY Conventional geostatistical methodology solves the problem of predicting the realized value of a linear functional of a Gaussian spatial stochastic process S(x) based on observations Yi = S(xi) + Zi at sampling locations xi, where the Zi are mutually independent, zero-mean Gaussian random variables. We describe two spatial applications for which Gaussian distributional assumptions are clearly inappropriate. The first concerns the assessment of residual contamination from nuclear weapons testing on a South Pacific island, in which the sampling method generates spatially indexed Poisson counts conditional on an unobserved spatially varying intensity of radioactivity; we conclude that a conventional geostatistical analysis oversmooths the data and underestimates the spatial extremes of the intensity. The second application provides a description of spatial variation in the risk of campylobacter infections relative to other enteric infections in part of north Lancashire and south Cumbria. For this application, we treat the data as binomial counts at unit postcode locations, conditionally on an unobserved relative risk surface which we estimate. The theoretical framework for our extension of geostatistical methods is that, conditionally on the unobserved process S(x), observations at sample locations xi form a generalized linear model with the corresponding values of S(xi) appearing as an offset term in the linear predictor. We use a Bayesian inferential framework, implemented via the Markov chain Monte Carlo method, to solve the prediction problem for non-linear functionals of S(x), making a proper allowance for the uncertainty in the estimation of any model parameters.", "authors": ["Peter J. Diggle", "Jonathan A. Tawn", "Rana Moyeed"], "year": 1998, "venue": "Journal of the Royal Statistical Society Series C (Applied Statistics)", "cited_by_count": 2186, "type": "article", "concepts": ["Statistics", "Mathematics", "Markov chain Monte Carlo", "Geostatistics", "Bayesian probability"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2517342784", "doi": "https://doi.org/10.1038/ncomms12558", "title": "Sixteen years of change in the global terrestrial human footprint and implications for biodiversity conservation", "abstract": "", "authors": ["Oscar Venter", "Eric W. Sanderson", "Ainhoa Magrach", "James R. Allan", "Jutta Beher", "Kendall R. Jones", "Hugh P. Possingham", "William F. Laurance", "Peter J. Wood", "B M Fekete", "Marc A. Levy", "James Watson"], "year": 2016, "venue": "Nature Communications", "cited_by_count": 1767, "type": "article", "concepts": ["Biodiversity", "Ecological footprint", "Footprint", "Planet", "Natural resource economics"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2101020813", "doi": "https://doi.org/10.1071/bt12225", "title": "New handbook for standardised measurement of plant functional traits worldwide", "abstract": "Plant functional traits are the features (morphological, physiological, phenological) that represent ecological strategies and determine how plants respond to environmental factors, affect other trophic levels and influence ecosystem properties. Variation in plant functional traits, and trait syndromes, has proven useful for tackling many important ecological questions at a range of scales, giving rise to a demand for standardised ways to measure ecologically meaningful plant traits. This line of research has been among the most fruitful avenues for understanding ecological and evolutionary patterns and processes. It also has the potential both to build a predictive set of local, regional and global relationships between plants and environment and to quantify a wide range of natural and human-driven processes, including changes in biodiversity, the impacts of species invasions, alterations in biogeochemical processes and vegetation–atmosphere interactions. The importance of these topics dictates the urgent need for more and better data, and increases the value of standardised protocols for quantifying trait variation of different species, in particular for traits with power to predict plant- and ecosystem-level processes, and for traits that can be measured relatively easily. Updated and expanded from the widely used previous version, this handbook retains the focus on clearly presented, widely applicable, step-by-step recipes, with a minimum of text on theory, and not only includes updated methods for the traits previously covered, but also introduces many new protocols for further traits. This new handbook has a better balance between whole-plant traits, leaf traits, root and stem traits and regenerative traits, and puts particular emphasis on traits important for predicting species’ effects on key ecosystem properties. We hope this new handbook becomes a standard companion in local and global efforts to learn about the responses and impacts of different plant species with respect to environmental changes in the present, past and future.", "authors": ["Natalia Pérez Harguindeguy", "Sandra Dı́az", "Éric Garnier", "Sandra Lavorel", "Hendrik Poorter", "Pedro Jaureguiberry", "M. Syndonia Bret‐Harte", "William K. Cornwell", "Joseph M. Craine", "Diego E. Gurvich", "Carlos Urcelay", "Erik J. Veneklaas", "Peter B. Reich", "Lourens Poorter", "Ian J. Wright", "Peter M. Ray", "Lucas Enrico", "Juli G. Pausas", "Arjen C. de Vos", "Nina Buchmann", "Guillermo Funes", "Fabien Quétier", "John Hodgson", "K. Thompson", "Huw D. Morgan", "Hans ter Steege", "Marcel G. A. van der Heijden", "Lawren Sack", "B. Blonder", "Peter Poschlod", "María V. Vaieretti", "Georgina Conti", "A. Carla Staver", "Sâmia Aquino", "J. H. C. Cornelissen"], "year": 2013, "venue": "Australian Journal of Botany", "cited_by_count": 3998, "type": "article", "concepts": ["Trait", "Biology", "Ecology", "Biodiversity", "Plant ecology"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W4366526182", "doi": "https://doi.org/10.1016/j.cag.2023.04.006", "title": "Mutual channel prior guided dual-domain interaction network for single image raindrop removal", "abstract": "", "authors": ["Yuanjian Qiao", "Mingwen Shao", "Huan Liu", "Kai Shang"], "year": 2023, "venue": "Computers & Graphics", "cited_by_count": 10, "type": "article", "concepts": ["Computer science", "Channel (broadcasting)", "Artificial intelligence", "Computer vision", "Block (permutation group theory)"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2095272243", "doi": "https://doi.org/10.2967/jnumed.106.035774", "title": "Partial-Volume Effect in PET Tumor Imaging", "abstract": "PET has the invaluable advantage of being intrinsically quantitative, enabling accurate measurements of tracer concentrations in vivo. In PET tumor imaging, indices characterizing tumor uptake, such as standardized uptake values, are becoming increasingly important, especially in the context of monitoring the response to therapy. However, when tracer uptake in small tumors is measured, large biases can be introduced by the partial-volume effect (PVE). The purposes of this article are to explain what PVE is and to describe its consequences in PET tumor imaging. The parameters on which PVE depends are reviewed. Actions that can be taken to reduce the errors attributable to PVE are described. Various PVE correction schemes are presented, and their applicability to PET tumor imaging is discussed.", "authors": ["M. Soret", "Stephen L. Bacharach", "Irène Buvat"], "year": 2007, "venue": "Journal of Nuclear Medicine", "cited_by_count": 1494, "type": "review", "concepts": ["Partial volume", "Pet imaging", "Context (archaeology)", "Nuclear medicine", "Positron emission tomography"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W4200271616", "doi": "https://doi.org/10.3390/rs14010080", "title": "The Restoration Potential of the Grasslands on the Tibetan Plateau", "abstract": "While the alpine grassland ecosystems on the Tibetan Plateau (TP) have generally improved in recent years, some grasslands still suffer from varying degrees of degradation. Studying the restoration potential (R) of the grasslands on the TP is crucial to the conservation and restoration of its alpine grassland ecosystems. Few studies have assessed the restoration value of the alpine grasslands on the TP. We attempt to estimate the actual (ANPP) and potential net primary productivity (PNPP) of the grasslands on the TP. On this basis, we defined R as the “gap” between the current and highest achievable levels of restoration of a grassland. Then, R estimates were yielded for the alpine grasslands on the TP, which we used to analyze the restoration value of these grasslands. Specifically, based on the meteorological data for the period 2001–2019, in conjunction with remote-sensing imagery acquired by a moderate-resolution imaging spectroradiometer for the same period, the Carnegie–Ames–Stanford approach model was selected to produce ANPP estimates for the grasslands on the TP. Then, the Thornthwaite memorial model, the principle of similar habitats, and the Chikugo model, were employed to generate PNPP estimates for these grasslands. In addition, the R of these grasslands was then assessed based on the difference between their PNPP and ANPP. The main results are summarized as follows. (1) A multiyear mean R of 332.33 g C·m–2 (81.59% of the ANPP) was determined for the grasslands on the TP over the period 2001–2019. A notable spatial distribution pattern of high Rs in the southwestern, eastern and middle parts of the TP, and low Rs in the northwestern part of the TP were also identified. Most of the grasslands in areas such as the southern part of Nagqu, the southwestern part of Ngari, Xigaze, Garze Tibetan Autonomous Prefecture, Aba Tibetan and Qiang Autonomous Prefecture, Gannan Tibetan Autonomous Prefecture, Huangnan Tibetan Autonomous Prefecture, Haibei Tibetan Autonomous Prefecture, Guoluo Tibetan Autonomous Prefecture and Yushu Tibetan Autonomous Prefecture were found to have high restoration value. (2) Grasslands with a stable R account were the highest proportion (76.13%) of all the grasslands on the TP, followed by those with a decreasing R (19.62%) and those with an increasing R (4.24%). Grasslands with an increasing R were mainly concentrated in the southern part of Xigaze, and parts of Yushu Tibetan Autonomous Prefecture, Guoluo Tibetan Autonomous Prefecture and Garze Tibetan Autonomous Prefecture. (3) Analysis based on the local conditions of the TP revealed a high restoration value for three types of grassland (i.e., alpine meadows, mountain meadows, and temperate meadow steppes), the grasslands distributed at altitudes of 3000–4000 m, and the grasslands located in the warm temperate zone. The results of this study are expected to provide scientific and theoretical support for the formulation of policies and measures aimed at conserving grasslands, as well as restoring ecosystems and degraded grasslands on the TP.", "authors": ["Ruijing Wang", "Qisheng Feng", "Zheren Jin", "Tiangang Liang"], "year": 2021, "venue": "Remote Sensing", "cited_by_count": 13, "type": "article", "concepts": ["Grassland", "Environmental science", "Primary production", "Grassland ecosystem", "Grassland degradation"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2970686316", "doi": "https://doi.org/10.1152/physrev.00018.2018", "title": "The Microbiota-Gut-Brain Axis", "abstract": "The importance of the gut-brain axis in maintaining homeostasis has long been appreciated. However, the past 15 yr have seen the emergence of the microbiota (the trillions of microorganisms within and on our bodies) as one of the key regulators of gut-brain function and has led to the appreciation of the importance of a distinct microbiota-gut-brain axis. This axis is gaining ever more traction in fields investigating the biological and physiological basis of psychiatric, neurodevelopmental, age-related, and neurodegenerative disorders. The microbiota and the brain communicate with each other via various routes including the immune system, tryptophan metabolism, the vagus nerve and the enteric nervous system, involving microbial metabolites such as short-chain fatty acids, branched chain amino acids, and peptidoglycans. Many factors can influence microbiota composition in early life, including infection, mode of birth delivery, use of antibiotic medications, the nature of nutritional provision, environmental stressors, and host genetics. At the other extreme of life, microbial diversity diminishes with aging. Stress, in particular, can significantly impact the microbiota-gut-brain axis at all stages of life. Much recent work has implicated the gut microbiota in many conditions including autism, anxiety, obesity, schizophrenia, Parkinson's disease, and Alzheimer's disease. Animal models have been paramount in linking the regulation of fundamental neural processes, such as neurogenesis and myelination, to microbiome activation of microglia. Moreover, translational human studies are ongoing and will greatly enhance the field. Future studies will focus on understanding the mechanisms underlying the microbiota-gut-brain axis and attempt to elucidate microbial-based intervention and therapeutic strategies for neuropsychiatric disorders.", "authors": ["John F. Cryan", "Kenneth J. O’Riordan", "Caitlin S.M. Cowan", "Kiran V. Sandhu", "Thomaz F. S. Bastiaanssen", "Marcus Boehme", "Martin G. Codagnone", "Sofia Cussotto", "Christine Fülling", "Anna V. Golubeva", "Katherine E. Guzzetta", "Minal Jaggar", "Caitríona M. Long-Smith", "Joshua M. Lyte", "Jason Martin", "Alicia Molinero-Perez", "Gerard M. Moloney", "Emanuela Morelli", "Enrique Morillas", "Rory O’Connor", "Joana S. Cruz-Pereira", "Veronica L. Peterson", "Kieran Rea", "Nathaniel L. Ritz", "Eoin Sherwin", "Simon Spichak", "Emily M. Teichman", "Marcel van de Wouw", "Ana Paula Ventura‐Silva", "Shauna E. Wallace-Fitzsimons", "Niall P. Hyland", "Gerard Clarke", "Timothy G. Dinan"], "year": 2019, "venue": "Physiological Reviews", "cited_by_count": 4372, "type": "review", "concepts": ["Gut–brain axis", "Gut flora", "Neuroscience", "Biology", "Microbiome"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W4407638147", "doi": "https://doi.org/10.1109/tits.2025.3538485", "title": "Enhancing Perception for Autonomous Vehicles: A Multi-Scale Feature Modulation Network for Image Restoration", "abstract": "Accurate environmental perception is essential for the effective operation of autonomous vehicles. However, visual images captured in dynamic environments or adverse weather conditions often suffer from various degradations. Image restoration focuses on reconstructing clear and sharp images by eliminating undesired degradations from corrupted inputs. These degradations typically vary in size and severity, making it crucial to employ robust multi-scale representation learning techniques. In this paper, we propose Multi-Scale Feature Modulation (MSFM), a novel deep convolutional architecture for image restoration. MSFM modulates multi-scale features in both frequency and spatial domains to make features sharper and closer to that of clean images. Specifically, our multi-scale frequency attention module transforms features into multiple scales and then modulates each scale in the implicit frequency domain using pooling and attention. Moreover, we develop a multi-scale spatial modulation module to refine pixels with the guidance of local features. The proposed frequency and spatial modules enable MSFM to better handle degradations of different sizes. Experimental results demonstrate that MSFM achieves state-of-the-art performance on 12 datasets for a range of image restoration tasks, i.e., image dehazing, image defocus/motion deblurring, and image desnowing. Furthermore, the restored images significantly improve the environmental perception of autonomous vehicles.", "authors": ["Yuning Cui", "Jianyong Zhu", "Alois Knoll"], "year": 2025, "venue": "IEEE Transactions on Intelligent Transportation Systems", "cited_by_count": 5, "type": "article", "concepts": ["Perception", "Scale (ratio)", "Feature (linguistics)", "Computer science", "Artificial intelligence"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2068226428", "doi": "https://doi.org/10.1371/journal.pone.0000711", "title": "Regional Decline of Coral Cover in the Indo-Pacific: Timing, Extent, and Subregional Comparisons", "abstract": "The rate and extent of coral loss in the Indo-Pacific are greater than expected. Coral cover was also surprisingly uniform among subregions and declined decades earlier than previously assumed, even on some of the Pacific's most intensely managed reefs. These results have significant implications for policy makers and resource managers as they search for successful models to reverse coral loss.", "authors": ["John F. Bruno", "Elizabeth R. Selig"], "year": 2007, "venue": "PLoS ONE", "cited_by_count": 1258, "type": "article", "concepts": ["Indo-Pacific", "Coral", "Cover (algebra)", "Geography", "Biology"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2969973211", "doi": "https://doi.org/10.1364/osac.2.002511", "title": "Comparison between the plenoptic sensor and the light field camera in restoring images through turbulence", "abstract": "Similar to the “lucky imaging” technique that selects the best local features over time, spatial redundancy allows for the localization of turbulence induced image distortions and selection of the best features that are least distorted by turbulence. A new technique to restore turbulence degraded images is proposed based on imaging with spatial redundancies. Two imaging frameworks that are candidates for implementation of the technique are the plenoptic sensor and the light field camera, which collect multiple depictions of the target through sub-aperture imaging. Preliminary studies have demonstrated the effectiveness of either device in imaging through turbulence. However, as visual distortions vary significantly from weak to strong turbulence conditions, it is unclear when and how a light field approach should be applied to enhance target recognition over distorted media. We present an in-depth study on the fundamental differences between the two devices with regards to turbulence distortion, as well as their image restoration mechanisms. Our analysis combined with proof-of-concept experiments show that the turbulence resilience of light field imaging techniques depends strongly on the mechanism of mapping the light field. Such universal finding serves as guidance for imaging and object recognition with light field approaches.", "authors": ["Chensheng Wu", "Daniel A. Paulson", "John R. Rzasa", "Christophér C. Davis"], "year": 2019, "venue": "OSA Continuum", "cited_by_count": 8, "type": "article", "concepts": ["Computer vision", "Light field", "Turbulence", "Artificial intelligence", "Computer science"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W1973577532", "doi": "https://doi.org/10.1029/2012rg000388", "title": "Global‐scale attribution of anthropogenic and natural dust sources and their emission rates based on MODIS Deep Blue aerosol products", "abstract": "Our understanding of the global dust cycle is limited by a dearth of information about dust sources, especially small‐scale features which could account for a large fraction of global emissions. Here we present a global‐scale high‐resolution (0.1°) mapping of sources based on Moderate Resolution Imaging Spectroradiometer (MODIS) Deep Blue estimates of dust optical depth in conjunction with other data sets including land use. We ascribe dust sources to natural and anthropogenic (primarily agricultural) origins, calculate their respective contributions to emissions, and extensively compare these products against literature. Natural dust sources globally account for 75% of emissions; anthropogenic sources account for 25%. North Africa accounts for 55% of global dust emissions with only 8% being anthropogenic, mostly from the Sahel. Elsewhere, anthropogenic dust emissions can be much higher (75% in Australia). Hydrologic dust sources (e.g., ephemeral water bodies) account for 31% worldwide; 15% of them are natural while 85% are anthropogenic. Globally, 20% of emissions are from vegetated surfaces, primarily desert shrublands and agricultural lands. Since anthropogenic dust sources are associated with land use and ephemeral water bodies, both in turn linked to the hydrological cycle, their emissions are affected by climate variability. Such changes in dust emissions can impact climate, air quality, and human health. Improved dust emission estimates will require a better mapping of threshold wind velocities, vegetation dynamics, and surface conditions (soil moisture and land use) especially in the sensitive regions identified here, as well as improved ability to address small‐scale convective processes producing dust via cold pool (haboob) events frequent in monsoon regimes.", "authors": ["Paul Ginoux", "Joseph M. Prospero", "Thomas E. Gill", "N. Christina Hsu", "Ming Zhao"], "year": 2012, "venue": "Reviews of Geophysics", "cited_by_count": 1625, "type": "article", "concepts": ["Environmental science", "Mineral dust", "Dust storm", "Moderate-resolution imaging spectroradiometer", "Water cycle"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2971982243", "doi": "https://doi.org/10.1038/s41467-019-11693-w", "title": "The future of Blue Carbon science", "abstract": "", "authors": ["Peter I. Macreadie", "Andrea Antón", "John A. Raven", "Nicola Beaumont", "Rod M. Connolly", "Daniel A. Friess", "Jeffrey J. Kelleway", "Hilary Kennedy", "Tomohiro Kuwae", "Paul S. Lavery", "Catherine E. Lovelock", "Dan A. Smale", "Eugenia T. Apostolaki", "Trisha B. Atwood", "Jeff Baldock", "Thomas S. Bianchi", "Gail L. Chmura", "Bradley D. Eyre", "James W. Fourqurean", "Jason M. Hall‐Spencer", "Mark Huxham", "Iris E. Hendriks", "Dorte Krause‐Jensen", "Dan Laffoley", "Tiziana Luisetti", "Núria Marbà", "Pere Masqué", "Karen J. McGlathery", "J. Patrick Megonigal", "Daniel Murdiyarso", "Bayden D. Russell", "Rui Santos", "Óscar Serrano", "Brian R. Silliman", "Kenta Watanabe", "Carlos M. Duarte"], "year": 2019, "venue": "Nature Communications", "cited_by_count": 910, "type": "review", "concepts": ["Carbon fibers", "Data science", "Computational biology", "Computer science", "Biology"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2509958485", "doi": "https://doi.org/10.1146/annurev-earth-063016-020552", "title": "Hydrogeomorphic Ecosystem Responses to Natural and Anthropogenic Changes in the Loess Plateau of China", "abstract": "China's Loess Plateau is both the largest and deepest loess deposit in the world, and it has long been one of the most severely eroded areas on Earth. Since the 1970s, numerous soil- and water-conservation practices have been implemented: terracing, planting of vegetation, natural vegetation rehabilitation, and check-dam construction. With the implementation of the Grain-for-Green Project in 1999, the Loess Plateau has become the most successful ecological restoration zone in China. However, these large-scale restoration measures and drought have significantly reduced both runoff and sediment from the Loess Plateau. This situation has both advantages and disadvantages for the lower Yellow River. Some local soil erosion has been successfully controlled, but the whole regional ecosystem remains very fragile. Therefore, it is necessary to balance each ecosystem service, for example, by determining the region's vegetation capacity and its spatial distribution for the sustainable development of the socioecological system of the Loess Plateau.", "authors": ["Bojie Fu", "Shuai Wang", "Yü Liu", "Jianbo Liu", "Wei Liang", "Chiyuan Miao"], "year": 2017, "venue": "Annual Review of Earth and Planetary Sciences", "cited_by_count": 983, "type": "article", "concepts": ["Vegetation (pathology)", "Surface runoff", "Environmental science", "Soil conservation", "Loess"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W1535679254", "doi": "https://doi.org/10.1111/j.1365-2699.2011.02595.x", "title": "The human dimension of fire regimes on Earth", "abstract": "Humans and their ancestors are unique in being a fire-making species, but 'natural' (i.e. independent of humans) fires have an ancient, geological history on Earth. Natural fires have influenced biological evolution and global biogeochemical cycles, making fire integral to the functioning of some biomes. Globally, debate rages about the impact on ecosystems of prehistoric human-set fires, with views ranging from catastrophic to negligible. Understanding of the diversity of human fire regimes on Earth in the past, present and future remains rudimentary. It remains uncertain how humans have caused a departure from 'natural' background levels that vary with climate change. Available evidence shows that modern humans can increase or decrease background levels of natural fire activity by clearing forests, promoting grazing, dispersing plants, altering ignition patterns and actively suppressing fires, thereby causing substantial ecosystem changes and loss of biodiversity. Some of these contemporary fire regimes cause substantial economic disruptions owing to the destruction of infrastructure, degradation of ecosystem services, loss of life, and smoke-related health effects. These episodic disasters help frame negative public attitudes towards landscape fires, despite the need for burning to sustain some ecosystems. Greenhouse gas-induced warming and changes in the hydrological cycle may increase the occurrence of large, severe fires, with potentially significant feedbacks to the Earth system. Improved understanding of human fire regimes demands: (1) better data on past and current human influences on fire regimes to enable global comparative analyses, (2) a greater understanding of different cultural traditions of landscape burning and their positive and negative social, economic and ecological effects, and (3) more realistic representations of anthropogenic fire in global vegetation and climate change models. We provide an historical framework to promote understanding of the development and diversification of fire regimes, covering the pre-human period, human domestication of fire, and the subsequent transition from subsistence agriculture to industrial economies. All of these phases still occur on Earth, providing opportunities for comparative research.", "authors": ["David M. J. S. Bowman", "Jennifer K. Balch", "Paulo Artaxo", "William J. Bond", "Mark A. Cochrane", "Carla M. D’Antonio", "Ruth DeFries", "Fay H. Johnston", "Jon E. Keeley", "Meg A. Krawchuk", "Christian A. Kull", "Michelle C. Mack", "Max A. Moritz", "Stephen J. Pyne", "Christopher I. Roos", "Andrew C. Scott", "Navjot S. Sodhi", "Thomas W. Swetnam"], "year": 2011, "venue": "Journal of Biogeography", "cited_by_count": 1197, "type": "article", "concepts": ["Fire regime", "Biodiversity", "Ecosystem", "Biome", "Climate change"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2061240737", "doi": "https://doi.org/10.1117/1.429925", "title": "Speckle in Optical Coherence Tomography", "abstract": "Speckle arises as a natural consequence of the limited spatial-frequency bandwidth of the interference signals measured in optical coherence tomography (OCT). In images of highly scattering biological tissues, speckle has a dual role as a source of noise and as a carrier of information about tissue microstructure. The first half of this paper provides an overview of the origin, statistical properties, and classification of speckle in OCT. The concepts of signal-carrying and signal-degrading speckle are defined in terms of the phase and amplitude disturbances of the sample beam. In the remaining half of the paper, four speckle-reduction methods-polarization diversity, spatial compounding, frequency compounding, and digital signal processing-are discussed and the potential effectiveness of each method is analyzed briefly with the aid of examples. Finally, remaining problems that merit further research are suggested. © 1999 Society of Photo-Optical Instrumentation Engineers.", "authors": ["Joseph M. Schmitt", "Shaohua Xiang", "Ka-Wai Yung"], "year": 1999, "venue": "Journal of Biomedical Optics", "cited_by_count": 831, "type": "article", "concepts": ["Optical coherence tomography", "Speckle pattern", "Optics", "Computer science", "Optical tomography"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2145885328", "doi": "https://doi.org/10.1155/2010/746052", "title": "Underwater Image Processing: State of the Art of Restoration and Image Enhancement Methods", "abstract": "", "authors": ["Raimondo Schettini", "Silvia Corchs"], "year": 2010, "venue": "EURASIP Journal on Advances in Signal Processing", "cited_by_count": 662, "type": "article", "concepts": ["Underwater", "Computer science", "Image restoration", "Image processing", "Image quality"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W3094777985", "doi": "https://doi.org/10.1093/eurheartj/ehu281", "title": "2014 ESC Guidelines on the diagnosis and treatment of aortic diseases", "abstract": "The ESC Guidelines represent the views of the ESC and were produced after careful consideration of the scientific and medical knowledge and the evidence available at the time of their dating.", "authors": ["Authors Task Force Members", "Raimund Erbel", "Victor Aboyans", "Cathérine Boileau", "Eduardo Bossone", "Roberto Di Bartolomeo", "Holger Eggebrecht", "Arturo Evangelista", "Volkmar Falk", "Herbert Frank", "Oliver Gaemperli", "Martin Grabenwöger", "Axel Haverich", "Bernard Iung", "Athanasios Manolis", "Folkert J. Meijboom", "Christoph Nienaber", "Marco Roffi", "Hervé Rousseau", "Udo Sechtem", "Per Anton Sirnes", "Regula S. von Allmen", "Christiaan Vrints"], "year": 2014, "venue": "European Heart Journal", "cited_by_count": 4331, "type": "article", "concepts": ["Medicine", "Medical prescription", "Health professionals", "Ambiguity", "Health care"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2980944208", "doi": "https://doi.org/10.1016/j.jhep.2019.10.003", "title": "The gut-liver axis in liver disease: Pathophysiological basis for therapy", "abstract": "", "authors": ["Agustı́n Albillos", "Andrea De Gottardi", "María Rescigno"], "year": 2019, "venue": "Journal of Hepatology", "cited_by_count": 1883, "type": "review", "concepts": ["Gut flora", "Fatty liver", "Cirrhosis", "Biology", "Liver disease"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2126236168", "doi": "https://doi.org/10.3390/rs3050878", "title": "Remote Sensing of Mangrove Ecosystems: A Review", "abstract": "Mangrove ecosystems dominate the coastal wetlands of tropical and subtropical regions throughout the world. They provide various ecological and economical ecosystem services contributing to coastal erosion protection, water filtration, provision of areas for fish and shrimp breeding, provision of building material and medicinal ingredients, and the attraction of tourists, amongst many other factors. At the same time, mangroves belong to the most threatened and vulnerable ecosystems worldwide and experienced a dramatic decline during the last half century. International programs, such as the Ramsar Convention on Wetlands or the Kyoto Protocol, underscore the importance of immediate protection measures and conservation activities to prevent the further loss of mangroves. In this context, remote sensing is the tool of choice to provide spatio-temporal information on mangrove ecosystem distribution, species differentiation, health status, and ongoing changes of mangrove populations. Such studies can be based on various sensors, ranging from aerial photography to high- and medium-resolution optical imagery and from hyperspectral data to active microwave (SAR) data. Remote-sensing techniques have demonstrated a high potential to detect, identify, map, and monitor mangrove conditions and changes during the last two decades, which is reflected by the large number of scientific papers published on this topic. To our knowledge, a recent review paper on the remote sensing of mangroves does not exist, although mangrove ecosystems have become the focus of attention in the context of current climate change and discussions of the services provided by these ecosystems. Also, climate change-related remote-sensing studies in coastal zones have increased drastically in recent years. The aim of this review paper is to provide a comprehensive overview and sound summary of all of the work undertaken, addressing the variety of remotely sensed data applied for mangrove ecosystem mapping, as well as the numerous methods and techniques used for data analyses, and to further discuss their potential and limitations.", "authors": ["Claudia Kuenzer", "Andrea Bluemel", "Steffen Gebhardt", "Tuan Vo Quoc", "Stefan Dech"], "year": 2011, "venue": "Remote Sensing", "cited_by_count": 742, "type": "review", "concepts": ["Mangrove", "Wetland", "Threatened species", "Context (archaeology)", "Remote sensing"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2587788572", "doi": "https://doi.org/10.5114/aoms.2016.63743", "title": "2D and 3D cell cultures – a comparison of different types of cancer cell cultures", "abstract": "Cell culture is a widely used <i>in vitro</i> tool for improving our understanding of cell biology, tissue morphology, and mechanisms of diseases, drug action, protein production and the development of tissue engineering. Most research regarding cancer biology is based on experiments using two-dimensional (2D) cell cultures <i>in vitro</i>. However, 2D cultures have many limitations, such as the disturbance of interactions between the cellular and extracellular environments, changes in cell morphology, polarity, and method of division. These disadvantages led to the creation of models which are more closely able to mimic conditions <i>in vivo</i>. One such method is three-dimensional culture (3D). Optimisation of the culture conditions may allow for a better understanding of cancer biology and facilitate the study of biomarkers and targeting therapies. In this review, we compare 2D and 3D cultures <i>in vitro</i> as well as different versions of 3D cultures.", "authors": ["Marta Kapałczyńska", "Tomasz Kolenda", "Weronika Przybyła", "M Zajaczkowska", "Anna Teresiak", "Violetta Filas", "Matthew Ibbs", "Renata Bliźniak", "Łukasz Łuczewski", "Katarzyna Lamperska"], "year": 2016, "venue": "Archives of Medical Science", "cited_by_count": 1447, "type": "article", "concepts": ["Cell culture", "In vitro", "Cell biology", "3D cell culture", "Cancer"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2114408828", "doi": "https://doi.org/10.1109/icassp.1988.196763", "title": "Restoration of images with nonstationary mean and autocorrelation", "abstract": "Methods are investigated for the restoration of images degraded by both blur and noise. The objective is to develop estimation strategies to deal with images that exhibit spatially varying statistics. The restoration starts with transforming the image with nonstationary statistics into an image that exhibits stationary characteristics. This transformation can be viewed as a prewhitening filter that normalizes the local mean and local variance of the image, creating a stationary, or near stationary, field. Then the ideal image is estimated from the transformed image on the basis of the linear minimum-mean-square-error criterion. The process removes image blur and noise and at the same time inverts the effects of the transformation.< <ETX xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">&gt;</ETX>", "authors": ["A.D. Hillery", "R.T. Chin"], "year": 2003, "venue": "", "cited_by_count": 3, "type": "article", "concepts": ["Image restoration", "Transformation (genetics)", "Noise (video)", "Image (mathematics)", "Autocorrelation"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2956015785", "doi": "https://doi.org/10.1186/s42492-019-0016-7", "title": "Brief review of image denoising techniques", "abstract": "", "authors": ["Linwei Fan", "Fan Zhang", "Hui Fan", "Caiming Zhang"], "year": 2019, "venue": "Visual Computing for Industry Biomedicine and Art", "cited_by_count": 621, "type": "review", "concepts": ["Noise reduction", "Computer science", "Artificial intelligence", "Computer vision", "Noise (video)"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2113903666", "doi": "https://doi.org/10.1371/journal.pone.0001548", "title": "Baselines and Degradation of Coral Reefs in the Northern Line Islands", "abstract": "Effective conservation requires rigorous baselines of pristine conditions to assess the impacts of human activities and to evaluate the efficacy of management. Most coral reefs are moderately to severely degraded by local human activities such as fishing and pollution as well as global change, hence it is difficult to separate local from global effects. To this end, we surveyed coral reefs on uninhabited atolls in the northern Line Islands to provide a baseline of reef community structure, and on increasingly populated atolls to document changes associated with human activities. We found that top predators and reef-building organisms dominated unpopulated Kingman and Palmyra, while small planktivorous fishes and fleshy algae dominated the populated atolls of Tabuaeran and Kiritimati. Sharks and other top predators overwhelmed the fish assemblages on Kingman and Palmyra so that the biomass pyramid was inverted (top-heavy). In contrast, the biomass pyramid at Tabuaeran and Kiritimati exhibited the typical bottom-heavy pattern. Reefs without people exhibited less coral disease and greater coral recruitment relative to more inhabited reefs. Thus, protection from overfishing and pollution appears to increase the resilience of reef ecosystems to the effects of global warming.", "authors": ["Stuart A. Sandin", "Jennifer E. Smith", "Edward E. DeMartini", "Elizabeth A. Dinsdale", "Simon D. Donner", "Alan M. Friedlander", "Talina Konotchick", "Maria Celia D. Malay", "James E. Maragos", "David Obura", "Olga Pantos", "Gustav Paulay", "Morgan Richie", "Forest Rohwer", "Robert E. Schroeder", "Sheila Walsh", "Jeremy B. C. Jackson", "Nancy­ Knowlton­", "Enric Sala"], "year": 2008, "venue": "PLoS ONE", "cited_by_count": 901, "type": "article", "concepts": ["Coral reef", "Reef", "Atoll", "Environmental issues with coral reefs", "Overfishing"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2259709654", "doi": "https://doi.org/10.1007/s00018-015-2052-6", "title": "The endoplasmic reticulum: structure, function and response to cellular signaling", "abstract": "", "authors": ["Dianne S. Schwarz", "Michael D. Blower"], "year": 2015, "venue": "Cellular and Molecular Life Sciences", "cited_by_count": 1530, "type": "review", "concepts": ["Endoplasmic reticulum", "Cell biology", "Organelle", "STIM1", "Membrane contact site"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2149757979", "doi": "https://doi.org/10.1155/2011/290602", "title": "Polymeric Scaffolds in Tissue Engineering Application: A Review", "abstract": "Current strategies of regenerative medicine are focused on the restoration of pathologically altered tissue architectures by transplantation of cells in combination with supportive scaffolds and biomolecules. In recent years, considerable interest has been given to biologically active scaffolds which are based on similar analogs of the extracellular matrix that have induced synthesis of tissues and organs. To restore function or regenerate tissue, a scaffold is necessary that will act as a temporary matrix for cell proliferation and extracellular matrix deposition, with subsequent ingrowth until the tissues are totally restored or regenerated. Scaffolds have been used for tissue engineering such as bone, cartilage, ligament, skin, vascular tissues, neural tissues, and skeletal muscle and as vehicle for the controlled delivery of drugs, proteins, and DNA. Various technologies come together to construct porous scaffolds to regenerate the tissues/organs and also for controlled and targeted release of bioactive agents in tissue engineering applications. In this paper, an overview of the different types of scaffolds with their material properties is discussed. The fabrication technologies for tissue engineering scaffolds, including the basic and conventional techniques to the more recent ones, are tabulated.", "authors": ["Brahatheeswaran Dhandayuthapani", "Yasuhiko Yoshida", "Toru Maekawa", "D. Sakthi Kumar"], "year": 2011, "venue": "International Journal of Polymer Science", "cited_by_count": 1732, "type": "review", "concepts": ["Scaffold", "Tissue engineering", "Regenerative medicine", "Extracellular matrix", "Biomedical engineering"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2981464168", "doi": "https://doi.org/10.1007/s10980-019-00912-w", "title": "Karst landscapes of China: patterns, ecosystem processes and services", "abstract": "Abstract Context The karst region of southwestern China, one of the largest continuous karsts in the world, is known for its unique landscapes and rich biodiversity. This region has suffered severe environmental degradation (e.g., vegetation cover loss, soil erosion and biodiversity loss). In recent decades, Chinese governments at different levels have initiated several ecological programs (e.g., Green for Grain, Mountain Closure) to restore the degraded environment and to alleviate poverty. Objectives This study summarizes landscape studies of karst landscapes patterns, their dynamics and interactions among landscape pattern, hydrological processes and ecosystem services (ES). Methods We conducted a systematic literature review of science and land use policy to identify knowledge gaps and recommend future research and policy directions. Results Karst landscapes have experienced rapid turnover in recent decades due largely to the overlap of intense human activity on the fragile karst ecosystems. Many studies have comprehensively examined hydrology, soil processes and ecosystem services (ES) and their relationships with landscape pattern. Most of these studies have found that karst ecosystems recover with improved ES. However, the importance of epikarst in hydrological and soil processes, intense anthropogenic disturbance and landscape heterogeneity in landscape models remains elusive. Conclusions Future research should focus on in-depth examination and modelling of karst specific hydrological and soil processes, investigating relationships between climatic change, landscape change, ecological processes, and region-specific ES assessments. Results from such research should provide the necessary scientific support for a comprehensive, national karst rocky desertification treatment project (Stage II) and poverty alleviation initiatives.", "authors": ["Kelin Wang", "Chunhua Zhang", "Hongsong Chen", "Yuemin Yue", "Wei Zhang", "Mingyang Zhang", "Xiangkun Qi", "Zhiyong Fu"], "year": 2019, "venue": "Landscape Ecology", "cited_by_count": 572, "type": "article", "concepts": ["Karst", "Ecosystem services", "Landscape ecology", "Biodiversity", "Geography"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2145020729", "doi": "https://doi.org/10.1002/mrm.21236", "title": "Undersampled radial MRI with multiple coils. Iterative image reconstruction using a total variation constraint", "abstract": "The reconstruction of artifact-free images from radially encoded MRI acquisitions poses a difficult task for undersampled data sets, that is for a much lower number of spokes in k-space than data samples per spoke. Here, we developed an iterative reconstruction method for undersampled radial MRI which (i) is based on a nonlinear optimization, (ii) allows for the incorporation of prior knowledge with use of penalty functions, and (iii) deals with data from multiple coils. The procedure arises as a two-step mechanism which first estimates the coil profiles and then renders a final image that complies with the actual observations. Prior knowledge is introduced by penalizing edges in coil profiles and by a total variation constraint for the final image. The latter condition leads to an effective suppression of undersampling (streaking) artifacts and further adds a certain degree of denoising. Apart from simulations, experimental results for a radial spin-echo MRI sequence are presented for phantoms and human brain in vivo at 2.9 T using 24, 48, and 96 spokes with 256 data samples. In comparison to conventional reconstructions (regridding) the proposed method yielded visually improved image quality in all cases.", "authors": ["Kai Tobias Block", "Martin Uecker", "Jens Frahm"], "year": 2007, "venue": "Magnetic Resonance in Medicine", "cited_by_count": 801, "type": "article", "concepts": ["Undersampling", "Iterative reconstruction", "Streaking", "Image quality", "Computer science"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2132041750", "doi": "https://doi.org/10.1017/cbo9781107415324.015", "title": "Carbon and Other Biogeochemical Cycles", "abstract": "For base year 2010, anthropogenic activities created ~210 (190 to 230) TgN of reactive nitrogen Nr from N2. This human-caused creation of reactive nitrogen in 2010 is at least 2 times larger than the rate of natural terrestrial creation of ~58 TgN (50 to 100 TgN yr−1) (Table 6.9, Section 1a). Note that the estimate of natural terrestrial biological fixation (58 TgN yr−1) is lower than former estimates (100 TgN yr−1, Galloway et al., 2004), but the ranges overlap, 50 to 100 TgN yr−1 vs. 90 to 120 TgN yr−1, respectively). Of this created reactive nitrogen, NOx and NH3 emissions from anthropogenic sources are about fourfold greater than natural emissions (Table 6.9, Section 1b). A greater portion of the NH3 emissions is deposited to the continents rather than to the oceans, relative to the deposition of NOy, due to the longer atmospheric residence time of the latter. These deposition estimates are lower limits, as they do not include organic nitrogen species. New model and measurement information (Kanakidou et al., 2012) suggests that incomplete inclusion of emissions and atmospheric chemistry of reduced and oxidized organic nitrogen components in current models may lead to systematic underestimates of total global reactive nitrogen deposition by up to 35% (Table 6.9, Section 1c). Discharge of reactive nitrogen to the coastal oceans is ~45 TgN yr−1 (Table 6.9, Section 1d). Denitrification converts Nr back to atmospheric N2. The current estimate for the production of atmospheric N2 is 110 TgN yr−1 (Bouwman et al., 2013).", "authors": ["Philippe Ciais"], "year": 2014, "venue": "Cambridge University Press eBooks", "cited_by_count": 2061, "type": "book-chapter", "concepts": ["Reactive nitrogen", "Biogeochemical cycle", "Nitrogen", "NOx", "Environmental chemistry"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W3001446396", "doi": "https://doi.org/10.1017/9781009157964.012", "title": "Sea Level Rise and Implications for Low-Lying Islands, Coasts and Communities", "abstract": "This chapter assesses past and future contributions to global, regional and extreme sea level changes, associated risk to low-lying islands, coasts, cities, and settlements, and response options and pathways to resilience and sustainable development along the coast.", "authors": ["Michael Oppenheimer"], "year": 2022, "venue": "Cambridge University Press eBooks", "cited_by_count": 877, "type": "book-chapter", "concepts": ["Lying", "Oceanography", "Geography", "Action (physics)", "Environmental science"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2088625008", "doi": "https://doi.org/10.1103/physrevb.75.155410", "title": "Epsilon-near-zero metamaterials and electromagnetic sources: Tailoring the radiation phase pattern", "abstract": "In this work, we investigate the response of epsilon-near-zero metamaterials and plasmonic materials to electromagnetic source excitation. The use of these media for tailoring the phase of radiation pattern of arbitrary sources is proposed and analyzed numerically and analytically for some canonical geometries. In particular, the possibility of employing planar layers, cylindrical shells, or other more complex shapes made of such materials in order to isolate two regions of space and to tailor the phase pattern in one region, fairly independent of the excitation shape present in the other region, is demonstrated with theoretical arguments and some numerical examples. Physical insights into the phenomenon are also presented and discussed together with potential applications of the phenomenon.", "authors": ["Andrea Alù", "Mário G. Silveirinha", "Alessandro Salandrino", "Nader Engheta"], "year": 2007, "venue": "Physical Review B", "cited_by_count": 1044, "type": "article", "concepts": ["Metamaterial", "Excitation", "Planar", "Physics", "Phase (matter)"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2004337957", "doi": "https://doi.org/10.1186/1741-7015-9-66", "title": "Bone regeneration: current concepts and future directions", "abstract": "", "authors": ["Rozalia Dimitriou", "Elena Jones", "Dennis McGonagle", "Peter V. Giannoudis"], "year": 2011, "venue": "BMC Medicine", "cited_by_count": 1963, "type": "review", "concepts": ["Medicine", "Regeneration (biology)", "Distraction osteogenesis", "Bone healing", "Osteoporosis"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W2981103490", "doi": "https://doi.org/10.1146/annurev-ento-011019-025151", "title": "Insect Declines in the Anthropocene", "abstract": "Insect declines are being reported worldwide for flying, ground, and aquatic lineages. Most reports come from western and northern Europe, where the insect fauna is well-studied and there are considerable demographic data for many taxonomically disparate lineages. Additional cases of faunal losses have been noted from Asia, North America, the Arctic, the Neotropics, and elsewhere. While this review addresses both species loss and population declines, its emphasis is on the latter. Declines of abundant species can be especially worrisome, given that they anchor trophic interactions and shoulder many of the essential ecosystem services of their respective communities. A review of the factors believed to be responsible for observed collapses and those perceived to be especially threatening to insects form the core of this treatment. In addition to widely recognized threats to insect biodiversity, e.g., habitat destruction, agricultural intensification (including pesticide use), climate change, and invasive species, this assessment highlights a few less commonly considered factors such as atmospheric nitrification from the burning of fossil fuels and the effects of droughts and changing precipitation patterns. Because the geographic extent and magnitude of insect declines are largely unknown, there is an urgent need for monitoring efforts, especially across ecological gradients, which will help to identify important causal factors in declines. This review also considers the status of vertebrate insectivores, reporting bias, challenges inherent in collecting and interpreting insect demographic data, and cases of increasing insect abundance.", "authors": ["David L. Wagner"], "year": 2019, "venue": "Annual Review of Entomology", "cited_by_count": 1261, "type": "review", "concepts": ["Ecology", "Biodiversity", "Biology", "Trophic level", "Habitat"], "search_query": "spatially varying degradation image restoration local"}
{"openalex_id": "https://openalex.org/W4390872095", "doi": "https://doi.org/10.1109/iccv51070.2023.01130", "title": "Diff-Retinex: Rethinking Low-light Image Enhancement with A Generative Diffusion Model", "abstract": "In this paper, we rethink the low-light image enhancement task and propose a physically explainable and generative diffusion model for low-light image enhancement, termed as Diff-Retinex. We aim to integrate the advantages of the physical model and the generative network. Furthermore, we hope to supplement and even deduce the information missing in the low-light image through the generative network. Therefore, Diff-Retinex formulates the lowlight image enhancement problem into Retinex decomposition and conditional image generation. In the Retinex decomposition, we integrate the superiority of attention in Transformer and meticulously design a Retinex Transformer decomposition network (TDN) to decompose the image into illumination and reflectance maps. Then, we design multi-path generative diffusion networks to reconstruct the normal-light Retinex probability distribution and solve the various degradations in these components respectively, including dark illumination, noise, color deviation, loss of scene contents, etc. Owing to generative diffusion model, Diff-Retinex puts the restoration of low-light subtle detail into practice. Extensive experiments conducted on real-world low-light datasets qualitatively and quantitatively demonstrate the effectiveness, superiority, and generalization of the proposed method.", "authors": ["Xunpeng Yi", "Han Xu", "Hao Zhang", "Linfeng Tang", "Jiayi Ma"], "year": 2023, "venue": "", "cited_by_count": 187, "type": "article", "concepts": ["Color constancy", "Artificial intelligence", "Generative model", "Computer science", "Computer vision"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402716100", "doi": "https://doi.org/10.1109/cvpr52733.2024.00268", "title": "Residual Denoising Diffusion Models", "abstract": "We propose residual denoising diffusion models (RDDM), a novel dual diffusion process that decouples the traditional single denoising diffusion process into residual diffusion and noise diffusion. This dual diffusion framework expands the denoising-based diffusion models, initially uninterpretable for image restoration, into a unified and interpretable model for both image generation and restoration by introducing residuals. Specifically, our residual diffusion represents directional diffusion from the target image to the degraded input image and explicitly guides the reverse generation process for image restoration, while noise diffusion represents random perturbations in the diffusion process. The residual prioritizes certainty, while the noise emphasizes diversity, enabling RDDM to effectively unify tasks with varying certainty or diversity requirements, such as image generation and restoration. We demonstrate that our sampling process is consistent with that of DDPM and DDIM through coefficient transformation, and propose a partially path-independent generation process to better understand the reverse process. Notably, our RDDM enables a generic UNet, trained with only an L1 loss and a batch size of 1, to compete with state-of-the-art image restoration methods. We provide code and pre-trained models to encourage further exploration, application, and development of our innovative framework (https://github.com/nachifurlRDDM).", "authors": ["Jiawei Liu", "Qiang Wang", "Huijie Fan", "Yinong Wang", "Yandong Tang", "Liangqiong Qu"], "year": 2024, "venue": "", "cited_by_count": 77, "type": "article", "concepts": ["Residual", "Diffusion", "Noise reduction", "Computer science", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4404533930", "doi": "https://doi.org/10.1007/978-3-031-73202-7_25", "title": "DiffBIR: Toward Blind Image Restoration with Generative Diffusion Prior", "abstract": "", "authors": ["Xinqi Lin", "Jingwen He", "Ziyan Chen", "Zhaoyang Lyu", "Bo Dai", "Fanghua Yu", "Yu Qiao", "Wanli Ouyang", "Chao Dong"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 136, "type": "book-chapter", "concepts": ["Computer science", "Generative grammar", "Image restoration", "Artificial intelligence", "Image (mathematics)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4393159973", "doi": "https://doi.org/10.1609/aaai.v38i8.28746", "title": "ResDiff: Combining CNN and Diffusion Model for Image Super-resolution", "abstract": "Adapting the Diffusion Probabilistic Model (DPM) for direct image super-resolution is wasteful, given that a simple Convolutional Neural Network (CNN) can recover the main low-frequency content. Therefore, we present ResDiff, a novel Diffusion Probabilistic Model based on Residual structure for Single Image Super-Resolution (SISR). ResDiff utilizes a combination of a CNN, which restores primary low-frequency components, and a DPM, which predicts the residual between the ground-truth image and the CNN predicted image. In contrast to the common diffusion-based methods that directly use LR space to guide the noise towards HR space, ResDiff utilizes the CNN’s initial prediction to direct the noise towards the residual space between HR space and CNN-predicted space, which not only accelerates the generation process but also acquires superior sample quality. Additionally, a frequency-domain-based loss function for CNN is introduced to facilitate its restoration, and a frequency-domain guided diffusion is designed for DPM on behalf of predicting high-frequency details. The extensive experiments on multiple benchmark datasets demonstrate that ResDiff outperforms previous diffusion based methods in terms of shorter model convergence time, superior generation quality, and more diverse samples.", "authors": ["Shuyao Shang", "Zhengyang Shan", "Guangxing Liu", "Lunqian Wang", "Xinghua Wang", "Zekai Zhang", "Jinglin Zhang"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 104, "type": "article", "concepts": ["Image (mathematics)", "Diffusion", "Superresolution", "Computer science", "Resolution (logic)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2095036901", "doi": "https://doi.org/10.1137/0103003", "title": "The Numerical Solution of Parabolic and Elliptic Differential Equations", "abstract": "Previous article Next article The Numerical Solution of Parabolic and Elliptic Differential EquationsD. W. Peaceman and H. H. Rachford, Jr.D. W. Peaceman and H. H. Rachford, Jr.https://doi.org/10.1137/0103003PDFPDF PLUSBibTexSections ToolsAdd to favoritesExport CitationTrack CitationsEmail SectionsAbout[1] G. H., Bruce, , D. W., Peaceman, , H. H., Rachford and , J. D. Rice, Calculation of unsteady-state gas flow through porous media, Trans. Amer. Inst. Mining and Met. Engrs., 198 (1953), 79– ISIGoogle Scholar[2] H. S. Carslaw and , J. C. Jaeger, Conduction of Heat in Solids, Oxford, at the Clarendon Press, 1947viii+386 MR0022294 Google Scholar[3] Stanley P. Frankel, Convergence rates of iterative treatments of partial differential equations, Math. Tables and Other Aids to Computation, 4 (1950), 65–75 MR0046149 CrossrefGoogle Scholar[4] George G. O'Brien, , Morton A. Hyman and , Sidney Kaplan, A study of the numerical solution of partial differential equations, J. Math. Physics, 29 (1951), 223–251 MR0040805 0042.13204 CrossrefISIGoogle Scholar[5] Jim Douglas, Jr., On the numerical integration of $\\partial\\sp 2u/\\partial x\\sp 2+\\partial\\sp 2u/\\partial y\\sp 2=\\partial u/\\partial t$ by implicit methods, J. Soc. Indust. Appl. Math., 3 (1955), 42–65 10.1137/0103004 MR0071875 0067.35802 LinkISIGoogle Scholar[6] Jim Douglas, Jr. and , T. M. Gallie, Jr., Variable time steps in the solution of the heat flow equation by a difference equation, Proc. Amer. Math. Soc., 6 (1955), 787–793 MR0078754 0066.10502 CrossrefGoogle Scholar[7] J. Douglas, Jr. and , D. W. Peaceman, Numerical solution of two-dimensional heat flow problems, to be presented at the May, 1955 meeting of The American Institute of Chemical Engineers at Houston, Texas Google Scholar Previous article Next article FiguresRelatedReferencesCited ByDetails A General Alternating-Direction Implicit Framework with Gaussian Process Regression Parameter Prediction for Large Sparse Linear SystemsKai Jiang, Xuehong Su, and Juan ZhangSIAM Journal on Scientific Computing, Vol. 44, No. 4 | 7 July 2022AbstractPDF (1383 KB)Convergence Analysis of the Nonoverlapping Robin--Robin Method for Nonlinear Elliptic EquationsEmil Engström and Eskil HansenSIAM Journal on Numerical Analysis, Vol. 60, No. 2 | 21 March 2022AbstractPDF (565 KB)Robust Alternating Direction Implicit Solver in Quantized Tensor Formats for a Three-Dimensional Elliptic PDEM. RakhubaSIAM Journal on Scientific Computing, Vol. 43, No. 2 | 4 March 2021AbstractPDF (935 KB)A Parallel Cyclic Reduction Algorithm for Pentadiagonal Systems with Application to a Convection-Dominated Heston PDEAbhijit Ghosh and Chittaranjan MishraSIAM Journal on Scientific Computing, Vol. 43, No. 2 | 29 April 2021AbstractPDF (643 KB)Operator Splitting for a Homogeneous Embedding of the Linear Complementarity ProblemBrendan O'DonoghueSIAM Journal on Optimization, Vol. 31, No. 3 | 4 August 2021AbstractPDF (695 KB)Adaptive Douglas--Rachford Splitting Algorithm from a Yosida Approximation StandpointZihan Liu and Kannan RamchandranSIAM Journal on Optimization, Vol. 31, No. 3 | 4 August 2021AbstractPDF (721 KB)Splitting with Near-Circulant Linear Systems: Applications to Total Variation CT and PETErnest K. Ryu, Seyoon Ko, and Joong-Ho WonSIAM Journal on Scientific Computing, Vol. 42, No. 1 | 4 February 2020AbstractPDF (1366 KB)Operator Splitting Performance Estimation: Tight Contraction Factors and Optimal Parameter SelectionErnest K. Ryu, Adrien B. Taylor, Carolina Bergeling, and Pontus GiselssonSIAM Journal on Optimization, Vol. 30, No. 3 | 13 August 2020AbstractPDF (569 KB)AMF-type W-methods for Parabolic Problems with Mixed DerivativesS. González-Pinto, E. Hairer, D. Hernández-Abreu, and S. Pérez-RodríguezSIAM Journal on Scientific Computing, Vol. 40, No. 5 | 13 September 2018AbstractPDF (702 KB)On MultiScale ADI Methods for Parabolic PDEs with a Discontinuous CoefficientZhilin Li, Xiaohong Chen, and Zhengru ZhangMultiscale Modeling & Simulation, Vol. 16, No. 4 | 18 October 2018AbstractPDF (7287 KB)On the Quasi-unconditional Stability of BDF-ADI Solvers for the Compressible Navier--Stokes Equations and Related Linear ProblemsOscar P. Bruno and Max CubillosSIAM Journal on Numerical Analysis, Vol. 55, No. 2 | 18 April 2017AbstractPDF (1278 KB)A Selective Linearization Method For Multiblock Convex OptimizationYu Du, Xiaodong Lin, and Andrzej RuszczyńskiSIAM Journal on Optimization, Vol. 27, No. 2 | 15 June 2017AbstractPDF (259 KB)Convergence Analysis of Douglas--Rachford Splitting Method for “Strongly + Weakly” Convex ProgrammingKe Guo, Deren Han, and Xiaoming YuanSIAM Journal on Numerical Analysis, Vol. 55, No. 4 | 6 July 2017AbstractPDF (1088 KB)Algebraic Multigrid Preconditioners for Multiphase Flow in Porous MediaQuan M. Bui, Howard C. Elman, and David J. MoultonSIAM Journal on Scientific Computing, Vol. 39, No. 5 | 26 October 2017AbstractPDF (511 KB)Fiber Orientation Distribution Estimation Using a Peaceman--Rachford Splitting MethodSIAM Journal on Imaging Sciences, Vol. 9, No. 2 | 3 May 2016AbstractPDF (1273 KB)Convergence Study on the Symmetric Version of ADMM with Larger Step SizesSIAM Journal on Imaging Sciences, Vol. 9, No. 3 | 22 September 2016AbstractPDF (836 KB)Isogeometric Preconditioners Based on Fast Solvers for the Sylvester EquationSIAM Journal on Scientific Computing, Vol. 38, No. 6 | 15 November 2016AbstractPDF (692 KB)Method of Lines Transpose: High Order L-Stable ${\\mathcal O}(N)$ Schemes for Parabolic Equations Using Successive ConvolutionSIAM Journal on Numerical Analysis, Vol. 54, No. 3 | 2 June 2016AbstractPDF (1298 KB)Computational Methods for Linear Matrix EquationsSIAM Review, Vol. 58, No. 3 | 4 August 2016AbstractPDF (851 KB)A Proximal Strictly Contractive Peaceman--Rachford Splitting Method for Convex Programming with Applications to ImagingSIAM Journal on Imaging Sciences, Vol. 8, No. 2 | 24 June 2015AbstractPDF (1523 KB)On the Numerical Behavior of Matrix Splitting Iteration Methods for Solving Linear SystemsSIAM Journal on Numerical Analysis, Vol. 53, No. 4 | 14 July 2015AbstractPDF (364 KB)A Generalized Proximal Point Algorithm and Its Convergence RateSIAM Journal on Optimization, Vol. 24, No. 4 | 14 October 2014AbstractPDF (1948 KB)Fourth Order Accurate Scheme for the Space Fractional Diffusion EquationsSIAM Journal on Numerical Analysis, Vol. 52, No. 3 | 12 June 2014AbstractPDF (453 KB)A Strictly Contractive Peaceman--Rachford Splitting Method for Convex ProgrammingSIAM Journal on Optimization, Vol. 24, No. 3 | 17 July 2014AbstractPDF (930 KB)Balanced Splitting and Rebalanced SplittingSIAM Journal on Numerical Analysis, Vol. 51, No. 6 | 19 November 2013AbstractPDF (587 KB)A Convergence Analysis of the Peaceman--Rachford Scheme for Semilinear Evolution EquationsSIAM Journal on Numerical Analysis, Vol. 51, No. 4 | 2 July 2013AbstractPDF (226 KB)An $h$-Adaptive Operator Splitting Method for Two-Phase Flow in 3D Heterogeneous Porous MediaSIAM Journal on Scientific Computing, Vol. 35, No. 1 | 29 January 2013AbstractPDF (1869 KB)Domain Decomposition Approaches for Mesh Generation via the Equidistribution PrincipleSIAM Journal on Numerical Analysis, Vol. 50, No. 4 | 23 August 2012AbstractPDF (429 KB)Fast Multiple-Splitting Algorithms for Convex OptimizationSIAM Journal on Optimization, Vol. 22, No. 2 | 24 May 2012AbstractPDF (1115 KB)A Variational Approach for Sharpening High Dimensional ImagesSIAM Journal on Imaging Sciences, Vol. 5, No. 1 | 24 January 2012AbstractPDF (4775 KB)An LQP-Based Decomposition Method for Solving a Class of Variational InequalitiesSIAM Journal on Optimization, Vol. 21, No. 4 | 22 November 2011AbstractPDF (176 KB)An Error Analysis for Rational Galerkin Projection Applied to the Sylvester EquationSIAM Journal on Numerical Analysis, Vol. 49, No. 6 | 22 November 2011AbstractPDF (279 KB)Analysis of the Rational Krylov Subspace and ADI Methods for Solving the Lyapunov EquationSIAM Journal on Numerical Analysis, Vol. 49, No. 5 | 20 September 2011AbstractPDF (334 KB)Energy-Conserved Splitting Finite-Difference Time-Domain Methods for Maxwell's Equations in Three DimensionsSIAM Journal on Numerical Analysis, Vol. 48, No. 4 | 31 August 2010AbstractPDF (552 KB)Inverse Iteration for Purely Imaginary Eigenvalues with Application to the Detection of Hopf Bifurcations in Large-Scale ProblemsSIAM Journal on Matrix Analysis and Applications, Vol. 31, No. 4 | 7 May 2010AbstractPDF (281 KB)From Functional Analysis to Iterative MethodsSIAM Review, Vol. 52, No. 2 | 6 May 2010AbstractPDF (279 KB)Nested Iterative Algorithms for Convex Constrained Image Recovery ProblemsSIAM Journal on Imaging Sciences, Vol. 2, No. 2 | 4 June 2009AbstractPDF (854 KB)General Projective Splitting Methods for Sums of Maximal Monotone OperatorsSIAM Journal on Control and Optimization, Vol. 48, No. 2 | 25 February 2009AbstractPDF (332 KB)Fixed-Point Continuation for $\\ell_1$-Minimization: Methodology and ConvergenceSIAM Journal on Optimization, Vol. 19, No. 3 | 31 October 2008AbstractPDF (335 KB)Efficient Preconditioning of Sequences of Nonsymmetric Linear SystemsSIAM Journal on Scientific Computing, Vol. 29, No. 5 | 28 September 2007AbstractPDF (242 KB)Robin–Robin Domain Decomposition Methods for the Stokes–Darcy CouplingSIAM Journal on Numerical Analysis, Vol. 45, No. 3 | 22 May 2007AbstractPDF (251 KB)An Alternating-Direction Implicit Orthogonal Spline Collocation Scheme for Nonlinear Parabolic Problems on Rectangular PolygonsSIAM Journal on Scientific Computing, Vol. 28, No. 3 | 4 August 2006AbstractPDF (241 KB)An Accelerated Splitting-up Method for Parabolic EquationsSIAM Journal on Mathematical Analysis, Vol. 37, No. 4 | 1 August 2006AbstractPDF (267 KB)An ADI-Like Preconditioner for Boltzmann TransportSIAM Journal on Scientific Computing, Vol. 26, No. 3 | 25 July 2006AbstractPDF (206 KB)Solving Degenerate Reaction-Diffusion Equations via Variable Step Peaceman--Rachford SplittingSIAM Journal on Scientific Computing, Vol. 25, No. 4 | 16 May 2012AbstractPDF (8559 KB)Hermitian and Skew-Hermitian Splitting Methods for Non-Hermitian Positive Definite Linear SystemsSIAM Journal on Matrix Analysis and Applications, Vol. 24, No. 3 | 31 July 2006AbstractPDF (257 KB)Stabilized Explicit-Implicit Domain Decomposition Methods for the Numerical Solution of Parabolic EquationsSIAM Journal on Scientific Computing, Vol. 24, No. 1 | 25 July 2006AbstractPDF (216 KB)Difference Graphs of Block ADI MethodSIAM Journal on Numerical Analysis, Vol. 38, No. 3 | 26 July 2006AbstractPDF (162 KB)A Cyclic Low-Rank Smith Method for Large Sparse Lyapunov EquationsSIAM Journal on Scientific Computing, Vol. 21, No. 4 | 25 July 2006AbstractPDF (377 KB)Domain Decomposition Operator Splittings for the Solution of Parabolic EquationsSIAM Journal on Scientific Computing, Vol. 19, No. 3 | 25 July 2006AbstractPDF (406 KB)Discrete-time Orthogonal Spline Collocation Methods for Schrödinger Equations in Two Space VariablesSIAM Journal on Numerical Analysis, Vol. 35, No. 2 | 25 July 2006AbstractPDF (458 KB)An ADI Method for Hysteretic Reaction-Diffusion SystemsSIAM Journal on Numerical Analysis, Vol. 34, No. 3 | 25 July 2006AbstractPDF (459 KB)Application of ADI Iterative Methods to the Restoration of Noisy ImagesSIAM Journal on Matrix Analysis and Applications, Vol. 17, No. 1 | 17 February 2012AbstractPDF (2458 KB)Coordination in Coarse-Grained DecompositionSIAM Journal on Optimization, Vol. 4, No. 4 | 13 July 2006AbstractPDF (1888 KB)Alternating Direction Preconditioning for Nonsymmetric Systems of Linear EquationsSIAM Journal on Scientific Computing, Vol. 15, No. 2 | 13 July 2006AbstractPDF (1688 KB)Alternating Direction Implicit Iteration for Systems with Complex SpectraSIAM Journal on Numerical Analysis, Vol. 28, No. 3 | 14 July 2006AbstractPDF (1238 KB)Vectorization of the Odd–Even Hopscotch Scheme and the Alternating Direction Implicit Scheme for the Two-Dimensional Burgers EquationsSIAM Journal on Scientific and Statistical Computing, Vol. 11, No. 2 | 13 July 2006AbstractPDF (1591 KB)The Solution of Two-Point Boundary Value Problems by the Alternating Group Explicit (AGE) MethodSIAM Journal on Scientific and Statistical Computing, Vol. 9, No. 3 | 13 July 2006AbstractPDF (639 KB)Tensor Product Generalized ADI Methods for Separable Elliptic ProblemsSIAM Journal on Numerical Analysis, Vol. 24, No. 1 | 14 July 2006AbstractPDF (1728 KB)Iterated Splitting Method of High Order for Time-Dependent Partial Differential EquationsSIAM Journal on Numerical Analysis, Vol. 21, No. 4 | 17 July 2006AbstractPDF (1855 KB)Multistep Splitting Methods of High Order for Initial Value ProblemsSIAM Journal on Numerical Analysis, Vol. 17, No. 3 | 17 July 2006AbstractPDF (1937 KB)Alternating Direction Implicit Methods for Parabolic Equations with a Mixed DerivativeSIAM Journal on Scientific and Statistical Computing, Vol. 1, No. 1 | 16 May 2012AbstractPDF (2857 KB)Splitting Algorithms for the Sum of Two Nonlinear OperatorsSIAM Journal on Numerical Analysis, Vol. 16, No. 6 | 17 July 2006AbstractPDF (1402 KB)Dynamic ADI Methods for Elliptic EquationsSIAM Journal on Numerical Analysis, Vol. 16, No. 5 | 17 July 2006AbstractPDF (2283 KB)The Alternating Phase Truncation Method for Numerical Solution of a Stefan ProblemSIAM Journal on Numerical Analysis, Vol. 16, No. 4 | 17 July 2006AbstractPDF (2605 KB)The Extrapolation of First Order Methods for Parabolic Partial Differential Equations. ISIAM Journal on Numerical Analysis, Vol. 15, No. 6 | 14 July 2006AbstractPDF (1229 KB)Numerical Solution of a Diffusion Consumption Problem with a Free BoundarySIAM Journal on Numerical Analysis, Vol. 12, No. 4 | 14 July 2006AbstractPDF (2304 KB)A Survey of Modern Numerical AnalysisSIAM Review, Vol. 15, No. 2 | 2 August 2006AbstractPDF (2464 KB)Iterative Solution of Implicit Approximations of Multidimensional Partial Differential EquationsSIAM Journal on Numerical Analysis, Vol. 5, No. 3 | 14 July 2006AbstractPDF (2718 KB)Rounding Errors in Alternating Direction Methods for Parabolic ProblemsSIAM Journal on Numerical Analysis, Vol. 5, No. 2 | 3 August 2006AbstractPDF (1267 KB)A New Computational Procedure for A.D.I. MethodsSIAM Journal on Numerical Analysis, Vol. 4, No. 2 | 14 July 2006AbstractPDF (593 KB)Multistage Alternating Direction MethodsSIAM Journal on Numerical Analysis, Vol. 3, No. 4 | 14 July 2006AbstractPDF (829 KB)Two-Level Difference Schemes for Hyperbolic SystemsSIAM Journal on Numerical Analysis, Vol. 3, No. 3 | 14 July 2006AbstractPDF (882 KB)A New Alternating Direction Method for Parabolic Equations in Three Space VariablesJournal of the Society for Industrial and Applied Mathematics, Vol. 13, No. 4 | 13 July 2006AbstractPDF (641 KB)Nonsymmetric Difference EquationsJournal of the Society for Industrial and Applied Mathematics, Vol. 13, No. 3 | 13 July 2006AbstractPDF (501 KB)Alternating Direction Schemes for the Heat Equation in a General DomainJournal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis, Vol. 2, No. 3 | 14 July 2006AbstractPDF (1121 KB)The Solution of Elliptic Difference Equations by Semi-Explicit Iterative TechniquesJournal of the Society for Industrial and Applied Mathematics Series B Numerical Analysis, Vol. 2, No. 1 | 3 August 2006AbstractPDF (1718 KB)An Alternating Direction Method for Operator EquationsJournal of the Society for Industrial and Applied Mathematics, Vol. 12, No. 4 | 13 July 2006AbstractPDF (461 KB)The Numerical Solution of the Dirichlet Problem for Laplace’s Equation by Linear ProgrammingJournal of the Society for Industrial and Applied Mathematics, Vol. 12, No. 1 | 13 July 2006AbstractPDF (374 KB)Another Alternating-Direction-Implicit MethodJournal of the Society for Industrial and Applied Mathematics, Vol. 11, No. 4 | 13 July 2006AbstractPDF (290 KB)Numerical Studies of Transition From Laminar to Turbulent Flow Over a Flat PlateJournal of the Society for Industrial and Applied Mathematics, Vol. 10, No. 4 | 13 July 2006AbstractPDF (2277 KB)On Incomplete Iteration for Implicit Parabolic Difference EquationsJournal of the Society for Industrial and Applied Mathematics, Vol. 9, No. 3 | 10 July 2006AbstractPDF (466 KB)An Alternating-Direction-Implicit Iteration TechniqueJournal of the Society for Industrial and Applied Mathematics, Vol. 8, No. 2 | 10 July 2006AbstractPDF (1508 KB)Simultaneous, Successive and Alternating Direction Iteration SchemesJournal of the Society for Industrial and Applied Mathematics, Vol. 8, No. 1 | 10 July 2006AbstractPDF (1569 KB)A Method of Block IterationJournal of the Society for Industrial and Applied Mathematics, Vol. 4, No. 4 | 10 July 2006AbstractPDF (667 KB)On the Numerical Integration of $\\frac{\\partial ^2 u}{\\partial x^2 } + \\frac{\\partial ^2 u}{\\partial y^2 } = \\frac{\\partial u}{\\partial t}$ by Implicit MethodsJim Douglas, Jr.Journal of the Society for Industrial and Applied Mathematics, Vol. 3, No. 1 | 10 July 2006AbstractPDF (1365 KB) Volume 3, Issue 1| 1955Journal of the Society for Industrial and Applied Mathematics1-65 History Submitted:18 October 1954Published online:10 July 2006 InformationCopyright © 1955 Society for Industrial and Applied MathematicsPDF Download Article & Publication DataArticle DOI:10.1137/0103003Article page range:pp. 28-41ISSN (print):0368-4245ISSN (online):2168-3484Publisher:Society for Industrial and Applied Mathematics", "authors": ["D.W. Peaceman", "H.H. Rachford"], "year": 1955, "venue": "Journal of the Society for Industrial and Applied Mathematics", "cited_by_count": 3246, "type": "article", "concepts": ["Partial differential equation", "Mathematics", "Elliptic partial differential equation", "Convergence (economics)", "Variable (mathematics)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4386066096", "doi": "https://doi.org/10.1109/cvpr52729.2023.01350", "title": "ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow Removal", "abstract": "Recent deep learning methods have achieved promising results in image shadow removal. However, their restored images still suffer from unsatisfactory boundary artifacts, due to the lack of degradation prior embedding and the deficiency in modeling capacity. Our work addresses these issues by proposing a unified diffusion framework that integrates both the image and degradation priors for highly effective shadow removal. In detail, we first propose a shadow degradation model, which inspires us to build a novel unrolling diffusion model, dubbed ShandowDiffusion. It remarkably improves the model's capacity in shadow removal via progressively refining the desired output with both degradation prior and diffusive generative prior, which by nature can serve as a new strong baseline for image restoration. Furthermore, ShadowDiffusion progressively refines the estimated shadow mask as an auxiliary task of the diffusion generator, which leads to more accurate and robust shadow-free image generation. We conduct extensive experiments on three popular public datasets, including ISTD, ISTD+, and SRD, to validate our method's effectiveness. Compared to the state-of-the-art methods, our model achieves a significant improvement in terms of PSNR, increasing from 31.69dB to 34. 73dB over SRD dataset. <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> <sup xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup> https://github.com/GuoLanqing/ShadowDiffusion", "authors": ["Lanqing Guo", "Chong Wang", "Wenhan Yang", "Siyu Huang", "Yufei Wang", "Hanspeter Pfister", "Bihan Wen"], "year": 2023, "venue": "", "cited_by_count": 108, "type": "article", "concepts": ["Shadow (psychology)", "Computer science", "Artificial intelligence", "Degradation (telecommunications)", "Image (mathematics)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4408235503", "doi": "https://doi.org/10.1109/tcsvt.2025.3549351", "title": "Efficient Image Enhancement With a Diffusion-Based Frequency Prior", "abstract": "Due to the lack of appropriate priors, generating the content of dark regions remains a challenge in low-light image enhancement tasks. Currently, diffusion models employ robust image generation capabilities for enhancing low-light images. However, diffusion models require multiple iterations at the image feature level to generate details and content, which limits the speed. Moreover, the diffusion-based methods tend to generate unexpected artifacts in the degraded regions. To address these issues, we propose a Frequency Priors-guided Image Enhancement (FPIE) network, including a frequency prior generation network and an image restoration network. FPIE significantly accelerates inference by learning abstract prior with frequency domain constraints. Concretely, to learn compacted priors at the frequency domain, we introduce a joint training approach for the prior generation and restoration models to constrain the distribution of priors. Furthermore, to better utilize frequency-domain features for enhancing the network’s generation capabilities, a wavelet-based transformer block is introduced to produce intricate details and avoid the artifacts of the output. Extensive experimental results on the commonly used benchmarks demonstrate that our approach achieves state-of-the-art performances and well generalization to real-world images.", "authors": ["Qingsen Yan", "Tao Hu", "Peng Wu", "Duwei Dai", "Shuhang Gu", "Wei Dong", "Yanning Zhang"], "year": 2025, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 56, "type": "article", "concepts": ["Image enhancement", "Computer science", "Image (mathematics)", "Artificial intelligence", "Computer vision"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4386043787", "doi": "https://doi.org/10.48550/arxiv.2308.09388", "title": "Diffusion Models for Image Restoration and Enhancement: A Comprehensive Survey", "abstract": "Image restoration (IR) has been an indispensable and challenging task in the low-level vision field, which strives to improve the subjective quality of images distorted by various forms of degradation. Recently, the diffusion model has achieved significant advancements in the visual generation of AIGC, thereby raising an intuitive question, \"whether diffusion model can boost image restoration\". To answer this, some pioneering studies attempt to integrate diffusion models into the image restoration task, resulting in superior performances than previous GAN-based methods. Despite that, a comprehensive and enlightening survey on diffusion model-based image restoration remains scarce. In this paper, we are the first to present a comprehensive review of recent diffusion model-based methods on image restoration, encompassing the learning paradigm, conditional strategy, framework design, modeling strategy, and evaluation. Concretely, we first introduce the background of the diffusion model briefly and then present two prevalent workflows that exploit diffusion models in image restoration. Subsequently, we classify and emphasize the innovative designs using diffusion models for both IR and blind/real-world IR, intending to inspire future development. To evaluate existing methods thoroughly, we summarize the commonly-used dataset, implementation details, and evaluation metrics. Additionally, we present the objective comparison for open-sourced methods across three tasks, including image super-resolution, deblurring, and inpainting. Ultimately, informed by the limitations in existing works, we propose five potential and challenging directions for the future research of diffusion model-based IR, including sampling efficiency, model compression, distortion simulation and estimation, distortion invariant learning, and framework design.", "authors": ["Xin Li", "Yulin Ren", "Xin Jin", "Cuiling Lan", "Xingrui Wang", "Wenjun Zeng", "Xinchao Wang", "Zhibo Chen"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 41, "type": "preprint", "concepts": ["Computer science", "Inpainting", "Image restoration", "Deblurring", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2119542322", "doi": "https://doi.org/10.1056/nejmoa1414792", "title": "Endovascular Therapy for Ischemic Stroke with Perfusion-Imaging Selection", "abstract": "In patients with ischemic stroke with a proximal cerebral arterial occlusion and salvageable tissue on CT perfusion imaging, early thrombectomy with the Solitaire FR stent retriever, as compared with alteplase alone, improved reperfusion, early neurologic recovery, and functional outcome. (Funded by the Australian National Health and Medical Research Council and others; EXTEND-IA ClinicalTrials.gov number, NCT01492725, and Australian New Zealand Clinical Trials Registry number, ACTRN12611000969965.).", "authors": ["Bruce Campbell", "Peter Mitchell", "Timothy Kleinig", "Helen M. Dewey", "Leonid Churilov", "Nawaf Yassi", "Bernard Yan", "Richard Dowling", "Mark Parsons", "Thomas J. Oxley", "Teddy Y. Wu", "Mark Brooks", "Marion Simpson", "Ferdinand Miteff", "Christopher Levi", "Martín Krause", "Timothy Harrington", "Kenneth Faulder", "Brendan Steinfort", "Miriam Priglinger", "Timothy Ang", "Rebecca Scroop", "P. Alan Barber", "Ben McGuinness", "Tissa Wijeratne", "Thanh G. Phan", "Winston Chong", "Ronil V. Chandra", "Christopher F. Bladin", "Monica Badve", "Henry E. Rice", "Laetitia de Villiers", "Henry Ma", "Patricia Desmond", "Geoffrey A. Donnan", "Stephen M. Davis"], "year": 2015, "venue": "New England Journal of Medicine", "cited_by_count": 5727, "type": "article", "concepts": ["Medicine", "Modified Rankin Scale", "Stroke (engine)", "Solitaire Cryptographic Algorithm", "Perfusion scanning"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4403947072", "doi": "https://doi.org/10.1007/978-3-031-73247-8_5", "title": "Pixel-Aware Stable Diffusion for Realistic Image Super-Resolution and Personalized Stylization", "abstract": "", "authors": ["Tao Yang", "Rongyuan Wu", "Peiran Ren", "Xuansong Xie", "Lei Zhang"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 58, "type": "book-chapter", "concepts": ["Computer science", "Pixel", "Computer vision", "Computer graphics (images)", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2171165037", "doi": "https://doi.org/10.1161/str.0b013e318284056a", "title": "Guidelines for the Early Management of Patients With Acute Ischemic Stroke", "abstract": "Because many of the recommendations are based on limited data, additional research on treatment of acute ischemic stroke remains urgently needed.", "authors": ["Edward C. Jauch", "Jeffrey L. Saver", "Harold P. Adams", "Askiel Bruno", "John J. Connors", "Bart M. Demaerschalk", "Pooja Khatri", "Paul W. McMullan", "Adnan I. Qureshi", "Kenneth Rosenfield", "Phillip Scott", "Debbie Summers", "David Z. Wang", "Max Wintermark", "Howard Yonas"], "year": 2013, "venue": "Stroke", "cited_by_count": 7620, "type": "article", "concepts": ["Medicine", "Stroke (engine)", "Guideline", "Psychological intervention", "Triage"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4386302521", "doi": "https://doi.org/10.48550/arxiv.2308.15070", "title": "DiffBIR: Towards Blind Image Restoration with Generative Diffusion Prior", "abstract": "We present DiffBIR, a general restoration pipeline that could handle different blind image restoration tasks in a unified framework. DiffBIR decouples blind image restoration problem into two stages: 1) degradation removal: removing image-independent content; 2) information regeneration: generating the lost image content. Each stage is developed independently but they work seamlessly in a cascaded manner. In the first stage, we use restoration modules to remove degradations and obtain high-fidelity restored results. For the second stage, we propose IRControlNet that leverages the generative ability of latent diffusion models to generate realistic details. Specifically, IRControlNet is trained based on specially produced condition images without distracting noisy content for stable generation performance. Moreover, we design a region-adaptive restoration guidance that can modify the denoising process during inference without model re-training, allowing users to balance realness and fidelity through a tunable guidance scale. Extensive experiments have demonstrated DiffBIR's superiority over state-of-the-art approaches for blind image super-resolution, blind face restoration and blind image denoising tasks on both synthetic and real-world datasets. The code is available at https://github.com/XPixelGroup/DiffBIR.", "authors": ["Xinqi Lin", "Jingwen He", "Ziyan Chen", "Zhaoyang Lyu", "Ben Fei", "Bo Dai", "Wanli Ouyang", "Yu Qiao", "Chao Dong"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 46, "type": "preprint", "concepts": ["Image restoration", "Computer science", "Fidelity", "Pipeline (software)", "Generative model"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4387211403", "doi": "https://doi.org/10.1007/978-3-031-43999-5_37", "title": "DisC-Diff: Disentangled Conditional Diffusion Model for Multi-contrast MRI Super-Resolution", "abstract": "", "authors": ["Mao Ye", "Lan Jiang", "Xi Chen", "Chao Li"], "year": 2023, "venue": "Lecture notes in computer science", "cited_by_count": 42, "type": "book-chapter", "concepts": ["Computer science", "Contrast (vision)", "Artificial intelligence", "Diffusion MRI", "Resolution (logic)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4409723823", "doi": "https://doi.org/10.1109/tpami.2025.3563612", "title": "Diff-Retinex++: Retinex-Driven Reinforced Diffusion Model for Low-Light Image Enhancement", "abstract": "This paper proposes a Retinex-driven reinforced diffusion model for low-light image enhancement, termed Diff-Retinex++, to address various degradations caused by low light. Our main approach integrates the diffusion model with Retinex-driven restoration to achieve physically-inspired generative enhancement, making it a pioneering effort. To be detailed, Diff-Retinex++ consists of two-stage view modules, including the Denoising Diffusion Model (DDM), and the Retinex-Driven Mixture of Experts Model (RMoE). First, DDM treats low-light image enhancement as one type of image generation task, benefiting from the powerful generation ability of diffusion model to handle the enhancement. Second, we design the Retinex theory into the plug-and-play supervision attention module. It leverages the latent features in the backbone and knowledge distillation to learn Retinex rules, and further regulates these latent features through the attention mechanism. In this way, it couples the relationship between Retinex decomposition and image enhancement in a new view, achieving dual improvement. In addition, the Low-Light Mixture of Experts preserves the vividness of the diffusion model and fidelity of the Retinex-driven restoration to the greatest extent. Ultimately, the iteration of DDM and RMoE achieves the goal of Retinex-driven reinforced diffusion model. Extensive experiments conducted on real-world low-light datasets qualitatively and quantitatively demonstrate the effectiveness, superiority, and generalization of the proposed method.", "authors": ["Xunpeng Yi", "Han Xu", "Hao Zhang", "Linfeng Tang", "Jiayi Ma"], "year": 2025, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 25, "type": "article", "concepts": ["Color constancy", "Artificial intelligence", "Image enhancement", "Computer vision", "Computer science"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402776053", "doi": "https://doi.org/10.1109/cvpr52733.2024.00244", "title": "Learning Diffusion Texture Priors for Image Restoration", "abstract": "Diffusion Models have shown remarkable performance in image generation tasks, which are capable of generating diverse and realistic image content. When adopting diffusion models for image restoration, the crucial challenge lies in how to preserve high-level image fidelity in the random-ness diffusion process and generate accurate background structures and realistic texture details. In this paper, we propose a general framework and develop a Diffusion Texture Prior Model (DTPM) for image restoration tasks. DTPM explicitly models high-quality texture details through the diffusion process, rather than global contextual content. In phase one of the training stage, we pretrain DTPM on approximately 55K high-quality image samples, after which we freeze most of its parameters. In phase two, we insert conditional guidance adapters into DTPM and equip it with an initial predictor, thereby facilitating its rapid adaptation to downstream image restoration tasks. Our DTPM could mitigate the randomness of traditional diffusion models by utilizing encapsulated rich and diverse texture knowledge and background structural information provided by the initial predictor during the sampling process.", "authors": ["Ye Tian", "Sixiang Chen", "Wenhao Chai", "Zhaohu Xing", "Jing Qin", "Lin Ge", "Lei Zhu"], "year": 2024, "venue": "", "cited_by_count": 21, "type": "article", "concepts": ["Prior probability", "Artificial intelligence", "Image restoration", "Texture (cosmology)", "Computer science"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2151734986", "doi": "https://doi.org/10.3322/caac.20114", "title": "Photodynamic therapy of cancer: An update", "abstract": "Photodynamic therapy (PDT) is a clinically approved, minimally invasive therapeutic procedure that can exert a selective cytotoxic activity toward malignant cells. The procedure involves administration of a photosensitizing agent followed by irradiation at a wavelength corresponding to an absorbance band of the sensitizer. In the presence of oxygen, a series of events lead to direct tumor cell death, damage to the microvasculature, and induction of a local inflammatory reaction. Clinical studies revealed that PDT can be curative, particularly in early stage tumors. It can prolong survival in patients with inoperable cancers and significantly improve quality of life. Minimal normal tissue toxicity, negligible systemic effects, greatly reduced long-term morbidity, lack of intrinsic or acquired resistance mechanisms, and excellent cosmetic as well as organ function-sparing effects of this treatment make it a valuable therapeutic option for combination treatments. With a number of recent technological improvements, PDT has the potential to become integrated into the mainstream of cancer treatment.", "authors": ["Patrizia Agostinis", "Kristian Berg", "Keith A. Cengel", "Thomas H. Foster", "Albert W. Girotti", "Sandra O. Gollnick", "Stephen M. Hahn", "Michael R. Hamblin", "Asta Juzeniene", "David Kessel", "Mladen Korbelik", "Johan Moan", "Paweł Mróz", "Dominika Nowis", "Jacques Piette", "Brian C. Wilson", "Jakub Gołąb"], "year": 2011, "venue": "CA A Cancer Journal for Clinicians", "cited_by_count": 5044, "type": "review", "concepts": ["Medicine", "Photodynamic therapy", "Cancer", "Toxicity", "Cancer treatment"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W3109746568", "doi": "https://doi.org/10.1038/s41573-020-0090-8", "title": "Engineering precision nanoparticles for drug delivery", "abstract": "", "authors": ["Michael J. Mitchell", "Margaret M. Billingsley", "Rebecca M. Haley", "Marissa E. Wechsler", "Nicholas A. Peppas", "Róbert Langer"], "year": 2020, "venue": "Nature Reviews Drug Discovery", "cited_by_count": 6843, "type": "review", "concepts": ["Precision medicine", "Drug delivery", "Personalized medicine", "Nanotechnology", "Computer science"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4390873198", "doi": "https://doi.org/10.1109/iccv51070.2023.00672", "title": "Towards Authentic Face Restoration with Iterative Diffusion Models and Beyond", "abstract": "An authentic face restoration system is becoming increasingly demanding in many computer vision applications, e.g., image enhancement, video communication, and taking portrait. Most of the advanced face restoration models can recover high-quality faces from low-quality ones but usually fail to faithfully generate realistic and high-frequency details that are favored by users. To achieve authentic restoration, we propose IDM, an Iteratively learned face restoration system based on denoising Diffusion Models (DDMs). We define the criterion of an authentic face restoration system, and argue that denoising diffusion models are naturally endowed with this property from two aspects: intrinsic iterative refinement and extrinsic iterative enhancement. Intrinsic learning can preserve the content well and gradually refine the high-quality details, while extrinsic enhancement helps clean the data and improve the restoration task one step further. We demonstrate superior performance on blind face restoration tasks. Beyond restoration, we find the authentically cleaned data by the proposed restoration system is also helpful to image generation tasks in terms of training stabilization and sample quality. Without modifying the models, we achieve better quality than state-of-the-art on FFHQ and ImageNet generation using either GANs or diffusion models.", "authors": ["Yang Zhao", "Tingbo Hou", "Yu-Chuan Su", "Xuhui Jia", "Yandong Li", "Matthias Grundmann"], "year": 2023, "venue": "", "cited_by_count": 17, "type": "article", "concepts": ["Computer science", "Image restoration", "Face (sociological concept)", "Noise reduction", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4385804911", "doi": "https://doi.org/10.1109/cvprw59228.2023.00123", "title": "Unlimited-Size Diffusion Restoration", "abstract": "Recently, using diffusion models for zero-shot image restoration (IR) has become a new hot paradigm. This type of method only needs to use the pre-trained off-the-shelf diffusion models, without any finetuning, and can directly handle various IR tasks. The upper limit of the restoration performance depends on the pre-trained diffusion models, which are in rapid evolution. However, current methods only discuss how to deal with fixed-size images, but dealing with images of arbitrary sizes is very important for practical applications. This paper focuses on how to use those diffusion-based zero-shot IR methods to deal with any size while maintaining the excellent characteristics of zero-shot. A simple way to solve arbitrary size is to divide it into fixed-size patches and solve each patch independently. But this may yield significant artifacts since it neither considers the global semantics ofall patches nor the local information of adjacent patches. Inspired by the Range-Null space Decomposition, we propose the Mask-Shift Restoration to address local incoherence and propose the Hierarchical Restoration to alleviate out-of-domain issues. Our simple, parameterfree approaches can be used not only for image restoration but also for image generation of unlimited sizes, with the potential to be a general tool for diffusion models. Code: https://github.com/wyhuai/DDNM/tree/main/hq_demo.", "authors": ["Yinhuai Wang", "Jiwen Yu", "Runyi Yu", "Jian Zhang"], "year": 2023, "venue": "", "cited_by_count": 15, "type": "article", "concepts": ["Computer science", "Diffusion", "Image restoration", "Image (mathematics)", "Range (aeronautics)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2946371186", "doi": "https://doi.org/10.1177/0271678x19845149", "title": "Non-invasive treatment with near-infrared light: A novel mechanisms-based strategy that evokes sustained reduction in brain injury after stroke", "abstract": "Ischemic stroke is a debilitating disease that causes significant brain injury. While restoration of blood flow is critical to salvage the ischemic brain, reperfusion can exacerbate damage by inducing generation of reactive oxygen species (ROS). Recent studies by our group found that non-invasive mitochondrial modulation with near-infrared (NIR) light limits ROS generation following global brain ischemia. NIR interacts with cytochrome <i>c</i> oxidase (COX) to transiently reduce COX activity, attenuate mitochondrial membrane potential hyperpolarization, and thus reduce ROS production. We evaluated a specific combination of COX-inhibitory NIR (750 nm and 950 nm) in a rat stroke model with longitudinal analysis of brain injury using magnetic resonance imaging. Treatment with NIR for 2 h resulted in a 21% reduction in brain injury at 24 h of reperfusion measured by diffusion-weighted imaging (DWI) and a 25% reduction in infarct volume measured by T2-weighted imaging (T2WI) at 7 and 14 days of reperfusion, respectively. Additionally, extended treatment reduced brain injury in the acute phase of brain injury, and 7 and 14 days of reperfusion, demonstrating a >50% reduction in infarction. Our data suggest that mitochondrial modulation with NIR attenuates ischemia-reperfusion injury and evokes a sustained reduction in infarct volume following ischemic stroke.", "authors": ["Christos D. Strubakos", "Michelle Malik", "Joseph M. Wider", "Icksoo Lee", "Christian A. Reynolds", "Panayiotis Mitsias", "Karin Przyklenk", "Maik Hüttemann", "Thomas H. Sanderson"], "year": 2019, "venue": "Journal of Cerebral Blood Flow & Metabolism", "cited_by_count": 36, "type": "article", "concepts": ["Stroke (engine)", "Medicine", "Reduction (mathematics)", "Traumatic brain injury", "Neuroscience"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4379089715", "doi": "https://doi.org/10.48550/arxiv.2305.20049", "title": "A Unified Conditional Framework for Diffusion-based Image Restoration", "abstract": "Diffusion Probabilistic Models (DPMs) have recently shown remarkable performance in image generation tasks, which are capable of generating highly realistic images. When adopting DPMs for image restoration tasks, the crucial aspect lies in how to integrate the conditional information to guide the DPMs to generate accurate and natural output, which has been largely overlooked in existing works. In this paper, we present a unified conditional framework based on diffusion models for image restoration. We leverage a lightweight UNet to predict initial guidance and the diffusion model to learn the residual of the guidance. By carefully designing the basic module and integration module for the diffusion model block, we integrate the guidance and other auxiliary conditional information into every block of the diffusion model to achieve spatially-adaptive generation conditioning. To handle high-resolution images, we propose a simple yet effective inter-step patch-splitting strategy to produce arbitrary-resolution images without grid artifacts. We evaluate our conditional framework on three challenging tasks: extreme low-light denoising, deblurring, and JPEG restoration, demonstrating its significant improvements in perceptual quality and the generalization to restoration tasks.", "authors": ["Yi Zhang", "Xiaoyu Shi", "Dasong Li", "Xiaogang Wang", "Jian Wang", "Hongsheng Li"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 11, "type": "preprint", "concepts": ["Computer science", "Deblurring", "Leverage (statistics)", "Image restoration", "JPEG"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402753813", "doi": "https://doi.org/10.1109/cvpr52733.2024.02440", "title": "Diffusion-based Blind Text Image Super-Resolution", "abstract": "Recovering degraded low-resolution text images is chal-lenging, especially for Chinese text images with complex strokes and severe degradation in real-world scenarios. En-suring both text fidelity and style realness is crucial for high-quality text image super-resolution. Recently, diffusion models have achieved great success in natural image synthesis and restoration due to their powerful data distribution modeling abilities and data generation capabili-ties. In this work, we propose an Image Diffusion Model (IDM) to restore text images with realistic styles. For diffusion models, they are not only suitable for modeling realis-tic image distribution but also appropriate for learning text distribution. Since text prior is important to guarantee the correctness of the restored text structure according to existing arts, we also propose a Text Diffusion Model (TDM) for text recognition which can guide IDM to generate text images with correct structures. We further propose a Mixture of Multi-modality module (MoM) to make these two diffusion models cooperate with each other in all the diffusion steps. Extensive experiments on synthetic and real-world datasets demonstrate that our Diffusion-based Blind Text Image Super-Resolution (DiffTSR) can restore text images with more accurate text structures as well as more realistic appearances simultaneously. Code is available at https://github.com/YuzheZhang-1999/DiffTSR.", "authors": ["Yuzhe Zhang", "Jiawei Zhang", "Hao Li", "Zhouxia Wang", "Luwei Hou", "Dongqing Zou", "Liheng Bian"], "year": 2024, "venue": "", "cited_by_count": 16, "type": "article", "concepts": ["Diffusion", "Computer science", "Image (mathematics)", "Image resolution", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402916064", "doi": "https://doi.org/10.1109/cvprw63382.2024.00658", "title": "Photo-Realistic Image Restoration in the Wild with Controlled Vision-Language Models", "abstract": "Though diffusion models have been successfully applied to various image restoration (IR) tasks, their performance is sensitive to the choice of training datasets. Typically, diffusion models trained in specific datasets fail to recover images that have out-of-distribution degradations. To address this problem, this work leverages a capable vision-language model and a synthetic degradation pipeline to learn image restoration in the wild (wild IR). More specifically, all low-quality images are simulated with a synthetic degradation pipeline that contains multiple common degradations such as blur, resize, noise, and JPEG compression. Then we introduce robust training for a degradation-aware CLIP model to extract enriched image content features to assist high-quality image restoration. Our base diffusion model is the image restoration SDE (IR-SDE). Built upon it, we further present a posterior sampling strategy for fast noise-free image generation. We evaluate our model on both synthetic and real-world degradation datasets. Moreover, experiments on the unified image restoration task illustrate that the proposed posterior sampling improves image generation quality for various degradations.", "authors": ["Ziwei Luo", "Fredrik Gustafsson", "Zheng Zhao", "Jens Sjölund", "Thomas B. Schön"], "year": 2024, "venue": "", "cited_by_count": 10, "type": "article", "concepts": ["Computer science", "Computer vision", "Image restoration", "Artificial intelligence", "Image (mathematics)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4393972605", "doi": "https://doi.org/10.1109/tip.2024.3383776", "title": "DriftRec: Adapting Diffusion Models to Blind JPEG Restoration", "abstract": "In this work, we utilize the high-fidelity generation abilities of diffusion models to solve blind JPEG restoration at high compression levels. We propose an elegant modification of the forward stochastic differential equation of diffusion models to adapt them to this restoration task and name our method DriftRec. Comparing DriftRec against an L<sub>2</sub> regression baseline with the same network architecture and state-of-the-art techniques for JPEG restoration, we show that our approach can escape the tendency of other methods to generate blurry images, and recovers the distribution of clean images significantly more faithfully. For this, only a dataset of clean/corrupted image pairs and no knowledge about the corruption operation is required, enabling wider applicability to other restoration tasks. In contrast to other conditional and unconditional diffusion models, we utilize the idea that the distributions of clean and corrupted images are much closer to each other than each is to the usual Gaussian prior of the reverse process in diffusion models. Our approach therefore requires only low levels of added noise and needs comparatively few sampling steps even without further optimizations. We show that DriftRec naturally generalizes to realistic and difficult scenarios such as unaligned double JPEG compression and blind restoration of JPEGs found online, without having encountered such examples during training.", "authors": ["Simon Welker", "Henry N. Chapman", "Timo Gerkmann"], "year": 2024, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 13, "type": "article", "concepts": ["Computer science", "Image restoration", "JPEG", "Artificial intelligence", "Computer vision"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2135194391", "doi": "https://doi.org/10.1023/a:1020281327116", "title": "An Introduction to MCMC for Machine Learning", "abstract": "", "authors": ["Christophe Andrieu", "Nando de Freitas", "Randal Douc", "Michael I. Jordan"], "year": 2003, "venue": "Machine Learning", "cited_by_count": 2379, "type": "article", "concepts": ["Computer science", "Markov chain Monte Carlo", "Monte Carlo method", "Probabilistic logic", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4401506925", "doi": "https://doi.org/10.1109/tcsvt.2024.3441713", "title": "Image Intrinsic Components Guided Conditional Diffusion Model for Low-Light Image Enhancement", "abstract": "Through formulating the image restoration as a generation problem, the conditional diffusion model has been applied to low-light image enhancement (LIE) to restore the details in dark regions. However, in the previous diffusion model based LIE methods, the conditions used for guiding generation are degraded images, such as low-light image, signal-to-noise ratio map and color map, which suffer from severe degradation and are simply fed into diffusion model by rigidly concatenating with the noise. To avoid using degraded conditions resulting in sub-optimal performance in recovering details and enhancing brightness, we use the image intrinsic components originating from the Retinex model as guidance, whose multi-scale features are flexibly integrated into the diffusion model, and propose a novel conditional diffusion model for LIE. Specifically, the input low-light image is decomposed into reflectance and illumination by a Retinex decomposition module, where two components contain abundant physical property and lighting conditions of the scene. Then, we extract the latent features from two conditions through a component-dependent feature extraction module, which is designed according to the physical property of components. Finally, instead of previous rigid concatenation manner, a well-designed feature fusion mechanism is equipped to adaptively embed generative conditions into diffusion model. Extensive experimental results demonstrate that our method outperforms the state-of-the-art methods, and is capable of effectively restoring the local details while brightening the dark regions. Our codes are available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/Knossosc/ICCDiff</uri>.", "authors": ["Sicong Kang", "Shuaibo Gao", "Wenhui Wu", "Xu Wang", "Shuoyao Wang", "Guoping Qiu"], "year": 2024, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 15, "type": "article", "concepts": ["Image enhancement", "Image (mathematics)", "Diffusion", "Image processing", "Computer science"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402716178", "doi": "https://doi.org/10.1109/cvpr52733.2024.00248", "title": "Restoration by Generation with Constrained Priors", "abstract": "The inherent generative power of denoising diffusion mod-els makes them well-suited for image restoration tasks where the objective is to find the optimal high-quality image within the generative space that closely resembles the input im-age. We propose a method to adapt a pretrained diffusion model for image restoration by simply adding noise to the input image to be restored and then denoise. Our method is based on the observation that the space of a generative model needs to be constrained. We impose this constraint by finetuning the generative model with a set of anchor images that capture the characteristics of the input image. With the constrained space, we can then leverage the sampling strat-egy used for generation to do image restoration. We evaluate against previous methods and show superior performances on multiple real-world restoration datasets in preserving identity and image quality. We also demonstrate an important and practical application on personalized restoration, where we use a personal album as the anchor images to constrain the generative space. This approach allows us to produce results that accurately preserve high-frequency details, which previous works are unable to do. Project webpage: https://gen2res.github.io.", "authors": ["Zheng Ding", "Xuaner Zhang", "Zhuowen Tu", "Zhihao Xia"], "year": 2024, "venue": "", "cited_by_count": 10, "type": "article", "concepts": ["Prior probability", "Computer science", "Mathematical optimization", "Artificial intelligence", "Mathematics"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402644702", "doi": "https://doi.org/10.1038/s41598-024-72820-2", "title": "Learning to reconstruct accelerated MRI through K-space cold diffusion without noise", "abstract": "", "authors": ["G.D. Shen", "Mengyu Li", "Chad W. Farris", "Stephan W. Anderson", "Xin Zhang"], "year": 2024, "venue": "Scientific Reports", "cited_by_count": 11, "type": "article", "concepts": ["Computer science", "Noise (video)", "Diffusion", "Diffusion MRI", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4361852499", "doi": "https://doi.org/10.1145/3577530.3577539", "title": "DiffGAR: Model-Agnostic Restoration from Generative Artifacts Using Image-to-Image Diffusion Models", "abstract": "Recent generative models show impressive results in photo-realistic image generation. However, artifacts often inevitably appear in the generated results, leading to downgraded user experience and reduced performance in downstream tasks. This work aims to develop a plugin post-processing module for diverse generative models, which can faithfully restore images from diverse generative artifacts. This is challenging because: (1) Unlike traditional degradation patterns, generative artifacts are non-linear and the transformation function is highly complex. (2) There are no readily available artifact-image pairs. (3) Different from model-specific anti-artifact methods, a model-agnostic framework views the generator as a black-box machine and has no access to the architecture details. In this work, we first design a group of mechanisms to simulate generative artifacts of popular generators (i.e., GANs, autoregressive models, and diffusion models), given real images. Second, we implement the model-agnostic anti-artifact framework as an image-to-image diffusion model, due to its advantage in generation quality and capacity. Finally, we design a conditioning scheme for the diffusion model to enable both blind and non-blind image restoration. A guidance parameter is also introduced to allow for a trade-off between restoration accuracy and image quality. Extensive experiments show that our method significantly outperforms previous approaches on the proposed datasets and real-world artifact images.", "authors": ["Yueqin Yin", "Lianghua Huang", "Yu Liu", "Kaiqi Huang"], "year": 2022, "venue": "", "cited_by_count": 7, "type": "article", "concepts": ["Computer science", "Artifact (error)", "Generator (circuit theory)", "Image (mathematics)", "Generative model"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4387211537", "doi": "https://doi.org/10.1007/978-3-031-43907-0_26", "title": "PET Image Denoising with Score-Based Diffusion Probabilistic Models", "abstract": "", "authors": ["Chenyu Shen", "Ziyuan Yang", "Yi Zhang"], "year": 2023, "venue": "Lecture notes in computer science", "cited_by_count": 15, "type": "book-chapter", "concepts": ["Computer science", "Probabilistic logic", "Artificial intelligence", "Noise reduction", "Noise (video)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W3188940990", "doi": "https://doi.org/10.1038/s41578-021-00358-0", "title": "Lipid nanoparticles for mRNA delivery", "abstract": "", "authors": ["Xucheng Hou", "Tal Zaks", "Róbert Langer", "Yizhou Dong"], "year": 2021, "venue": "Nature Reviews Materials", "cited_by_count": 3213, "type": "review", "concepts": ["Messenger RNA", "Translation (biology)", "Nanoparticle", "Nucleic acid", "RNA"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4393150395", "doi": "https://doi.org/10.1609/aaai.v38i2.27833", "title": "Improving Diffusion-Based Image Restoration with Error Contraction and Error Correction", "abstract": "Generative diffusion prior captured from the off-the-shelf denoising diffusion generative model has recently attained significant interest. However, several attempts have been made to adopt diffusion models to noisy inverse problems either fail to achieve satisfactory results or require a few thousand iterations to achieve high-quality reconstructions. In this work, we propose a diffusion-based image restoration with error contraction and error correction (DiffECC) method. Two strategies are introduced to contract the restoration error in the posterior sampling process. First, we combine existing CNN-based approaches with diffusion models to ensure data consistency from the beginning. Second, to amplify the error contraction effects of the noise, a restart sampling algorithm is designed. In the error correction strategy, the estimation-correction idea is proposed on both the data term and the prior term. Solving them iteratively within the diffusion sampling framework leads to superior image generation results. Experimental results for image restoration tasks such as super-resolution (SR), Gaussian deblurring, and motion deblurring demonstrate that our approach can reconstruct high-quality images compared with state-of-the-art sampling-based diffusion models.", "authors": ["Qiqi Bao", "Hui Zheng", "Rui Zhu", "Peiran Ren", "Xuansong Xie", "Wenming Yang"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 6, "type": "article", "concepts": ["Contraction (grammar)", "Computer science", "Error detection and correction", "Image restoration", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4393155853", "doi": "https://doi.org/10.1609/aaai.v38i2.27861", "title": "Iterative Token Evaluation and Refinement for Real-World Super-resolution", "abstract": "Real-world image super-resolution (RWSR) is a long-standing problem as low-quality (LQ) images often have complex and unidentified degradations. Existing methods such as Generative Adversarial Networks (GANs) or continuous diffusion models present their own issues including GANs being difficult to train while continuous diffusion models requiring numerous inference steps. In this paper, we propose an Iterative Token Evaluation and Refinement (ITER) framework for RWSR, which utilizes a discrete diffusion model operating in the discrete token representation space, i.e., indexes of features extracted from a VQGAN codebook pre-trained with high-quality (HQ) images. We show that ITER is easier to train than GANs and more efficient than continuous diffusion models. Specifically, we divide RWSR into two sub-tasks, i.e., distortion removal and texture generation. Distortion removal involves simple HQ token prediction with LQ images, while texture generation uses a discrete diffusion model to iteratively refine the distortion removal output with a token refinement network. In particular, we propose to include a token evaluation network in the discrete diffusion process. It learns to evaluate which tokens are good restorations and helps to improve the iterative refinement results. Moreover, the evaluation network can first check status of the distortion removal output and then adaptively select total refinement steps needed, thereby maintaining a good balance between distortion removal and texture generation. Extensive experimental results show that ITER is easy to train and performs well within just 8 iterative steps.", "authors": ["Chaofeng Chen", "Shangchen Zhou", "Liang Liao", "Haoning Wu", "Wenxiu Sun", "Qiong Yan", "Weisi Lin"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 8, "type": "article", "concepts": ["Security token", "Resolution (logic)", "Computer science", "Artificial intelligence", "Computer security"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402727905", "doi": "https://doi.org/10.1109/cvpr52733.2024.00280", "title": "Boosting Image Restoration via Priors from Pre-Trained Models", "abstract": "Pre-trained models with large-scale training data, such as CLIP and Stable Diffusion, have demonstrated remarkable performance in various high-level computer vision tasks such as image understanding and generation from language descriptions. Yet, their potential for low-level tasks such as image restoration remains relatively unexplored. In this paper, we explore such models to enhance image restoration. As off-the-shelf features (OSF) from pre-trained models do not directly serve image restoration, we propose to learn an additional lightweight module called Pre-Train-Guided Refinement Module (PTG-RM) to refine restoration results of a target restoration network with OSF. PTG-RM consists of two components, Pre-Train-Guided Spatial-Varying Enhancement (PTG-SVE), and Pre-Train-Guided Channel-Spatial Attention (PTG-CSA). PTG-SVE enables optimal short- and long-range neural operations, while PTG-CSA enhances spatial-channel attention for restoration-related learning. Extensive experiments demonstrate that PTG-RM, with its compact size (<1M parameters), effectively enhances restoration performance of various models across different tasks, including low-light enhancement, deraining, deblurring, and denoising.", "authors": ["Xiaogang Xu", "Shu Kong", "Tao Hu", "Zhe Liu", "Hujun Bao"], "year": 2024, "venue": "", "cited_by_count": 10, "type": "article", "concepts": ["Boosting (machine learning)", "Prior probability", "Artificial intelligence", "Computer science", "Image restoration"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4409883308", "doi": "https://doi.org/10.1109/jphot.2025.3564831", "title": "KEDM: Knowledge-Embedded Diffusion Model for Infrared Image Destriping", "abstract": "Infrared imaging systems are widely used across industries. However, their output images often exhibit striped noise due to the nonuniform response of the detection system, which significantly affects image quality and visual fidelity. To address challenges such as incomplete stripe removal, potential loss of image details and textures, and the generation of artificial artifacts during destriping, we propose a novel stripe removal method based on a knowledge-embedded diffusion model (KEDM). This approach effectively integrates the spatial distribution characteristics of stripe noise with an innovative, data-driven diffusion network model, creating a hybrid knowledge and data-driven framework for stripe correction. The core components of KEDM are the latent diffusion model (LDM) architecture and the directional wavelet convolution module (DWCM). Specifically, LDM leverages a pretrained variational autoencoder (VAE) to transform the input image into latent feature space for efficient diffusion propagation, reducing computational complexity while preserving image restoration quality. Meanwhile, DWCM uses wavelet convolution operations to construct prior loss functions for stripe noise, precisely guiding the diffusion reconstruction process to achieve a clean, stripe-free image. Empirical evaluations on several benchmark datasets demonstrate that the proposed KEDM outperforms other stateof-the-art destriping algorithms in terms of visual quality and quantitative metrics, validating its excellent performance.", "authors": ["Lingxiao Li", "Xin Wang", "Dan Huang", "Yunan He", "Zhuqiang Zhong", "Qingling Xia"], "year": 2025, "venue": "IEEE photonics journal", "cited_by_count": 12, "type": "article", "concepts": ["Computer science", "Diffusion", "Infrared", "Astronomy", "Physics"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4386273147", "doi": "https://doi.org/10.48550/arxiv.2308.14469", "title": "Pixel-Aware Stable Diffusion for Realistic Image Super-resolution and Personalized Stylization", "abstract": "Diffusion models have demonstrated impressive performance in various image generation, editing, enhancement and translation tasks. In particular, the pre-trained text-to-image stable diffusion models provide a potential solution to the challenging realistic image super-resolution (Real-ISR) and image stylization problems with their strong generative priors. However, the existing methods along this line often fail to keep faithful pixel-wise image structures. If extra skip connections between the encoder and the decoder of a VAE are used to reproduce details, additional training in image space will be required, limiting the application to tasks in latent space such as image stylization. In this work, we propose a pixel-aware stable diffusion (PASD) network to achieve robust Real-ISR and personalized image stylization. Specifically, a pixel-aware cross attention module is introduced to enable diffusion models perceiving image local structures in pixel-wise level, while a degradation removal module is used to extract degradation insensitive features to guide the diffusion process together with image high level information. An adjustable noise schedule is introduced to further improve the image restoration results. By simply replacing the base diffusion model with a stylized one, PASD can generate diverse stylized images without collecting pairwise training data, and by shifting the base model with an aesthetic one, PASD can bring old photos back to life. Extensive experiments in a variety of image enhancement and stylization tasks demonstrate the effectiveness of our proposed PASD approach. Our source codes are available at \\url{https://github.com/yangxy/PASD/}.", "authors": ["Tao Yang", "Peiran Ren", "Xuansong Xie", "Lei Zhang", "Zhang, Lei"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 11, "type": "preprint", "concepts": ["Pixel", "Computer vision", "Image (mathematics)", "Diffusion", "Artificial intelligence"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4402726982", "doi": "https://doi.org/10.1109/cvpr52733.2024.00864", "title": "CoDi: Conditional Diffusion Distillation for Higher-Fidelity and Faster Image Generation", "abstract": "Large generative diffusion models have revolution-ized text-to-image generation and offer immense po-tential for conditional generation tasks such as im-age enhancement, restoration, editing, and compositing. However, their widespread adoption is hindered by the high computational cost, which limits their real-time application. To address this challenge, we in-troduce a novel method dubbed CoDi, that adapts a pre-trained latent diffusion model to accept additional image conditioning inputs while significantly reducing the sampling steps required to achieve high-quality results. Our method can leverage architectures such as ControlNet to incorporate conditioning inputs with-out compromising the model's prior knowledge gained during large scale pre-training. Additionally, a con-ditional consistency loss enforces consistent predictions across diffusion steps, effectively compelling the model to generate high-quality images with conditions in a few steps. Our conditional-task learning and distil-lation approach outperforms previous distillation meth-ods, achieving a new state-of-the-art in producing high-quality images with very few steps (e.g., 1–4) across multiple tasks, including super-resolution, text-guided image editing, and depth-to-image generation.", "authors": ["Kangfu Mei", "Mauricio Delbracio", "Hossein Talebi", "Zhengzhong Tu", "Vishal M. Patel", "Peyman Milanfar"], "year": 2024, "venue": "", "cited_by_count": 10, "type": "article", "concepts": ["Fidelity", "Computer science", "Diffusion", "Image (mathematics)", "Distillation"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4406331742", "doi": "https://doi.org/10.3390/electronics14020282", "title": "Design Transformation Pathways for AI-Generated Images in Chinese Traditional Architecture", "abstract": "This study introduces a design transformation model for AI-generated Chinese traditional architectural images (SD Lora&amp;Canny) based on Stable Diffusion (SD). By integrating parameterization techniques such as Low-Rank Adaptation (Lora) and edge detection algorithms (Canny), the model achieves precise restoration of the architectural form, color elements, and decorative symbols in Chinese traditional architecture. Using the Beijing Drum Tower as the experimental subject, statistical analysis software (SPSS V28.0) was employed to conduct a quantitative evaluation and comparative analysis of architectural images generated by the DALL-E, MidJourney, SD, and SD Lora&amp;Canny models. The results demonstrate that the SD Lora&amp;Canny model significantly outperforms traditional generation tools in restoration accuracy and visual fidelity. Finally, this study applied the SD Lora&amp;Canny model to create the digital cultural product AR Drum and Bell Tower Fridge Magnet, showcasing its practical application in digital cultural creation and verifying its innovative potential in the digital preservation and transmission of Chinese traditional architecture.", "authors": ["Yi Lu", "Jiacheng Wu", "Mengyao Wang", "Jiayi Fu", "Wanxu Xie", "Pohsun Wang", "Pengcheng Zhao"], "year": 2025, "venue": "Electronics", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Transformation (genetics)", "Artificial intelligence", "Computer vision", "Canny edge detector"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2158993832", "doi": "https://doi.org/10.1029/2001rg000106", "title": "Gravity wave dynamics and effects in the middle atmosphere", "abstract": "Atmospheric gravity waves have been a subject of intense research activity in recent years because of their myriad effects and their major contributions to atmospheric circulation, structure, and variability. Apart from occasionally strong lower‐atmospheric effects, the major wave influences occur in the middle atmosphere, between ∼ 10 and 110 km altitudes because of decreasing density and increasing wave amplitudes with altitude. Theoretical, numerical, and observational studies have advanced our understanding of gravity waves on many fronts since the review by Fritts [1984a] ; the present review will focus on these more recent contributions. Progress includes a better appreciation of gravity wave sources and characteristics, the evolution of the gravity wave spectrum with altitude and with variations of wind and stability, the character and implications of observed climatologies, and the wave interaction and instability processes that constrain wave amplitudes and spectral shape. Recent studies have also expanded dramatically our understanding of gravity wave influences on the large‐scale circulation and the thermal and constituent structures of the middle atmosphere. These advances have led to a number of parameterizations of gravity wave effects which are enabling ever more realistic descriptions of gravity wave forcing in large‐scale models. There remain, nevertheless, a number of areas in which further progress is needed in refining our understanding of and our ability to describe and predict gravity wave influences in the middle atmosphere. Our view of these unknowns and needs is also offered.", "authors": ["David C. Fritts", "M. Joan Alexander"], "year": 2003, "venue": "Reviews of Geophysics", "cited_by_count": 2716, "type": "article", "concepts": ["Gravity wave", "Atmosphere (unit)", "Atmospheric wave", "Gravitational wave", "Physics"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W4310556944", "doi": "https://doi.org/10.48550/arxiv.2211.16582", "title": "SinDDM: A Single Image Denoising Diffusion Model", "abstract": "Denoising diffusion models (DDMs) have led to staggering performance leaps in image generation, editing and restoration. However, existing DDMs use very large datasets for training. Here, we introduce a framework for training a DDM on a single image. Our method, which we coin SinDDM, learns the internal statistics of the training image by using a multi-scale diffusion process. To drive the reverse diffusion process, we use a fully-convolutional light-weight denoiser, which is conditioned on both the noise level and the scale. This architecture allows generating samples of arbitrary dimensions, in a coarse-to-fine manner. As we illustrate, SinDDM generates diverse high-quality samples, and is applicable in a wide array of tasks, including style transfer and harmonization. Furthermore, it can be easily guided by external supervision. Particularly, we demonstrate text-guided generation from a single image using a pre-trained CLIP model.", "authors": ["В. А. Куликов", "Shahar Yadin", "Matan Kleiner", "Tomer Michaeli"], "year": 2022, "venue": "arXiv (Cornell University)", "cited_by_count": 9, "type": "preprint", "concepts": ["LEAPS", "Noise reduction", "Computer science", "Noise (video)", "Image (mathematics)"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W1977871291", "doi": "https://doi.org/10.1038/nature06917", "title": "Imaging in the era of molecular oncology", "abstract": "", "authors": ["Ralph Weissleder", "Mikäel J. Pittet"], "year": 2008, "venue": "Nature", "cited_by_count": 2299, "type": "review", "concepts": ["Molecular imaging", "Cancer imaging", "In vivo", "Optical imaging", "Preclinical imaging"], "search_query": "diffusion model image restoration generation"}
{"openalex_id": "https://openalex.org/W2277195237", "doi": "https://doi.org/10.1007/s11263-016-0981-7", "title": "Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations", "abstract": "Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an image. When asked “What vehicle is the person riding?”, computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) to answer correctly that “the person is riding a horse-drawn carriage.” In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense annotations of objects, attributes, and relationships within each image to learn these models. Specifically, our dataset contains over 108K images where each image has an average of $$35$$ objects, $$26$$ attributes, and $$21$$ pairwise relationships between objects. We canonicalize the objects, attributes, relationships, and noun phrases in region descriptions and questions answer pairs to WordNet synsets. Together, these annotations represent the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answer pairs.", "authors": ["Ranjay Krishna", "Yuke Zhu", "Oliver Groth", "Justin Johnson", "Kenji Hata", "Joshua Kravitz", "Stephanie Chen", "Yannis Kalantidis", "Li-Jia Li", "David A. Shamma", "Michael S. Bernstein", "Li Fei-Fei"], "year": 2017, "venue": "International Journal of Computer Vision", "cited_by_count": 5052, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Natural language processing", "Genome", "Image (mathematics)"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4323651349", "doi": "https://doi.org/10.48550/arxiv.2303.04129", "title": "Foundation Models for Decision Making: Problems, Methods, and Opportunities", "abstract": "Foundation models pretrained on diverse data at scale have demonstrated extraordinary capabilities in a wide range of vision and language tasks. When such models are deployed in real world environments, they inevitably interface with other entities and agents. For example, language models are often used to interact with human beings through dialogue, and visual perception models are used to autonomously navigate neighborhood streets. In response to these developments, new paradigms are emerging for training foundation models to interact with other agents and perform long-term reasoning. These paradigms leverage the existence of ever-larger datasets curated for multimodal, multitask, and generalist interaction. Research at the intersection of foundation models and decision making holds tremendous promise for creating powerful new systems that can interact effectively across a diverse range of applications such as dialogue, autonomous driving, healthcare, education, and robotics. In this manuscript, we examine the scope of foundation models for decision making, and provide conceptual tools and technical background for understanding the problem space and exploring new research directions. We review recent approaches that ground foundation models in practical decision making applications through a variety of methods such as prompting, conditional generative modeling, planning, optimal control, and reinforcement learning, and discuss common challenges and open problems in the field.", "authors": ["Sherry Yang", "Ofir Nachum", "Yilun Du", "Jason Lee", "Pieter Abbeel", "Dale Schuurmans"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 50, "type": "preprint", "concepts": ["Computer science", "Leverage (statistics)", "Variety (cybernetics)", "Reinforcement learning", "Artificial intelligence"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2794284562", "doi": "https://doi.org/10.1155/2018/7068349", "title": "Deep Learning for Computer Vision: A Brief Review", "abstract": "Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.", "authors": ["Athanasios Voulodimos", "Nikolaos Doulamis", "Anastasios Doulamis", "Eftychios Protopapadakis"], "year": 2018, "venue": "Computational Intelligence and Neuroscience", "cited_by_count": 3204, "type": "review", "concepts": ["Artificial intelligence", "Deep learning", "Computer science", "Boltzmann machine", "Convolutional neural network"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4380993798", "doi": "https://doi.org/10.48550/arxiv.2306.08640", "title": "AssistGPT: A General Multi-modal Assistant that can Plan, Execute, Inspect, and Learn", "abstract": "Recent research on Large Language Models (LLMs) has led to remarkable advancements in general NLP AI assistants. Some studies have further explored the use of LLMs for planning and invoking models or APIs to address more general multi-modal user queries. Despite this progress, complex visual-based tasks still remain challenging due to the diverse nature of visual tasks. This diversity is reflected in two aspects: 1) Reasoning paths. For many real-life applications, it is hard to accurately decompose a query simply by examining the query itself. Planning based on the specific visual content and the results of each step is usually required. 2) Flexible inputs and intermediate results. Input forms could be flexible for in-the-wild cases, and involves not only a single image or video but a mixture of videos and images, e.g., a user-view image with some reference videos. Besides, a complex reasoning process will also generate diverse multimodal intermediate results, e.g., video narrations, segmented video clips, etc. To address such general cases, we propose a multi-modal AI assistant, AssistGPT, with an interleaved code and language reasoning approach called Plan, Execute, Inspect, and Learn (PEIL) to integrate LLMs with various tools. Specifically, the Planner is capable of using natural language to plan which tool in Executor should do next based on the current reasoning progress. Inspector is an efficient memory manager to assist the Planner to feed proper visual information into a specific tool. Finally, since the entire reasoning process is complex and flexible, a Learner is designed to enable the model to autonomously explore and discover the optimal solution. We conducted experiments on A-OKVQA and NExT-QA benchmarks, achieving state-of-the-art results. Moreover, showcases demonstrate the ability of our system to handle questions far more complex than those found in the benchmarks.", "authors": ["Difei Gao", "Lei Ji", "Luowei Zhou", "Kevin Qinghong Lin", "Joya Chen", "Zihan Fan", "Mike Zheng Shou"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 19, "type": "preprint", "concepts": ["Computer science", "Planner", "Process (computing)", "Plan (archaeology)", "Modal"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2112891119", "doi": "https://doi.org/10.1093/cercor/bhp055", "title": "Where Is the Semantic System? A Critical Review and Meta-Analysis of 120 Functional Neuroimaging Studies", "abstract": "Semantic memory refers to knowledge about people, objects, actions, relations, self, and culture acquired through experience. The neural systems that store and retrieve this information have been studied for many years, but a consensus regarding their identity has not been reached. Using strict inclusion criteria, we analyzed 120 functional neuroimaging studies focusing on semantic processing. Reliable areas of activation in these studies were identified using the activation likelihood estimate (ALE) technique. These activations formed a distinct, left-lateralized network comprised of 7 regions: posterior inferior parietal lobe, middle temporal gyrus, fusiform and parahippocampal gyri, dorsomedial prefrontal cortex, inferior frontal gyrus, ventromedial prefrontal cortex, and posterior cingulate gyrus. Secondary analyses showed specific subregions of this network associated with knowledge of actions, manipulable artifacts, abstract concepts, and concrete concepts. The cortical regions involved in semantic processing can be grouped into 3 broad categories: posterior multimodal and heteromodal association cortex, heteromodal prefrontal cortex, and medial limbic regions. The expansion of these regions in the human relative to the nonhuman primate brain may explain uniquely human capacities to use language productively, plan, solve problems, and create cultural and technological artifacts, all of which depend on the fluid and efficient retrieval and manipulation of semantic knowledge.", "authors": ["Jeffrey R. Binder", "Rutvik H. Desai", "William W. Graves", "Lisa L. Conant"], "year": 2009, "venue": "Cerebral Cortex", "cited_by_count": 4087, "type": "review", "concepts": ["Parahippocampal gyrus", "Fusiform gyrus", "Psychology", "Semantic memory", "Prefrontal cortex"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4365143687", "doi": "https://doi.org/10.1038/s41586-023-05881-4", "title": "Foundation models for generalist medical artificial intelligence", "abstract": "The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary to enable them. We expect that GMAI-enabled applications will challenge current strategies for regulating and validating AI devices for medicine and will shift practices associated with the collection of large medical datasets.", "authors": ["Michael Moor", "Oishi Banerjee", "Zahra Shakeri Hossein Abad", "Harlan M. Krumholz", "Jure Leskovec", "Eric J. Topol", "Pranav Rajpurkar"], "year": 2023, "venue": "Nature", "cited_by_count": 1340, "type": "review", "concepts": ["Computer science", "Set (abstract data type)", "Artificial intelligence", "Modalities", "Task (project management)"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4399857194", "doi": "https://doi.org/10.1145/3674149", "title": "Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam", "abstract": "The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at https://github.com/nabormendonca/gpt-4v-enade-cs-2021 .", "authors": ["Nabor C. Mendonça"], "year": 2024, "venue": "ACM Transactions on Computing Education", "cited_by_count": 13, "type": "article", "concepts": ["Computer science", "Mathematics education", "Visual reasoning", "Artificial intelligence", "Psychology"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4401580665", "doi": "https://doi.org/10.3390/make6030093", "title": "Visual Reasoning and Multi-Agent Approach in Multimodal Large Language Models (MLLMs): Solving TSP and mTSP Combinatorial Challenges", "abstract": "Multimodal Large Language Models (MLLMs) harness comprehensive knowledge spanning text, images, and audio to adeptly tackle complex problems. This study explores the ability of MLLMs in visually solving the Traveling Salesman Problem (TSP) and Multiple Traveling Salesman Problem (mTSP) using images that portray point distributions on a two-dimensional plane. We introduce a novel approach employing multiple specialized agents within the MLLM framework, each dedicated to optimizing solutions for these combinatorial challenges. We benchmarked our multi-agent model solutions against the Google OR tools, which served as the baseline for comparison. The results demonstrated that both multi-agent models—Multi-Agent 1, which includes the initializer, critic, and scorer agents, and Multi-Agent 2, which comprises only the initializer and critic agents—significantly improved the solution quality for TSP and mTSP problems. Multi-Agent 1 excelled in environments requiring detailed route refinement and evaluation, providing a robust framework for sophisticated optimizations. In contrast, Multi-Agent 2, focusing on iterative refinements by the initializer and critic, proved effective for rapid decision-making scenarios. These experiments yield promising outcomes, showcasing the robust visual reasoning capabilities of MLLMs in addressing diverse combinatorial problems. The findings underscore the potential of MLLMs as powerful tools in computational optimization, offering insights that could inspire further advancements in this promising field.", "authors": ["Mohammed Elhenawy", "Ahmad Abutahoun", "Taqwa I. Alhadidi", "Ahmed Jaber", "Huthaifa I. Ashqar", "Shadi Jaradat", "Ahmed Abdelhay", "Sébastien Glaser", "Andry Rakotonirainy"], "year": 2024, "venue": "Machine Learning and Knowledge Extraction", "cited_by_count": 18, "type": "article", "concepts": ["Computer science", "Artificial intelligence"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2112957339", "doi": null, "title": "Confronting the Challenges of Participatory Culture: Media Education for the 21st Century", "abstract": "Henry Jenkins, Director of the Comparative Media Studies Program at the Massachusetts Institute of Technology authored this white paper, exploring new frameworks and models for media literacy.", "authors": ["Henry Jenkins"], "year": 2006, "venue": "BiblioBoard Library Catalog (Open Research Library)", "cited_by_count": 3189, "type": "book", "concepts": ["Participatory culture", "Public relations", "Social media", "Citizen journalism", "Scholarship"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2168448159", "doi": "https://doi.org/10.1103/revmodphys.77.137", "title": "The Kuramoto model: A simple paradigm for synchronization phenomena", "abstract": "Synchronization phenomena in large populations of interacting elements are the subject of intense research efforts in physical, biological, chemical, and social systems. A successful approach to the problem of synchronization consists of modeling each member of the population as a phase oscillator. In this review, synchronization is analyzed in one of the most representative models of coupled phase oscillators, the Kuramoto model. A rigorous mathematical treatment, specific numerical methods, and many variations and extensions of the original model that have appeared in the last few years are presented. Relevant applications of the model in different contexts are also included.", "authors": ["Juan A. Acebrón", "L. L. Bonilla", "C. J. Pérez Vicente", "Félix Ritort", "Renato Spigler"], "year": 2005, "venue": "Reviews of Modern Physics", "cited_by_count": 3388, "type": "article", "concepts": ["Synchronization (alternating current)", "Physics", "Statistical physics", "Kuramoto model", "Simple (philosophy)"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2950761309", "doi": "https://doi.org/10.48550/arxiv.1505.00468", "title": "VQA: Visual Question Answering", "abstract": "We propose the task of free-form and open-ended Visual Question Answering (VQA). Given an image and a natural language question about the image, the task is to provide an accurate natural language answer. Mirroring real-world scenarios, such as helping the visually impaired, both the questions and answers are open-ended. Visual questions selectively target different areas of an image, including background details and underlying context. As a result, a system that succeeds at VQA typically needs a more detailed understanding of the image and complex reasoning than a system producing generic image captions. Moreover, VQA is amenable to automatic evaluation, since many open-ended answers contain only a few words or a closed set of answers that can be provided in a multiple-choice format. We provide a dataset containing ~0.25M images, ~0.76M questions, and ~10M answers (www.visualqa.org), and discuss the information it provides. Numerous baselines and methods for VQA are provided and compared with human performance. Our VQA demo is available on CloudCV (http://cloudcv.org/vqa).", "authors": ["Aishwarya Agrawal", "Jiasen Lu", "Stanislaw Antol", "Margaret Mitchell", "C. Lawrence Zitnick", "Dhruv Batra", "Devi Parikh"], "year": 2015, "venue": "arXiv (Cornell University)", "cited_by_count": 1094, "type": "preprint", "concepts": ["Question answering", "Mirroring", "Computer science", "Set (abstract data type)", "Task (project management)"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2778852739", "doi": "https://doi.org/10.25073/2525-2445/vnufs.4217", "title": "READING IMAGES - THE GRAMMAR OF VISUAL DESIGN", "abstract": "Authors: Gunther Kress &amp; Theo van Leeuwen Routledge, 2006, ISBN-13: 978-0415319157", "authors": ["Tran Thi Thuy"], "year": 2017, "venue": "VNU Journal of Foreign Studies", "cited_by_count": 860, "type": "article", "concepts": ["Reading (process)", "Computer science", "Grammar", "Artificial intelligence", "Natural language processing"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4376226279", "doi": "https://doi.org/10.1109/tpami.2023.3275156", "title": "Multimodal Learning With Transformers: A Survey", "abstract": "Transformer is a promising neural network learner, and has achieved great success in various machine learning tasks. Thanks to the recent prevalence of multimodal applications and Big Data, Transformer-based multimodal learning has become a hot topic in AI research. This paper presents a comprehensive survey of Transformer techniques oriented at multimodal data. The main contents of this survey include: (1) a background of multimodal learning, Transformer ecosystem, and the multimodal Big Data era, (2) a systematic review of Vanilla Transformer, Vision Transformer, and multimodal Transformers, from a geometrically topological perspective, (3) a review of multimodal Transformer applications, via two important paradigms, i.e., for multimodal pretraining and for specific multimodal tasks, (4) a summary of the common challenges and designs shared by the multimodal Transformer models and applications, and (5) a discussion of open problems and potential research directions for the community.", "authors": ["Peng Xu", "Xiatian Zhu", "David A. Clifton"], "year": 2023, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 758, "type": "article", "concepts": ["Transformer", "Computer science", "Multimodal learning", "Multimodal therapy", "Artificial intelligence"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4386142022", "doi": "https://doi.org/10.1007/s12559-023-10179-8", "title": "Interpreting Black-Box Models: A Review on Explainable Artificial Intelligence", "abstract": "", "authors": ["Vikas Hassija", "Vinay Chamola", "A. Mahapatra", "Abhinandan Singal", "Divyansh Goel", "Kaizhu Huang", "Simone Scardapane", "Indro Spinelli", "Mufti Mahmud", "Amir Hussain"], "year": 2023, "venue": "Cognitive Computation", "cited_by_count": 1368, "type": "review", "concepts": ["Transparency (behavior)", "Computer science", "Black box", "Process (computing)", "Predictability"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4405433256", "doi": "https://doi.org/10.1103/physrevphyseducres.21.010154", "title": "Performance of ChatGPT on tasks involving physics visual representations: The case of the brief electricity and magnetism assessment", "abstract": "[This paper is part of the Focused Collection in Artificial Intelligence Tools in Physics Teaching and Physics Education Research.] Artificial intelligence-based chatbots are increasingly influencing physics education because of their ability to interpret and respond to textual and visual inputs. This study evaluates the performance of two large multimodal model-based chatbots, ChatGPT-4 and ChatGPT-4o, on the brief electricity and magnetism assessment (BEMA), a conceptual physics inventory rich in visual representations such as vector fields, circuit diagrams, and graphs. Quantitative analysis shows that ChatGPT-4o outperforms both ChatGPT-4 and a large sample of university students, and demonstrates improvements in ChatGPT-4o’s vision interpretation ability over its predecessor ChatGPT-4. However, qualitative analysis of ChatGPT-4o’s responses reveals persistent challenges. We identified three types of difficulties in the chatbot’s responses to tasks on BEMA: (i) difficulties with visual interpretation, (ii) difficulties in providing correct physics laws or rules, and (iii) difficulties with spatial coordination and application of physics representations. Spatial reasoning tasks, particularly those requiring the use of the right-hand rule, proved especially problematic. These findings highlight that the most broadly used large multimodal model-based chatbot, ChatGPT-4o, still exhibits significant difficulties in engaging with physics tasks involving visual representations. While the chatbot shows potential for educational applications, including personalized tutoring and accessibility support for students who are blind or have low vision, its limitations necessitate caution. On the other hand, our findings can also be leveraged to design assessments that are difficult for chatbots to solve.", "authors": ["Giulia Polverini", "J.-B. Melin", "Elias Önerud", "Bor Gregorcic"], "year": 2025, "venue": "Physical Review Physics Education Research", "cited_by_count": 5, "type": "preprint", "concepts": ["Magnetism", "Electricity", "Electromagnetism", "Physics", "Theoretical physics"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4210827551", "doi": "https://doi.org/10.1007/s10462-022-10144-1", "title": "A survey on sentiment analysis methods, applications, and challenges", "abstract": "", "authors": ["Mayur Wankhade", "Annavarapu Chandra Sekhara Rao", "Chaitanya Kulkarni"], "year": 2022, "venue": "Artificial Intelligence Review", "cited_by_count": 1306, "type": "article", "concepts": ["Computer science", "Sentiment analysis", "Data science", "Artificial intelligence"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2843010082", "doi": "https://doi.org/10.1093/jamia/ocy072", "title": "Conversational agents in healthcare: a systematic review", "abstract": "The protocol for this systematic review is registered at PROSPERO with the number CRD42017065917.", "authors": ["Liliana Laranjo", "Adam G. Dunn", "Huong Ly Tong", "A. Baki Kocaballı", "Jessica Chen", "Rabia Bashir", "Didi Surian", "Blanca Gallego", "Farah Magrabi", "Annie Lau", "Enrico Coiera"], "year": 2018, "venue": "Journal of the American Medical Informatics Association", "cited_by_count": 1214, "type": "review", "concepts": ["PsycINFO", "CINAHL", "Protocol (science)", "Computer science", "Randomized controlled trial"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2007557128", "doi": "https://doi.org/10.1523/jneurosci.5118-08.2009", "title": "Musical Training Shapes Structural Brain Development", "abstract": "The human brain has the remarkable capacity to alter in response to environmental demands. Training-induced structural brain changes have been demonstrated in the healthy adult human brain. However, no study has yet directly related structural brain changes to behavioral changes in the developing brain, addressing the question of whether structural brain differences seen in adults (comparing experts with matched controls) are a product of \"nature\" (via biological brain predispositions) or \"nurture\" (via early training). Long-term instrumental music training is an intense, multisensory, and motor experience and offers an ideal opportunity to study structural brain plasticity in the developing brain in correlation with behavioral changes induced by training. Here we demonstrate structural brain changes after only 15 months of musical training in early childhood, which were correlated with improvements in musically relevant motor and auditory skills. These findings shed light on brain plasticity and suggest that structural brain differences in adult experts (whether musicians or experts in other areas) are likely due to training-induced brain plasticity.", "authors": ["Krista L. Hyde", "Jason P. Lerch", "Andrea Norton", "Marie Forgeard", "Ellen Winner", "Alan C. Evans", "Gottfried Schlaug"], "year": 2009, "venue": "Journal of Neuroscience", "cited_by_count": 953, "type": "article", "concepts": ["Psychology", "Neuroplasticity", "Structural plasticity", "Nature versus nurture", "Human brain"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4393065402", "doi": "https://doi.org/10.1007/s11704-024-40231-1", "title": "A survey on large language model based autonomous agents", "abstract": "Abstract Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.", "authors": ["Lei Wang", "Chen Ma", "Xueyang Feng", "Zeyu Zhang", "Hao Yang", "Jingsen Zhang", "Zhiyuan Chen", "Jiakai Tang", "Xu Chen", "Yankai Lin", "Wayne Xin Zhao", "Zhewei Wei", "Ji-Rong Wen"], "year": 2024, "venue": "Frontiers of Computer Science", "cited_by_count": 836, "type": "article", "concepts": ["Computer science", "Artificial intelligence"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W3004493409", "doi": "https://doi.org/10.1002/widm.1356", "title": "Bias in data‐driven artificial intelligence systems—An introductory survey", "abstract": "Abstract Artificial Intelligence (AI)‐based systems are widely employed nowadays to make decisions that have far‐reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well‐grounded in a legal frame. In this survey, we focus on data‐driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth. This article is categorized under: Commercial, Legal, and Ethical Issues &gt; Fairness in Data Mining Commercial, Legal, and Ethical Issues &gt; Ethical Considerations Commercial, Legal, and Ethical Issues &gt; Legal Issues", "authors": ["Eirini Ntoutsi", "Pavlos Fafalios", "Ujwal Gadiraju", "Vasileios Iosifidis", "Wolfgang Nejdl", "María-Esther Vidal", "Salvatore Ruggieri", "Franco Turini", "Symeon Papadopoulos", "Emmanouil Krasanakis", "Ioannis Kompatsiaris", "Katharina Kinder‐Kurlanda", "Claudia Wagner", "Fariba Karimi", "Miriam Fernández", "Harith Alani", "Bettina Berendt", "Tina Kruegel", "Christian Heinze", "Klaus Broelemann", "Gjergji Kasneci", "Thanassis Tiropanis", "Steffen Staab"], "year": 2020, "venue": "Wiley Interdisciplinary Reviews Data Mining and Knowledge Discovery", "cited_by_count": 941, "type": "article", "concepts": ["Computer science", "Big data", "Artificial intelligence", "Software deployment", "Ethical issues"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W3176923149", "doi": "https://doi.org/10.1186/s40537-021-00492-0", "title": "Text Data Augmentation for Deep Learning", "abstract": "Natural Language Processing (NLP) is one of the most captivating applications of Deep Learning. In this survey, we consider how the Data Augmentation training strategy can aid in its development. We begin with the major motifs of Data Augmentation summarized into strengthening local decision boundaries, brute force training, causality and counterfactual examples, and the distinction between meaning and form. We follow these motifs with a concrete list of augmentation frameworks that have been developed for text data. Deep Learning generally struggles with the measurement of generalization and characterization of overfitting. We highlight studies that cover how augmentations can construct test sets for generalization. NLP is at an early stage in applying Data Augmentation compared to Computer Vision. We highlight the key differences and promising ideas that have yet to be tested in NLP. For the sake of practical implementation, we describe tools that facilitate Data Augmentation such as the use of consistency regularization, controllers, and offline and online augmentation pipelines, to preview a few. Finally, we discuss interesting topics around Data Augmentation in NLP such as task-specific augmentations, the use of prior knowledge in self-supervised learning versus Data Augmentation, intersections with transfer and multi-task learning, and ideas for AI-GAs (AI-Generating Algorithms). We hope this paper inspires further research interest in Text Data Augmentation.", "authors": ["Connor Shorten", "Taghi M. Khoshgoftaar", "Borko Furht"], "year": 2021, "venue": "Journal Of Big Data", "cited_by_count": 1636, "type": "article", "concepts": ["Computer science", "Computational Science and Engineering", "Deep learning", "Artificial intelligence", "Data science"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2067796135", "doi": "https://doi.org/10.1111/j.1540-4560.1967.tb00578.x", "title": "A Social Psychology of Bilingualism", "abstract": "The purpose of this research study was to expose EFL learners to the cultural aspects of English-speaking countries through the use of multimodal literacies in order to give them opportunities for increasing their cross-cultural awareness. Cross-cultural skills play a significant role in language learning. Previous research has discovered that including cross-cultural aspects in language teaching contributes to enhancing self-identity, citizenship, and respect for diverse lifestyles. Besides, it has been demonstrated that cultural traits that underlie the English language are associated to the way in which individuals construct meaning, but little attention has been given to the effects of semiotic elements in cross-cultural exposure specifically, through the use of multimodal literacies in contrasting tasks. The present qualitative action research study used questionnaires, journals, artifacts, and reflective logs to collect data for determining the effects of implementing multimodal literacies to enhance cross-cultural awareness in students with A1 level of proficiency according to the CEFR. Data were analyzed using the grounded theory, and it demonstrated that the students gained significant awareness of cultural patterns that are embedded in communicative interactions so that they made connections between foreign and own identities. This lends support to the notion those strategies should be more widely adopted by the educational community.", "authors": ["Wallace E. Lambert"], "year": 1967, "venue": "Journal of Social Issues", "cited_by_count": 831, "type": "article", "concepts": ["Neuroscience of multilingualism", "Citation", "Psychology", "Library science", "Computer science"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2963541336", "doi": "https://doi.org/10.18653/v1/d18-1167", "title": "TVQA: Localized, Compositional Video Question Answering", "abstract": "Recent years have witnessed an increasing interest in image-based question-answering (QA) tasks. However, due to data limitations, there has been much less work on video-based QA. In this paper, we present TVQA, a largescale video QA dataset based on 6 popular TV shows. TVQA consists of 152,545 QA pairs from 21,793 clips, spanning over 460 hours of video. Questions are designed to be compositional in nature, requiring systems to jointly localize relevant moments within a clip, comprehend subtitle-based dialogue, and recognize relevant visual concepts. We provide analyses of this new dataset as well as several baselines and a multi-stream end-to-end trainable neural network framework for the TVQA task.", "authors": ["Jie Lei", "Licheng Yu", "Mohit Bansal", "Tamara L. Berg"], "year": 2018, "venue": "", "cited_by_count": 517, "type": "article", "concepts": ["Computer science", "Question answering", "Subtitle", "Task (project management)", "CLIPS"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4211153864", "doi": "https://doi.org/10.1016/j.imavis.2008.11.007", "title": "Social signal processing: Survey of an emerging domain", "abstract": "", "authors": ["Alessandro Vinciarelli", "Maja Pantić", "Hervé Bourlard"], "year": 2008, "venue": "Image and Vision Computing", "cited_by_count": 796, "type": "article", "concepts": ["Social intelligence", "Set (abstract data type)", "Politeness", "Computer science", "Everyday life"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4406537084", "doi": "https://doi.org/10.3390/ijgi14010035", "title": "Towards AI-Assisted Mapmaking: Assessing the Capabilities of GPT-4o in Cartographic Design", "abstract": "Cartographic design is fundamental to effective mapmaking, requiring adherence to principles such as visual hierarchy, symbolization, and color theory to convey spatial information accurately and intuitively, while Artificial Intelligence (AI) and Large Language Models (LLMs) have transformed various fields, their application in cartographic design remains underexplored. This study assesses the capabilities of a multimodal advanced LLM, GPT-4o, in understanding and suggesting cartographic design elements, focusing on adherence to established cartographic principles. Two assessments were conducted: a text-to-text evaluation and an image-to-text evaluation. In the text-to-text assessment, GPT-4o was presented with 15 queries derived from key concepts in cartography, covering classification, symbolization, visual hierarchy, color theory, and typography. Each query was posed multiple times under different temperature settings to evaluate consistency and variability. In the image-to-text evaluation, GPT-4o analyzed maps containing deliberate cartographic errors to assess its ability to identify issues and suggest improvements. The results indicate that GPT-4o demonstrates general reliability in text-based tasks, with variability influenced by temperature settings. The model showed proficiency in classification and symbolization tasks but occasionally deviated from theoretical expectations. In visual hierarchy and layout, the model performed consistently, suggesting appropriate design choices. In the image-to-text assessment, GPT-4o effectively identified critical design flaws such as inappropriate color schemes, poor contrast and misuse of shape and size variables, offering actionable suggestions for improvement. However, limitations include dependency on input quality and challenges in interpreting nuanced spatial relationships. The study concludes that LLMs like GPT-4o have significant potential in cartographic design, particularly for tasks involving creative exploration and routine design support. Their ability to critique and generate cartographic elements positions them as valuable tools for enhancing human expertise. Further research is recommended to enhance their spatial reasoning capabilities and expand their use of visual variables beyond color, thereby improving their applicability in professional cartographic workflows.", "authors": ["Abdulkadir Memduhoğlu"], "year": 2025, "venue": "ISPRS International Journal of Geo-Information", "cited_by_count": 6, "type": "article", "concepts": ["Cartography", "Geography", "Computer science"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2913144876", "doi": "https://doi.org/10.1007/s10648-019-09465-5", "title": "Cognitive Architecture and Instructional Design: 20 Years Later", "abstract": "Cognitive load theory was introduced in the 1980s as an instructional design theory based on several uncontroversial aspects of human cognitive architecture. Our knowledge of many of the characteristics of working memory, long-term memory and the relations between them had been well-established for many decades prior to the introduction of the theory. Curiously, this knowledge had had a limited impact on the field of instructional design with most instructional design recommendations proceeding as though working memory and long-term memory did not exist. In contrast, cognitive load theory emphasised that all novel information first is processed by a capacity and duration limited working memory and then stored in an unlimited long-term memory for later use. Once information is stored in long-term memory, the capacity and duration limits of working memory disappear transforming our ability to function. By the late 1990s, sufficient data had been collected using the theory to warrant an extended analysis resulting in the publication of Sweller et al. (Educational Psychology Review, 10, 251–296, 1998). Extensive further theoretical and empirical work have been carried out since that time and this paper is an attempt to summarise the last 20 years of cognitive load theory and to sketch directions for future research.", "authors": ["John Sweller", "Jeroen J. G. van Merriënboer", "Fred Paas"], "year": 2019, "venue": "Educational Psychology Review", "cited_by_count": 1684, "type": "article", "concepts": ["Working memory", "Educational psychology", "Cognitive load", "Cognitive architecture", "Cognitive psychology"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W3153469116", "doi": "https://doi.org/10.18653/v1/2021.emnlp-main.595", "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning", "abstract": "Image captioning has conventionally relied on reference-based automatic evaluations, where machine captions are compared against captions written by humans. This is in contrast to the reference-free manner in which humans assess caption quality.", "authors": ["Jack Hessel", "Ari Holtzman", "Maxwell Forbes", "Ronan Le Bras", "Yejin Choi"], "year": 2021, "venue": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing", "cited_by_count": 827, "type": "article", "concepts": ["Closed captioning", "Computer science", "Metric (unit)", "Artificial intelligence", "Information retrieval"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2087392613", "doi": "https://doi.org/10.3758/brm.41.3.841", "title": "Coding gestural behavior with the NEUROGES-ELAN system", "abstract": "", "authors": ["Hedda Lausberg", "Han Sloetjes"], "year": 2009, "venue": "Behavior Research Methods", "cited_by_count": 598, "type": "article", "concepts": ["Gesture", "Computer science", "Annotation", "Coding (social sciences)", "Psycholinguistics"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2146246269", "doi": "https://doi.org/10.1146/annurev-neuro-062012-170325", "title": "Decoding Neural Representational Spaces Using Multivariate Pattern Analysis", "abstract": "A major challenge for systems neuroscience is to break the neural code. Computational algorithms for encoding information into neural activity and extracting information from measured activity afford understanding of how percepts, memories, thought, and knowledge are represented in patterns of brain activity. The past decade and a half has seen significant advances in the development of methods for decoding human neural activity, such as multivariate pattern classification, representational similarity analysis, hyperalignment, and stimulus-model-based encoding and decoding. This article reviews these advances and integrates neural decoding methods into a common framework organized around the concept of high-dimensional representational spaces.", "authors": ["James V. Haxby", "Andrew C. Connolly", "J. Swaroop Guntupalli"], "year": 2014, "venue": "Annual Review of Neuroscience", "cited_by_count": 811, "type": "review", "concepts": ["Neural decoding", "Decoding methods", "Computer science", "Stimulus (psychology)", "Encoding (memory)"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2119163516", "doi": "https://doi.org/10.3389/fnins.2012.00055", "title": "Review of the BCI Competition IV", "abstract": "The BCI competition IV stands in the tradition of prior BCI competitions that aim to provide high quality neuroscientific data for open access to the scientific community. As experienced already in prior competitions not only scientists from the narrow field of BCI compete, but scholars with a broad variety of backgrounds and nationalities. They include high specialists as well as students. The goals of all BCI competitions have always been to challenge with respect to novel paradigms and complex data. We report on the following challenges: (1) asynchronous data, (2) synthetic, (3) multi-class continuous data, (4) session-to-session transfer, (5) directionally modulated MEG, (6) finger movements recorded by ECoG. As after past competitions, our hope is that winning entries may enhance the analysis methods of future BCIs.", "authors": ["Michael Tangermann", "Klaus‐Robert Müller", "Ad Aertsen", "Niels Birbaumer", "Christoph Braun", "Clemens Brunner", "Robert Leeb", "Carsten Mehring", "Kai J. Miller", "Gernot Müller-Putz", "Guido Nolte", "Gert Pfurtscheller", "Hubert Preißl", "Gerwin Schalk", "Alois Schlögl", "Carmen Vidaurre", "Stephan Waldert", "Benjamin Blankertz"], "year": 2012, "venue": "Frontiers in Neuroscience", "cited_by_count": 1156, "type": "article", "concepts": ["Brain–computer interface", "Session (web analytics)", "Competition (biology)", "Asynchronous communication", "Computer science"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4360980141", "doi": "https://doi.org/10.1007/s10956-023-10039-y", "title": "Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence", "abstract": "Abstract The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.", "authors": ["Grant Cooper"], "year": 2023, "venue": "Journal of Science Education and Technology", "cited_by_count": 1060, "type": "article", "concepts": ["Transformative learning", "Science education", "Rubric", "Engineering ethics", "Narrative"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W3132191748", "doi": "https://doi.org/10.1109/jproc.2021.3060483", "title": "Explaining Deep Neural Networks and Beyond: A Review of Methods and Applications", "abstract": "With the broader and highly successful usage of machine learning (ML) in industry and the sciences, there has been a growing demand for explainable artificial intelligence (XAI). Interpretability and explanation methods for gaining a better understanding of the problem-solving abilities and strategies of nonlinear ML, in particular, deep neural networks, are, therefore, receiving increased attention. In this work, we aim to: 1) provide a timely overview of this active emerging field, with a focus on “post hoc” explanations, and explain its theoretical foundations; 2) put interpretability algorithms to a test both from a theory and comparative evaluation perspective using extensive simulations; 3) outline best practice aspects, i.e., how to best include interpretation methods into the standard usage of ML; and 4) demonstrate successful usage of XAI in a representative selection of application scenarios. Finally, we discuss challenges and possible future directions of this exciting foundational field of ML.", "authors": ["Wojciech Samek", "Grégoire Montavon", "Sebastian Lapuschkin", "Christopher J. Anders", "Klaus‐Robert Müller"], "year": 2021, "venue": "Proceedings of the IEEE", "cited_by_count": 1203, "type": "review", "concepts": ["Interpretability", "Artificial intelligence", "Computer science", "Machine learning", "Field (mathematics)"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2946165673", "doi": "https://doi.org/10.1109/access.2019.2916887", "title": "Deep Multimodal Representation Learning: A Survey", "abstract": "Multimodal representation learning, which aims to narrow the heterogeneity gap among different modalities, plays an indispensable role in the utilization of ubiquitous multimodal data. Due to the powerful representation ability with multiple levels of abstraction, deep learning-based multimodal representation learning has attracted much attention in recent years. In this paper, we provided a comprehensive survey on deep multimodal representation learning which has never been concentrated entirely. To facilitate the discussion on how the heterogeneity gap is narrowed, according to the underlying structures in which different modalities are integrated, we category deep multimodal representation learning methods into three frameworks: joint representation, coordinated representation, and encoder-decoder. Additionally, we review some typical models in this area ranging from conventional models to newly developed technologies. This paper highlights on the key issues of newly developed technologies, such as encoder-decoder model, generative adversarial networks, and attention mechanism in a multimodal representation learning perspective, which, to the best of our knowledge, have never been reviewed previously, even though they have become the major focuses of much contemporary research. For each framework or model, we discuss its basic structure, learning objective, application scenes, key issues, advantages, and disadvantages, such that both novel and experienced researchers can benefit from this survey. Finally, we suggest some important directions for future work.", "authors": ["Wenzhong Guo", "Jianwen Wang", "Shiping Wang"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 484, "type": "article", "concepts": ["Computer science", "Modalities", "Representation (politics)", "Multimodal learning", "Feature learning"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2604799547", "doi": "https://doi.org/10.1613/jair.5477", "title": "Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation", "abstract": "This paper surveys the current state of the art in Natural Language Generation (NLG), defined as the task of generating text or speech from non-linguistic input. A survey of NLG is timely in view of the changes that the field has undergone over the past two decades, especially in relation to new (usually data-driven) methods, as well as new applications of NLG technology. This survey therefore aims to (a) give an up-to-date synthesis of research on the core tasks in NLG and the architectures adopted in which such tasks are organised; (b) highlight a number of recent research topics that have arisen partly as a result of growing synergies between NLG and other areas of artificial intelligence; (c) draw attention to the challenges in NLG evaluation, relating them to similar challenges faced in other areas of NLP, with an emphasis on different evaluation methods and the relationships between them.", "authors": ["Albert Gatt", "Emiel Krahmer"], "year": 2018, "venue": "Journal of Artificial Intelligence Research", "cited_by_count": 740, "type": "article", "concepts": ["Natural language generation", "Computer science", "Core (optical fiber)", "Relation (database)", "Field (mathematics)"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W2155158173", "doi": "https://doi.org/10.3389/fnsys.2013.00031", "title": "The Ease of Language Understanding (ELU) model: theoretical, empirical, and clinical advances", "abstract": "Working memory is important for online language processing during conversation. We use it to maintain relevant information, to inhibit or ignore irrelevant information, and to attend to conversation selectively. Working memory helps us to keep track of and actively participate in conversation, including taking turns and following the gist. This paper examines the Ease of Language Understanding model (i.e., the ELU model, Rönnberg, 2003; Rönnberg et al., 2008) in light of new behavioral and neural findings concerning the role of working memory capacity (WMC) in uni-modal and bimodal language processing. The new ELU model is a meaning prediction system that depends on phonological and semantic interactions in rapid implicit and slower explicit processing mechanisms that both depend on WMC albeit in different ways. It is based on findings that address the relationship between WMC and (a) early attention processes in listening to speech, (b) signal processing in hearing aids and its effects on short-term memory, (c) inhibition of speech maskers and its effect on episodic long-term memory, (d) the effects of hearing impairment on episodic and semantic long-term memory, and finally, (e) listening effort. New predictions and clinical implications are outlined. Comparisons with other WMC and speech perception models are made.", "authors": ["Jer­ker Rönnberg", "Thomas Lunner", "Adriana A. Zekveld", "Patrik Sörqvist", "Henrik Danielsson", "Björn Lyxell", "Örjan Dahlström", "Carine Signoret", "Stefan Stenfelt", "M. Kathleen Pichora‐Fuller", "Mary Rudner"], "year": 2013, "venue": "Frontiers in Systems Neuroscience", "cited_by_count": 936, "type": "article", "concepts": ["Active listening", "Conversation", "Cognitive psychology", "Working memory", "Semantic memory"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4411023341", "doi": "https://doi.org/10.1016/j.aiia.2025.05.006", "title": "A review on enhancing agricultural intelligence with large language models", "abstract": "This paper systematically explores the application potential of large language models (LLMs) in the field of agricultural intelligence, focusing on key technologies and practical pathways. The study focuses on the adaptation of LLMs to agricultural knowledge, starting with foundational concepts such as architecture design, pre-training strategies, and fine-tuning techniques, to build a technical framework for knowledge integration in the agricultural domain. Using tools such as vector databases and knowledge graphs, the study enables the structured development of professional agricultural knowledge bases. Additionally, by combining multimodal learning and intelligent question-answering (Q&A) system design, it validates the application value of LLMs in agricultural knowledge services. Addressing core challenges in domain adaptation, including knowledge acquisition and integration, logical reasoning, multimodal data processing, agent collaboration, and dynamic knowledge updating, the paper proposes targeted solutions. The study further explores the innovative applications of LLMs in scenarios such as precision crop management and market dynamics analysis, providing theoretical support and technical pathways for the development of agricultural intelligence. Through the technological innovation of large language models and their deep integration with the agricultural sector, the intelligence level of agricultural production, decision-making, and services can be effectively enhanced. • LLMs adapt to agriculture via specialized architecture and fine-tuning techniques. • Knowledge integration uses vector databases and graphs for structured repositories. • Multimodal learning combines visual-language models for enhanced decision-making. • Intelligent Q&A systems deliver precise agricultural knowledge and decision support.", "authors": ["H.-X Li", "Huarui Wu", "Qiaoxing Li", "Chunjiang Zhao"], "year": 2025, "venue": "Artificial Intelligence in Agriculture", "cited_by_count": 4, "type": "review", "concepts": ["Agriculture", "Computer science", "Data science", "Natural language processing", "Geography"], "search_query": "large multimodal model tool use visual reasoning"}
{"openalex_id": "https://openalex.org/W4386065725", "doi": "https://doi.org/10.1109/cvpr52729.2023.00179", "title": "CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution", "abstract": "Learning continuous image representations is recently gaining popularity for image super-resolution (SR) because of its ability to reconstruct high-resolution images with arbitrary scales from low-resolution inputs. Existing methods mostly ensemble nearby features to predict the new pixel at any queried coordinate in the SR image. Such a local ensemble suffers from some limitations: i) it has no learnable parameters and it neglects the similarity of the visual features; ii) it has a limited receptive field and cannot ensemble relevant features in a large field which are important in an image. To address these issues, this paper proposes a continuous implicit attention-in-attention network, called CiaoSR. We explicitly design an implicit attention network to learn the ensemble weights for the nearby local features. Furthermore, we embed a scale-aware attention in this implicit attention network to exploit additional non-local information. Extensive experiments on benchmark datasets demonstrate CiaoSR significantly outperforms the existing single image SR methods with the same backbone. In addition, CiaoSR also achieves the state-of-the-art performance on the arbitrary-scale SR task. The effectiveness of the method is also demonstrated on the real-world SR setting. More importantly, CiaoSR can be flexibly integrated into any backbone to improve the SR performance.", "authors": ["Jiezhang Cao", "Qin Wang", "Yongqin Xian", "Yawei Li", "Bingbing Ni", "Zhiming Pi", "Kai Zhang", "Yulun Zhang", "Radu Timofte", "Luc Van Gool"], "year": 2023, "venue": "", "cited_by_count": 64, "type": "article", "concepts": ["Computer science", "Image (mathematics)", "Attention network", "Scale (ratio)", "Artificial intelligence"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2963031226", "doi": "https://doi.org/10.1109/cvpr.2019.00167", "title": "Meta-SR: A Magnification-Arbitrary Network for Super-Resolution", "abstract": "Recent research on super-resolution has achieved great success due to the development of deep convolutional neural networks (DCNNs). However, super-resolution of arbitrary scale factor has been ignored for a long time. Most previous researchers regard super-resolution of differentscale factors as independent tasks. They train a specific model for each scale factor which is inefficient in computing, and prior work only take the super-resolution of several integer scale factors into consideration. In this work,we propose a novel method called Meta-SR to firstly solve super-resolution of arbitrary scale factor (including non-integer scale factors) with a single model. In our Meta-SR,the Meta-Upscale Module is proposed to replace the traditional upscale module. For arbitrary scale factor, the Meta-Upscale Module dynamically predicts the weights of the up-scale filters by taking the scale factor as input and use these weights to generate the HR image of arbitrary size. For any low-resolution image, our Meta-SR can continuously zoomin it with arbitrary scale factor by only using a single model.We evaluated the proposed method through extensive experiments on widely used benchmark datasets on single image super-resolution. The experimental results show the superiority of our Meta-Upscale.", "authors": ["Xuecai Hu", "Haoyuan Mu", "Xiangyu Zhang", "Zilei Wang", "Tieniu Tan", "Jian Sun"], "year": 2019, "venue": "", "cited_by_count": 478, "type": "article", "concepts": ["Benchmark (surveying)", "Convolutional neural network", "Magnification", "Scale factor (cosmology)", "Computer science"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4402753921", "doi": "https://doi.org/10.1109/cvpr52733.2024.00293", "title": "Continuous Optical Zooming: A Benchmark for Arbitrary-Scale Image Super-Resolution in Real World", "abstract": "Most current arbitrary-scale image super-resolution (SR) methods has commonly relied on simulated data generated by simple synthetic degradation models (e.g., bicubic down-sampling) at continuous various scales, thereby falling short in capturing the complex degradation of real-world images. This limitation hinders the visual quality of these methods when applied to real-world images. To address this issue, we propose the Continuous Optical Zooming dataset (COZ), by constructing an automatic imaging system to collect images at fine-grained various focal lengths within a specific range and providing strict image pair alignment. The COZ dataset serves as a benchmark to provide real-world data for training and testing arbitrary-scale SR models. To enhance the model's robustness against real-world image degradation, we propose a Local Mix Implicit network (LMI) based on the MLP-mixer architecture and meta-learning, which directly learns the local texture information by simultaneously mixing features and coordinates of multiple independent points. The extensive experiments demonstrate the superior performance of the arbitrary-scale SR models trained on the COZ dataset compared to models trained on simulated data. Our LMI model exhibits the superior effectiveness compared to other models. This study is of great significance in developing more efficient algorithms and improving the performance of arbitrary-scale image SR methods in practical applications. Our dataset and codes are available at https://github.com/pf0607/COZ.", "authors": ["Huiyuan Fu", "Fei Peng", "Xianwei Li", "Yejun Li", "Xin Wang", "Huadóng Ma"], "year": 2024, "venue": "", "cited_by_count": 9, "type": "article", "concepts": ["Zoom", "Benchmark (surveying)", "Scale (ratio)", "Computer science", "Image (mathematics)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4362063345", "doi": "https://doi.org/10.3390/rs15071827", "title": "Combining Discrete and Continuous Representation: Scale-Arbitrary Super-Resolution for Satellite Images", "abstract": "The advancements in image super-resolution technology have led to its widespread use in remote sensing applications. However, there is currently a lack of a general solution for the reconstruction of satellite images at arbitrary resolutions. The existing scale-arbitrary super-resolution methods are primarily predicated on learning either a discrete representation (DR) or a continuous representation (CR) of the image, with DR retaining the sensitivity to resolution and CR guaranteeing the generalization of the model. In this paper, we propose a novel image representation that combines the discrete and continuous representation, known as CDCR, which enables the extension of images to any desired resolution in a plug-and-play manner. CDCR consists of two components: a CR-based dense prediction that gathers more available information and a DR-based resolution-specific refinement that adjusts the predicted values of local pixels. Furthermore, we introduce a scale cumulative ascent (SCA) method, which enhances the performance of the dense prediction and improves the accuracy of the generated images at ultra-high magnifications. The efficacy and dependability of CDCR are substantiated by extensive experiments conducted on multiple remote sensing datasets, providing strong support for scenarios that require accurate images.", "authors": ["Tai An", "Chunlei Huo", "Shiming Xiang", "Chunhong Pan"], "year": 2023, "venue": "Remote Sensing", "cited_by_count": 6, "type": "article", "concepts": ["Computer science", "Representation (politics)", "Generalization", "Pixel", "Scale (ratio)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W3214047808", "doi": "https://doi.org/10.1109/cvpr52688.2022.00197", "title": "Local Texture Estimator for Implicit Representation Function", "abstract": "Recent works with an implicit neural function shed light on representing images in arbitrary resolution. However, a standalone multi-layer perceptron shows limited performance in learning high-frequency components. In this paper, we propose a Local Texture Estimator (LTE), a dominant-frequency estimator for natural images, enabling an implicit function to capture fine details while reconstructing images in a continuous manner. When jointly trained with a deep super-resolution (SR) architecture, LTE is capable of characterizing image textures in 2D Fourier space. We show that an LTE-based neuralfunction achieves favorable performance against existing deep SR methods within an arbitrary-scale factor. Furthermore, we demonstrate that our implementation takes the shortest running time compared to previous works.", "authors": ["Jaewon Lee", "Kyong Hwan Jin"], "year": 2022, "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "cited_by_count": 183, "type": "article", "concepts": ["Estimator", "Computer science", "Function (biology)", "Artificial intelligence", "Representation (politics)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2972373240", "doi": "https://doi.org/10.1007/978-3-030-30493-5_48", "title": "Hypernetwork Functional Image Representation", "abstract": "", "authors": ["Sylwester Klocek", "Łukasz Maziarka", "Maciej Wołczyk", "Jacek Tabor", "Jakub Nowak", "Marek Śmieja"], "year": 2019, "venue": "Lecture notes in computer science", "cited_by_count": 66, "type": "book-chapter", "concepts": ["Computer science", "Representation (politics)", "Image (mathematics)", "Artificial intelligence", "Pixel"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4386065378", "doi": "https://doi.org/10.1109/cvpr52729.2023.01750", "title": "Super-Resolution Neural Operator", "abstract": "We propose Super-resolution Neural Operator (SRNO), a deep operator learning framework that can resolve high-resolution (HR) images at arbitrary scales from the low-resolution (LR) counterparts. Treating the LR-HR image pairs as continuous functions approximated with different grid sizes, SRNO learns the mapping between the corresponding function spaces. From the perspective of approximation theory, SRNO first embeds the LR input into a higher-dimensional latent representation space, trying to capture sufficient basis functions, and then iteratively approximates the implicit image function with a kernel integral mechanism, followed by a final dimensionality reduction step to generate the RGB representation at the target coordinates. The key characteristics distinguishing SRNO from prior continuous SR works are: 1) the kernel integral in each layer is efficiently implemented via the Galerkin-type attention, which possesses non-local properties in the spatial domain and therefore benefits the grid-free continuum; and 2) the multilayer attention architecture allows for the dynamic latent basis update, which is crucial for SR problems to “hallucinate” high-frequency information from the LR image. Experiments show that SRNO outperforms existing continuous SR methods in terms of both accuracy and running time. Our code is at https://github.com/2y7c3/Super-Resolution-Neural-Operator.", "authors": ["Min Wei", "Xuesong Zhang"], "year": 2023, "venue": "", "cited_by_count": 58, "type": "article", "concepts": ["Computer science", "Operator (biology)", "Resolution (logic)", "Artificial intelligence", "Artificial neural network"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W3214116240", "doi": "https://doi.org/10.48550/arxiv.2112.06174", "title": "Implicit Transformer Network for Screen Content Image Continuous Super-Resolution", "abstract": "Nowadays, there is an explosive growth of screen contents due to the wide application of screen sharing, remote cooperation, and online education. To match the limited terminal bandwidth, high-resolution (HR) screen contents may be downsampled and compressed. At the receiver side, the super-resolution (SR) of low-resolution (LR) screen content images (SCIs) is highly demanded by the HR display or by the users to zoom in for detail observation. However, image SR methods mostly designed for natural images do not generalize well for SCIs due to the very different image characteristics as well as the requirement of SCI browsing at arbitrary scales. To this end, we propose a novel Implicit Transformer Super-Resolution Network (ITSRN) for SCISR. For high-quality continuous SR at arbitrary ratios, pixel values at query coordinates are inferred from image features at key coordinates by the proposed implicit transformer and an implicit position encoding scheme is proposed to aggregate similar neighboring pixel values to the query one. We construct benchmark SCI1K and SCI1K-compression datasets with LR and HR SCI pairs. Extensive experiments show that the proposed ITSRN significantly outperforms several competitive continuous and discrete SR methods for both compressed and uncompressed SCIs.", "authors": ["Jingyu Yang", "Sheng Shen", "Huanjing Yue", "Kun Li"], "year": 2021, "venue": "arXiv (Cornell University)", "cited_by_count": 32, "type": "preprint", "concepts": ["Computer science", "Zoom", "Uncompressed video", "Computer vision", "Transformer"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W3137005722", "doi": "https://doi.org/10.48550/arxiv.2103.12716", "title": "UltraSR: Spatial Encoding is a Missing Key for Implicit Image Function-based Arbitrary-Scale Super-Resolution", "abstract": "The recent success of NeRF and other related implicit neural representation methods has opened a new path for continuous image representation, where pixel values no longer need to be looked up from stored discrete 2D arrays but can be inferred from neural network models on a continuous spatial domain. Although the recent work LIIF has demonstrated that such novel approaches can achieve good performance on the arbitrary-scale super-resolution task, their upscaled images frequently show structural distortion due to the inaccurate prediction of high-frequency textures. In this work, we propose UltraSR, a simple yet effective new network design based on implicit image functions in which we deeply integrated spatial coordinates and periodic encoding with the implicit neural representation. Through extensive experiments and ablation studies, we show that spatial encoding is a missing key toward the next-stage high-performing implicit image function. Our UltraSR sets new state-of-the-art performance on the DIV2K benchmark under all super-resolution scales compared to previous state-of-the-art methods. UltraSR also achieves superior performance on other standard benchmark datasets in which it outperforms prior works in almost all experiments.", "authors": ["Xingqian Xu", "Zhangyang Wang", "Humphrey Shi"], "year": 2021, "venue": "arXiv (Cornell University)", "cited_by_count": 39, "type": "preprint", "concepts": ["Encoding (memory)", "Benchmark (surveying)", "Computer science", "Representation (politics)", "Image (mathematics)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4402733583", "doi": "https://doi.org/10.1109/cvpr52733.2024.00879", "title": "Arbitrary-Scale Image Generation and Upsampling Using Latent Diffusion Model and Implicit Neural Decoder", "abstract": "Super-resolution (SR) and image generation are important tasks in computer vision and are widely adopted in real-world applications. Most existing methods, however, generate images only at fixed-scale magnification and suffer from over-smoothing and artifacts. Additionally, they do not offer enough diversity of output images nor image consistency at different scales. Most relevant work applied Implicit Neural Representation (INR) to the denoising diffusion model to obtain continuous-resolution yet diverse and high-quality SR results. Since this model operates in the image space, the larger the resolution of image is produced, the more memory and inference time is required, and it also does not maintain scale-specific consistency. We propose a novel pipeline that can super-resolve an input image or generate from a random noise a novel image at arbitrary scales. The method consists of a pre-trained auto-encoder, a latent diffusion model, and an implicit neural decoder, and their learning strategies. The proposed method adopts diffusion processes in a latent space, thus efficient, yet aligned with output image space decoded by MLPs at arbitrary scales. More specifically, our arbitrary-scale decoder is designed by the symmetric decoder w/o up-scaling from the pre-trained auto-encoder, and Local Implicit Image Function (LIIF) in series. The latent diffusion process is learnt by the denoising and the alignment losses jointly. Errors in output images are backpropagated via the fixed decoder, improving the quality of output images. In the extensive experiments using multiple public benchmarks on the two tasks i.e. image super-resolution and novel image generation at arbitrary scales, the proposed method outperforms relevant methods in metrics of image quality, diversity and scale consistency. It is significantly better than the relevant prior-art in the inference speed and memory usage.", "authors": ["Jinseok Kim", "Tae-Kyun Kim"], "year": 2024, "venue": "", "cited_by_count": 25, "type": "article", "concepts": ["Upsampling", "Computer science", "Scale (ratio)", "Image (mathematics)", "Artificial intelligence"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2274287116", "doi": "https://doi.org/10.1609/aaai.v31i1.11231", "title": "Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning", "abstract": "Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.", "authors": ["Christian Szegedy", "Sergey Ioffe", "Vincent Vanhoucke", "Alexander A. Alemi"], "year": 2017, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 4483, "type": "article", "concepts": ["Residual", "Residual neural network", "Computer science", "Margin (machine learning)", "Artificial intelligence"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4390872795", "doi": "https://doi.org/10.1109/iccv51070.2023.01937", "title": "CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image Arbitrary-Scale Super Resolution", "abstract": "Medical image arbitrary-scale super-resolution (MIASSR) has recently gained widespread attention, aiming to supersample medical volumes at arbitrary scales via a single model. However, existing MIASSR methods face two major limitations: (i) reliance on high-resolution (HR) volumes and (ii) limited generalization ability, which restricts their applications in various scenarios. To overcome these limitations, we propose Cube-based Neural Radiance Field (CuNeRF), a zero-shot MIASSR framework that is able to yield medical images at arbitrary scales and free viewpoints in a continuous domain. Unlike existing MISR methods that only fit the mapping between low-resolution (LR) and HR volumes, CuNeRF focuses on building a continuous volumetric representation from each LR volume without the knowledge of the corresponding HR one. This is achieved by the proposed differentiable modules: cube-based sampling, isotropic volume rendering, and cube-based hierarchical rendering. Through extensive experiments on magnetic resource imaging (MRI) and computed tomography (CT) modalities, we demonstrate that CuNeRF can synthesize high-quality SR medical images, which outperforms state-of-the-art MISR methods, achieving better visual verisimilitude and fewer objectionable artifacts. Compared to existing MISR methods, our CuNeRF is more applicable in practice.", "authors": ["Zixuan Chen", "Lingxiao Yang", "Jianhuang Lai", "Xiaohua Xie"], "year": 2023, "venue": "", "cited_by_count": 29, "type": "article", "concepts": ["Computer science", "Rendering (computer graphics)", "Cube (algebra)", "Volume rendering", "Artificial intelligence"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W1970333790", "doi": "https://doi.org/10.1190/1.1893867", "title": "Iterative depth migration by backward time propagation", "abstract": "PreviousNext No AccessSEG Technical Program Expanded Abstracts 1983Iterative depth migration by backward time propagationAuthors: N. D. WhitmoreN. D. WhitmoreAmoco Production Co.https://doi.org/10.1190/1.1893867 SectionsAboutPDF/ePub ToolsAdd to favoritesDownload CitationsTrack CitationsPermissions ShareFacebookTwitterLinked InReddit Permalink: https://doi.org/10.1190/1.1893867FiguresReferencesRelatedDetailsCited byQ-compensated wavefield depth extrapolation-based migration using a viscoacoustic wave equationJiachun You, Wei Liu, Xingguo Huang, Yajuan Xue, and Junxing Cao5 December 2023 | GEOPHYSICS, Vol. 89, No. 1Deep learning framework for true amplitude imaging: Effect of conditioners and initial models28 July 2022 | Geophysical Prospecting, Vol. 72, No. 1Multi-image, reverse time, and Kirchhoff migrations with compact Green's functionsCarlos Cunha, Gerson Ritter, Alexandre Sardinha, Bruno Pereira Dias, Claudio Guerra, Fernanda Thedy, Nelson Hargreaves, and Rodrigo Coacci12 December 2023 | GEOPHYSICS, Vol. 89, No. 1Improvement of inverse scattering angle-domain common image gathers using optical flowAmmir A. Karsou, Sérgio L. E. F. da Silva, Felipe V. Capuzzo, Felipe T. Costa, Jorge Lopez, Roger M. Moreira, and Marco Cetale14 December 2023Acoustic approximation VTI reverse-time migration using pseudo-depth mapping methodXinwen Zhang, Jianping Huang, and Zhenchun Li14 December 2023Multiparameter least‐squares reverse time migration using the viscoacoustic‐wave equation17 October 2023 | Geophysical Prospecting, Vol. 85Vector-based seismic decomposition by reverse time methodsRussian Journal of Earth SciencesViscoacoustic One-Way Fourier Finite Difference Propagator Based on Time Fractional Viscoacoustic Wave Equation16 July 2023 | Pure and Applied Geophysics, Vol. 180, No. 8Cased-hole reverse time migration imaging using ultrasonic pitch-catch measurement: Theory and synthetic case studiesHua Wang, Meng Li, Zhilong Fang, Shaopeng Shi, Tianlin Liu, and Aihua Tao22 May 2023 | GEOPHYSICS, Vol. 88, No. 4An efficient low-frequency artifact suppression method at excitation time for excitation amplitude imaging condition5 December 2022 | Acta Geophysica, Vol. 71, No. 3Anisotropic elastic least-squares reverse time migration with density variations in vertical transverse isotropic media12 May 2023 | Acta Geophysica, Vol. 78Crosscorrelation-based Marchenko imaging with an optimal apertureXiaochun Chen, Yezheng Hu, Yukai Wo, Xuri Huang, Yubo Yue, Weiping Cao, and Kang Chen4 May 2023 | GEOPHYSICS, Vol. 88, No. 3Least-squares reverse time migration with shifted total variation regularizationToktam Zand, Hasan Ghasemzadeh, Ali Gholami, and Alison Malcolm13 March 2023 | GEOPHYSICS, Vol. 88, No. 2Three-dimensional elastic reverse-time migration using a high-order temporal and spatial staggered-grid finite-difference scheme26 January 2023 | Frontiers in Earth Science, Vol. 11Stress tensor double dot product imaging condition for elastic reverse time migration24 January 2023 | Geophysical Prospecting, Vol. 42Pseudo-depth domain reverse time migration in VTI medium based on GPU parallel strategy12 January 2023 | Frontiers in Earth Science, Vol. 10Least-Squares Full-Wavefield Reverse Time Migration Using a Modeling Engine With Vector ReflectivityIEEE Transactions on Geoscience and Remote Sensing, Vol. 61Least-Squares Reverse Time Migration Using the Inverse Scattering Imaging ConditionIEEE Transactions on Geoscience and Remote Sensing, Vol. 61Plane Wave Reverse Time Image for Nondestructive TestsIEEE Access, Vol. 11Velocity-Adaptive Irregular Point Spread Function Deconvolution Imaging Using X-Shaped Denoising Diffusion FilteringIEEE Transactions on Geoscience and Remote Sensing, Vol. 61LsmGANs: Image-Domain Least-Squares Migration Using a New Framework of Generative Adversarial NetworksIEEE Transactions on Geoscience and Remote Sensing, Vol. 61Reverse Time Migration of Ground Penetrating Radar With Optimized Full Wavefield Separation Based on Poynting Vector Imaging Condition and TV-L1-Based Artifacts SuppressionIEEE Transactions on Geoscience and Remote Sensing, Vol. 61A new elastic least-squares reverse-time migration method based on the new gradient equations9 August 2022 | Acta Geophysica, Vol. 70, No. 6Decomposition and Properties of the Traveltime Sensitivity Kernels in Transversely Isotropic Elastic Media10 December 2022 | Minerals, Vol. 12, No. 12Least-squares reverse time migration via deep learning-based updating operatorsKristian Torres and Mauricio Sacchi22 September 2022 | GEOPHYSICS, Vol. 87, No. 6Frequency Domain Q-Compensated Reverse Time Migration Using Anti-Dispersion Acoustic Equation31 January 2023 | Russian Journal of Nondestructive Testing, Vol. 58, No. 11High‐Resolution Fault‐Rupture Imaging by Combining a Backprojection Method With Binarized MUSIC Spectral Image Calculation24 November 2022 | Journal of Geophysical Research: Solid Earth, Vol. 127, No. 11Exploiting temporal data reuse and asynchrony in the reverse time migration3 October 2022 | The International Journal of High Performance Computing Applications, Vol. 4Seismic imaging uncertainty using deep learning predicted Green's functionsHan Liu, Anar Yusifov, Muhong Zhou, and Linda Hodgson8 August 2022Fast Gauss-Newton full-wavefield migrationSiamak Abolhassani and Eric Verschuur15 August 2022Least-squares RTM with shifted total variation regularization for depth imaging of sparse short-offset seismic dataToktam Zand, Andrzej Gorszczyk, Ali Gholami, Hasan Ghasemzadeh, and Alison Malcolm15 August 2022Reverse-time migration of mobile marine vibrator dataKhalid Almuteri, Paul Sava, and Jeffrey Shragge15 August 2022A High-Precision Elastic Reverse-Time Migration for Complex Geologic Structure Imaging in Applied Geophysics24 July 2022 | Remote Sensing, Vol. 14, No. 15Efficient wavefield separation by reformulation of two-way wave-equation depth-extrapolation schemeJiachun You, Naide Pan, Wei Liu, and Junxing Cao1 June 2022 | GEOPHYSICS, Vol. 87, No. 4Salt Tectonic Modeling Using Reverse Time Migration Imaging and Sensitivity Kernel Wavelength Analysis27 January 2022 | Surveys in Geophysics, Vol. 43, No. 3Adaptive Feedback Convolutional‐Neural‐Network‐Based High‐Resolution Reflection‐Waveform Inversion22 June 2022 | Journal of Geophysical Research: Solid Earth, Vol. 127, No. 6Least-squares reverse time migration with a multiplicative Cauchy constraintGang Yao, Bo Wu, Nuno V. da Silva, Henry A. Debens, Di Wu, and Jingjie Cao26 April 2022 | GEOPHYSICS, Vol. 87, No. 3Reverse Time Migration of Time‐Lapse Walkaway VSP Data for Monitoring CO 2 Injection at the SACROC CO 2 ‐EOR Field11 March 2022Reproduction wavefield reverse time migration22 March 2021 | Exploration Geophysics, Vol. 53, No. 2Reverse time migration with an exact two-way illumination compensationYuzhu Liu, Weigang Liu, Zheng Wu, and Jizhong Yang10 February 2022 | GEOPHYSICS, Vol. 87, No. 2Source-Free P-SV Converted-Wave Reverse-Time Migration Using First-Order Velocity-Dilatation-Rotation Equations27 January 2022 | Frontiers in Earth Science, Vol. 10Approximating the Gauss–Newton Hessian Using a Space-Wavenumber Filter and its Applications in Least-Squares Seismic ImagingIEEE Transactions on Geoscience and Remote Sensing, Vol. 60Topography-Dependent Q -Compensated Least-Squares Reverse Time Migration of Prismatic WavesIEEE Transactions on Geoscience and Remote Sensing, Vol. 60Data-driven prestack-waveform inversion using genetic algorithm: Methodology and examplesLingxiao Jia, Subhashis Mallick, and Cheng Wang7 September 2021 | Interpretation, Vol. 9, No. 4Elastic least-squares reverse time migration based on decoupled wave equationsYu Zhong, Hanming Gu, Yangting Liu, and QingHui Mao27 September 2021 | GEOPHYSICS, Vol. 86, No. 6Mitigating Velocity Errors in Least-Squares Imaging Using Angle-Dependent Forward and Adjoint Gaussian Beam Operators15 November 2021 | Surveys in Geophysics, Vol. 42, No. 6Angle-Weighted Reverse Time Migration With Wavefield Decomposition Based on the Optical Flow Vector27 October 2021 | Frontiers in Earth Science, Vol. 9Efficient snapshot-free reverse time migration and computation of multiparameter gradients in full-waveform inversionJohan O. A. Robertsson, Fredrik Andersson, and René-Édouard Plessix27 July 2021 | GEOPHYSICS, Vol. 86, No. 5Subbasalt Marchenko imaging with offshore Brazil field dataXueyi Jia, Anatoly Baumstein, Charlie Jing, Erik Neumann, and Roel Snieder18 August 2021 | GEOPHYSICS, Vol. 86, No. 5Full wavefield least-squares reverse time migrationMikhail Davydenko and Eric Verschuur31 August 2021 | GEOPHYSICS, Vol. 86, No. 5A spatially constrained divisive hierarchical k-means clustering to capture prior features from migration velocity model to build training model set for deep-learning LSRTMYulang Wu, George A. McMechan, and Yanfei Wang1 September 2021Variable density acoustic RTM of VSP data based on the time–space domain LS-based SFD method12 June 2021 | Acta Geophysica, Vol. 69, No. 4True amplitude depth migration using curveletsHamideh Sanavi, Peyman P. Moghaddam, and Felix J. Herrmann12 July 2021 | GEOPHYSICS, Vol. 86, No. 4Frequency-Domain Common Image Gathers for Quickly Checking the Accuracy of Migration Velocity30 June 2021 | Frontiers in Earth Science, Vol. 9Simultaneous joint migration inversion with calendar-time constraints as a processing tool for semi-continuous surveysShan Qu and Eric Verschuur8 April 2021 | GEOPHYSICS, Vol. 86, No. 3A high-efficiency wavefield decomposition method based on the Hilbert transformXuebao Guo, Ying Shi, Weihong Wang, Xuan Ke, Hong Liu, and Shumin Chen8 April 2021 | GEOPHYSICS, Vol. 86, No. 3Influence Of Array Parameters On Defect Imaging In Plate By Modified RTM MethodModel parameterizations in the time-domain multi-parameter acoustic least-squares reverse time migration8 February 2021 | Acta Geophysica, Vol. 69, No. 2Improvement of RTM image with a de-primary algorithm and impedance-matching technique22 July 2020 | Exploration Geophysics, Vol. 52, No. 2Suppressing residual low-frequency noise in VSP reverse time migration by combining wavefield decomposition imaging condition with Poynting vector filtering6 October 2020 | Exploration Geophysics, Vol. 52, No. 2Minibatch least-squares reverse time migration in a deep-learning frameworkJanaki Vamaraju, Jeremy Vila, Mauricio Araya-Polo, Debanjan Datta, Mohamed Sidahmed, and Mrinal K. Sen9 February 2021 | GEOPHYSICS, Vol. 86, No. 2Combination of the common reflection surface-based prestack data regularization and reverse time migration: Application to real land dataGerman Garabito, Paul L. Stoffa, Yuri S. F. Bezerra, and João L. Caldeira15 February 2021 | GEOPHYSICS, Vol. 86, No. 2Target-oriented reverse time migration in transverse isotropy media4 February 2021 | Acta Geophysica, Vol. 69, No. 1Flank-preserving deprimary reverse time migrationYimin Sun and Tong W. Fei16 December 2020 | GEOPHYSICS, Vol. 86, No. 1Mesh-free radial-basis-function-generated finite differences and their application in reverse time migrationHan Wu, Chengyu Sun, Shizhong Li, Jie Tang, and Ning Xu11 January 2021 | GEOPHYSICS, Vol. 86, No. 1Source-domain full-waveform inversionsYulang Wu and George A. McMechan21 January 2021 | GEOPHYSICS, Vol. 86, No. 1Seismic Imaging, Overview27 May 2021Least-squares reverse time migration with sparse regularization in the 2D wavelet domainFeipeng Li, Jinghuai Gao, Zhaoqi Gao, Xiudi Jiang, and Wenbo Sun13 October 2020 | GEOPHYSICS, Vol. 85, No. 6A weighted Runge-Kutta discontinuous Galerkin method for reverse time migrationChujun Qiu, Dinghui Yang, Xijun He, and Jingshuang Li21 October 2020 | GEOPHYSICS, Vol. 85, No. 6Prestack reverse time imaging in tunnels based on the decoupled nonconversion elastic-wave equationYuxiao Ren, Zhichao Yang, Bin Liu, Xinji Xu, and Yangkang Chen21 October 2020 | GEOPHYSICS, Vol. 85, No. 6Full-wave-equation depth extrapolation for migration using matrix multiplicationJiachun You and Junxing Cao10 November 2020 | GEOPHYSICS, Vol. 85, No. 6An efficient super-virtual shot encoding scheme for multisource reverse time migrationXiaofeng Jia, Wenyang Chen, and Bin Chen23 November 2020 | GEOPHYSICS, Vol. 85, No. 6Multifrequency beam-based migration in inhomogeneous media using windowed Fourier transform frames3 August 2020 | Geophysical Journal International, Vol. 223, No. 2Time‐domain sparsity promoting least‐squares reverse time migration with source estimation24 September 2020 | Geophysical Prospecting, Vol. 68, No. 9Efficient Acoustic Wave Equation Modeling in TTI Media26 October 2020Up/Down Image Separation in Elastic Reverse Time Migration20 May 2020 | Pure and Applied Geophysics, Vol. 177, No. 10Data- and model-domain up/down wave separation for reverse-time migration with free-surface multiples18 June 2020 | Geophysical Journal International, Vol. 223, No. 1Including internal multiples from the estimated image in least-squares reverse-time migrationMikhail Davydenko and Eric Verschuur30 September 2020Seismic imaging with weighted stacking of common-image gathersRongrong Lin, Hao Hu, and Yingcai Zheng30 September 2020Improving the image quality of elastic reverse-time migration in the dip-angle domain using deep learningYongming Lu, Hui Sun, Xiaoyi Wang, Qiancheng Liu, and Hao Zhang23 July 2020 | GEOPHYSICS, Vol. 85, No. 5Three-dimensional angle-domain double-square-root migration in VTI media for the large-scale wide-azimuth seismic data1 June 2020 | Acta Geophysica, Vol. 68, No. 4Data‐driven retrieval of primary plane‐wave responses28 May 2020 | Geophysical Prospecting, Vol. 68, No. 6Consensus optimization of total variation–based reverse time migration3 April 2020 | Computational Geosciences, Vol. 24, No. 3Elastic reverse-time migration in irregular tunnel environment based on polar coordinates25 September 2020 | Applied Geophysics, Vol. 17, No. 2Reverse time migration imaging of tunnels via the finite element method using an unstructured mesh25 September 2020 | Applied Geophysics, Vol. 17, No. 2Seismic surveying and imaging at the laboratory scale: A framework to cross-validate experiments and simulations for a salt-body environmentBence Solymosi, Nathalie Favretto-Cristini, Vadim Monteiller, Paul Cristini, Bjørn Ursin, and Dimitri Komatitsch4 March 2020 | GEOPHYSICS, Vol. 85, No. 3A review on reflection-waveform inversion18 March 2020 | Petroleum Science, Vol. 17, No. 2Fast least-squares reverse time migration via a superposition of Kronecker productsWenlei Gao, Gian Matharu, and Mauricio D. Sacchi12 February 2020 | GEOPHYSICS, Vol. 85, No. 2Fast Single-Step Least-Squares Reverse-Time Imaging via Adaptive Matching Filters in BeamsIEEE Transactions on Geoscience and Remote Sensing, Vol. 58, No. 3Seismic Imaging, Overview22 January 2020Single-Step Data-Domain Least-Squares Reverse-Time Migration Using Gabor Deconvolution for Subsalt ImagingIEEE Geoscience and Remote Sensing Letters, Vol. 17, No. 1Analysis of direction-decomposed and vector-based elastic reverse time migration using the Hilbert transformTing Hu, Hong Liu, Xuebao Guo, Yuxin Yuan, and Zhiyang Wang28 October 2019 | GEOPHYSICS, Vol. 84, No. 6Depth Imaging of Complex Geological Structures using the RTM Technique in Order to Reduce Exploration Costs28 October 2019A causal imaging condition for reverse time migration using the Discrete Hilbert transform and its efficient implementation on GPU29 August 2019 | Journal of Geophysics and Engineering, Vol. 16, No. 5Comparison between Born and Kirchhoff operators for least-squares reverse time migration and the constraint of the propagation of the background wavefieldKai Yang and Jianfeng Zhang12 August 2019 | GEOPHYSICS, Vol. 84, No. 5Compressive least-squares migration with on-the-fly Fourier transformsPhilipp A. Witte, Mathias Louboutin, Fabio Luporini, Gerard J. Gorman, and Felix J. Herrmann8 August 2019 | GEOPHYSICS, Vol. 84, No. 5Efficient wavefield reconstruction at half the Nyquist rateAli Gholami, Alan Richardson, Toktam Zand, and Alison Malcolm8 August 2019 | GEOPHYSICS, Vol. 84, No. 5Reverse Time Migration of Seismic Forward-Prospecting Data in Tunnels Based on Beamforming Methods4 March 2019 | Rock Mechanics and Rock Engineering, Vol. 52, No. 9Energy Flow Domain Reverse-Time Migration for Borehole RadarIEEE Transactions on Geoscience and Remote Sensing, Vol. 57, No. 9Pure P- and S-wave elastic reverse time migration with adjoint state method imaging conditionJorge E. Monsegny and Daniel O. Trad10 August 2019Low frequency artifact attenuation of reverse-time-migration through anisotropic tensorZhaolin Zhu and Danping Cao10 August 2019Simple, efficient hybrid domain common image gatherC. Shin, T. Ha, and S. Ko10 August 2019Event-driven workflows for large-scale seismic imaging in the cloudPhilipp A. Witte, Mathias Louboutin, Henryk Modzelewski, Charles Jones, James Selvage, and Felix J. Herrmann10 August 2019Reverse time migration as the transpose of forward operator by rapid expansion method (REM)Reynam C. Pestana and Daniel Revelo10 August 2019WEMVA based on source to image point offsetsMark Roberts10 August 2019Kirchhoff approximation based least-squares reverse time migration for subsalt imagingKai Yang and Jianfeng Zhang10 August 2019Curvilinear finite-difference method for wavefield propagation with surface topographyWei Dai, Zhen Xu, Xin Cheng, Kun Jiao, and Denes Vigh10 August 2019Unsupervised physics-based neural networks for seismic migrationJanaki Vamaraju and Mrinal K. Sen17 July 2019 | Interpretation, Vol. 7, No. 3Finite element reverse time migration imaging in tunnels using an unstructured mesh16 July 2019 | Applied Geophysics, Vol. 23Q-compensated reverse time migration in viscoacoustic media including surface topographyYingming Qu and Jinli Li26 April 2019 | GEOPHYSICS, Vol. 84, No. 4Migration-based filtering: Applications to geophysical imaging dataJianjian Huo, Binzhong Zhou, Qing Zhao, Iain M. Mason, and Ying Rao26 April 2019 | GEOPHYSICS, Vol. 84, No. 4A Wave-field Decomposition for Reverse Time Migration to Reduce the Low-wavenumber ArtifactImaging a crack in a thin plate by reverse time migration with dispersive flexural wavesWave Motion, Vol. 89Reverse Time Migration in Euclidean and Riemannian coordinates10 May 2019 | CT&F - Ciencia, Tecnología y Futuro, Vol. 9, No. 1Prestack elastic RTM for VTI media using vector wavefield decomposition and vector imaging conditions12 May 2019 | Exploration Geophysics, Vol. 50, No. 3Imaging vertical interfaces using acoustic time reversalSatyan Singh and Andrew Curtis11 March 2019 | GEOPHYSICS, Vol. 84, No. 3Dip-angle image gather computation using the Poynting vector in elastic reverse time migration and their application for noise suppressionQiancheng Liu26 March 2019 | GEOPHYSICS, Vol. 84, No. 3Performance and stability of the double absorbing boundary method for acoustic-wave propagationToby Potter, Jeffrey Shragge, and David Lumley21 February 2019 | GEOPHYSICS, Vol. 84, No. 2Reverse time migration via frequency-adaptive multiscale spatial gridsYongchae Cho and Richard L. Gibson, Jr.4 February 2019 | GEOPHYSICS, Vol. 84, No. 2Surface Imaging Functions for Elastic Reverse Time Migration21 March 2019 | Journal of Geophysical Research: Solid Earth, Vol. 124, No. 3Source-free converted-wave reverse time migration: Formulation and limitationsYue Du, Yunyue Elita Li, Jizhong Yang, Arthur Cheng, and Xinding Fang4 December 2018 | GEOPHYSICS, Vol. 84, No. 1Distributed-Memory Load Balancing With Cyclic Token-Based Work-Stealing Applied to Reverse Time MigrationIEEE Access, Vol. 7Green's theorem in seismic imaging across the scales11 April 2019 | Solid Earth, Vol. 10, No. 2Selected-aperture imaging of walkaway VSP reverse time migrationXuan Ke and Ying Shi14 December 2018Acceleration and Applications of Anisotropic Reverse time migrationPengfei Duan, Degang Jin, Hong Liu, Long Wang, and Guangming He11 December 2018Fast plane-wave reverse time migrationXiongwen Wang, Xu Ji, Hongwei Liu, and Yi Luo24 October 2018 | GEOPHYSICS, Vol. 83, No. 6Efficient dip‐angle angle‐domain common‐image gather estimation using Poynting vector in acoustic reverse time migration and its application in noise suppression23 October 2018 | Geophysical Prospecting, Vol. 66, No. 9A stable approach for Q-compensated viscoelastic reverse time migration using excitation amplitude imaging conditionXuebin Zhao, Hui Zhou, Yufeng Wang, Hanming Chen, Zheng Zhou, Pengyuan Sun, and Jianlei Zhang29 August 2018 | GEOPHYSICS, Vol. 83, No. 5Time-domain least-squares Gaussian beam migration with L1 regularizationJidong Yang and Hejun Zhu27 August 2018An efficient 3D reverse time migration in vertical time-domain based on optimal operator boundary storage strategyPeiran Duan, Bingluo Gu, and Zhenchun Li27 August 2018Reverse-time migration via frequency-adaptive multiscale spatial gridsYongchae Cho and Richard L. Gibson, Jr.27 August 2018A new correlation based least-squares reverse time migrationFeipeng Li, Jinghuai Gao, Xiudi Jiang, and Wenbo Sun27 August 2018Extension of the common image gathers by VPRTM methodGennady Erokhin, Aleksandr Danilin, and Maksim Kozlov27 August 2018Effects of wrong adjoints for RTM in TTI mediaMathias Louboutin, Philipp Witte, and Felix J. Herrmann27 August imaging condition for elastic reverse time Zhang, Du, and August time migration with Yang, Liu, Xu, and August 2018A finite-difference approach for in isotropic and and Hejun June 2018 | GEOPHYSICS, Vol. 83, No. least-squares reverse time and Daniel July 2018 | GEOPHYSICS, Vol. 83, No. 4True amplitude in reverse time extrapolation of and Wu and George A. April 2018 | GEOPHYSICS, Vol. 83, No. of reverse-time migration using March 2018 | Geophysical Prospecting, Vol. 66, No. using finite November | Computational Geosciences, Vol. No. Reverse Time Migration Using Imaging March Q in viscoelastic media by least-squares reverse time and George A. January 2018 | GEOPHYSICS, Vol. 83, No. of imaging for December | Geophysical Journal International, Vol. No. velocity and wave-equation depth migration in an A case from the and J. November | Interpretation, Vol. No. time for the acoustic wave October | Geophysical Journal International, Vol. No. June finite-difference elastic-wave extrapolation based on the Du, Zhao, Guo, Pengyuan Sun, Jianlei Zhang, and November | GEOPHYSICS, Vol. 83, No. elastic reverse time migration and angle-domain common-image gathers with wavefield decomposition of P- and and George A. November | GEOPHYSICS, Vol. 83, No. acoustic least-squares two-way wave-equation migration with exact adjoint Xu and Mauricio D. November | GEOPHYSICS, Vol. 83, No. 1Seismic January 2018An in wavefield extrapolation and imaging condition to reverse time migration Ali and August | GEOPHYSICS, Vol. No. plane‐wave February | Geophysical Prospecting, Vol. No. and their and seismic April | Geophysical Prospecting, Vol. No. source vector with Fourier transform to gathers from reverse time migration in and George A. August | GEOPHYSICS, Vol. No. on and its in and August | GEOPHYSICS, Vol. No. least-squares reverse time migration via elastic full-waveform inversion with and Mauricio D. July | GEOPHYSICS, Vol. No. February 2018 | Journal of Geophysics, Vol. No. vector image New for of Erokhin, Aleksandr Danilin, Maksim and August reverse time migration using multiscale forward Richard L. Gibson, and August prestack inversion and acoustic reverse time Jia, Subhashis Mallick, and August reverse time migration using wavefield decomposition based on Hilbert Wang, Xue, and Xu August for imaging with Green's Singh and Roel May | GEOPHYSICS, Vol. No. time migration of migration using the wavefield decomposition imaging Wang, Xue, Xu Tong W. and Yi May | GEOPHYSICS, Vol. No. March to Poynting for gathers from reverse time Tang, George A. McMechan, and Wang7 February | GEOPHYSICS, Vol. No. elastic reverse time migration based on imaging Du, Guo, Zhao, Wang, and February | GEOPHYSICS, Vol. No. wavefield separation based on the February | GEOPHYSICS, Vol. No. image via August | Geophysical Prospecting, Vol. No. migration from using unstructured August | Geophysical Prospecting, Vol. No. and imaging for deep of Vol. No. Migration and of June June and inversion for media using a July | Geophysical Prospecting, Vol. No. reverse time migration in the of density Yang, Liu, and October | GEOPHYSICS, Vol. No. of Elastic Reverse-Time Migration Using an December | Acta Geophysica, Vol. No. wave propagation in isotropic September | GEOPHYSICS, Vol. No. 5Comparison of viscoacoustic for Q-compensated reverse time Guo, George A. McMechan, and July | GEOPHYSICS, Vol. No. in imaging using a 3D RTM Li, and September migration method for for imaging and at the and James Liu, Wu, Lin, and September the model through the wave Paul Sava, and September for imaging with Green's Singh and September Geophysics September Migration September wavefield with optical for elastic angle-domain common-image D. and George A. May | GEOPHYSICS, Vol. No. least-squares reverse time migration using wave Sun, and June | GEOPHYSICS, Vol. No. 4An efficient for least-squares reverse time Liu, Xu, and May | GEOPHYSICS, Vol. No. of up/down acoustic reverse time migration Wang, George A. McMechan, and May | GEOPHYSICS, Vol. No. the source from the reverse-time migration using a Geosciences, Vol. imaging of Vol. No. by acoustic time and April | GEOPHYSICS, Vol. No. of reverse time migration using the reverse time migration noise September | Geophysical", "authors": ["N. D. Whitmore"], "year": 1983, "venue": "", "cited_by_count": 567, "type": "article", "concepts": ["Computer science"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2793369479", "doi": "https://doi.org/10.1038/nature26160", "title": "Unconventional superconductivity in magic-angle graphene superlattices", "abstract": "", "authors": ["Yuan Cao", "Valla Fatemi", "Shiang Fang", "Kenji Watanabe", "Takashi Taniguchi", "Efthimios Kaxiras", "Pablo Jarillo‐Herrero"], "year": 2018, "venue": "Nature", "cited_by_count": 7958, "type": "article", "concepts": ["Condensed matter physics", "Superconductivity", "Superlattice", "Bilayer graphene", "Physics"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4390893614", "doi": "https://doi.org/10.1016/j.compbiomed.2024.108003", "title": "Arbitrary scale super-resolution diffusion model for brain MRI images", "abstract": "", "authors": ["Zhitao Han", "Wenhui Huang"], "year": 2024, "venue": "Computers in Biology and Medicine", "cited_by_count": 18, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Smoothing", "Scale (ratio)", "Weighting"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4319300019", "doi": "https://doi.org/10.1109/wacv56688.2023.00491", "title": "Single Image Super-Resolution via a Dual Interactive Implicit Neural Network", "abstract": "In this paper, we introduce a novel implicit neural network for the task of single image super-resolution at arbitrary scale factors. To do this, we represent an image as a decoding function that maps locations in the image along with their associated features to their reciprocal pixel attributes. Since the pixel locations are continuous in this representation, our method can refer to any location in an image of varying resolution. To retrieve an image of a particular resolution, we apply a decoding function to a grid of locations each of which refers to the center of a pixel in the output image. In contrast to other techniques, our dual interactive neural network decouples content and positional features. As a result, we obtain a fully implicit representation of the image that solves the super-resolution problem at (real-valued) elective scales using a single model. We demonstrate the efficacy and flexibility of our approach against the state of the art on publicly available benchmark datasets.", "authors": ["Quan Nguyen", "William J. Beksi"], "year": 2023, "venue": "2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)", "cited_by_count": 21, "type": "article", "concepts": ["Computer science", "Pixel", "Artificial intelligence", "Decoding methods", "Image (mathematics)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W1988849934", "doi": "https://doi.org/10.1137/1011036", "title": "Convergence Conditions for Ascent Methods", "abstract": "Previous article Next article Convergence Conditions for Ascent MethodsPhilip WolfePhilip Wolfehttps://doi.org/10.1137/1011036PDFBibTexSections ToolsAdd to favoritesExport CitationTrack CitationsEmail SectionsAboutAbstractLiberal conditions on the steps of a “descent” method for finding extrema of a function are given; most known results are special cases.[1] Haskell B. Curry, The method of steepest descent for non-linear minimization problems, Quart. Appl. Math., 2 (1944), 258–261 MR0010667 0061.26801 CrossrefGoogle Scholar[2] Augustine Cauchy, Méthode générale pour la résolution des systèmes d'équations simultanées, C.R. Acad. Sci., 25 (1847), 536–538 Google Scholar[3] A. A. Goldstein, Minimizing functionals on normed-linear spaces, SIAM J. Control, 4 (1966), 81–89 10.1137/0304008 MR0196900 0147.12701 LinkGoogle Scholar[4] A. A. Goldstein, Cauchy's method of minimization, Numer. Math., 4 (1962), 146–150 10.1007/BF01386306 MR0141222 0105.10201 CrossrefGoogle Scholar[5] Alexander Ostrowski, Solution of equations and systems of equations, Second edition. Pure and Applied Mathematics, Vol. 9, Academic Press, New York, 1966xiv+338 MR0216746 0222.65070 Google Scholar[6] G. Zoutehdijk, 1967, Private communication Google Scholar[7] R. Fletcher and , C. M. Reeves, Function minimization by conjugate gradients, Comput. J., 7 (1964), 149–154 10.1093/comjnl/7.2.149 MR0187375 0132.11701 CrossrefISIGoogle Scholar[8] W. Oettli, 1967, Private communication Google Scholar[9] L. V. Kantorovich and , G. P. Akilov, Functional analysis in normed spaces, Translated from the Russian by D. E. Brown. Edited by A. P. Robertson. International Series of Monographs in Pure and Applied Mathematics, Vol. 46, The Macmillan Co., New York, 1964xiii+771, Chap. 15 MR0213845 0127.06104 Google Scholar[10] Hirotugu Akaike, On a successive transformation of probability distribution and its application to the analysis of the optimum gradient method, Ann. Inst. Statist. Math. Tokyo, 11 (1959), 1–16 10.1007/BF01831719 MR0107973 0100.14002 CrossrefISIGoogle Scholar[11] R. Fletcher and , M. J. D. Powell, A rapidly convergent descent method for minimization, Comput. J., 6 (1963/1964), 163–168 MR0152116 0132.11603 CrossrefISIGoogle Scholar[12] M. J. Box, A comparison of several current optimization methods, and the use of transformations in constrained problems, Comput. J., 9 (1966), 67–77 MR0192645 0146.13304 CrossrefISIGoogle Scholar[13] Donald M. Topkis and , Arthur F. Veinott, on the convergence of some feasible direction algorithms for nonlinear programming, J. SIAM control, 5 (1967), 268–274 10.1137/0305018 0158.18805 LinkGoogle Scholar[14] Philip Wolfe, on the convergence of gradient methods under constraints, Rep., RZ-204, IBM watson research center, yorktown heights, new york, 1966 Google Scholar Previous article Next article FiguresRelatedReferencesCited ByDetails Two efficient modifications of AZPRP conjugate gradient method with sufficient descent propertyJournal of Inequalities and Applications, Vol. 2022, No. 1 | 10 January 2022 Cross Ref Optimal Transport Based Seismic Inversion:Beyond Cycle SkippingCommunications on Pure and Applied Mathematics, Vol. 75, No. 10 | 1 April 2021 Cross Ref A robust BFGS algorithm for unconstrained nonlinear optimization problemsOptimization, Vol. 17 | 19 September 2022 Cross Ref Two Methods for the Implicit Integration of Stiff Reaction SystemsComputational Methods in Applied Mathematics, Vol. 0, No. 0 | 14 September 2022 Cross Ref Simple and fast convergent procedure to estimate recursive path analysis modelBehaviormetrika, Vol. 107 | 6 September 2022 Cross Ref Adaptive three-term PRP algorithms without gradient Lipschitz continuity condition for nonconvex functionsNumerical Algorithms, Vol. 91, No. 1 | 20 January 2022 Cross Ref A Hybrid Stochastic Deterministic Algorithm for Solving Unconstrained Optimization ProblemsMathematics, Vol. 10, No. 17 | 23 August 2022 Cross Ref Pseudospectral methods and iterative solvers for optimization problems from multiscale particle dynamicsBIT Numerical Mathematics, Vol. 48 | 11 August 2022 Cross Ref An outlier-resistant κ -generalized approach for robust physical parameter estimationPhysica A: Statistical Mechanics and its Applications, Vol. 600 | 1 Aug 2022 Cross Ref An Active Set Trust-Region Method for Bound-Constrained OptimizationBulletin of the Iranian Mathematical Society, Vol. 48, No. 4 | 27 July 2021 Cross Ref Advancing Three-Dimensional Coupled Water Quality Model of Marine Ranches: Model Development, Global Sensitivity Analysis, and Optimization Based on Observation SystemJournal of Marine Science and Engineering, Vol. 10, No. 8 | 27 July 2022 Cross Ref Robust regression against heavy heterogeneous contaminationMetrika, Vol. 16 | 1 July 2022 Cross Ref A new class of nonlinear conjugate gradient coefficients for unconstrained optimizationAsian-European Journal of Mathematics, Vol. 15, No. 07 | 14 October 2021 Cross Ref New iterative conjugate gradient method for nonlinear unconstrained optimizationRAIRO - Operations Research, Vol. 56, No. 4 | 29 July 2022 Cross Ref Optimizing Oblique Projections for Nonlinear Systems using TrajectoriesSamuel E. Otto, Alberto Padovan, and Clarence W. RowleySIAM Journal on Scientific Computing, Vol. 44, No. 3 | 24 June 2022AbstractPDF (2764 KB)Variational methods for finding periodic orbits in the incompressible Navier–Stokes equationsJournal of Fluid Mechanics, Vol. 941 | 26 April 2022 Cross Ref LMBOPT: a limited memory method for bound-constrained optimizationMathematical Programming Computation, Vol. 14, No. 2 | 10 January 2022 Cross Ref Accelerated memory-less SR1 method with generalized secant equation for unconstrained optimizationCalcolo, Vol. 59, No. 2 | 11 March 2022 Cross Ref DiffPoseNet: Direct Differentiable Camera Pose Estimation2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) | 1 Jun 2022 Cross Ref A modified secant equation quasi-Newton method for unconstrained optimizationJournal of Applied Mathematics and Computing, Vol. 30 | 31 May 2022 Cross Ref Coupled support tensor machine classification for multimodal neuroimaging dataStatistical Analysis and Data Mining: The ASA Data Science Journal, Vol. 10 | 23 May 2022 Cross Ref A new hybrid conjugate gradient method of unconstrained optimization methodsAsian-European Journal of Mathematics, Vol. 15, No. 04 | 18 June 2021 Cross Ref A link between the steepest descent method and fixed-point iterationsOptimization Letters, Vol. 69 | 18 March 2022 Cross Ref A hybrid-line-and-curve search globalization technique for inexact Newton methodsApplied Numerical Mathematics, Vol. 173 | 1 Mar 2022 Cross Ref Development and Evaluation of Geometry Optimization Algorithms in Conjunction with ANI PotentialsJournal of Chemical Theory and Computation, Vol. 18, No. 2 | 12 January 2022 Cross Ref Nonlinear System Identification: Learning While Respecting Physical Models Using a Sequential Monte Carlo MethodIEEE Control Systems, Vol. 42, No. 1 | 1 Feb 2022 Cross Ref Visual analytics for nonlinear programming in robot motion planningJournal of Visualization, Vol. 25, No. 1 | 13 September 2021 Cross Ref Elastic wave full-waveform inversion in the time domain by the trust region methodJournal of Applied Geophysics, Vol. 197 | 1 Feb 2022 Cross Ref Adjoint Waveform Tomography of South AmericaJournal of Geophysical Research: Solid Earth, Vol. 127, No. 2 | 27 January 2022 Cross Ref A conjugate gradient algorithm based on double parameter scaled Broyden–Fletcher–Goldfarb–Shanno update for optimization problems and image restorationNeural Computing and Applications, Vol. 34, No. 1 | 13 August 2021 Cross Ref In-line viscosity identification via thermal-rheological measurements in an annular duct for polymer processingInternational Journal of Heat and Mass Transfer, Vol. 182 | 1 Jan 2022 Cross Ref Regularized elastic full-waveform inversion using deep learningAdvances in Subsurface Data Analytics | 1 Jan 2022 Cross Ref Nonlinear Optimization: A Brief OverviewNumerical Infinities and Infinitesimals in Optimization | 6 July 2022 Cross Ref Leveraging Joint-Diagonalization in Transform-Learning NMFIEEE Transactions on Signal Processing, Vol. 70 | 1 Jan 2022 Cross Ref Backtracking Gradient Descent Method and Some Applications in Large Scale Optimisation. Part 2: Algorithms and ExperimentsApplied Mathematics & Optimization, Vol. 84, No. 3 | 6 September 2020 Cross Ref Optical diffraction tomography from single-molecule localization microscopyOptics Communications, Vol. 499 | 1 Nov 2021 Cross Ref Constrained neural network training and its application to hyperelastic material modelingComputational Mechanics, Vol. 68, No. 5 | 3 August 2021 Cross Ref The Human Lumbar Spine During High-Rate Under Seat Loading: A Combined Metric Injury CriteriaAnnals of Biomedical Engineering, Vol. 49, No. 11 | 23 July 2021 Cross Ref Rayleigh Wave Dispersion Spectrum Inversion Across ScalesSurveys in Geophysics, Vol. 42, No. 6 | 19 October 2021 Cross Ref Pre-conditioned BFGS-based uncertainty quantification in elastic full-waveform inversionGeophysical Journal International, Vol. 228, No. 2 | 21 September 2021 Cross Ref Neural network method for solving parabolic two-temperature microscale heat conduction in double-layered thin films exposed to ultrashort-pulsed lasersInternational Journal of Heat and Mass Transfer, Vol. 178 | 1 Oct 2021 Cross Ref New hyrid conjugate gradient method as a convex combination of HZ and CD methodsAsian-European Journal of Mathematics, Vol. 14, No. 10 | 6 March 2021 Cross Ref Parallel Dislocation Model Implementation for Earthquake Source Parameter Estimation on Multi-Threaded GPUApplied Sciences, Vol. 11, No. 20 | 11 October 2021 Cross Ref Extended full waveform inversion with matching filterGeophysical Prospecting, Vol. 69, No. 7 | 24 June 2021 Cross Ref Full-waveform Inversion Based on q-Laplace DistributionPure and Applied Geophysics, Vol. 178, No. 9 | 24 August 2021 Cross Ref Modifications of Hestenes and Stiefel CG Method for Solving Unconstrained Optimization Problems2021 7th International Conference on Contemporary Information Technology and Mathematics (ICCITM) | 25 Aug 2021 Cross Ref A note on memory-less SR1 and memory-less BFGS methods for large-scale unconstrained optimizationNumerical Algorithms, Vol. 11 | 17 August 2021 Cross Ref A Descent Four-Term Conjugate Gradient Method with Global Convergence Properties for Large-Scale Unconstrained Optimisation ProblemsMathematical Problems in Engineering, Vol. 2021 | 14 Aug 2021 Cross Ref A modified conjugate gradient-based Elman neural networkCognitive Systems Research, Vol. 68 | 1 Aug 2021 Cross Ref On the estimation of destructive cure rate model: A new study with exponentially weighted Poisson competing risksStatistica Neerlandica, Vol. 75, No. 3 | 2 March 2021 Cross Ref A Modified Liu and Storey Conjugate Gradient Method for Large Scale Unconstrained Optimization ProblemsAlgorithms, Vol. 14, No. 8 | 28 July 2021 Cross Ref Robust parameter estimation based on the generalized log-likelihood in the context of Sharma-Taneja-Mittal measurePhysical Review E, Vol. 104, No. 2 | 6 August 2021 Cross Ref Geodesic density regression for correcting 4DCT pulmonary respiratory motion artifactsMedical Image Analysis, Vol. 72 | 1 Aug 2021 Cross Ref Optimisation of Parameters in a German Bight Circulation Model by 4DVAR Assimilation of Current and Water Level ObservationsFrontiers in Marine Science, Vol. 8 | 29 July 2021 Cross Ref ASLR: An Adaptive Scheduler for Learning Rate2021 International Joint Conference on Neural Networks (IJCNN) | 18 Jul 2021 Cross Ref A Convex Combination between Two Different Search Directions of Conjugate Gradient Method and Application in Image RestorationMathematical Problems in Engineering, Vol. 2021 | 13 Jul 2021 Cross Ref An Adaptive Three-Term Conjugate Gradient Method with Sufficient Descent Condition and Conjugacy ConditionJournal of the Operations Research Society of China, Vol. 9, No. 2 | 12 July 2019 Cross Ref Direct Energy Minimization Based on Exponential Transformation in Density Functional Calculations of Finite and Extended SystemsComputer Physics Communications | 1 Jun 2021 Cross Ref A new three-term spectral conjugate gradient algorithm with higher numerical performance for solving large scale optimization problems based on Quasi-Newton equationInternational Journal of Modeling, Simulation, and Scientific Computing | 31 May 2021 Cross Ref Robust approaches for inverse problems based on Tsallis and Kaniadakis generalised statisticsThe European Physical Journal Plus, Vol. 136, No. 5 | 11 May 2021 Cross Ref Stochastic quasi-Newton with line-search regularisationAutomatica, Vol. 127 | 1 May 2021 Cross Ref An Efficient Modified AZPRP Conjugate Gradient Method for Large-Scale Unconstrained Optimization ProblemJournal of Mathematics, Vol. 2021 | 26 Apr 2021 Cross Ref A new hybrid conjugate gradient algorithm as a convex combination of MMWU and RMIL nonlinear problemsJournal of Interdisciplinary Mathematics, Vol. 24, No. 3 | 18 March 2021 Cross Ref Estimation of discrete choice models with hybrid stochastic adaptive batch size algorithmsJournal of Choice Modelling, Vol. 38 | 1 Mar 2021 Cross Ref A Modified Descent Spectral Conjugate Gradient Method for Unconstrained OptimizationIranian Journal of Science and Technology, Transactions A: Science, Vol. 45, No. 1 | 31 October 2020 Cross Ref QSSR Modeling of Bacillus Subtilis Lipase A Peptide Collision Cross-Sections in Ion Mobility Spectrometry: Local Descriptor Versus Global DescriptorThe Protein Journal, Vol. 40, No. 1 | 16 January 2021 Cross Ref Numerical optimization of a multiphysics calculation scheme based on partial convergenceAnnals of Nuclear Energy, Vol. 151 | 1 Feb 2021 Cross Ref A new accelerated diagonal quasi-Newton updating method with scaled forward finite differences directional derivative for unconstrained optimizationOptimization, Vol. 70, No. 2 | 16 January 2020 Cross Ref A Three-Term Gradient Descent Method with Subspace TechniquesMathematical Problems in Engineering, Vol. 2021 | 7 Jan 2021 Cross Ref Implementing and modifying Broyden class updates for large scale optimizationComputational Optimization and Applications, Vol. 78, No. 1 | 9 November 2020 Cross Ref Set-point optimization in wind farms to mitigate effects of flow blockage induced by atmospheric gravity wavesWind Energy Science, Vol. 6, No. 1 | 5 February 2021 Cross Ref Statistics and Numerical MethodsPattern Recognition, Tracking and Vertex Reconstruction in Particle Detectors | 23 November 2020 Cross Ref A training algorithm with selectable search direction for complex-valued feedforward neural networksNeural Networks, Vol. 40 | 1 Jan 2021 Cross Ref A decent three term conjugate gradient method with global convergence properties for large scale unconstrained optimization problemsAIMS Mathematics, Vol. 6, No. 10 | 1 Jan 2021 Cross Ref Adaptive Learning Rate and Momentum for Training Deep Neural NetworksMachine Learning and Knowledge Discovery in Databases. Research Track | 11 September 2021 Cross Ref A Quasi‐Newton Reformulated Geostatistical Approach on Reduced Dimensions for Large‐Dimensional Inverse ProblemsWater Resources Research, Vol. 57, No. 1 | 22 January 2021 Cross Ref Manifold Optimization for High-Accuracy Spatial Location Estimation Using Ultrasound WavesIEEE Transactions on Signal Processing, Vol. 69 | 1 Jan 2021 Cross Ref Basic Descent MethodsLinear and Nonlinear Programming | 20 August 2021 Cross Ref Taking the 4D Nature of fMRI Data Into Account Promises Significant Gains in Data CompletionIEEE Access, Vol. 9 | 1 Jan 2021 Cross Ref Approaching the full configuration interaction ground state from an arbitrary wavefunction with gradient descent and quasi-Newton algorithmsThe Journal of Chemical Physics, Vol. 153, No. 23 | 21 Dec 2020 Cross Ref Customized Federated Learning for accelerated edge computing with heterogeneous task targetsComputer Networks, Vol. 183 | 1 Dec 2020 Cross Ref Hybrid Riemannian conjugate gradient methods with global convergence propertiesComputational Optimization and Applications, Vol. 77, No. 3 | 5 September 2020 Cross Ref A one-parameter class of three-term conjugate gradient methods with an adaptive parameter choiceOptimization Methods and Software, Vol. 35, No. 6 | 13 September 2018 Cross Ref Gaussian Process Regression for Maximum Entropy DistributionJournal of Computational Physics, Vol. 418 | 1 Oct 2020 Cross Ref A new non-linear conjugate gradient algorithm for destructive cure rate model and a simulation study: illustration with negative binomial competing risksCommunications in Statistics - Simulation and Computation, Vol. 6 | 10 September 2020 Cross Ref A double parameter self-scaling memoryless BFGS method for unconstrained optimizationComputational and Applied Mathematics, Vol. 39, No. 3 | 2 June 2020 Cross Ref Adaptive type-2 neural fuzzy sliding mode control of a class of nonlinear systemsNonlinear Dynamics, Vol. 101, No. 4 | 18 August 2020 Cross Ref A modified nonlinear Polak–Ribière–Polyak conjugate gradient method with sufficient descent propertyCalcolo, Vol. 57, No. 3 | 26 August 2020 Cross Ref Semi-discrete optimal transport: a solution procedure for the unsquared Euclidean distance caseMathematical Methods of Operations Research, Vol. 92, No. 1 | 12 February 2020 Cross Ref Probing depth and lateral variations of upper-mantle seismic anisotropy from full-waveform inversion of teleseismic body-wavesGeophysical Journal International, Vol. 222, No. 1 | 20 April 2020 Cross Ref High-resolution reservoir characterization using deep learning-aided elastic full-waveform inversion: The North Sea field data exampleGEOPHYSICS, Vol. 85, No. 4 | 8 May 2020 Cross Ref Estimation of Beta-Pareto Distribution Based on Several Optimization MethodsMathematics, Vol. 8, No. 7 | 1 July 2020 Cross Ref Multi‐parameter reflection waveform inversion for acoustic transversely isotropic media with a vertical symmetry axisGeophysical Prospecting, Vol. 68, No. 6 | 17 June 2020 Cross Ref The application of nonlinear least-squares estimation algorithms in atmospheric density model calibrationAircraft Engineering and Aerospace Technology, Vol. 92, No. 7 | 20 May 2020 Cross Ref Decreasing the uncertainty of analysis using numerical algorithms robust to and of Scientific Vol. 91, No. 6 | 1 Jun 2020 Cross Ref An Efficient Three-Term Method for Models in Regression Vol. 8, No. 6 | 15 June 2020 Cross Ref of the by Finite for Unconstrained of Optimization Theory and Applications, Vol. No. 3 | 10 May 2020 Cross Ref New conjugate gradient algorithms based on self-scaling memoryless Broyden–Fletcher–Goldfarb–Shanno Vol. 57, No. 2 | 18 May 2020 Cross Ref A class of convergent three-term conjugate gradient methodsApplied Numerical Mathematics, Vol. 151 | 1 May 2020 Cross Ref A neural Conjugate gradient algorithm and its convergence Sciences, Vol. | 1 May 2020 Cross Ref Three-Dimensional Regularized A from the Vol. 10, No. 5 | 22 May 2020 Cross Ref On Quasi‐Newton methods in fast Journal for Numerical Methods in Engineering, Vol. No. 8 | 23 2019 Cross Ref Some three-term conjugate gradient methods with the new direction Numerical Mathematics, Vol. | 1 Apr 2020 Cross Ref Analysis of the gradient method with an search on a class of convex Methods and Software, Vol. 35, No. 2 | 9 October 2019 Cross Ref search methods for global of Mathematics and Vol. No. | 27 August 2019 Cross Ref Adaptive Control of a Using a Neural Journal for Science and Engineering, Vol. 45, No. 3 | 21 January 2020 Cross Ref A on Optimization Algorithms in of Conference Vol. No. 1 | 1 Mar 2020 Cross Ref Global Convergence of the to a Computation, Vol. No. 1 | 1 Mar 2020 Cross Ref Using a Conjugate Gradient Regression Resources Research, Vol. No. 1 | 27 June 2019 Cross Ref optimization in using gradient descent Vol. | 1 Feb 2020 Cross Ref for from diffraction Vol. No. 1 | 1 January 2020 Cross Ref using and neural Visual Vol. No. 1 | 22 August 2018 Cross Ref A New Hybrid Method for Unconstrained Differentiable of Nonlinear | 20 February 2020 Cross Ref Quasi-Newton Optimization Methods for Deep Learning Learning Applications | 29 February 2020 Cross Ref by edge with Gaussian of Vol. No. 1 | 9 August 2019 Cross Ref of Mathematical Optimization Problems | 1 October 2020 Cross Ref An efficient solution scheme for in a Methods in Applied Mechanics and Engineering, Vol. | 1 Jan 2020 Cross Ref Image and Estimation with International on Computational in Adaptive | 1 Dec 2019 Cross Ref A new accelerated conjugate gradient method for large-scale unconstrained optimizationJournal of Inequalities and Applications, Vol. No. 1 | 20 November 2019 Cross Ref Research of estimation methods for full waveform inversion in time Geophysics, Vol. No. 6 | 17 September 2019 Cross Ref elastic full-waveform Vol. 84, No. 6 | 16 October 2019 Cross Ref A Hybrid of Quasi-Newton Method with CG Method for Unconstrained of Conference Vol. No. 1 | 1 Nov 2019 Cross Ref Conjugate gradient-based fuzzy neural network parameter identification and its convergence Vol. | 1 Oct 2019 Cross Ref Regularized elastic full-waveform inversion using deep Vol. 84, No. 5 | 24 August 2019 Cross Ref and Parallel Learning Algorithms Learning Rate in and Vol. 6 | 27 August 2019 Cross Ref of Networks via CompletionIEEE Transactions on Communications, Vol. No. 8 | 1 Aug 2019 Cross Ref A diagonal quasi-Newton updating method for unconstrained optimizationNumerical Algorithms, Vol. No. 2 | 29 June 2018 Cross Ref A New Quasi-Newton Method Finite for Unconstrained Functional Analysis and Optimization, Vol. 6 | 20 May 2019 Cross Ref Efficient by of Chemical Theory and Computation, Vol. 15, No. 5 | 2 April 2019 Cross Ref An efficient adaptive three-term of the conjugate gradient Methods and Software, Vol. 34, No. 3 | 15 October 2018 Cross Ref A Quasi-Newton Algorithm on the Manifold for with 2019 - 2019 International Conference on and Signal | 1 May 2019 Cross Ref of the and from Mathematical Modelling, Vol. 68 | 1 Apr 2019 Cross Ref inversion of data using an application for the estimation of the Journal International, Vol. No. 1 | 17 January 2019 Cross Ref An Estimation Algorithm for Models with Spatial of the Society of Vol. No. 2 | 5 March 2019 Cross Ref The of and A Journal of the Vol. 8, No. 1 | 22 March 2018 Cross Ref The Optimal Location of Vol. 9, No. 3 | 27 February 2019 Cross Ref Convergence Rate of Descent Method with New on Riemannian of Optimization Theory and Applications, Vol. No. 3 | 24 September 2018 Cross Ref in Hybrid and Transactions on Signal and Information Networks, Vol. No. 1 | 1 Mar 2019 Cross Ref A new hybrid approach for optimization of Vol. No. 2 | 24 April 2019 Cross Ref for Hybrid Transactions on Vol. 49, No. 2 | 1 Feb 2019 Cross Ref A New Conjugate Gradient Method with Optimal Parameter Functional Analysis and Optimization, Vol. 40, No. 2 | 20 November 2018 Cross Ref of Models of Networks | 14 2018 Cross Ref the distribution of to on using Vol. | 1 Jan 2019 Cross Ref A Quasi-Newton Algorithm for Optimizing with G. and Journal on Optimization, Vol. No. 2 | 11 April 2019 Cross Ref 2019 Cross Ref Unconstrained Optimization | 10 November 2019 Cross Ref Optimization and Simulation | 2 January 2020 Cross Ref New Hybrid Conjugate Gradient Method A Convex Combination of and Vol. 39, No. 1 | 4 January 2019 Cross Ref optimization via a and a Control, Optimisation and of Vol. 25 | 5 April 2019 Cross Ref in quasi-Newton Programming Computation, Vol. 10, No. 4 | 12 February 2018 Cross Ref An Accelerated Three-Term Conjugate Gradient Method with Sufficient Descent Condition and Conjugacy ConditionJournal of Optimization Theory and Applications, Vol. No. 3 | 28 August 2018 Cross Ref the properties of International Conference on and | 1 Dec 2018 Cross Ref A New Conjugate Gradient Algorithm for Training in Neural Transactions on Neural Networks and Learning Systems, Vol. No. 12 | 1 Dec 2018 Cross Ref waveform inversion in time and domain of in seismic a Research Journal, Vol. No. 4 | 1 October 2018 Cross Ref A diagonal quasi-Newton updating method based on the function of and for unconstrained optimizationOptimization, Vol. No. 9 | 17 June 2018 Cross Ref in parameter and time estimation for Vol. | 1 2018 Cross Ref Optimal control of systems using hybrid numerical optimization Vol. No. 8 | 2 May 2018 Cross Ref Analysis by Transactions on Signal Processing, Vol. No. 15 | 1 Aug 2018 Cross Ref of large-scale systems in of Applied Physics, Vol. No. 4 | 28 Jul 2018 Cross Ref A Method for Nonlinear Problems Based on for Systems - Modeling, and | 18 July 2018 Cross Ref A hybrid conjugate gradient image approach for Science Journal, Vol. No. 5 | 16 February 2018 Cross Ref A Coupled with an Gradient Method and Application to ProblemsMathematical Problems in Engineering, Vol. 2018 | 2 Jul 2018 Cross Ref Optimization approach for the Vol. No. 4 | 1 Jul 2018 Cross Ref A Broyden–Fletcher–Goldfarb–Shanno Method Based on Minimizing the Function of and for Unconstrained of Optimization Theory and Applications, Vol. 178, No. 1 | 4 May 2018 Cross Ref by a modified Newton method using Physics and Vol. No. 6 | 18 April 2018 Cross Ref A on the via and Analysis, Vol. No. 2 | 17 February 2018 Cross Ref Some three-term conjugate gradient methods with the inexact search Vol. No. 2 | 16 March 2018 Cross Ref of Science and Technology, Vol. No. 3 | 25 May 2018 Cross Ref of deep", "authors": ["Philip Wolfe"], "year": 1969, "venue": "SIAM Review", "cited_by_count": 1053, "type": "article", "concepts": ["Convergence (economics)", "Applied mathematics", "Mathematics", "Computer science", "Economics"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4411019521", "doi": "https://doi.org/10.1109/tip.2025.3570571", "title": "Learning Guided Implicit Depth Function With Scale-Aware Feature Fusion", "abstract": "Recently, the single image super-resolution based on implicit image function is a hot topic, which learns a universal model for arbitrary upsampling scales. By contrast, color-guided depth map super-resolution is less explored based on implicit function learning. The related research faces three questions. First, is it also necessary and applicable to fuse the depth feature and the color feature in the encoder with continuous upsampling scales? Second, is the scale information in the encoder as important as that in the decoder? Third, how to efficiently and effectively model the affinity of location distance and content similarity within cross domains in the decoder? This paper proposes a transformer-based network to answer the above questions, which includes a depth super-resolution branch and a guidance extraction branch. Specifically, in the encoder, the effective implicit cross transformer is designed to fuse the guidance from the color feature with continuous coordinate mapping. In addition, the unrelated guidance is filtered out by correlation evaluation in the high-dimension feature space. Unlike the scale only introduced in the decoder, this paper additionally embeds the scale into the position encoding and the feed-forward network in the encoder to learn the scale-aware feature representation. In the decoder, the high-resolution depth feature is reconstructed by using the internal prior and the external guidance. The internal prior is implemented by implicit self-attention in the depth super-resolution branch, and the external guidance is exploited via implicit cross-attention between both branches. Finally, the above decoded features are complementary to generate the high-resolution depth map. The sufficient experiments on the synthetic and real datasets for in-distribution and out-of-distribution upsampling scales validate the improved performance. The code and the models are public via https://github.com/NaNRan13/GIDF.", "authors": ["Yifan Zuo", "Yuqi Hu", "Yaping Xu", "Zhi Wang", "Yuming Fang", "Jiebin Yan", "Wenhui Jiang", "Yuxin Peng", "Yan Huang"], "year": 2025, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 20, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Scale (ratio)", "Function (biology)", "Feature (linguistics)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4319999899", "doi": "https://doi.org/10.1109/tgrs.2023.3240254", "title": "Learning Dynamic Scale Awareness and Global Implicit Functions for Continuous-Scale Super-Resolution of Remote Sensing Images", "abstract": "The mainstream remote sensing image (RSI) super-resolution (SR) algorithms treat tasks with different scale factors independently, and a single model can only process a fixed integer scale factor. However, in practical applications, it is important to continuously super-resolve RSIs to multiple resolutions, as different resolutions present various levels of detail. Retraining the model for each scale factor consumes huge computational resources and storage space. Existing continuous-scale SR models employ static convolutions, and most are designed for natural scenes, ignoring dynamic feature extraction needs for different scale factors and the inherent properties of RSIs. In addition, efficiently obtaining the continuous representation of RSIs and avoiding the artifacts of RSI SR results is still a challenging problem. To address the above problems, we propose a scale-aware dynamic network (SADN) for RSI continuous-scale SR. First, we devise a scale-aware dynamic convolutional (SAD-Conv) layer to handle the strong randomness of the RSI textural distribution and achieve dynamic feature extraction according to scale factors. Second, we devise a continuous-scale upsampling module (CSUM) with the multi-bilinear global implicit function (MBGIF) for any-scale upsampling. The CSUM constructs multiple feature spaces with asymptotic resolutions to approximate the continuous representation of an image, and then, the MBGIF makes full use of multiresolution features to map arbitrary coordinates to spectral values. We evaluate our SADN using various benchmarks, and the experimental results show that the CSUM can efficiently achieve continuous-scale upsampling while maintaining excellent objective and visual performance. Moreover, our SADN uses fewer parameters and even outperforms the state-of-the-art fixed-scale SR methods. The source code is available at <uri xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">https://github.com/hanlinwu/SADN</uri> .", "authors": ["Hanlin Wu", "Ning Ni", "Libao Zhang"], "year": 2023, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 22, "type": "article", "concepts": ["Upsampling", "Computer science", "Scale (ratio)", "Feature (linguistics)", "Bilinear interpolation"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W3109870583", "doi": "https://doi.org/10.1109/tgrs.2020.3038653", "title": "A Unified Network for Arbitrary Scale Super-Resolution of Video Satellite Images", "abstract": "Super-resolution (SR) has attracted increasing attention as it can improve the quality of video satellite images. Most previous studies only consider several integer magnification factors and focus on obtaining a specific SR model for each scale factor. However, in the real world, it is a common requirement to zoom the videos arbitrarily by rolling the mouse wheel. In this article, we propose a unified network for arbitrary scale SR (ASSR) of video satellite images. The proposed ASSR consists of two modules, i.e., feature learning module and arbitrary upscale module. The feature learning module accepts multiple low-resolution (LR) frames and extracts useful features of those frames by using many 3-D residual blocks. The arbitrary upscale module takes the extracted features as input and enhances the spatial resolution by subpixel convolution and bicubic-based adjustment. Different from existing video satellite image SR methods, ASSR can continuously zoom LR video satellite images with arbitrary integer and noninteger scale factors in a single model. Experiments have been conducted on real video satellite images acquired by Jilin-1 and OVS-1. Quantitative and qualitative results have demonstrated that ASSR has superior reconstruction performance compared with the state-of-the-art SR methods.", "authors": ["Zhi He", "Dan He"], "year": 2020, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 20, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Satellite", "Computer vision", "Zoom"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4361280618", "doi": "https://doi.org/10.3390/s23073573", "title": "SR-FEINR: Continuous Remote Sensing Image Super-Resolution Using Feature-Enhanced Implicit Neural Representation", "abstract": "Remote sensing images often have limited resolution, which can hinder their effectiveness in various applications. Super-resolution techniques can enhance the resolution of remote sensing images, and arbitrary resolution super-resolution techniques provide additional flexibility in choosing appropriate image resolutions for different tasks. However, for subsequent processing, such as detection and classification, the resolution of the input image may vary greatly for different methods. In this paper, we propose a method for continuous remote sensing image super-resolution using feature-enhanced implicit neural representation (SR-FEINR). Continuous remote sensing image super-resolution means users can scale a low-resolution image into an image with arbitrary resolution. Our algorithm is composed of three main components: a low-resolution image feature extraction module, a positional encoding module, and a feature-enhanced multi-layer perceptron module. We are the first to apply implicit neural representation in a continuous remote sensing image super-resolution task. Through extensive experiments on two popular remote sensing image datasets, we have shown that our SR-FEINR outperforms the state-of-the-art algorithms in terms of accuracy. Our algorithm showed an average improvement of 0.05 dB over the existing method on ×30 across three datasets.", "authors": ["Jinming Luo", "Lei Han", "Xianjie Gao", "Xiuping Liu", "Weiming Wang"], "year": 2023, "venue": "Sensors", "cited_by_count": 10, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Feature (linguistics)", "Image (mathematics)", "Image resolution"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4385188589", "doi": "https://doi.org/10.1016/j.neucom.2023.126584", "title": "Scale-Aware Frequency Attention network for super-resolution", "abstract": "", "authors": ["Wei Yu", "Zonglin Li", "Qinglin Liu", "Feng Jiang", "Changyong Guo", "Shengping Zhang"], "year": 2023, "venue": "Neurocomputing", "cited_by_count": 13, "type": "article", "concepts": ["Overfitting", "Computer science", "Convolutional neural network", "Frequency domain", "Convolution (computer science)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4312342061", "doi": "https://doi.org/10.1007/978-3-031-19797-0_11", "title": "Learning Local Implicit Fourier Representation for Image Warping", "abstract": "", "authors": ["Jaewon Lee", "Kwang Pyo Choi", "Kyong Hwan Jin"], "year": 2022, "venue": "Lecture notes in computer science", "cited_by_count": 17, "type": "book-chapter", "concepts": ["Image warping", "Computer science", "Artificial intelligence", "Fourier transform", "Homography"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2294985758", "doi": "https://doi.org/10.1145/237170.237200", "title": "The lumigraph", "abstract": "This paper discusses a new method for capturing the complete appearance of bothsynthetic and real world objects and scenes,representing this information, and then using this representation to render images of the object from new camera positions. Unlike the shape capture process traditionally used in computer vision and the rendering process traditionally used in computer graphics, our approach does not rely on geometric representations. Instead we sample and reconstruct a 4D function. which we call a Lumigraph. The Lumigraph is a subset o f the complete plenoptic fu nction that describes the flow of light at all positions in all directions. With the Lumigraph. new images of the object can be generated very quick]y,independentof the geometric or illumination complexity of the scene or object. The paper discusses a complete working system including the capture of sainples. the construction of the Lumigraph, and thesubsequent rendering of images from this new representation. even i f given accurate geometric models.", "authors": ["Steven J. Gortler", "Radek Grzeszczuk", "Richard Szeliski", "Michael F. Cohen"], "year": 1996, "venue": "", "cited_by_count": 2440, "type": "article", "concepts": ["Citation", "Computer science", "World Wide Web", "Microsoft excel", "Microsoft Office"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4308235807", "doi": "https://doi.org/10.1109/icip46576.2022.9897382", "title": "Adaptive Local Implicit Image Function for Arbitrary-Scale Super-Resolution", "abstract": "Image representation is critical for many visual tasks. Instead of representing images discretely with 2D arrays of pixels, a recent study, namely local implicit image function (LIIF), denotes images as a continuous function where pixel values are expansion by using the corresponding coordinates as inputs. Due to its continuous nature, LIIF can be adopted for arbitrary-scale image super-resolution tasks, resulting in a single effective and efficient model for various up-scaling factors. However, LIIF often suffers from structural distortions and ringing artifacts around edges, mostly because all pixels share the same model, thus ignoring the local properties of the image. In this paper, we propose a novel adaptive local image function (A-LIIF) to alleviate this problem. Specifically, our A-LIIF consists of two main components: an encoder and a expansion network. The former captures cross-scale image features, while the latter models the continuous up-scaling function by a weighted combination of multiple local implicit image functions. Accordingly, our A-LIIF can reconstruct the high-frequency textures and structures more accurately. Experiments on multiple benchmark datasets verify the effectiveness of our method. Our codes are available at https://github.com/LeeHW-THU/A-LIIF.", "authors": ["Hongwei Li", "Tao Dai", "Yiming Li", "Xueyi Zou", "Shu‐Tao Xia"], "year": 2022, "venue": "2022 IEEE International Conference on Image Processing (ICIP)", "cited_by_count": 14, "type": "article", "concepts": ["Pixel", "Image (mathematics)", "Computer science", "Function (biology)", "Artificial intelligence"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2978556994", "doi": "https://doi.org/10.1038/s41377-019-0194-2", "title": "Optical vortices 30 years on: OAM manipulation from topological charge to multiple singularities", "abstract": "", "authors": ["Yijie Shen", "Xuejiao Wang", "Zhenwei Xie", "Changjun Min", "Xing Fu", "Qiang Liu", "Mali Gong", "Xiaocong Yuan"], "year": 2019, "venue": "Light Science & Applications", "cited_by_count": 2068, "type": "review", "concepts": ["Optical vortex", "Vortex", "Physics", "Topological quantum number", "Angular momentum"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4392607678", "doi": "https://doi.org/10.1109/tmm.2024.3373257", "title": "Activating More Information in Arbitrary-Scale Image Super-Resolution", "abstract": "Single-image super-resolution (SISR) has experienced vigorous growth with the rapid development of deep learning. However, handling arbitrary scales ( <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">e.g.,</i> integers, non-integers, or asymmetric) using a single model remains a challenging task. Existing super-resolution (SR) networks commonly employ static convolutions during feature extraction, which cannot effectively perceive changes in scales. Moreover, these continuous-scale upsampling modules only utilize the scale factors, without considering the diversity of local features. To activate more information for better reconstruction, two plug-in and compatible modules for fixed-scale networks are designed to perform arbitrary-scale SR tasks. Firstly, we design a Scale-aware Local Feature Adaptation Module (SLFAM), which adaptively adjusts the attention weights of dynamic filters based on the local features and scales. It enables the network to possess stronger representation capabilities. Then we propose a Local Feature Adaptation Upsampling Module (LFAUM), which combines scales and local features to perform arbitrary-scale reconstruction. It allows the upsampling to adapt to local structures. Besides, deformable convolution is utilized letting more information to be activated in the reconstruction, enabling the network to better adapt to the texture features. Extensive experiments on various benchmark datasets demonstrate that integrating the proposed modules into a fixed-scale SR network enables it to achieve satisfactory results with non-integer or asymmetric scales while maintaining advanced performance with integer scales.", "authors": ["Yaoqian Zhao", "Qizhi Teng", "Honggang Chen", "Zhang Shu-jiang", "Xiaohai He", "Yi Li", "Ray E. Sheriff"], "year": 2024, "venue": "IEEE Transactions on Multimedia", "cited_by_count": 11, "type": "article", "concepts": ["Computer science", "Scale (ratio)", "Image (mathematics)", "Image resolution", "Computer vision"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4306995891", "doi": "https://doi.org/10.48550/arxiv.2210.08676", "title": "Scale-Agnostic Super-Resolution in MRI using Feature-Based Coordinate Networks", "abstract": "We propose using a coordinate network decoder for the task of super-resolution in MRI. The continuous signal representation of coordinate networks enables this approach to be scale-agnostic, i.e. one can train over a continuous range of scales and subsequently query at arbitrary resolutions. Due to the difficulty of performing super-resolution on inherently noisy data, we analyze network behavior under multiple denoising strategies. Lastly we compare this method to a standard convolutional decoder using both quantitative metrics and a radiologist study implemented in Voxel, our newly developed tool for web-based evaluation of medical images.", "authors": ["Dave Van Veen", "Rogier van der Sluijs", "Batu Ozturkler", "Arjun Desai", "Christian Bluethgen", "Robert D. Boutin", "Marc H. Willis", "Gordon Wetzstein", "David B. Lindell", "Shreyas Vasanawala", "John M. Pauly", "Akshay Chaudhari"], "year": 2022, "venue": "arXiv (Cornell University)", "cited_by_count": 6, "type": "preprint", "concepts": ["Computer science", "Representation (politics)", "Artificial intelligence", "Scale (ratio)", "Range (aeronautics)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W3209689485", "doi": "https://doi.org/10.1109/lgrs.2021.3122985", "title": "Hierarchical Feature Aggregation and Self-Learning Network for Remote Sensing Image Continuous-Scale Super-Resolution", "abstract": "Conducting research on remote sensing image (RSI) super-resolution (SR) is important, especially in terms of the continuous scale, which is beneficial to the application of RSI, such as RSI object detection and data fusion. Continuous-scale SR aims to use a single model to achieve SR at arbitrary (integer and noninteger) scale factors. Therefore, in this letter, we propose a hierarchical feature aggregation and self-learning network for RSI continuous-scale SR (RSI-HFAS). Our network can magnify the RSI continuously, which is beneficial for extracting the RSI multiscale features. First, we design a hierarchical feature aggregation module (HFAM) that is used for hierarchical feature extraction by placing convolutional layers on different floors and completing global feature fusion, which is crucial for achieving RSI continuous-scale SR with a single model. Second, the proposed network introduces a feedback mechanism, which can refine the hierarchical feature through feature feedback and enrich the texture parts of the RSI step by step. Finally, we design a self-learning upscaling structure to dynamically predict the number and weights of the upsampling filters, which can achieve RSI continuous-scale SR. Compared to the meta-learning based on enhanced deep SR (META-EDSR) method, our experimental results show a nearly 0.2-dB improvement on the metrics of the peak signal-to-noise ratio (PSNR).", "authors": ["Ning Ni", "Hanlin Wu", "Libao Zhang"], "year": 2021, "venue": "IEEE Geoscience and Remote Sensing Letters", "cited_by_count": 11, "type": "article", "concepts": ["Computer science", "Feature (linguistics)", "Upsampling", "Feature extraction", "Artificial intelligence"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2147626801", "doi": "https://doi.org/10.1051/0004-6361/201220873", "title": "LOFAR: The LOw-Frequency ARray", "abstract": "LOFAR, the LOw-Frequency ARray, is a new-generation radio interferometer constructed in the north of the Netherlands and across europe. Utilizing a novel phased-array design, LOFAR covers the largely unexplored low-frequency range from 10–240 MHz and provides a number of unique observing capabilities. Spreading out from a core located near the village of Exloo in the northeast of the Netherlands, a total of 40 LOFAR stations are nearing completion. A further five stations have been deployed throughout Germany, and one station has been built in each of France, Sweden, and the UK. Digital beam-forming techniques make the LOFAR system agile and allow for rapid repointing of the telescope as well as the potential for multiple simultaneous observations. With its dense core array and long interferometric baselines, LOFAR achieves unparalleled sensitivity and angular resolution in the low-frequency radio regime. The LOFAR facilities are jointly operated by the International LOFAR Telescope (ILT) foundation, as an observatory open to the global astronomical community. LOFAR is one of the first radio observatories to feature automated processing pipelines to deliver fully calibrated science products to its user community. LOFAR’s new capabilities, techniques and modus operandi make it an important pathfinder for the Square Kilometre Array (SKA). We give an overview of the LOFAR instrument, its major hardware and software components, and the core science objectives that have driven its design. In addition, we present a selection of new results from the commissioning phase of this new radio observatory.", "authors": ["M. P. van Haarlem", "M. W. Wise", "A. W. Gunst", "G. Heald", "J. P. McKean", "J. W. T. Hessels", "A. G. de Bruyn", "R. Nijboer", "J. Swinbank", "R. A. Fallows", "M. A. Brentjens", "A. Nelles", "R. Beck", "H. Falcke", "R. P. Fender", "J.R. Hörandel", "L. V. E. Koopmans", "G. Mann", "G. K. Miley", "H. J. A. Röttgering", "B. W. Stappers", "R. A. M. J. Wijers", "Saleem Zaroubi", "M. van den Akker", "A. Alexov", "J. M. Anderson", "Kevin D. Anderson", "A. van Ardenne", "M. Arts", "A. Asgekar", "I. M. Avruch", "F. Batejat", "L. Bähren", "M. E. Bell", "M. R. Bell", "Ilse van Bemmel", "P. Bennema", "Mark Bentum", "G. Bernardi", "P. N. Best", "L. Bırzan", "A. Bonafede", "Albert‐Jan Boonstra", "Róbert Braun", "Joel N. Bregman", "F. Breitling", "R. H. van de Brink", "J. W. Broderick", "P. Chris Broekema", "W. N. Brouw", "M. Brüggen", "H. R. Butcher", "W. van Cappellen", "B. Ciardi", "Thijs Coenen", "J. E. Conway", "A. H. W. M. Coolen", "A. Corstanje", "S. Damstra", "O.T. Davies", "Adam T. Deller", "R.‐J. Dettmar", "Ger van Diepen", "K. Dijkstra", "P. Donker", "A. Doorduin", "J. Dromer", "M. Drost", "A. van Duin", "J. Eislöffel", "J. van Enst", "C. Ferrari", "W. Frieswijk", "Henk S. GANKEMA", "M. A. Garrett", "F. de Gasperin", "M. Gerbers", "E. de Geus", "J.‐M. Grießmeier", "T. Grit", "P. Gruppen", "J. P. Hamaker", "T. E. Hassall", "M. Hoeft", "H. A. Holties", "A. Horneffer", "A. J. van der Horst", "A. van Houwelingen", "A. Huijgen", "M. Iacobelli", "H. T. Intema", "N. Jackson", "Vibor Jelić", "A. de Jong", "E. Juette", "D. Kant", "A. Karastergiou", "A. Koers", "H. Kollen", "V. I. Kondratiev"], "year": 2013, "venue": "Astronomy and Astrophysics", "cited_by_count": 2571, "type": "article", "concepts": ["LOFAR", "Radio telescope", "Observatory", "Remote sensing", "Telescope"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4402754305", "doi": "https://doi.org/10.1109/cvpr52733.2024.02459", "title": "Latent Modulated Function for Computational Optimal Continuous Image Representation", "abstract": "The recent work Local Implicit Image Function (LIIF) and subsequent Implicit Neural Representation (INR) based works have achieved remarkable success in Arbitrary-Scale Super-Resolution (ASSR) by using MLP to decode Low-Resolution (LR) features. However, these continuous image representations typically implement decoding in High-Resolution (HR) High-Dimensional (HD) space, leading to a quadratic increase in computational cost and seriously hindering the practical applications of ASSR. To tackle this problem, we propose a novel Latent Modulated Function (LMF), which decouples the HR-HD decoding process into shared latent decoding in LR-HD space and independent rendering in HR Low-Dimensional (LD) space, thereby realizing the first computational optimal paradigm of continuous image representation. Specifically, LMF utilizes an HD MLP in latent space to generate latent modulations of each LR feature vector. This enables a modulated LD MLP in render space to quickly adapt to any input feature vector and perform rendering at arbitrary resolution. Further-more, we leverage the positive correlation between modulation intensity and input image complexity to design a Controllable Multi-Scale Rendering (CMSR) algorithm, offering the flexibility to adjust the decoding efficiency based on the rendering precision. Extensive experiments demonstrate that converting existing INR-based ASSR methods to LMF can reduce the computational cost by up to 99.9%, accelerate inference by up to 57×, and save up to 76% of parameters, while maintaining competitive performance. The code is available at https://github.com/HeZongyao/LMF.", "authors": ["Zongyao He", "Zhi Jin"], "year": 2024, "venue": "", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Representation (politics)", "Image (mathematics)", "Function (biology)", "Artificial intelligence"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2529052661", "doi": "https://doi.org/10.1016/j.ymeth.2016.09.016", "title": "TrackMate: An open and extensible platform for single-particle tracking", "abstract": "", "authors": ["Jean-Yves Tinévez", "Nick Perry", "Johannes Schindelin", "Genevieve M. Hoopes", "Gregory D. Reynolds", "Emmanuel Laplantine", "Sebastian Y. Bednarek", "Spencer Shorte", "Kevin W. Eliceiri"], "year": 2016, "venue": "Methods", "cited_by_count": 3597, "type": "article", "concepts": ["Computer science", "Visualization", "Modular design", "Plug-in", "Context (archaeology)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2134770831", "doi": "https://doi.org/10.1051/aas:2000126", "title": "Evolutionary tracks and isochrones for low- and intermediate-mass stars: From 0.15 to 7 $M_{\\odot}$, and from $Z=0.0004$ to 0.03", "abstract": "We present a large grid of stellar evolutionary tracks, which are suitable to modelling star clusters and galaxies by means of population synthesis. The tracks are presented for the initial chemical compositions , , , , (solar composition), and . They are computed with updated opacities and equation of state, and a moderate amount of convective overshoot. The range of initial masses goes from to , and the evolutionary phases extend from the zero age main sequence (ZAMS) till either the thermally pulsing AGB regime or carbon ignition. We also present an additional set of models with solar composition, computed using the classical Schwarzschild criterion for convective boundaries. From all these tracks, we derive the theoretical isochrones in the Johnson-Cousins UBVRIJHK broad-band photometric system.", "authors": ["L. Girardi", "A. Bressan", "G. Bertelli", "C. Chiosi"], "year": 2000, "venue": "Astronomy and Astrophysics Supplement Series", "cited_by_count": 2423, "type": "article", "concepts": ["Astrophysics", "Physics", "Schwarzschild radius", "Population", "Convection"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4409368689", "doi": "https://doi.org/10.1609/aaai.v39i4.32369", "title": "GaussianSR: High Fidelity 2D Gaussian Splatting for Arbitrary-Scale Image Super-Resolution", "abstract": "Implicit neural representations (INRs) have revolutionized arbitrary-scale super-resolution (ASSR) by modeling images as continuous functions. Most existing INR-based ASSR networks first extract features from the given low-resolution image using an encoder, and then render the super-resolved result via a multi-layer perceptron decoder. Although these approaches have shown promising results, their performance is constrained by the limited representation ability of discrete latent codes in the encoded features. In this paper, we propose a novel ASSR method named GaussianSR that overcomes this limitation through 2D Gaussian Splatting (2DGS). Unlike traditional methods that treat pixels as discrete points, GaussianSR represents each pixel as a continuous Gaussian field. The encoded features are simultaneously refined and upsampled by rendering the mutually stacked Gaussian fields. As a result, long-range dependencies are established to enhance representation ability. In addition, a classifier is developed to dynamically assign Gaussian kernels to all pixels to further improve flexibility. All components of GaussianSR (i.e. encoder, classifier, Gaussian kernels, and decoder) are jointly learned end-to-end. Experiments demonstrate that GaussianSR achieves superior ASSR performance with fewer parameters than existing methods while enjoying interpretable and content-aware feature aggregations.", "authors": ["Jintong Hu", "Bin Xia", "Bin Chen", "Wenming Yang", "Zhang Lei"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 10, "type": "article", "concepts": ["Computer science", "Scale (ratio)", "High fidelity", "Gaussian", "Fidelity"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2103680334", "doi": "https://doi.org/10.1175/2008mwr2387.1", "title": "Explicit Forecasts of Winter Precipitation Using an Improved Bulk Microphysics Scheme. Part II: Implementation of a New Snow Parameterization", "abstract": "Abstract A new bulk microphysical parameterization (BMP) has been developed for use with the Weather Research and Forecasting (WRF) Model or other mesoscale models. As compared with earlier single-moment BMPs, the new scheme incorporates a large number of improvements to both physical processes and computer coding, and it employs many techniques found in far more sophisticated spectral/bin schemes using lookup tables. Unlike any other BMP, the assumed snow size distribution depends on both ice water content and temperature and is represented as a sum of exponential and gamma distributions. Furthermore, snow assumes a nonspherical shape with a bulk density that varies inversely with diameter as found in observations and in contrast to nearly all other BMPs that assume spherical snow with constant density. The new scheme’s snow category was readily modified to match previous research in sensitivity experiments designed to test the sphericity and distribution shape characteristics. From analysis of four idealized sensitivity experiments, it was determined that the sphericity and constant density assumptions play a major role in producing supercooled liquid water whereas the assumed distribution shape plays a lesser, but nonnegligible, role. Further testing using numerous case studies and comparing model results with in situ and other observations confirmed the results of the idealized experiments and are briefly mentioned herein, but more detailed, microphysical comparisons with observations are found in a companion paper in this series (Part III, forthcoming).", "authors": ["Gregory Thompson", "Paul R. Field", "Roy Rasmussen", "William D. Hall"], "year": 2008, "venue": "Monthly Weather Review", "cited_by_count": 3106, "type": "article", "concepts": ["Sphericity", "Snow", "Bin", "Snowflake", "Environmental science"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2550557946", "doi": "https://doi.org/10.1088/2040-8978/19/1/013001", "title": "Roadmap on structured light", "abstract": "Structured light refers to the generation and application of custom light fields. As the tools and technology to create and detect structured light have evolved, steadily the applications have begun to emerge. This roadmap touches on the key fields within structured light from the", "authors": ["Halina Rubinsztein‐Dunlop", "Andrew Forbes", "Michael Berry", "Mark R. Dennis", "Davıd L. Andrews", "Masud Mansuripur", "Cornelia Denz", "Christina Alpmann", "Peter Banzer", "Thomas Bauer", "Ebrahim Karimi", "Lorenzo Marrucci", "Miles J. Padgett", "Monika Ritsch‐Marte", "Natalia M. Litchinitser", "N. P. Bigelow", "Carmelo Rosales‐Guzmán", "Antonella Belmonte", "Juan P. Torres", "Tyler W. Neely", "Mark Baker", "Reuven Gordon", "Alexander B. Stilgoe", "Jacquiline Romero", "A. G. White", "Robert Fickler", "Alan E. Willner", "Guodong Xie", "Benjamin McMorran", "Andrew M. Weiner"], "year": 2016, "venue": "Journal of Optics", "cited_by_count": 1285, "type": "article", "concepts": ["Structured light", "Computer science", "Light field", "Key (lock)", "Perspective (graphical)"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4392838798", "doi": "https://doi.org/10.29026/oea.2024.230145", "title": "Towards the performance limit of catenary meta-optics via field-driven optimization", "abstract": "Catenary optics enables metasurfaces with higher efficiency and wider bandwidth, and is highly anticipated in the imaging system, super-resolution lithography, and broadband absorbers. However, the periodic boundary approximation without considering aperiodic electromagnetic crosstalk poses challenges for catenary optical devices to reach their performance limits. Here, perfect control of both local geometric and propagation phases is realized through field-driven optimization, in which the field distribution is calculated under real boundary conditions. Different from other optimization methods requiring a mass of iterations, the proposed design method requires less than ten iterations to get the efficiency close to the optimal value. Based on the library of shape-optimized catenary structures, centimeter-scale devices can be designed in ten seconds, with the performance improved by ~15%. Furthermore, this method has the ability to extend catenary-like continuous structures to arbitrary polarization, including both linear and elliptical polarizations, which is difficult to achieve with traditional design methods. It provides a way for the development of catenary optics and serves as a potent tool for constructing high-performance optical devices.", "authors": ["Siran Chen", "Yingli Ha", "Fei Zhang", "Mingbo Pu", "Hanlin Bao", "Mingfeng Xu", "Yinghui Guo", "Yue Shen", "Xiaoliang Ma", "Xiong Li", "Xiangang Luo"], "year": 2024, "venue": "Opto-Electronic Advances", "cited_by_count": 15, "type": "article", "concepts": ["Catenary", "Limit (mathematics)", "Field (mathematics)", "Computer science", "Optics"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2027888086", "doi": "https://doi.org/10.1103/physrevb.43.130", "title": "Thermal fluctuations, quenched disorder, phase transitions, and transport in type-II superconductors", "abstract": "The effects of thermal fluctuations, quenched disorder, and anisotropy on the phases and phase transitions in type-II superconductors are examined, focusing on linear and nonlinear transport properties. In zero magnetic field there are two crossovers upon approaching ${\\mathit{T}}_{\\mathit{c}}$, first the ``Ginzburg'' crossover from mean-field behavior to the universality class of an uncharged superfluid, and then, much closer to ${\\mathit{T}}_{\\mathit{c}}$ for strongly type-II systems, a crossover to the universality class of a charged superfluid. The primary focus of this paper is on the behavior in the presence of a penetrating magnetic field. In a clean system the vortex-lattice phase can melt due to thermal fluctuations; we estimate the phase boundary in a variety of regimes. Pinning of vortices due to impurities or other defects destroys the long-range correlations of the vortex lattice, probably replacing it with a new vortex-glass phase that has spin-glasslike off-diagonal long-range order and is truly superconducting, in contrast to conventional theories of ``flux creep.'' The properties of this vortex-glass phase are examined, as well as the critical behavior near the transition from the vortex-glass to the vortex-fluid phase. The crossover from lattice to vortex-glass behavior for weak pinning is also examined. Linear and nonlinear conductivity measurements and other experiments on the high-${\\mathit{T}}_{\\mathit{c}}$ superconductors Y-Ba-Cu-O and Bi-Sr-Ca-Cu-O are discussed in light of the results. The latter is found to exhibit strongly two-dimensional behavior over large portions of its phase diagram.", "authors": ["Daniel S. Fisher", "Matthew P. A. Fisher", "David A. Huse"], "year": 1991, "venue": "Physical review. B, Condensed matter", "cited_by_count": 2361, "type": "article", "concepts": ["Condensed matter physics", "Superconductivity", "Vortex", "Physics", "Type-II superconductor"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4387968080", "doi": "https://doi.org/10.1145/3581783.3612230", "title": "DuDoINet: Dual-Domain Implicit Network for Multi-Modality MR Image Arbitrary-scale Super-Resolution", "abstract": "Compared to single-modality magnetic resonance (MR) image super-resolution (SR) methods, multi-modality MR image methods can utilize high-resolution reference modality (e.g., T1 modality) to provide valuable complementary information for low-resolution target modality (e.g., T2 modality) in SR reconstruction, which can further improve the quality of the SR images. Although they have achieved impressive results, these methods still suffer from the following drawbacks: (1) They can only handle fixed integer upsampling factors, such as 2X, 3X, and 4X, and require training and storing corresponding models for each upsampling factor, which is infeasible in clinical practice; (2) They only perform feature extraction and reconstruction in the image domain. However, the aliasing artifacts produced in the image domain are structural and non-local. Therefore, using only the image domain cannot effectively reconstruct high-quality aliasing-free SR images. To address these issues, we develop a brand-new Dual-Domain Implicit Network (DuDoINet) for multi-modality MR image arbitrary-scale SR. Specifically, we propose a dual-domain learning scheme for multi-modality MR image SR, which allows the network to sufficiently exploit the frequency and image domain information in MR images. In addition, we design implicit attention to achieve arbitrary-scale upsampling of MR images, which utilizes a continuously differentiable function that generates pixel values from pixel coordinates. Furthermore, we designed a deformable cross-modality attention mechanism that can adaptively transfer high-frequency details from the T1 to the T2 modality, better integrating valuable complementary information from the T1 modality. Extensive and comprehensive experiments on healthy subjects and patient datasets demonstrate that our DuDoINet outperforms SOTA methods, demonstrating its great potential for clinical practice.", "authors": ["Guangyuan Li", "Wei Xing", "Lei Zhao", "Zehua Lan", "Zhanjie Zhang", "Jiakai Sun", "Haolin Yin", "Huaizhong Lin", "Zhijie Lin"], "year": 2023, "venue": "", "cited_by_count": 10, "type": "article", "concepts": ["Upsampling", "Modality (human–computer interaction)", "Computer science", "Artificial intelligence", "Aliasing"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4395675185", "doi": "https://doi.org/10.3390/app14093678", "title": "Residual Dense Swin Transformer for Continuous-Scale Super-Resolution Algorithm", "abstract": "The single-image super-resolution task benefits has a wide range of application scenarios, so has long been a hotspot in the field of computer vision. However, designing a continuous-scale super-resolution algorithm with excellent performance is still a difficult problem to solve. In order to solve this problem, we propose a continuous-scale SR algorithm based on a Transformer, which is called residual dense Swin Transformer (RDST). Firstly, we design a residual dense Transformer block (RDTB) to enhance the information flow before and after the network and extract local fusion features. Then, we use multilevel feature fusion to obtain richer feature information. Finally, we use the upsampling module based on the local implicit image function (LIIF) to obtain continuous-scale super-resolution results. We test RDST on multiple benchmarks. The experimental results show that RDST achieves SOTA performance in the fixed scale of super-resolution tasks in the distribution, and significantly improves (0.1∼0.6 dB) the arbitrary scale of super-resolution tasks out of distribution. Sufficient experiments show that our RDST can use fewer parameters, and its performance is better than the SOTA SR method.", "authors": ["J. Juan Liu", "Zihan Gui", "Chenghao Yuan", "Guangyi Yang", "Yi Gao"], "year": 2024, "venue": "Applied Sciences", "cited_by_count": 3, "type": "article", "concepts": ["Algorithm", "Computer science", "Materials science"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2968923792", "doi": "https://doi.org/10.1038/s41524-019-0221-0", "title": "Recent advances and applications of machine learning in solid-state materials science", "abstract": "", "authors": ["Jonathan Schmidt", "Mário R. G. Marques", "Silvana Botti", "Miguel A. L. Marques"], "year": 2019, "venue": "npj Computational Materials", "cited_by_count": 2256, "type": "article", "concepts": ["Interpretability", "Toolbox", "Machine learning", "Artificial intelligence", "Computer science"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2098362450", "doi": "https://doi.org/10.1145/166117.166153", "title": "View interpolation for image synthesis", "abstract": "Image-space simplifications have been used to accelerate the calculation of computer graphic images since the dawn of visual simulation. Texture mapping has been used to provide a means by which images may themselves be used as display primitives. The work reported by this paper endeavors to carry this concept to its logical extreme by using interpolated images to portray three-dimensional scenes. The special-effects technique of morphing, which combines interpolation of texture maps and their shape, is applied to computing arbitrary intermediate frames from an array of prestored images. If the images are a structured set of views of a 3D object or scene, intermediate frames derived by morphing can be used to approximate intermediate 3D transformations of the object or scene. Using the view interpolation approach to synthesize 3D scenes has two main advantages. First, the 3D representation of the scene may be replaced with images. Second, the image synthesis time is independent of the scene complexity. The correspondence between images, required for the morphing method, can be predetermined automatically using the range data associated with the images. The method is further accelerated by a quadtree decomposition and a view-independent visible priority. Our experiments have shown that the morphing can be performed at interactive rates on today's high-end personal computers. Potential applications of the method include virtual holograms, a walkthrough in a virtual environment, image-based primitives and incremental rendering. The method also can be used to greatly accelerate the computation of motion blur and soft shadows cast by area light sources.", "authors": ["Shenchang Eric Chen", "Lance R. Williams"], "year": 1993, "venue": "", "cited_by_count": 1096, "type": "article", "concepts": ["Citation", "Computer science", "Interpolation (computer graphics)", "Graphics", "Chen"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W4390970383", "doi": "https://doi.org/10.1109/bibm58861.2023.10385408", "title": "Deep Residual Fourier and Self-Attention for Arbitrary Scale MRI Super-Resolution", "abstract": "The excellent inherent contrast between biological tissues afforded by MR imaging is one of the foremost characteristics of this technique, but it depends on the scan time and hardware devices. Recent studies have shown significant progress in deep learning-based single-image super-resolution (SISR) algorithms based on MR images. Many researchers have employed implicit functions for super-resolution tasks, achieving arbitrary resolution upsampling. Nevertheless, challenges like loss of generated image texture and weak high-frequency features persist. We propose an arbitrary multiple super-resolution model based on deep residual Fourier transform and a selfattention mechanism to tackle these issues. We first use the deep Fourier residual block to construct the high and low-frequency difference of the image, compensating for the spectral bias of the multiple perceptron (MLP) network. Building upon the substantial similarity in medical image tissue structures, we add a vertical and horizontal self-attention mechanism to capture the internal correlation of features in the vertical and horizontal directions. Finally, we learn a continuous functional representation to execute super-resolution tasks at any scale. Experiment results show the effectiveness of our method on the T2 sequence of public dataset SIMON and T1, T2, and Proton Density (PD) weighted scan sequences of public dataset IXI. We conduct qualitative and quantitative comparisons of the three contrasts, illustrating the superiority of our approach.", "authors": ["Xiaojie Wang", "Jing Xia", "Shanshan Gao", "Xingwei Hao", "Yuanfeng Zhou"], "year": 2023, "venue": "", "cited_by_count": 5, "type": "article", "concepts": ["Residual", "Computer science", "Upsampling", "Artificial intelligence", "Deep learning"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2166436681", "doi": "https://doi.org/10.12942/lrr-2014-4", "title": "The Confrontation between General Relativity and Experiment", "abstract": "", "authors": ["Clifford M. Will"], "year": 2014, "venue": "Living Reviews in Relativity", "cited_by_count": 3654, "type": "review", "concepts": ["Theory of relativity", "Theoretical physics", "Physics"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2127994875", "doi": "https://doi.org/10.1093/eurheartj/ehp297", "title": "Guidelines for the diagnosis and treatment of pulmonary hypertension: The Task Force for the Diagnosis and Treatment of Pulmonary Hypertension of the European Society of Cardiology (ESC) and the European Respiratory Society (ERS), endorsed by the International Society of Heart and Lung Transplantation (ISHLT)", "abstract": "The ESC Guidelines represent the views of the ESC and were arrived at after careful consideration of the available evidence at the time they were written. Health professionals are encouraged to take them fully into account when exercising their clinical judgement. The guidelines do not, however, override the individual responsibility of health professionals to make appropriate decisions in the circumstances of the individual patients, in consultation with that patient, and where appropriate and necessary the patient's guardian or carer. It is also the health professional's responsibility to verify the rules and regulations applicable to drugs and devices at the time of prescription.", "authors": ["Nazzareno Galiè", "Marius M. Hoeper", "Marc Humbert", "Adam Torbicki", "J.-L. Vachiéry", "Joan Albert Barberà", "Maurice Beghetti", "Paul Corris", "Seán Gaine", "J. Simon R. Gibbs", "M. A. Gomez-Sanchez", "Guillaume Jondeau", "Walter Klepetko", "Christian Opitz", "A. Peacock", "Leona J. Rubin", "Michael J. Zellweger", "G. Simonneau", "A. Vahanian", "A. Auricchio", "Jeroen J. Bax", "Claudio Ceconi", "V. Dean", "Gerasimos Filippatos", "Christian Funck‐Brentano", "Richard Hobbs", "Peter Kearney", "T. McDonagh", "K. McGregor", "Bogdan A. Popescu", "Z. Reiner", "Udo Sechtem", "P. A. Sirnes", "Michał Tendera", "P. Vardas", "Petr Widimský", "Udo Sechtem", "N. Al Attar", "Felicita Andreotti", "M. Aschermann", "Riccardo Asteggiano", "Raymond L. Benza", "Rolf M.F. Berger", "Dominique Bonnet", "Marion Delcroix", "Luke Howard", "Anastasia Kitsiou", "Iréne Lang", "Aldo P. Maggioni", "Jens Erik Nielsen‐Kudsk", "M. Park", "Pasquale Perrone Filardi", "Susanna Price", "María Teresa Subirana Domenech", "Anton Vonk Noordegraaf", "J Zamorano", "A. Vonk-Noordegraaf", "J. L. Zamorano"], "year": 2009, "venue": "European Heart Journal", "cited_by_count": 3844, "type": "article", "concepts": ["Medicine", "Pulmonary hypertension", "Guardian", "Medical prescription", "Judgement"], "search_query": "image super resolution continuous scale arbitrary"}
{"openalex_id": "https://openalex.org/W2964179170", "doi": "https://doi.org/10.1109/jstars.2017.2779539", "title": "Hyperspectral Image Restoration Via Total Variation Regularized Low-Rank Tensor Decomposition", "abstract": "Hyperspectral images (HSIs) are often corrupted by a mixture of several types of noise during the acquisition process, e.g., Gaussian noise, impulse noise, dead lines, stripes, etc. Such complex noise could degrade the quality of the acquired HSIs, limiting the precision of the subsequent processing. In this paper, we present a novel tensor-based HSI restoration approach by fully identifying the intrinsic structures of the clean HSI part and the mixed noise part. Specifically, for the clean HSI part, we use tensor Tucker decomposition to describe the global correlation among all bands, and an anisotropic spatial-spectral total variation regularization to characterize the piecewise smooth structure in both spatial and spectral domains. For the mixed noise part, we adopt the ℓ <sub xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sub> norm regularization to detect the sparse noise, including stripes, impulse noise, and dead pixels. Despite that TV regularization has the ability of removing Gaussian noise, the Frobenius norm term is further used to model heavy Gaussian noise for some real-world scenarios. Then, we develop an efficient algorithm for solving the resulting optimization problem by using the augmented Lagrange multiplier method. Finally, extensive experiments on simulated and real-world noisy HSIs are carried out to demonstrate the superiority of the proposed method over the existing state-of-the-art ones.", "authors": ["Yao Wang", "Jiangjun Peng", "Qian Zhao", "Yee Leung", "Xi-Le Zhao", "Deyu Meng"], "year": 2017, "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "cited_by_count": 454, "type": "article", "concepts": ["Hyperspectral imaging", "Impulse noise", "Gaussian noise", "Regularization (linguistics)", "Piecewise"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4286238648", "doi": "https://doi.org/10.1145/3503161.3548344", "title": "RCRN: Real-world Character Image Restoration Network via Skeleton Extraction", "abstract": "Constructing high-quality character image datasets is challenging because real-world images are often affected by image degradation. There are limitations when applying current image restoration methods to such real-world character images, since (i) the categories of noise in character images are different from those in general images; (ii) real-world character images usually contain more complex image degradation, e.g., mixed noise at different noise levels. To address these problems, we propose a real-world character restoration network (RCRN) to effectively restore degraded character images, where character skeleton information and scale-ensemble feature extraction are utilized to obtain better restoration performance. The proposed method consists of a skeleton extractor (SENet) and a character image restorer (CiRNet). SENet aims to preserve the structural consistency of the character and normalize complex noise. Then, CiRNet reconstructs clean images from degraded character images and their skeletons. Due to the lack of benchmarks for real-world character image restoration, we constructed a dataset containing 1,606 character images with real-world degradation to evaluate the validity of the proposed method. The experimental results demonstrate that RCRN outperforms state-of-the-art methods quantitatively and qualitatively.", "authors": ["Daqian Shi", "Xiaolei Diao", "Hao Tang", "Xiaomin Li", "Hao Xing", "Hao Xu"], "year": 2022, "venue": "Proceedings of the 30th ACM International Conference on Multimedia", "cited_by_count": 20, "type": "article", "concepts": ["Character (mathematics)", "Computer science", "Artificial intelligence", "Image restoration", "Noise (video)"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4212843049", "doi": "https://doi.org/10.1109/wacvw54805.2022.00005", "title": "Task Adaptive Network for Image Restoration with Combined Degradation Factors", "abstract": "Existing methods have achieved excellent performance on image restoration, but most of them are designed for one type of degradation. However, the weather is complex in the real world. So networks designed for single tasks are usually difficult to apply. Therefore, we propose a task-adaptive attention module to enable the network to restore images with multiple degradation factors. The task-adaptive attention module mainly includes three parts: Task-Adaptive sub-network, Task Channel Attention, and Task Operation Attention. To evaluate the model, we construct a mixed degradation factors dataset that combines three degradation factors of rain, haze, and raindrop. The experimental results show that our method not only better restores images with mixed degradation factors, but also show competitive results compared to the state-of-the-art models of each task.", "authors": ["Jingyuan Zhou", "Chak Tou Leong", "Minyi Lin", "Wantong Liao", "Congduan Li"], "year": 2022, "venue": "", "cited_by_count": 8, "type": "article", "concepts": ["Degradation (telecommunications)", "Computer science", "Task (project management)", "Construct (python library)", "Image (mathematics)"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W3118406639", "doi": "https://doi.org/10.1007/s11760-020-01824-y", "title": "Mixed distortion image enhancement method based on joint of deep residuals learning and reinforcement learning", "abstract": "", "authors": ["Xiaohong Wang", "Fang Liu", "Xiangcai Ma"], "year": 2021, "venue": "Signal Image and Video Processing", "cited_by_count": 8, "type": "article", "concepts": ["Deblurring", "Reinforcement learning", "Distortion (music)", "Computer science", "Artificial intelligence"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4401418599", "doi": "https://doi.org/10.1016/j.patcog.2024.110865", "title": "A novel image dehazing algorithm for complex natural environments", "abstract": "", "authors": ["Yuanzhou Zheng", "Long Qian", "Yuanfeng Zhang", "Jingxin Cao", "Xinyu Liu", "Yong Ma"], "year": 2024, "venue": "Pattern Recognition", "cited_by_count": 14, "type": "article", "concepts": ["Haze", "Computer science", "Preprocessor", "Artificial intelligence", "Computer vision"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4415178442", "doi": "https://doi.org/10.1109/tip.2025.3618377", "title": "UniUIR: Considering Underwater Image Restoration as an All-in-One Learner", "abstract": "Existing underwater image restoration (UIR) methods generally only handle color distortion or jointly address color and haze issues, but they often overlook the more complex degradations that can occur in underwater scenes. To address this limitation, we propose a Universal Underwater Image Restoration method, termed as UniUIR, considering the complex scenario of real-world underwater mixed distortions as an all-in-one manner. To disentangle degradation-specific effects and capture their inter-correlations, we propose the Mamba Mixture-of-Experts module (MMoEM). Each expert specializes in distinct aspects of degradation, while gating mechanism dynamically routes features to appropriate experts. This design enables collaborative prior extraction and preserves global context, all within linear computational complexity. Building upon this foundation, to enhance degradation representation and address the task conflicts that arise when handling multiple types of degradation, we introduce the spatial-frequency prior generator. This module extracts degradation prior information in both spatial and frequency domains, and adaptively selects the most appropriate task-specific prompts based on image content, thereby improving the accuracy of image restoration. Finally, to more effectively address complex, region-dependent distortions in UIR task, we incorporate depth information derived from a large-scale pre-trained depth prediction model, thereby enabling the network to perceive and leverage depth variations across different image regions to handle localized degradation. Extensive experiments demonstrate that UniUIR can produce more attractive results across qualitative and quantitative comparisons, and shows strong generalization than state-of-the-art methods. Project page at https://house-yuyu.github.io/UniUIR.", "authors": ["Xu Zhang", "Huan Zhang", "Guoli Wang", "Qian Zhang", "Lefei Zhang", "Bo Du"], "year": 2025, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 8, "type": "article", "concepts": [], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2067267561", "doi": "https://doi.org/10.1152/physrev.00011.2010", "title": "Physiology of Microglia", "abstract": "Microglial cells are the resident macrophages in the central nervous system. These cells of mesodermal/mesenchymal origin migrate into all regions of the central nervous system, disseminate through the brain parenchyma, and acquire a specific ramified morphological phenotype termed \"resting microglia.\" Recent studies indicate that even in the normal brain, microglia have highly motile processes by which they scan their territorial domains. By a large number of signaling pathways they can communicate with macroglial cells and neurons and with cells of the immune system. Likewise, microglial cells express receptors classically described for brain-specific communication such as neurotransmitter receptors and those first discovered as immune cell-specific such as for cytokines. Microglial cells are considered the most susceptible sensors of brain pathology. Upon any detection of signs for brain lesions or nervous system dysfunction, microglial cells undergo a complex, multistage activation process that converts them into the \"activated microglial cell.\" This cell form has the capacity to release a large number of substances that can act detrimental or beneficial for the surrounding cells. Activated microglial cells can migrate to the site of injury, proliferate, and phagocytose cells and cellular compartments.", "authors": ["Helmut Kettenmann", "Uwe‐Karsten Hanisch", "Mami Noda", "Alexei Verkhratsky"], "year": 2011, "venue": "Physiological Reviews", "cited_by_count": 3431, "type": "review", "concepts": ["Microglia", "Biology", "Central nervous system", "Neuroscience", "Immune system"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W3199138638", "doi": "https://doi.org/10.1109/tcsvt.2021.3112548", "title": "Rethinking Deinterlacing for Early Interlaced Videos", "abstract": "In recent years, high-definition restoration of early videos have received much attention. Real-world interlaced videos usually contain various degradations mixed with interlacing artifacts, such as noises and compression artifacts. Unfortunately, traditional deinterlacing methods only focus on the inverse process of interlacing scanning, and cannot remove these complex and complicated artifacts. Hence, this paper proposes an image deinterlacing network (DIN), which is specifically designed for joint removal of interlacing mixed with other artifacts. The DIN is composed of two stages, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">i.e.</i> , a cooperative vertical interpolation stage for splitting and fully using the information of adjacent fields, and a field-merging stage to perceive movements and suppress ghost artifacts. Experimental results demonstrate the effectiveness of the proposed DIN on both synthetic and real-world test sets.", "authors": ["Yang Zhao", "Wei Jia", "Ronggang Wang"], "year": 2021, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 5, "type": "article", "concepts": ["Interlacing", "Computer science", "Artificial intelligence", "Computer vision", "Interpolation (computer graphics)"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4413156075", "doi": "https://doi.org/10.1109/cvpr52734.2025.01191", "title": "Visual-Instructed Degradation Diffusion for All-in-One Image Restoration", "abstract": "Image restoration tasks like deblurring, denoising, and dehazing usually need distinct models for each degradation type, restricting their generalization in real-world scenarios with mixed or unknown degradations. In this work, we propose Defusion, a novel all-in-one image restoration framework that utilizes visual instruction-guided degradation diffusion. Unlike existing methods that rely on task-specific models or ambiguous text-based priors, Defusion constructs explicit visual instructions that align with the visual degradation patterns. These instructions are grounded by applying degradations to standardized visual elements, capturing intrinsic degradation features while agnostic to image semantics. Defusion then uses these visual instructions to guide a diffusion-based model that operates directly in the degradation space, where it reconstructs high-quality images by denoising the degradation effects with enhanced stability and generalizability. Comprehensive experiments demonstrate that Defusion outperforms state-of-the-art methods across diverse image restoration tasks, including complex and real-world degradations.", "authors": ["Wenbo Luo", "Haina Qin", "Zewen Chen", "Libin Wang", "Dandan Zheng", "Yuming Li", "Yufan Liu", "Bing Li", "Weiming Hu"], "year": 2025, "venue": "", "cited_by_count": 2, "type": "article", "concepts": ["Degradation (telecommunications)", "Image restoration", "Computer science", "Diffusion", "Computer vision"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W3028960763", "doi": "https://doi.org/10.1038/s41580-020-0251-y", "title": "RNA delivery by extracellular vesicles in mammalian cells and its applications", "abstract": "", "authors": ["Killian P. O’Brien", "Koen Breyne", "Stefano Ughetto", "Louise C. Laurent", "Xandra O. Breakefield"], "year": 2020, "venue": "Nature Reviews Molecular Cell Biology", "cited_by_count": 1723, "type": "review", "concepts": ["Microvesicles", "Extracellular vesicle", "Extracellular", "Cell biology", "Vesicle"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W3197735684", "doi": "https://doi.org/10.5751/es-12625-260319", "title": "The role of Indigenous peoples and local communities in effective and equitable conservation", "abstract": "Dawson, N. M., B. Coolsaet, E. J. Sterling, R. Loveridge, N. D. Gross-Camp, S. Wongbusarakum, K. K. Sangha, L. M. Scherl, H. Phuong Phan, N. Zafra-Calvo, W. G. Lavey, P. Byakagaba, C. J. Idrobo, A. Chenet, N. J. Bennett, S. Mansourian, and F. J. Rosado-May. 2021. The role of Indigenous peoples and local communities in effective and equitable conservation. Ecology and Society 26(3):19. https://doi.org/10.5751/ES-12625-260319", "authors": ["Neil Dawson", "Brendan Coolsaet", "Eleanor J. Sterling", "Robin Loveridge", "Gross-Camp Nicole D", "Supin Wongbusarakum", "Kamaljit K. Sangha", "Lea M. Scherl", "Hao Phuong Phan", "Noelia Zafra‐Calvo", "Warren G. Lavey", "Patrick Byakagaba", "C. Julián Idrobo", "Aude Chenet", "Nathan Bennett", "Stéphanie Mansourian", "Francisco J. Rosado-May"], "year": 2021, "venue": "Ecology and Society", "cited_by_count": 775, "type": "article", "concepts": ["Indigenous", "Ecology", "Geography", "Political science", "Socioeconomics"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2976035075", "doi": null, "title": "IMAGE RESTORATIONS USING DEEP LEARNING TECHNIQUES", "abstract": "Conventional methods for solving image restoration problems are typically built on an image degradation model and on some priors of the latent image. The model of the degraded image and the prior knowledge of the latent image are necessary because the restoration is an ill posted inverse problem. However, for some applications, such as those addressed in this thesis, the image degradation process is too complex to model precisely; in addition, mathematical priors, such as low rank and sparsity of the image signal, are often too idealistic for real world images. These difficulties limit the performance of existing image restoration algorithms, but they can be, to certain extent, overcome by the techniques of machine learning, particularly deep convolutional neural networks. Machine learning allows large sample statistics far beyond what is available in a single input image to be exploited. More importantly, the big data can be used to train deep neural networks to learn the complex non-linear mapping between the degraded and original images. This circumvents the difficulty of building an explicit realistic mathematical model when the degradation causes are complex and compounded. In this thesis, we design and implement deep convolutional neural networks (DCNN) for two challenging image restoration problems: reflection removal and joint demosaicking-deblurring. The first problem is one of blind source separation; its DCNN solution requires a large set of paired clean and mixed images for training. As these paired training images are very difficult, if not impossible, to acquire in the real world, we develop a novel technique to synthesize the required training images that satisfactorily approximate the real ones. For the joint demosaicking-deblurring problem, we propose a new multiscale DCNN architecture consisting of a cascade of subnetworks so that the underlying blind deconvolution task can be broken into smaller subproblems and solved more effectively and robustly. In both cases extensive experiments are carried out. Experimental results demonstrate clear advantages of the proposed DCNN methods over existing ones.", "authors": ["Zhixiang Chi"], "year": 2018, "venue": "MacSphere (McMaster University)", "cited_by_count": 1, "type": "dissertation", "concepts": ["Artificial intelligence", "Deep learning", "Computer science", "Dentistry", "Orthodontics"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4390650730", "doi": "https://doi.org/10.1007/s10462-023-10631-z", "title": "Deep learning models for digital image processing: a review", "abstract": "", "authors": ["R Archana", "P. S. Eliahim Jeevaraj"], "year": 2024, "venue": "Artificial Intelligence Review", "cited_by_count": 442, "type": "review", "concepts": ["Computer science", "Interpretability", "Artificial intelligence", "Machine learning", "Image processing"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4413013541", "doi": "https://doi.org/10.1038/s41598-025-14581-0", "title": "Real-world super-resolution with VLM-based degradation prior learning", "abstract": "", "authors": ["Xiaxu Chen", "De-kang Mao", "Jun Ke"], "year": 2025, "venue": "Scientific Reports", "cited_by_count": 1, "type": "article", "concepts": ["Degradation (telecommunications)", "Computer science", "Resolution (logic)", "Artificial intelligence", "Telecommunications"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2130747214", "doi": "https://doi.org/10.1016/j.femsre.2003.08.001", "title": "Ecology of prokaryotic viruses", "abstract": "The finding that total viral abundance is higher than total prokaryotic abundance and that a significant fraction of the prokaryotic community is infected with phages in aquatic systems has stimulated research on the ecology of prokaryotic viruses and their role in ecosystems. This review treats the ecology of prokaryotic viruses ('phages') in marine, freshwater and soil systems from a 'virus point of view'. The abundance of viruses varies strongly in different environments and is related to bacterial abundance or activity suggesting that the majority of the viruses found in the environment are typically phages. Data on phage diversity are sparse but indicate that phages are extremely diverse in natural systems. Lytic phages are predators of prokaryotes, whereas lysogenic and chronic infections represent a parasitic interaction. Some forms of lysogeny might be described best as mutualism. The little existing ecological data on phage populations indicate a large variety of environmental niches and survival strategies. The host cell is the main resource for phages and the resource quality, i.e., the metabolic state of the host cell, is a critical factor in all steps of the phage life cycle. Virus-induced mortality of prokaryotes varies strongly on a temporal and spatial scale and shows that phages can be important predators of bacterioplankton. This mortality and the release of cell lysis products into the environment can strongly influence microbial food web processes and biogeochemical cycles. Phages can also affect host diversity, e.g., by 'killing the winner' and keeping in check competitively dominant species or populations. Moreover, they mediate gene transfer between prokaryotes, but this remains largely unknown in the environment. Genomics or proteomics are providing us now with powerful tools in phage ecology, but final testing will have to be performed in the environment.", "authors": ["Markus G. Weinbauer"], "year": 2003, "venue": "FEMS Microbiology Reviews", "cited_by_count": 1742, "type": "review", "concepts": ["Biology", "Lysogenic cycle", "Lytic cycle", "Ecology", "Microbial ecology"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2475009926", "doi": "https://doi.org/10.1016/j.cirp.2016.05.004", "title": "Design for Additive Manufacturing: Trends, opportunities, considerations, and constraints", "abstract": "", "authors": ["Mary Kathryn Thompson", "Giovanni Moroni", "Tom Vaneker", "Georges Fadel", "R.I. Campbell", "Ian Gibson", "Alain Bernard", "Joachim Schulz", "Patricia Graf", "Bhrigu Ahuja", "Filomeno Martina"], "year": 2016, "venue": "CIRP Annals", "cited_by_count": 1859, "type": "article", "concepts": ["Manufacturing engineering", "Process (computing)", "Key (lock)", "Production (economics)", "Advanced manufacturing"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2045561515", "doi": "https://doi.org/10.3389/fnhum.2015.00003", "title": "fNIRS-based brain-computer interfaces: a review", "abstract": "A brain-computer interface (BCI) is a communication system that allows the use of brain activity to control computers or other external devices. It can, by bypassing the peripheral nervous system, provide a means of communication for people suffering from severe motor disabilities or in a persistent vegetative state. In this paper, brain-signal generation tasks, noise removal methods, feature extraction/selection schemes, and classification techniques for fNIRS-based BCI are reviewed. The most common brain areas for fNIRS BCI are the primary motor cortex and the prefrontal cortex. In relation to the motor cortex, motor imagery tasks were preferred to motor execution tasks since possible proprioceptive feedback could be avoided. In relation to the prefrontal cortex, fNIRS showed a significant advantage due to no hair in detecting the cognitive tasks like mental arithmetic, music imagery, emotion induction, etc. In removing physiological noise in fNIRS data, band-pass filtering was mostly used. However, more advanced techniques like adaptive filtering, independent component analysis (ICA), multi optodes arrangement, etc. are being pursued to overcome the problem that a band-pass filter cannot be used when both brain and physiological signals occur within a close band. In extracting features related to the desired brain signal, the mean, variance, peak value, slope, skewness, and kurtosis of the noised-removed hemodynamic response were used. For classification, the linear discriminant analysis method provided simple but good performance among others: support vector machine (SVM), hidden Markov model (HMM), artificial neural network, etc. fNIRS will be more widely used to monitor the occurrence of neuro-plasticity after neuro-rehabilitation and neuro-stimulation. Technical breakthroughs in the future are expected via bundled-type probes, hybrid EEG-fNIRS BCI, and through the detection of initial dips.", "authors": ["Noman Naseer", "Keum‐Shik Hong"], "year": 2015, "venue": "Frontiers in Human Neuroscience", "cited_by_count": 963, "type": "review", "concepts": ["Brain–computer interface", "Computer science", "Motor imagery", "Functional near-infrared spectroscopy", "Artificial intelligence"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2023696667", "doi": "https://doi.org/10.1007/s13593-011-0065-6", "title": "Agroecologically efficient agricultural systems for smallholder farmers: contributions to food sovereignty", "abstract": "", "authors": ["Miguel A. Altieri", "Fernando R. Funes-Monzote", "Paulo Petersen"], "year": 2011, "venue": "Agronomy for Sustainable Development", "cited_by_count": 752, "type": "article", "concepts": ["Agroecology", "Food security", "Food sovereignty", "Agricultural biodiversity", "Agriculture"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W3207673409", "doi": "https://doi.org/10.1016/j.inffus.2021.09.005", "title": "Real-world single image super-resolution: A brief review", "abstract": "", "authors": ["Honggang Chen", "Xiaohai He", "Linbo Qing", "Yuanyuan Wu", "Chao Ren", "Ray E. Sheriff", "Ce Zhu"], "year": 2021, "venue": "Information Fusion", "cited_by_count": 361, "type": "review", "concepts": ["Computer science", "Benchmark (surveying)", "Superresolution", "Artificial intelligence", "Image (mathematics)"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4319080562", "doi": "https://doi.org/10.1038/s41467-023-36197-6", "title": "Direct regeneration of degraded lithium-ion battery cathodes with a multifunctional organic lithium salt", "abstract": "", "authors": ["Guanjun Ji", "Junxiong Wang", "Zheng Liang", "Kai Jia", "Jun Ma", "Zhaofeng Zhuang", "Guangmin Zhou", "Hui–Ming Cheng"], "year": 2023, "venue": "Nature Communications", "cited_by_count": 434, "type": "article", "concepts": ["Lithium (medication)", "Materials science", "Cathode", "Battery (electricity)", "Chemical engineering"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2140169405", "doi": "https://doi.org/10.3389/fmicb.2013.00314", "title": "Biomineralization of calcium carbonates and their engineered applications: a review", "abstract": "Microbially induced calcium carbonate precipitation (MICCP) is a naturally occurring biological process in which microbes produce inorganic materials as part of their basic metabolic activities. This technology has been widely explored and promising with potential in various technical applications. In the present review, the detailed mechanism of production of calcium carbonate biominerals by ureolytic bacteria has been discussed along with role of bacteria and the sectors where these biominerals are being used. The applications of bacterially produced carbonate biominerals for improving the durability of buildings, remediation of environment (water and soil), sequestration of atmospheric CO2 filler material in rubbers and plastics etc. are discussed. The study also sheds light on benefits of bacterial biominerals over traditional agents and also the issues that lie in the path of successful commercialization of the technology of microbially induced calcium carbonate precipitation from lab to field scale.", "authors": ["Navdeep Kaur Dhami", "M. Sudhakara Reddy", "Abhijit Mukherjee"], "year": 2013, "venue": "Frontiers in Microbiology", "cited_by_count": 700, "type": "review", "concepts": ["Biomineralization", "Calcium carbonate", "Environmental remediation", "Precipitation", "Carbonate"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2102547670", "doi": "https://doi.org/10.1016/j.jenvman.2011.06.028", "title": "Landscape – wildfire interactions in southern Europe: Implications for landscape management", "abstract": "", "authors": ["Francisco Moreira", "Olga Viedma", "Μαργαρίτα Αριανούτσου", "Thomas Curt", "Nikos Koutsias", "Éric Rigolot", "Anna Barbati", "Piermaria Corona", "Pedro G. Vaz", "Gavriil Xanthopoulos", "Florent Mouillot", "Ertugrul Bilgili"], "year": 2011, "venue": "Journal of Environmental Management", "cited_by_count": 886, "type": "review", "concepts": ["Shrubland", "Geography", "Environmental resource management", "Land cover", "Land use"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4385691013", "doi": "https://doi.org/10.1038/s41586-023-06406-9", "title": "Diverse values of nature for sustainability", "abstract": "", "authors": ["Unai Pascual", "Patricia Balvanera", "Christopher B. Anderson", "Rebecca Chaplin‐Kramer", "Mike Christie", "David González-Jiménez", "Adrián Martín", "Christopher M. Raymond", "Mette Termansen", "Arild Vatn", "Simone Athayde", "Brigitte Baptiste", "David N. Barton", "Sander Jacobs", "Eszter Kelemen", "Ritesh Kumar", "Elena Lazos", "Tuyeni H. Mwampamba", "Barbara Nakangu", "Patrick O’Farrell", "Suneetha M. Subramanian", "Meine van Noordwijk", "SoEun Ahn", "Sacha Amaruzaman", "Ariane Amin", "Paola Arias‐Arévalo", "Gabriela Arroyo-Robles", "Mariana Cantú-Fernández", "Antonio Arjona Castro", "Victoria Contreras", "Alta De Vos", "Nicolas Dendoncker", "Stefanie Engel", "Uta Eser", "Daniel P. Faith", "Anna Filyushkina", "Houda Ghazi", "Erik Gómez‐Baggethun", "Rachelle K. Gould", "Louise Guibrunet", "Haripriya Gundimeda", "Thomas P. Hahn", "Zuzana V. Harmáčková", "Marcello Hernández‐Blanco", "Andra‐Ioana Horcea‐Milcu", "Mariaelena Huambachano", "Natalia Lutti Hummel Wicher", "Cem İskender Aydın", "Mine Işlar", "Ann‐Kathrin Koessler", "Jasper O. Kenter", "Marina Kosmus", "Heera Lee", "Beria Leimona", "Sharachchandra Lélé", "Dominic Lenzi", "Bosco Lliso", "Lelani Mannetti", "Juliana Merçon", "Ana Sofía Monroy‐Sais", "Nibedita Mukherjee", "Barbara Muraca", "Roldán Muradian", "Ranjini Murali", "Sara Nelson", "Gabriel R. Nemogá", "Jonas Ngouhouo Poufoun", "Aidin Niamir", "Emmanuel Nuesiri", "Tobias Ochieng Nyumba", "Begüm Özkaynak", "Ignacio Palomo", "Ram Pandit", "Agnieszka Pawłowska-Mainville", "Luciana Porter‐Bolland", "Martin F. Quaas", "Julian Rode", "Ricardo Rozzi", "Sonya Sachdeva", "Aibek Samakov", "Marije Schaafsma", "Nadia Sitas", "Paula Ungar", "Evonne Yiu", "Yuki Yoshida", "Eglée L. Zent"], "year": 2023, "venue": "Nature", "cited_by_count": 548, "type": "article", "concepts": ["Sustainability", "Biology", "Ecology"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2884616676", "doi": "https://doi.org/10.1016/j.addr.2018.07.007", "title": "Tumor targeting via EPR: Strategies to enhance patient responses", "abstract": "", "authors": ["Susanne K. Golombek", "Jan‐Niklas May", "Benjamin Theek", "Lia Appold", "Natascha Drude", "Fabian Kießling", "Twan Lammers"], "year": 2018, "venue": "Advanced Drug Delivery Reviews", "cited_by_count": 1166, "type": "review", "concepts": ["Nanomedicine", "Medicine", "Electron paramagnetic resonance", "Nanotechnology", "Computational biology"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4413156658", "doi": "https://doi.org/10.1109/cvpr52734.2025.00701", "title": "OSMamba: Omnidirectional Spectral Mamba with Dual-Domain Prior Generator for Exposure Correction", "abstract": "Exposure correction is a fundamental problem in computer vision and image processing. Recently, frequency domainbased methods have achieved impressive improvement, yet they still struggle with complex real-world scenarios under extreme exposure conditions. This is due to the local convolutional receptive fields failing to model long-range dependencies in the spectrum, and the non-generative learning paradigm being inadequate for retrieving lost details from severely degraded regions. In this paper, we propose Omnidirectional Spectral Mamba (OSMamba), a novel exposure correction network that incorporates the advantages of state space models and generative diffusion models to address these limitations. Specifically, OSMamba introduces an omnidirectional spectral scanning mechanism that adapts Mamba to the frequency domain to capture comprehensive long-range dependencies in both the amplitude and phase spectra of deep image features, hence enhancing illumination correction and structure recovery. Furthermore, we develop a dual-domain prior generator that learns from well-exposed images to generate a degradation-free diffusion prior containing correct information about severely under- and over-exposed regions for better detail restoration. Extensive experiments on multiple-exposure and mixed-exposure datasets demonstrate that the proposed OSMamba achieves state-of-the-art performance both quantitatively and qualitatively. Our code and models can be found at https://github.com/cvsym/OSMamba.", "authors": ["Gehui Li", "Bin Chen", "Chen Zhao", "Lei Zhang", "Jian Zhang"], "year": 2025, "venue": "", "cited_by_count": 2, "type": "article", "concepts": ["Generator (circuit theory)", "Dual (grammatical number)", "Omnidirectional antenna", "Computer science", "Physics"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4210916416", "doi": "https://doi.org/10.1145/3485128", "title": "Tackling Climate Change with Machine Learning", "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning experts, may wonder how we can help. Here we describe how machine learning can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by machine learning, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the machine learning community to join the global effort against climate change.", "authors": ["David Rolnick", "Priya L. Donti", "Lynn H. Kaack", "Kelly Kochanski", "Alexandre Lacoste", "Kris Sankaran", "Andrew Slavin Ross", "Nikola Milojevic-Dupont", "Natasha Jaques", "Anna Waldman‐Brown", "Alexandra Sasha Luccioni", "Tegan Maharaj", "Evan David Sherwin", "S. Karthik Mukkavilli", "Konrad P. Körding", "Carla P. Gomes", "Andrew Y. Ng", "Demis Hassabis", "John Platt", "Felix Creutzig", "Jennifer Chayes", "Yoshua Bengio"], "year": 2022, "venue": "OPUS 4 (Zuse Institute Berlin)", "cited_by_count": 759, "type": "review", "concepts": ["Climate change", "Wonder", "Computer science", "Greenhouse gas", "Join (topology)"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2737364956", "doi": "https://doi.org/10.1039/c7cs00363c", "title": "Promises, facts and challenges for graphene in biomedical applications", "abstract": "The graphene family has captured the interest and the imagination of an increasing number of scientists working in different fields, ranging from composites to flexible electronics. In the area of biomedical applications, graphene is especially involved in drug delivery, biosensing and tissue engineering, with strong contributions to the whole nanomedicine area. Besides the interesting results obtained so far and the evident success, there are still many problems to solve, on the way to the manufacturing of biomedical devices, including the lack of standardization in the production of the graphene family members. Control of lateral size, aggregation state (single vs. few layers) and oxidation state (unmodified graphene vs. oxidized graphenes) is essential for the translation of this material into clinical assays. In this Tutorial Review we critically describe the latest developments of the graphene family materials into the biomedical field. We analyze graphene-based devices starting from graphene synthetic strategies, functionalization and processibility protocols up to the final in vitro and in vivo applications. We also address the toxicological impact and the limitations in translating graphene materials into advanced clinical tools. Finally, new trends and guidelines for future developments are presented.", "authors": ["Giacomo Reina", "José M. González‐Domínguez", "Alejandro Criado", "Ester Vázquez", "Alberto Bianco", "Maurizio Prato"], "year": 2017, "venue": "Chemical Society Reviews", "cited_by_count": 691, "type": "review", "concepts": ["Graphene", "Nanotechnology", "Drug delivery", "Materials science", "Computer science"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W41464513", "doi": "https://doi.org/10.17528/cifor/002601", "title": "Moving ahead with REDD: issues, options and implications", "abstract": "This book has been produced in just two months thanks to the enthusiasm", "authors": ["Arild Angelsen", "(eds.)"], "year": 2008, "venue": "Center for International Forestry Research (CIFOR) eBooks", "cited_by_count": 606, "type": "book", "concepts": ["Computer science", "Environmental science"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W4409964091", "doi": "https://doi.org/10.5455/jjcit.71-1735034495", "title": "Study of Recent Image Restoration Techniques: A Comprehensive Survey", "abstract": "The rapid advancements in digital imaging technologies have created a growing demand for effective image restoration techniques. Various kinds of degradation, including noise, blur, and low resolution, should be handled with these techniques. Restoration is important in many applications, including medical imaging, surveillance, photography, and remote sensing, where image quality will be critical to the correctness of analysis and decision. This article provides an all-inclusive review of state-of-the-art (SOTA) methods in image restoration, covering traditional methods as well as modern techniques like deep learning and transformer-based models. Traditional image restoration techniques include deblurring, denoising, and super-resolution based on mathematical models and handcrafted algorithms. These methods were indeed effective for certain types of noise or blur but generalized poorly to various real-world scenarios. Recent advances in machine learning (ML), especially deep learning (DL) using convolutional neural networks (CNNs), have made data-driven approaches that learn directly from large datasets much more effective. Recently, transformer-based models-Vision Transformers and Swin Transformers-have shown the ability to capture global dependencies in images, leading to superior performance on complex restoration tasks. It also mentions the challenge of generalization across the type of degradation, say mixed noise or blur, and across different datasets. The proposed survey indicates the limitations of existing approaches, including computational cost and generalization challenges, and offers insights into possible directions for future research. Considering these challenges and achievements, this article attempts to provide helpful guidance on methods for future research on restoring images.", "authors": ["Nikita Singhal", "Anup Kadam", "Pravesh Kumar", "HARKIRAT SINGH", "A. N. Thakur", "Pranay Pranay"], "year": 2025, "venue": "Jordanian Journal of Computers and Information Technology", "cited_by_count": 1, "type": "article", "concepts": ["Image restoration", "Computer science", "Image (mathematics)", "Psychology", "Artificial intelligence"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W1673751863", "doi": "https://doi.org/10.1111/brv.12140", "title": "The return of metabolism: biochemistry and physiology of the pentose phosphate pathway", "abstract": "The pentose phosphate pathway (PPP) is a fundamental component of cellular metabolism. The PPP is important to maintain carbon homoeostasis, to provide precursors for nucleotide and amino acid biosynthesis, to provide reducing molecules for anabolism, and to defeat oxidative stress. The PPP shares reactions with the Entner-Doudoroff pathway and Calvin cycle and divides into an oxidative and non-oxidative branch. The oxidative branch is highly active in most eukaryotes and converts glucose 6-phosphate into carbon dioxide, ribulose 5-phosphate and NADPH. The latter function is critical to maintain redox balance under stress situations, when cells proliferate rapidly, in ageing, and for the 'Warburg effect' of cancer cells. The non-oxidative branch instead is virtually ubiquitous, and metabolizes the glycolytic intermediates fructose 6-phosphate and glyceraldehyde 3-phosphate as well as sedoheptulose sugars, yielding ribose 5-phosphate for the synthesis of nucleic acids and sugar phosphate precursors for the synthesis of amino acids. Whereas the oxidative PPP is considered unidirectional, the non-oxidative branch can supply glycolysis with intermediates derived from ribose 5-phosphate and vice versa, depending on the biochemical demand. These functions require dynamic regulation of the PPP pathway that is achieved through hierarchical interactions between transcriptome, proteome and metabolome. Consequently, the biochemistry and regulation of this pathway, while still unresolved in many cases, are archetypal for the dynamics of the metabolic network of the cell. In this comprehensive article we review seminal work that led to the discovery and description of the pathway that date back now for 80 years, and address recent results about genetic and metabolic mechanisms that regulate its activity. These biochemical principles are discussed in the context of PPP deficiencies causing metabolic disease and the role of this pathway in biotechnology, bacterial and parasite infections, neurons, stem cell potency and cancer metabolism.", "authors": ["Anna Stincone", "Alessandro Prigione", "Thorsten Cramer", "Mirjam M. C. Wamelink", "Kate Campbell", "Eric C. Cheung", "Viridiana Olín‐Sandoval", "Nana‐Maria Grüning", "Antje Krüger", "Mohammad Tauqeer Alam", "Markus A. Keller", "Michael Breitenbach", "Kevin M. Brindle", "Joshua D. Rabinowitz", "Markus Ralser"], "year": 2014, "venue": "Biological reviews/Biological reviews of the Cambridge Philosophical Society", "cited_by_count": 1456, "type": "review", "concepts": ["Pentose phosphate pathway", "Biochemistry", "Oxidative phosphorylation", "Glycolysis", "Metabolism"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W2059612594", "doi": "https://doi.org/10.1016/j.cviu.2015.02.008", "title": "Optical flow modeling and computation: A survey", "abstract": "", "authors": ["Denis Fortun", "Patrick Bouthémy", "Charles Kervrann"], "year": 2015, "venue": "Computer Vision and Image Understanding", "cited_by_count": 403, "type": "article", "concepts": ["Computer science", "Computation", "Optical flow", "Estimation", "Data science"], "search_query": "real world image degradation mixed complex restoration"}
{"openalex_id": "https://openalex.org/W1963936491", "doi": "https://doi.org/10.1038/srep08732", "title": "Recent ecological transitions in China: greening, browning and influential factors", "abstract": "", "authors": ["Yihe Lü", "Liwei Zhang", "Xiaoming Feng", "Yuan Zeng", "Bojie Fu", "Xueling Yao", "Junran Li", "Bingfang Wu"], "year": 2015, "venue": "Scientific Reports", "cited_by_count": 270, "type": "article", "concepts": ["Greening", "China", "Browning", "Ecology", "Geography"], "search_query": "real world image degradation mixed complex restoration"}

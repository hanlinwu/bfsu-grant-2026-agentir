{"openalex_id": "https://openalex.org/W2895357007", "doi": "https://doi.org/10.1101/gad.314617.118", "title": "Roles of the immune system in cancer: from tumor initiation to metastatic progression", "authors": ["Hugo González", "Catharina Hagerling", "Zena Werb"], "year": 2018, "venue": "Genes & Development", "cited_by_count": 2085, "type": "review", "concepts": ["Immune system", "Biology", "Cancer", "Cytotoxic T cell", "Cancer research"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Cancer immunology paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2768033029", "doi": "https://doi.org/10.1083/jcb.201708092", "title": "Senescence and aging: Causes, consequences, and therapeutic avenues", "authors": ["Domhnall McHugh", "Jesús Gil"], "year": 2017, "venue": "The Journal of Cell Biology", "cited_by_count": 1184, "type": "review", "concepts": ["Senescence", "Disease", "Biology", "Cellular senescence", "Cancer"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Cell biology paper on aging/senescence, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W1977276601", "doi": "https://doi.org/10.1111/j.1442-8903.2006.00285.x", "title": "The meanings of vegetation condition", "authors": ["David A. Keith", "Emma Gorrod"], "year": 2006, "venue": "Ecological Management & Restoration", "cited_by_count": 27, "type": "article", "concepts": ["Vegetation (pathology)", "Clearing", "Payment", "Meaning (existential)", "Incentive"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Ecology paper on vegetation condition, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4226042837", "doi": "https://doi.org/10.1609/aaai.v36i2.20072", "title": "Image-Adaptive YOLO for Object Detection in Adverse Weather Conditions", "authors": ["Wenyu Liu", "Gaofeng Ren", "Runsheng Yu", "Shi Guo", "Jianke Zhu", "Lei Zhang"], "year": 2022, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 496, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Object detection", "Convolutional neural network", "Code (set theory)"], "search_query": "all-in-one image restoration unified model degradation", "score": 4, "subtopic": "", "rationale": "Jointly learns image enhancement and object detection for adverse weather; uses differentiable image processing. Adjacent to restoration for perception but not a restoration-focused method.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "IA-YOLO: differentiable image processing module predicted by CNN-PP, jointly trained with YOLOv3", "key_findings": "Adaptive enhancement improves detection in foggy/low-light scenarios", "limitations": "Task focus is detection, not restoration quality per se"}}
{"openalex_id": "https://openalex.org/W2004936701", "doi": "https://doi.org/10.1097/01.blo.0000175122.50804.ce", "title": "Local Antibiotic Delivery Systems", "authors": ["Arlen D. Hanssen", "Douglas R. Osmon", "Robin Patel"], "year": 2005, "venue": "Clinical Orthopaedics and Related Research", "cited_by_count": 67, "type": "article", "concepts": ["Antibiotics", "Medicine", "Intensive care medicine", "Dosing", "Adverse effect"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Medical/orthopaedic paper on antibiotic delivery, completely unrelated.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2890970077", "doi": "https://doi.org/10.1038/s41396-019-0383-2", "title": "Agricultural intensification reduces microbial network complexity and the abundance of keystone taxa in roots", "authors": ["Samiran Banerjee", "Florian Walder", "Lucie Büchi", "Marcel Meyer", "Alain Held", "Andreas Gattinger", "Thomas Keller", "Raphaël Charles", "Marcel G. A. van der Heijden"], "year": 2019, "venue": "The ISME Journal", "cited_by_count": 1236, "type": "article", "concepts": ["Biology", "Agroecosystem", "Keystone species", "Abundance (ecology)", "Organic farming"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Microbiology/ecology paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2050839858", "doi": "https://doi.org/10.1161/01.cir.100.9.999", "title": "Mechanisms and Models in Heart Failure", "authors": ["Douglas L. Mann"], "year": 1999, "venue": "Circulation", "cited_by_count": 773, "type": "review", "concepts": ["Medicine", "Heart failure", "Cardiology", "Intensive care medicine", "Internal medicine"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Cardiology paper on heart failure, completely unrelated.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4417248878", "doi": "https://doi.org/10.1109/tpami.2025.3642852", "title": "Beyond Degradation Redundancy: Contrastive Prompt Learning for All-in-One Image Restoration", "authors": ["Gang Wu", "Junjun Jiang", "Kui Jiang", "Xianming Liu", "Liqiang Nie"], "year": 2025, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 1, "type": "article", "concepts": [], "search_query": "all-in-one image restoration unified model degradation", "score": 8, "subtopic": "All-in-One Restoration", "rationale": "Directly addresses all-in-one image restoration with contrastive prompt learning to reduce degradation redundancy, published in TPAMI. Highly relevant to the unified model track.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "CPL framework: Sparse Prompt Module (SPM) + Contrastive Prompt Regularization (CPR) to strengthen task boundaries", "key_findings": "Achieves state-of-the-art on 5 benchmarks in multi-task and composite degradation settings", "limitations": "Focuses on known degradation types; not agent-based"}}
{"openalex_id": "https://openalex.org/W2397311736", "doi": "https://doi.org/10.5194/hess-21-589-2017", "title": "MSWEP: 3-hourly 0.25° global gridded precipitation (1979–2015) by merging gauge, satellite, and reanalysis data", "authors": ["Hylke E. Beck", "Albert I. J. M. van Dijk", "Vincenzo Levizzani", "Jaap Schellekens", "Diego G. Miralles", "Brecht Martens", "Ad de Roo"], "year": 2017, "venue": "Hydrology and earth system sciences", "cited_by_count": 1060, "type": "article", "concepts": ["Orography", "Environmental science", "Satellite", "Meteorology", "Rain gauge"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Hydrology/meteorology paper on precipitation data, completely unrelated.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4409262098", "doi": "https://doi.org/10.1109/wacv61041.2025.00069", "title": "All-in-One Image Compression and Restoration", "authors": ["H. Zeng", "Jiacheng Li", "Ziqiang Zheng", "Zhiwei Xiong"], "year": 2025, "venue": "", "cited_by_count": 1, "type": "article", "concepts": ["Image restoration", "Image compression", "Computer science", "Computer vision", "Compression (physics)"], "search_query": "all-in-one image restoration unified model degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "Unified framework for all-in-one image compression and restoration handling various degradations. Directly relevant to unified restoration models.", "alignment": {"task": "high", "method": "medium", "modality": "high"}, "extraction": {"design": "Content information aggregation + degradation representation aggregation in a joint compression-restoration framework", "key_findings": "Superior RD performance on various degraded inputs, strong generalization to real-world scenarios", "limitations": "Couples compression with restoration; not applicable to pure restoration pipelines"}}
{"openalex_id": "https://openalex.org/W3089028909", "doi": "https://doi.org/10.1109/jproc.2021.3052449", "title": "A Unifying Review of Deep and Shallow Anomaly Detection", "authors": ["Lukas Ruff", "Jacob R. Kauffmann", "Robert A. Vandermeulen", "Gregoire Montavon", "Wojciech Samek", "Marius Kloft", "Thomas G. Dietterich", "Klaus-Robert Muller"], "year": 2021, "venue": "Proceedings of the IEEE", "cited_by_count": 755, "type": "article", "concepts": [], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Anomaly detection survey, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W1996113298", "doi": "https://doi.org/10.1002/ijc.27316", "title": "Cellular senescence and tumor suppressor gene p16", "authors": ["Hani Rayess", "Marilene B. Wang", "Eri S. Srivatsan"], "year": 2011, "venue": "International Journal of Cancer", "cited_by_count": 793, "type": "review", "concepts": ["Cell biology", "Biology", "Senescence", "Retinoblastoma protein", "E2F1"], "search_query": "all-in-one image restoration unified model degradation", "score": 1, "subtopic": "", "rationale": "Cell biology paper on tumor suppression, completely unrelated.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4405974083", "doi": "https://doi.org/10.1109/tcsi.2024.3519532", "title": "A Unified Accelerator for All-in-One Image Restoration Based on Prompt Degradation Learning", "authors": ["Siyu Zhang", "Qiwei Dong", "Wendong Mao", "Zhongfeng Wang"], "year": 2025, "venue": "IEEE Transactions on Circuits and Systems I Regular Papers", "cited_by_count": 3, "type": "article", "concepts": ["Degradation (telecommunications)", "Image restoration", "Computer science", "Image (mathematics)", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "Algorithm-hardware co-design for all-in-one image restoration with prompt-based degradation learning. Addresses unified multi-task restoration including hardware efficiency.", "alignment": {"task": "high", "method": "medium", "modality": "high"}, "extraction": {"design": "ERFM model + integer approximation + head-stationary dataflow on TSMC 28nm CMOS", "key_findings": "3.3x throughput and 3.7x energy efficiency improvements over vision transformer accelerators", "limitations": "Hardware-specific; prompt learning approach less novel than pure algorithmic contributions"}}
{"openalex_id": "https://openalex.org/W4381798022", "doi": "https://doi.org/10.48550/arxiv.2306.13090", "title": "PromptIR: Prompting for All-in-One Blind Image Restoration", "authors": ["Vaishnav Potlapalli", "Syed Waqas Zamir", "Salman Khan", "Fahad Shahbaz Khan"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 34, "type": "preprint", "concepts": ["Image restoration", "Computer science", "Degradation (telecommunications)", "Image (mathematics)", "Generalization"], "search_query": "prompt-based image restoration learning degradation", "score": 9, "subtopic": "All-in-One Restoration", "rationale": "PromptIR is a key all-in-one blind image restoration method using prompts to encode degradation-specific information. Directly cited in the research theme.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Prompt-based learning module encoding degradation info, dynamically guides restoration network; plug-and-play prompts", "key_findings": "State-of-the-art on denoising, deraining, dehazing with no prior knowledge of corruption type", "limitations": "Blind to composite/mixed degradations; prompt design is task-specific"}}
{"openalex_id": "https://openalex.org/W4405865448", "doi": "https://doi.org/10.1016/j.patcog.2024.111312", "title": "Visual style prompt learning using diffusion models for blind face restoration", "authors": ["Wanglong Lu", "J P Wang", "Tao Wang", "Kaihao Zhang", "Xianta Jiang", "Hanli Zhao"], "year": 2024, "venue": "Pattern Recognition", "cited_by_count": 39, "type": "article", "concepts": ["Face (sociological concept)", "Style (visual arts)", "Computer science", "Artificial intelligence", "Computer vision"], "search_query": "prompt-based image restoration learning degradation", "score": 6, "subtopic": "Diffusion Restoration", "rationale": "Uses diffusion models with visual style prompts for blind face restoration. Combines prompt learning and diffusion for a specific restoration task.", "alignment": {"task": "high", "method": "medium", "modality": "medium"}, "extraction": {"design": "Visual style prompt extraction + diffusion model backbone for blind face restoration", "key_findings": "Improved perceptual quality in blind face restoration benchmark evaluations", "limitations": "Face-specific; not a general image restoration approach"}}
{"openalex_id": "https://openalex.org/W4396782894", "doi": "https://doi.org/10.1109/tcsvt.2024.3398810", "title": "Prompt-Based Ingredient-Oriented All-in-One Image Restoration", "authors": ["Hu Gao", "Jing Yang", "Ying Zhang", "Ning Wang", "Jingfan Yang", "Depeng Dang"], "year": 2024, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 26, "type": "article", "concepts": ["Ingredient", "Image restoration", "Computer science", "Image processing", "Computer vision"], "search_query": "prompt-based image restoration learning degradation", "score": 8, "subtopic": "All-in-One Restoration", "rationale": "All-in-one image restoration method using prompt-based ingredient-oriented learning with CNN-Transformer hybrid. Published in TCSVT.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "CAPTNet: encoder with degradation-specific prompts guiding decoder, CNN+Transformer, multi-head rearranged attention with prompts", "key_findings": "Competitive performance on multiple degradation tasks", "limitations": "Ingredient-oriented approach may not generalize to unseen degradation types"}}
{"openalex_id": "https://openalex.org/W4404844036", "doi": "https://doi.org/10.1016/j.patcog.2024.111223", "title": "FrePrompter: Frequency self-prompt for all-in-one image restoration", "authors": ["Zhijian Wu", "Wenhui Liu", "Jingchao Wang", "Jun Li", "Dingjiang Huang"], "year": 2024, "venue": "Pattern Recognition", "cited_by_count": 14, "type": "article", "concepts": ["Image restoration", "Image (mathematics)", "Artificial intelligence", "Computer vision", "Computer science"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "All-in-one image restoration using frequency-domain self-prompting. Combines frequency analysis with prompt learning for unified restoration.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Frequency-based self-prompt generation for all-in-one restoration without explicit degradation labels", "key_findings": "Achieves good performance across multiple degradation types using frequency prompts", "limitations": "Abstract unavailable; limited details on composite degradation handling"}}
{"openalex_id": "https://openalex.org/W4402915930", "doi": "https://doi.org/10.1109/cvprw63382.2024.00645", "title": "PromptCIR: Blind Compressed Image Restoration with Prompt Learning", "authors": ["Bingchen Li", "Xin Li", "Yiting Lu", "Ruoyu Feng", "Mengxi Guo", "Shijie Zhao", "Zhang Li", "Zhibo Chen"], "year": 2024, "venue": "", "cited_by_count": 17, "type": "article", "concepts": ["Computer science", "Image restoration", "Artificial intelligence", "Computer vision", "Image (mathematics)"], "search_query": "prompt-based image restoration learning degradation", "score": 6, "subtopic": "All-in-One Restoration", "rationale": "Prompt-learning approach for blind compressed image restoration (JPEG artifacts). Related to all-in-one restoration paradigm but specific to compression artifacts.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Prompts encode compression info implicitly, interact with soft weights from image features for dynamic content/distortion-aware guidance", "key_findings": "Won 1st place in NTIRE 2024 blind compressed image enhancement", "limitations": "Specific to compression artifacts, not general multi-degradation restoration"}}
{"openalex_id": "https://openalex.org/W4379141198", "doi": "https://doi.org/10.1016/j.eswa.2023.120646", "title": "Exposing low-quality deepfake videos of Social Network Service using Spatial Restored Detection Framework", "authors": ["Ying Li", "Shan Bian", "Chuntao Wang", "Kemal Polat", "Adi Alhudhaif", "Fayadh Alenezi"], "year": 2023, "venue": "Expert Systems with Applications", "cited_by_count": 26, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Block (permutation group theory)", "Feature (linguistics)", "Quality (philosophy)"], "search_query": "prompt-based image restoration learning degradation", "score": 2, "subtopic": "", "rationale": "Deepfake detection paper; spatial restoration used as preprocessing for detection, not image restoration research.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4406092414", "doi": "https://doi.org/10.1016/j.inffus.2025.102930", "title": "Ada4DIR: An adaptive model-driven all-in-one image restoration network for remote sensing images", "authors": ["Ziyang Lihe", "Qiangqiang Yuan", "Jiang He", "Xianyu Jin", "Yi Xiao", "Yuzeng Chen", "Huanfeng Shen", "Liangpei Zhang"], "year": 2025, "venue": "Information Fusion", "cited_by_count": 5, "type": "article", "concepts": ["Computer science", "Image (mathematics)", "Artificial intelligence", "Image restoration", "Computer vision"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "All-in-one image restoration network for remote sensing, model-driven adaptive approach. Extends unified restoration to remote sensing domain.", "alignment": {"task": "high", "method": "medium", "modality": "medium"}, "extraction": {"design": "Adaptive model-driven all-in-one restoration tailored for remote sensing image degradations", "key_findings": "Effective multi-degradation restoration for remote sensing images", "limitations": "Domain-specific (remote sensing); abstract unavailable"}}
{"openalex_id": "https://openalex.org/W4387486933", "doi": "https://doi.org/10.1109/icamechs59878.2023.10272811", "title": "An Attempt at Zero-shot Ancient Documents Restoration Based on Diffusion Models", "authors": ["Hayata Kaneko", "Yuuya Yoshizu", "Ryuto Ishibashi", "Lin Meng"], "year": 2023, "venue": "", "cited_by_count": 5, "type": "article", "concepts": ["Computer science", "Image restoration", "Masking (illustration)", "Artificial intelligence", "Noise (video)"], "search_query": "prompt-based image restoration learning degradation", "score": 4, "subtopic": "", "rationale": "Uses diffusion models for document restoration in zero-shot setting. Restoration application but domain-specific (ancient documents) and limited technical novelty.", "alignment": {"task": "medium", "method": "medium", "modality": "low"}, "extraction": {"design": "DDRM-based zero-shot restoration with noise masking for ancient document inpainting", "key_findings": "Noise masking improves faithfulness of zero-shot character restoration", "limitations": "Very specific domain; zero-shot approach is application of existing DDRM"}}
{"openalex_id": "https://openalex.org/W4404176632", "doi": "https://doi.org/10.1007/978-3-031-72855-6_11", "title": "UniProcessor: A Text-Induced Unified Low-Level Image Processor", "authors": ["Huiyu Duan", "Xiongkuo Min", "Sijing Wu", "Wei Shen", "Guangtao Zhai"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 6, "type": "book-chapter", "concepts": ["Uniprocessor system", "Computer science", "Image (mathematics)", "Artificial intelligence", "Parallel computing"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "Text-induced unified low-level image processor; uses text/language prompts to guide unified image processing, relevant to the VLM-guided restoration theme.", "alignment": {"task": "high", "method": "medium", "modality": "high"}, "extraction": {"design": "Text prompts induce unified low-level image processing across multiple tasks", "key_findings": "Unified text-guided approach handles multiple low-level vision tasks", "limitations": "Abstract unavailable; details limited"}}
{"openalex_id": "https://openalex.org/W2971398159", "doi": "https://doi.org/10.1111/rec.13035", "title": "International principles and standards for the practice of ecological restoration. Second edition", "authors": ["George D. Gann", "Tein McDonald", "Bethanie Walder", "James Aronson", "Cara R. Nelson", "Justin Jonson", "James G. Hallett", "Cristina Eisenberg", "Manuel R. Guariguata", "Junguo Liu", "Fangyuan Hua", "Cristián Echeverría", "Emily K. Gonzales", "Nancy L. Shaw", "Kris Decleer", "Kingsley W. Dixon"], "year": 2019, "venue": "Restoration Ecology", "cited_by_count": 1302, "type": "article", "concepts": ["Restoration ecology", "Ecology", "Geography", "Environmental resource management", "Environmental ethics"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Ecological restoration paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4411047697", "doi": "https://doi.org/10.1016/j.patcog.2025.111875", "title": "AdaPrompt-IR: Adaptive learning to perceive degradation semantic and prompting for all-in-one image restoration", "authors": ["Wei Sun", "Qianzhou Wang", "Yaqi Wang", "Zhiqiang Hou", "Qingsen Yan", "Shuicheng Yan"], "year": 2025, "venue": "Pattern Recognition", "cited_by_count": 3, "type": "article", "concepts": ["Degradation (telecommunications)", "Computer science", "Artificial intelligence", "Image (mathematics)", "Image restoration"], "search_query": "prompt-based image restoration learning degradation", "score": 8, "subtopic": "All-in-One Restoration", "rationale": "Adaptive prompt-based all-in-one image restoration that perceives degradation semantics for dynamic guidance. Very relevant to unified restoration with semantic awareness.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Adaptive degradation semantic perception + prompt generation for all-in-one restoration", "key_findings": "Semantically adaptive prompts improve restoration across diverse degradation types", "limitations": "Abstract unavailable; details limited"}}
{"openalex_id": "https://openalex.org/W4401444389", "doi": "https://doi.org/10.1007/s11760-024-03493-7", "title": "Rethinking all-in-one adverse weather removal for object detection", "authors": ["Yufeng Li", "Jiayu Chen", "Chuanlong Xie", "Hongming Chen"], "year": 2024, "venue": "Signal Image and Video Processing", "cited_by_count": 4, "type": "article", "concepts": ["Adverse weather", "Object (grammar)", "Computer science", "Artificial intelligence", "Environmental science"], "search_query": "prompt-based image restoration learning degradation", "score": 5, "subtopic": "All-in-One Restoration", "rationale": "Rethinks all-in-one adverse weather removal in the context of improving object detection. Touches on unified restoration but focuses on downstream perception task.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "All-in-one weather removal method evaluated for object detection improvement", "key_findings": "Reconsiders all-in-one restoration objective from detection perspective", "limitations": "Abstract unavailable; task focus is detection not restoration quality"}}
{"openalex_id": "https://openalex.org/W4407677384", "doi": "https://doi.org/10.1016/j.engappai.2025.110267", "title": "Adaptive prompt guided unified image restoration with latent diffusion model", "authors": ["Xiang Lv", "Mingwen Shao", "Yecong Wan", "Yuanjian Qiao", "Changzhong Wang"], "year": 2025, "venue": "Engineering Applications of Artificial Intelligence", "cited_by_count": 4, "type": "article", "concepts": ["Computer science", "Diffusion", "Image (mathematics)", "Image restoration", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation", "score": 8, "subtopic": "Diffusion Restoration", "rationale": "Adaptive prompt-guided unified image restoration using latent diffusion model. Combines diffusion-based restoration with adaptive prompts for multiple degradation types.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Adaptive prompts guide latent diffusion model for unified multi-degradation image restoration", "key_findings": "Effective unified restoration using diffusion priors with adaptive prompt guidance", "limitations": "Abstract unavailable; diffusion inference typically slow"}}
{"openalex_id": "https://openalex.org/W4402915827", "doi": "https://doi.org/10.1109/tcsvt.2024.3469190", "title": "Multi-Weather Restoration: An Efficient Prompt-Guided Convolution Architecture", "authors": ["Chengyang Li", "Fangwei Sun", "Heng Zhou", "Yongqiang Xie", "Zhongbo Li", "Li Zhu"], "year": 2024, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 6, "type": "article", "concepts": ["Architecture", "Convolution (computer science)", "Computer science", "Artificial intelligence", "Geography"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "Efficient prompt-guided convolution architecture for multi-weather restoration. Addresses multiple weather degradations with prompt generation module.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "MW-ConvNet: U-shaped CNN with prompt generation module at encoder terminus, wavelet pooling for frequency separation", "key_findings": "0.12s/image inference; outperforms transformer/diffusion methods in speed with competitive quality", "limitations": "Pure CNN, lacks global modeling ability of transformers"}}
{"openalex_id": "https://openalex.org/W4311263589", "doi": "https://doi.org/10.5281/zenodo.3553579", "title": "Summary for policymakers of the global assessment report on biodiversity and ecosystem services", "authors": ["IPBES"], "year": 2019, "venue": "Zenodo (CERN European Organization for Nuclear Research)", "cited_by_count": 1078, "type": "report", "concepts": ["Ecosystem services", "Biodiversity", "Ecosystem", "Environmental resource management", "Business"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Biodiversity policy report, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4404635286", "doi": "https://doi.org/10.1016/j.neucom.2024.128955", "title": "Multi-modal degradation feature learning for unified image restoration based on contrastive learning", "authors": ["Lei Chen", "Qibing Xiong", "Wei Zhang", "Xiaoli Liang", "Zhihua Gan", "Lianqing Li", "Xin He"], "year": 2024, "venue": "Neurocomputing", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Feature (linguistics)", "Modal", "Degradation (telecommunications)"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "Multi-modal (visual + text) degradation feature learning for unified image restoration using contrastive learning. Leverages vision-language models for restoration guidance.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "MultiContentNet learns multi-modal features (visual degradation + textual context), used as prompts for restoration network via cross-attention", "key_findings": "State-of-the-art on 6 blind restoration tasks; VLM features improve cross-database restoration", "limitations": "Two-stage approach with separate feature learning adds complexity"}}
{"openalex_id": "https://openalex.org/W4415124039", "doi": "https://doi.org/10.1109/tits.2025.3617507", "title": "Frequency-Prompted Image Restoration to Enhance Perception in Intelligent Transportation Systems", "authors": ["Yuning Cui", "Mingyu Liu", "Xiongfei Su", "Alois Knoll"], "year": 2025, "venue": "IEEE Transactions on Intelligent Transportation Systems", "cited_by_count": 2, "type": "article", "concepts": [], "search_query": "prompt-based image restoration learning degradation", "score": 6, "subtopic": "All-in-One Restoration", "rationale": "Frequency prompt approach for image restoration targeting intelligent transportation; plug-and-play module compatible with CNN/Transformer backbones.", "alignment": {"task": "high", "method": "medium", "modality": "medium"}, "extraction": {"design": "Frequency prompt generation module + dual-dimension attention integration as plug-in; applicable to CNN and Transformer backbones", "key_findings": "SOTA on 15 datasets for 5 restoration tasks; generalizes to composite degradation", "limitations": "Domain-specific evaluation (ITS); frequency-only prompts may miss semantic degradation info"}}
{"openalex_id": "https://openalex.org/W4394617226", "doi": "https://doi.org/10.3389/fmars.2024.1382147", "title": "Learning degradation-aware visual prompt for maritime image restoration under adverse weather conditions", "authors": ["Xin He", "Tong Jia", "Junjie Li"], "year": 2024, "venue": "Frontiers in Marine Science", "cited_by_count": 1, "type": "article", "concepts": ["Adverse weather", "Degradation (telecommunications)", "Environmental science", "Computer science", "Meteorology"], "search_query": "prompt-based image restoration learning degradation", "score": 5, "subtopic": "All-in-One Restoration", "rationale": "Prompt-based degradation-aware learning for maritime image restoration under adverse weather. Domain-specific but uses the same prompt learning paradigm.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "Soft-prompt technology generates learnable visual parameters conditioned on weather degradation cues; restoration + prompting modules", "key_findings": "Superior performance on maritime dehazing and deraining tasks", "limitations": "Domain-specific (maritime); limited generalization"}}
{"openalex_id": "https://openalex.org/W4399740511", "doi": "https://doi.org/10.3390/electronics13122346", "title": "Underwater Fish Object Detection with Degraded Prior Knowledge", "authors": ["Shijian Zheng", "Rujing Wang", "Liusan Wang"], "year": 2024, "venue": "Electronics", "cited_by_count": 5, "type": "article", "concepts": ["Underwater", "Fish <Actinopterygii>", "Object (grammar)", "Computer science", "Object detection"], "search_query": "prompt-based image restoration learning degradation", "score": 3, "subtopic": "", "rationale": "Underwater fish detection using degradation prior knowledge. Tangentially related (uses prompt-based degradation features) but focused on detection, not restoration.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4404338208", "doi": "https://doi.org/10.48550/arxiv.2410.18666", "title": "DreamClear: High-Capacity Real-World Image Restoration with Privacy-Safe Dataset Curation", "authors": ["Yuang Ai", "Xiaoqiang Zhou", "Huaibo Huang", "Xiaotian Han", "Zhengyu Chen", "Quanzeng You", "Hongxia Yang"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 2, "type": "preprint", "concepts": ["Computer science", "Image (mathematics)", "Privacy protection", "Internet privacy", "Data science"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "Real-World Degradation", "rationale": "DiT-based real-world image restoration using MLLM perceptual capabilities and Mixture of Adaptive Modulator for diverse real-world degradations. Combines MLLMs with restoration.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "GenIR data pipeline + DreamClear DiT model with MoAM (token-wise degradation priors to integrate restoration experts)", "key_findings": "Superior real-world restoration; privacy-safe 1M image dataset; handles diverse degradations via MoAM", "limitations": "Large model scale; data curation pipeline is complex"}}
{"openalex_id": "https://openalex.org/W3171835979", "doi": "https://doi.org/10.1038/s41573-021-00219-z", "title": "Noncoding RNA therapeutics — challenges and potential solutions", "authors": ["Melanie Winkle", "Sherien M. El-Daly", "Muller Fabbri", "George A. Călin"], "year": 2021, "venue": "Nature Reviews Drug Discovery", "cited_by_count": 1504, "type": "review", "concepts": ["microRNA", "Non-coding RNA", "RNA", "Long non-coding RNA", "Computational biology"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "RNA therapeutics paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4387583542", "doi": "https://doi.org/10.1109/etfa54631.2023.10275673", "title": "Non-Contact Heart Rate Measurement from Deteriorated Videos", "authors": ["Nhi Nguyen", "Le Ngu Nguyen", "Constantino Álvarez Casado", "Olli Sílven", "Miguel Bordallo López"], "year": 2023, "venue": "", "cited_by_count": 4, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Artifact (error)", "Inpainting", "Computer vision"], "search_query": "prompt-based image restoration learning degradation", "score": 2, "subtopic": "", "rationale": "Remote photoplethysmography paper using image restoration as preprocessing. Not a restoration research paper.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4392783067", "doi": "https://doi.org/10.1038/s41392-024-01743-1", "title": "Microbiota–gut–brain axis and its therapeutic applications in neurodegenerative diseases", "authors": ["Jian Sheng Loh", "Wen Qi Mak", "Li Tan", "Chu Xin Ng", "Hong Hao Chan", "Shiau Hueh Yeow", "Jhi Biau Foo", "Yong Sze Ong", "Chee Wun How", "Kooi Yeong Khaw"], "year": 2024, "venue": "Signal Transduction and Targeted Therapy", "cited_by_count": 730, "type": "review", "concepts": ["Gut-brain axis", "Microbiome", "Gut flora", "Neurodegeneration", "Biology"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Neuroscience/microbiology paper, completely unrelated.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4403556433", "doi": "https://doi.org/10.48550/arxiv.2409.03455", "title": "Data-free Distillation with Degradation-prompt Diffusion for Multi-weather Image Restoration", "authors": ["Pei Wang", "Xiaotong Luo", "Yuan Xie", "Yanyun Qu"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 1, "type": "preprint", "concepts": ["Degradation (telecommunications)", "Distillation", "Environmental science", "Diffusion", "Image (mathematics)"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "Knowledge Distillation", "rationale": "Data-free knowledge distillation for multi-weather image restoration using degradation-prompt diffusion. Directly addresses knowledge distillation for image restoration deployment.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "D4IR: degradation-aware prompt adapter + diffusion model to synthesize domain-related images for data-free student distillation", "key_findings": "Achieves comparable performance to distillation with original data; superior to unsupervised methods", "limitations": "Preprint; domain shift between generated and original data remains a challenge"}}
{"openalex_id": "https://openalex.org/W4409367756", "doi": "https://doi.org/10.1609/aaai.v39i5.32587", "title": "UP-Restorer: When Unrolling Meets Prompts for Unified Image Restoration", "authors": ["Minghao Liu", "Wenhan Yang", "Jinyi Luo", "Jiaying Liu"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 1, "type": "article", "concepts": ["Image (mathematics)", "Computer science", "Psychology", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation", "score": 8, "subtopic": "All-in-One Restoration", "rationale": "Unrolling optimization meets prompt learning for all-in-one image restoration. Novel physics-inspired approach combining MAP optimization unrolling with diffusion-based prompt guidance.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Unrolling MAP optimization into score-based diffusion model with dynamically generated prompts for transmission/atmospheric/noise maps", "key_findings": "Significant improvements across multiple restoration tasks; physics-motivated design", "limitations": "Complex architecture combining optimization unrolling with diffusion"}}
{"openalex_id": "https://openalex.org/W4392972181", "doi": "https://doi.org/10.48550/arxiv.2403.11157", "title": "Selective Hourglass Mapping for Universal Image Restoration Based on Diffusion Model", "authors": ["Dian Zheng", "Xiaoming Wu", "Shuzhou Yang", "Jian Zhang", "Jian-Fang Hu", "Wei-Shi Zheng"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Hourglass", "Image restoration", "Image (mathematics)", "Computer vision", "Computer science"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "Diffusion Restoration", "rationale": "Universal image restoration using selective hourglass mapping with diffusion model; shares information across tasks with Shared Distribution Term (SDT).", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "DiffUIR: selective strong condition guidance + SDT to map different degradation distributions to a shared one; reverse maps back with task-specific guidance", "key_findings": "SOTA on 5 restoration tasks, 22 benchmarks; lightweight (0.89M) achieves strong performance", "limitations": "Preprint; diffusion inference cost"}}
{"openalex_id": "https://openalex.org/W2529869467", "doi": "https://doi.org/10.1016/j.scitotenv.2016.09.228", "title": "The EU Water Framework Directive: From great expectations to problems with implementation", "authors": ["Nikolaos Voulvoulis", "Karl Dominic Arpon", "Theodoros Giakoumis"], "year": 2016, "venue": "The Science of The Total Environment", "cited_by_count": 521, "type": "article", "concepts": ["Water Framework Directive", "Directive", "Legislation", "Environmental planning", "Paradigm shift"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Environmental policy paper, completely unrelated.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2904110151", "doi": "https://doi.org/10.1002/wcc.565", "title": "Explaining differential vulnerability to climate change: A social science review", "abstract": "The varied effects of recent extreme weather events around the world exemplify the uneven impacts of climate change on populations, even within relatively small geographic regions. Differential human vulnerability to environmental hazards results from a range of social, economic, historical, and political factors, all of which operate at multiple scales. While adaptation to climate change has been the dominant focus of policy and research agendas, it is essential to ask as well why some communities and peoples are disproportionately exposed to and affected by climate threats. The cases and synthesis presented here are organized around four key themes (resource access, governance, culture, and knowledge), which we approach from four social science fields (cultural anthropology, archaeology, human geography, and sociology). Social scientific approaches to human vulnerability draw vital attention to the root causes of climate change threats and the reasons that people are forced to adapt to them. Because vulnerability is a multidimensional process rather than an unchanging state, a dynamic social approach to vulnerability is most likely to improve mitigation and adaptation planning efforts. This article is categorized under:Vulnerability and Adaptation to Climate Change > Values-Based Approach to Vulnerability and Adaptation.", "authors": ["Kimberley Anh Thomas", "Dean Hardy", "Heather Lazrus", "Michael Méndez", "Ben Orlove", "Isabel Rivera‐Collazo", "J. Timmons Roberts", "Marcy Rockman", "Benjamin P. Warner", "Robert Winthrop"], "year": 2018, "venue": "Wiley Interdisciplinary Reviews Climate Change", "cited_by_count": 794, "type": "review", "concepts": ["Vulnerability (computing)", "Climate change", "Social vulnerability", "Vulnerability assessment", "Adaptation (eye)"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Climate change social science review, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4411445611", "doi": "https://doi.org/10.2139/ssrn.5311960", "title": "Multi-Dimension Visual Prompt Enhanced Image Restoration Network Via Mamba-Transformer Aggregation", "abstract": "", "authors": ["Aiwen Jiang", "Hourong Chen", "Jihua Ye", "Mingwen Wang", "Bo Liu"], "year": 2025, "venue": "SSRN Electronic Journal", "cited_by_count": 1, "type": "preprint", "concepts": ["Transformer", "Dimension (graph theory)", "Image (mathematics)", "Computer science", "Mathematics"], "search_query": "prompt-based image restoration learning degradation", "score": 8, "subtopic": "All-in-One Restoration", "rationale": "Prompt-based image restoration using Mamba-Transformer aggregation, directly relevant to unified/prompt-based restoration.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Mamba-Transformer aggregation with multi-dimension visual prompts", "key_findings": "Enhanced image restoration via visual prompts", "limitations": "SSRN preprint, limited venue prestige"}}
{"openalex_id": "https://openalex.org/W2336023654", "doi": "https://doi.org/10.5751/es-02716-130240", "title": "Adaptive Capacity and Traps", "abstract": "Adaptive capacity is the ability of a living system, such as a social-ecological system, to adjust responses to changing internal demands and external drivers. Although adaptive capacity is a frequent topic of study in the resilience literature, there are few formal models. This paper introduces such a model and uses it to explore adaptive capacity by contrast with the opposite condition, or traps. In a socialecological rigidity trap, strong self-reinforcing controls prevent the flexibility needed for adaptation. In the model, too much control erodes adaptive capacity and thereby increases the risk of catastrophic breakdown. In a social-ecological poverty trap, loose connections prevent the mobilization of ideas and resources to solve problems. In the model, too little control impedes the focus needed for adaptation. Fluctuations of internal demand or external shocks generate pulses of adaptive capacity, which may gain traction and pull the system out of the poverty trap. The model suggests some general properties of traps in social-ecological systems. It is general and flexible, so it can be used as a building block in more specific and detailed models of adaptive capacity for a particular region.", "authors": ["Stephen R. Carpenter", "William A. Brock"], "year": 2008, "venue": "Ecology and Society", "cited_by_count": 475, "type": "article", "concepts": ["Adaptive capacity", "Environmental resource management", "Geography", "Climate change", "Business"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Ecology paper on adaptive capacity in social-ecological systems, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4412488893", "doi": "https://doi.org/10.1109/tpami.2025.3589606", "title": "Re-Boosting Self-Collaboration Parallel Prompt GAN for Unsupervised Image Restoration", "abstract": "Deep learning methods have demonstrated state-of-the-art performance in image restoration, especially when trained on large-scale paired datasets. However, acquiring paired data in real-world scenarios poses a significant challenge. Unsupervised restoration approaches based on generative adversarial networks (GANs) offer a promising solution without requiring paired datasets. Yet, these GAN-based approaches struggle to surpass the performance of conventional unsupervised GAN-based frameworks without significantly modifying model structures or increasing the computational complexity. To address these issues, we propose a self-collaboration (SC) strategy for existing restoration models. This strategy utilizes information from the previous stage as feedback to guide subsequent stages, achieving significant performance improvement without increasing the framework's inference complexity. The SC strategy comprises a prompt learning (PL) module and a restorer ($Res$Res). It iteratively replaces the previous less powerful fixed restorer $\\overline{Res}$Res¯ in the PL module with a more powerful $Res$Res. The enhanced PL module generates better pseudo-degraded/clean image pairs, leading to a more powerful $Res$Res for the next iteration. Our SC can significantly improve the $Res$Res 's performance by over 1.5 dB without adding extra parameters or computational complexity during inference. Meanwhile, existing self-ensemble (SE) and our SC strategies enhance the performance of pre-trained restorers from different perspectives. As SE increases computational complexity during inference, we propose a re-boosting module to the SC (Reb-SC) to improve the SC strategy further by incorporating SE into SC without increasing inference time. This approach further enhances the restorer's performance by approximately 0.3 dB. Additionally, we present a baseline framework that includes parallel generative adversarial branches with complementary \"self-synthesis\" and \"unpaired-synthesis\" constraints, ensuring the effectiveness of the training framework. Extensive experimental results on restoration tasks demonstrate that the proposed model performs favorably against existing state-of-the-art unsupervised restoration methods.", "authors": ["Lin Xin", "Yuyan Zhou", "Jingtong Yue", "Chao Ren", "Kelvin C. K. Chan", "Qi Lu", "Ming-Hsuan Yang"], "year": 2025, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 2, "type": "article", "concepts": ["Boosting (machine learning)", "Inference", "Computer science", "Computational complexity theory", "Artificial intelligence"], "search_query": "prompt-based image restoration learning degradation", "score": 8, "subtopic": "All-in-One Restoration", "rationale": "Self-collaboration parallel prompt GAN for unsupervised image restoration; prompt-based multi-task restoration approach.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Parallel prompt GAN with self-collaboration for unsupervised restoration", "key_findings": "Achieves competitive results without paired training data", "limitations": "GAN-based may have stability issues"}}
{"openalex_id": "https://openalex.org/W3009526937", "doi": "https://doi.org/10.1002/pan3.10080", "title": "Action needed for the EU Common Agricultural Policy to address sustainability challenges", "abstract": "Making agriculture sustainable is a global challenge. In the European Union (EU), the Common Agricultural Policy (CAP) is failing with respect to biodiversity, climate, soil, land degradation as well as socio-economic challenges.The European Commission's proposal for a CAP post-2020 provides a scope for enhanced sustainability. However, it also allows Member States to choose low-ambition implementation pathways. It therefore remains essential to address citizens' demands for sustainable agriculture and rectify systemic weaknesses in the CAP, using the full breadth of available scientific evidence and knowledge.Concerned about current attempts to dilute the environmental ambition of the future CAP, and the lack of concrete proposals for improving the CAP in the draft of the European Green Deal, we call on the European Parliament, Council and Commission to adopt 10 urgent action points for delivering sustainable food production, biodiversity conservation and climate mitigation.Knowledge is available to help moving towards evidence-based, sustainable European agriculture that can benefit people, nature and their joint futures.The statements made in this article have the broad support of the scientific community, as expressed by above 3,600 signatories to the preprint version of this manuscript. The list can be found here (https://doi.org/10.5281/zenodo.3685632).", "authors": ["Guy Pe’er", "Aletta Bonn", "Helge Bruelheide", "Petra Dieker", "Nico Eisenhauer", "Peter H. Feindt", "Gregor Hagedorn", "Bernd Hansjürgens", "Irina Herzon", "Ângela Lomba", "Elisabeth Marquard", "Francisco Moreira", "Heike Nitsch", "Rainer Oppermann", "Andrea Perino", "Norbert Röder", "Christian Schleyer", "Stefan Schindler", "Christine Wolf", "Yves Zinngrebe", "Sebastian Lakner"], "year": 2020, "venue": "People and Nature", "cited_by_count": 548, "type": "article", "concepts": ["Common Agricultural Policy", "Sustainability", "European union", "Business", "Parliament"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Agricultural policy paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2604754546", "doi": "https://doi.org/10.1038/ncomms14727", "title": "Dopamine neuronal loss contributes to memory and reward dysfunction in a model of Alzheimer’s disease", "abstract": "", "authors": ["Annalisa Nobili", "Emanuele Claudio Latagliata", "Maria Teresa Viscomi", "Virve Cavallucci", "Debora Cutuli", "Giacomo Giacovazzo", "Paraskevi Krashia", "Francesca Romana Rizzo", "Ramona Marino", "Mauro Federici", "Paola De Bartolo", "Daniela Aversa", "Maria Concetta Dell’Acqua", "Alberto Cordella", "Marco Sancandi", "Flavio Keller", "Laura Petrosini", "Stefano Puglisi‐Allegra", "Nicola Biagio Mercuri", "Roberto Coccurello", "Nicola Berretta", "Marcello D’Amelio"], "year": 2017, "venue": "Nature Communications", "cited_by_count": 487, "type": "article", "concepts": ["Ventral tegmental area", "Pars compacta", "Neuroscience", "Substantia nigra", "Dopamine"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Neuroscience paper on dopamine and Alzheimer's, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4292488030", "doi": "https://doi.org/10.1038/s41591-022-01923-y", "title": "Cellular senescence and senolytics: the path to the clinic", "abstract": "", "authors": ["Selim Chaib", "Tamar Tchkonia", "James L. Kirkland"], "year": 2022, "venue": "Nature Medicine", "cited_by_count": 941, "type": "review", "concepts": ["Senescence", "Cellular senescence", "Medicine", "Clinical trial", "Psychological intervention"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Medical paper on cellular senescence, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2775636951", "doi": "https://doi.org/10.1016/j.preteyeres.2017.11.003", "title": "Optical coherence tomography angiography", "abstract": "", "authors": ["Richard F. Spaide", "James G. Fujimoto", "Nadia K. Waheed", "Srinivas R. Sadda", "Giovanni Staurenghi"], "year": 2017, "venue": "Progress in Retinal and Eye Research", "cited_by_count": 1618, "type": "review", "concepts": ["Choroid", "Medicine", "Optical coherence tomography", "Macular degeneration", "Retina"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Medical imaging paper on OCT angiography for eye diseases, not related to image restoration methods.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W3000049009", "doi": "https://doi.org/10.3390/land9010028", "title": "A Bibliometric Analysis on Land Degradation: Current Status, Development, and Future Directions", "abstract": "Land degradation is a global issue receiving much attention currently. In order to objectively reveal the research situation of land degradation, bibliometrix and biblioshiny software packages have been used to conduct data mining and quantitative analysis on research papers in the fields of land degradation during 1990–2019 (data update time was 8 April 2019) in the Web of Science core collection database. The results show that: (1) during the past 20 years, the number of papers on land degradation has increased. According to the number of articles, it is divided into four stages: a low-production exploration period, a developmental sprout period, expansion of the promotion period, and a high-yield active period. (2) Land-degradation research covers 93 countries or regions. The top five countries in terms of research volume are China, the United States, the United Kingdom, Germany, and Australia. China, the United States, and the United Kingdom are the most important countries for international cooperation in the field of land degradation. However, cooperation between countries is not very close overall. (3) Land degradation, degradation, desertification, remote sensing, soil erosion, and soil degradation are high-frequency keywords in the field of land degradation in recent years. (4) The research hotspots in the field of land degradation mainly focus on research directions such as restoration and reconstruction of land degradation, and sustainable management of land resources. (5) The themes of various periods in the field of land degradation are diversified, and the evolutionary relationship is complex. There are 15 evolutionary paths with regard to dynamic monitoring of land degradation, environmental governance of land degradation, and responses of land degradation to land-use change. Finally, the paper concludes that the research directions on land degradation in future include the process, mechanism, and effect of land degradation, the application of new technologies, new monitoring methods for land degradation, theory enhancement, methods and models of ecological restoration, reconstruction of degraded land, multidisciplinary integrated system research, constructing a policy guarantee system for the reconstruction of degraded land, and strengthening research on land resource engineering.", "authors": ["Hualin Xie", "Yanwei Zhang", "Zhilong Wu", "Tiangui Lv"], "year": 2020, "venue": "Land", "cited_by_count": 406, "type": "article", "concepts": ["Land degradation", "Desertification", "Sustainable land management", "China", "Land management"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Land degradation bibliometric study, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W3169893408", "doi": "https://doi.org/10.1007/s40747-021-00428-4", "title": "Methods for image denoising using convolutional neural network: a review", "abstract": "Abstract Image denoising faces significant challenges, arising from the sources of noise. Specifically, Gaussian, impulse, salt, pepper, and speckle noise are complicated sources of noise in imaging. Convolutional neural network (CNN) has increasingly received attention in image denoising task. Several CNN methods for denoising images have been studied. These methods used different datasets for evaluation. In this paper, we offer an elaborate study on different CNN techniques used in image denoising. Different CNN methods for image denoising were categorized and analyzed. Popular datasets used for evaluating CNN image denoising methods were investigated. Several CNN image denoising papers were selected for review and analysis. Motivations and principles of CNN methods were outlined. Some state-of-the-arts CNN image denoising methods were depicted in graphical forms, while other methods were elaborately explained. We proposed a review of image denoising with CNN. Previous and recent papers on image denoising with CNN were selected. Potential challenges and directions for future research were equally fully explicated.", "authors": ["Ademola E. Ilesanmi", "Taiwo Ilesanmi"], "year": 2021, "venue": "Complex & Intelligent Systems", "cited_by_count": 348, "type": "review", "concepts": ["Noise reduction", "Convolutional neural network", "Computer science", "Artificial intelligence", "Non-local means"], "search_query": "prompt-based image restoration learning degradation", "score": 6, "subtopic": "Real-World Degradation", "rationale": "Review of CNN-based image denoising methods; relevant to image restoration but focused on single-task denoising.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Survey of CNN denoising methods including Gaussian, impulse, salt-pepper noise", "key_findings": "Comprehensive review of denoising architectures", "limitations": "Focused only on denoising, not multi-task"}}
{"openalex_id": "https://openalex.org/W7117495353", "doi": "https://doi.org/10.1109/tgrs.2025.3649014", "title": "INP-Net: Implicit Neural Prompting Network for Remote Sensing Image Dehazing", "abstract": "Restoring high-quality images from hazy observations is crucial for visual perception and downstream detection in remote sensing applications. Recent deep learning-based methods have achieved remarkable progress in dehazing, however, they often suffer from either unreliable prompting guidance or inadequate global modeling. To bridge these gaps, we propose INP-Net, an Implicit Neural Prompting Network for remote sensing image dehazing. INP-Net introduces an implicit neural prompting mechanism that exploits learnable implicit neural representations (INR) in the YCbCr color space as degradation-insensitive prompts, which are dynamically injected into the RGB decoding pipeline. In addition, we design the Adaptive Sampling and Prior-enhanced (ASP) Transformer Block to enrich global feature diversity. The ASP comprises two core components: Adaptive Soft Sampling Self-Attention (ASSA), which performs probabilistic token selection to eliminate channel redundancy and enhance discriminative representations; and the Prior-Modulated Mixed-Scale Feed-Forward Network (PMFN), which leverages haze prior knowledge as a multi-scale modulator to guide local feature restoration. Extensive experiments on multiple benchmark datasets demonstrate that the proposed INP-Net surpasses state-of-the-art methods both quantitatively and qualitatively. Our method achieves PSNR gains of 0.47 dB and 0.75 dB over state-of-the-art methods on the challenging StateHaze1K-thick and NH-Haze datasets, respectively.", "authors": ["Shan Liang", "Tao Gao", "Ting Chen", "Yuanbo Wen", "Qianxi Zhang", "Xiao Wang"], "year": 2025, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 1, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Redundancy (engineering)", "Computer vision", "Decoding methods"], "search_query": "prompt-based image restoration learning degradation", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "Implicit neural prompting for remote sensing dehazing; prompt-based restoration relevant to unified approaches.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "Implicit neural prompting network for dehazing remote sensing images", "key_findings": "Reduces redundancy via implicit prompts", "limitations": "Domain-specific to remote sensing"}}
{"openalex_id": "https://openalex.org/W2114655563", "doi": "https://doi.org/10.3389/fnagi.2013.00034", "title": "A delicate balance: Iron metabolism and diseases of the brain", "abstract": "Iron is the most abundant transition metal within the brain, and is vital for a number of cellular processes including neurotransmitter synthesis, myelination of neurons, and mitochondrial function. Redox cycling between ferrous and ferric iron is utilized in biology for various electron transfer reactions essential to life, yet this same chemistry mediates deleterious reactions with oxygen that induce oxidative stress. Consequently, there is a precise and tightly controlled mechanism to regulate iron in the brain. When iron is dysregulated, both conditions of iron overload and iron deficiencies are harmful to the brain. This review focuses on how iron metabolism is maintained in the brain, and how an alteration to iron and iron metabolism adversely affects neurological function.", "authors": ["Dominic J. Hare", "Scott Ayton", "Ashley I. Bush", "Peng Lei"], "year": 2013, "venue": "Frontiers in Aging Neuroscience", "cited_by_count": 429, "type": "article", "concepts": ["Ferrous", "Metabolism", "Oxidative stress", "Brain function", "Ferric"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Neuroscience paper on iron metabolism in the brain, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W3202997660", "doi": "https://doi.org/10.1038/s43587-021-00121-8", "title": "Strategies for targeting senescent cells in human disease", "abstract": "", "authors": ["Nathan Gasek", "George A. Kuchel", "James L. Kirkland", "Ming Xu"], "year": 2021, "venue": "Nature Aging", "cited_by_count": 455, "type": "review", "concepts": ["Senescence", "Paracrine signalling", "Biology", "Carcinogenesis", "Disease"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Biology paper on senescent cell targeting, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4404431554", "doi": "https://doi.org/10.1016/j.jenvman.2024.123336", "title": "Characterizing and modeling spatiotemporal trends in rangelands: Prosopis juliflora impact in middle Awash Basin, Ethiopia", "abstract": "", "authors": ["Kalid Hassen Yasin"], "year": 2024, "venue": "Journal of Environmental Management", "cited_by_count": 3, "type": "article", "concepts": ["Rangeland", "Environmental science", "Vegetation (pathology)", "Edaphic", "Prosopis juliflora"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Environmental science paper on rangeland trends, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4392775085", "doi": "https://doi.org/10.1038/s41392-024-01745-z", "title": "Nanotechnology’s frontier in combatting infectious and inflammatory diseases: prevention and treatment", "abstract": "Inflammation-associated diseases encompass a range of infectious diseases and non-infectious inflammatory diseases, which continuously pose one of the most serious threats to human health, attributed to factors such as the emergence of new pathogens, increasing drug resistance, changes in living environments and lifestyles, and the aging population. Despite rapid advancements in mechanistic research and drug development for these diseases, current treatments often have limited efficacy and notable side effects, necessitating the development of more effective and targeted anti-inflammatory therapies. In recent years, the rapid development of nanotechnology has provided crucial technological support for the prevention, treatment, and detection of inflammation-associated diseases. Various types of nanoparticles (NPs) play significant roles, serving as vaccine vehicles to enhance immunogenicity and as drug carriers to improve targeting and bioavailability. NPs can also directly combat pathogens and inflammation. In addition, nanotechnology has facilitated the development of biosensors for pathogen detection and imaging techniques for inflammatory diseases. This review categorizes and characterizes different types of NPs, summarizes their applications in the prevention, treatment, and detection of infectious and inflammatory diseases. It also discusses the challenges associated with clinical translation in this field and explores the latest developments and prospects. In conclusion, nanotechnology opens up new possibilities for the comprehensive management of infectious and inflammatory diseases.", "authors": ["Yujing Huang", "Xiaohan Guo", "Yi Wu", "Xingyu Chen", "Lixiang Feng", "Na Xie", "Guobo Shen"], "year": 2024, "venue": "Signal Transduction and Targeted Therapy", "cited_by_count": 368, "type": "article", "concepts": ["Medicine", "Drug development", "Immunogenicity", "Drug", "Intensive care medicine"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Nanotechnology medical paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2553239728", "doi": "https://doi.org/10.1523/jneurosci.2351-16.2016", "title": "Casting a Wide Net: Role of Perineuronal Nets in Neural Plasticity", "abstract": "Perineuronal nets (PNNs) are unique extracellular matrix structures that wrap around certain neurons in the CNS during development and control plasticity in the adult CNS. They appear to contribute to a wide range of diseases/disorders of the brain, are involved in recovery from spinal cord injury, and are altered during aging, learning and memory, and after exposure to drugs of abuse. Here the focus is on how a major component of PNNs, chondroitin sulfate proteoglycans, control plasticity, and on the role of PNNs in memory in normal aging, in a tauopathy model of Alzheimer's disease, and in drug addiction. Also discussed is how altered extracellular matrix/PNN formation during development may produce synaptic pathology associated with schizophrenia, bipolar disorder, major depression, and autism spectrum disorders. Understanding the molecular underpinnings of how PNNs are altered in normal physiology and disease will offer insights into new treatment approaches for these diseases.", "authors": ["Barbara A. Sorg", "Sabina Berretta", "Jordan M. Blacktop", "James W. Fawcett", "Hiroshi Kitagawa", "Jessica C. F. Kwok", "Marta Miquel"], "year": 2016, "venue": "Journal of Neuroscience", "cited_by_count": 453, "type": "review", "concepts": ["Perineuronal net", "Neuroscience", "Neuroplasticity", "Synaptic plasticity", "Biology"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Neuroscience paper on perineuronal nets, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2023606650", "doi": "https://doi.org/10.1016/j.echo.2004.07.013", "title": "American Society of Echocardiography recommendations for use of echocardiography in clinical trials", "abstract": "", "authors": ["John S. Gottdiener", "James Bednarz", "Richard B. Devereux", "Julius M. Gardin", "Allan L. Klein", "Warren J. Manning", "Annitta Morehead", "Dalane W. Kitzman", "Jae K. Oh", "Miguel A. Quiñones", "Nelson B. Schiller", "James H. Stein", "Neil J. Weissman"], "year": 2004, "venue": "Journal of the American Society of Echocardiography", "cited_by_count": 906, "type": "review", "concepts": ["Medicine", "Reproducibility", "Cardiology", "Internal medicine", "Doppler echocardiography"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Medical imaging paper on echocardiography, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4387533377", "doi": "https://doi.org/10.1016/j.jenvman.2023.119230", "title": "A systematic review of industrial wastewater management: Evaluating challenges and enablers", "abstract": "", "authors": ["Bikram Jit Singh", "Ayon Chakraborty", "Rippin Sehgal"], "year": 2023, "venue": "Journal of Environmental Management", "cited_by_count": 454, "type": "review", "concepts": ["Stakeholder", "Sustainability", "Business", "Circular economy", "Industrial wastewater treatment"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Environmental engineering paper on wastewater management, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4388461325", "doi": "https://doi.org/10.1016/j.ecoinf.2023.102365", "title": "The first inventory of gullies in the Upper Taquari River Basin (Brazil) and its agreement with land use classes", "abstract": "", "authors": ["Rômullo Oliveira Louzada", "Ivan Bergier", "Fábio de Oliveira Roque"], "year": 2023, "venue": "Ecological Informatics", "cited_by_count": 3, "type": "article", "concepts": ["Context (archaeology)", "Vegetation (pathology)", "Hydrology (agriculture)", "Land use", "Terrain"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Environmental science paper on gullies and land use, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2084852600", "doi": "https://doi.org/10.1007/s13280-012-0256-7", "title": "A Review of the Elements of Human Well-Being with an Emphasis on the Contribution of Ecosystem Services", "abstract": "", "authors": ["James K. Summers", "Lisa M. Smith", "Jason L. Case", "Rick A. Linthurst"], "year": 2012, "venue": "AMBIO", "cited_by_count": 377, "type": "review", "concepts": ["Emphasis (telecommunications)", "Ecosystem services", "Ecosystem", "Environmental resource management", "Business"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Ecosystem services paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4304780007", "doi": "https://doi.org/10.1038/s41586-022-05318-4", "title": "A function-based typology for Earth’s ecosystems", "abstract": "", "authors": ["David A. Keith", "José R. Ferrer‐Paris", "Emily Nicholson", "Melanie J. Bishop", "Beth Polidoro", "Eva Ramírez-Llodra", "Mark G. Tozer", "Jeanne Nel", "Ralph Mac Nally", "Edward J. Gregr", "Kate E. Watermeyer", "Franz Essl", "Don Faber‐Langendoen", "Janet Franklin", "Caroline E. R. Lehmann", "Andrés Etter", "Dirk J. Roux", "Jonathan S. Stark", "Jessica A. Rowland", "Neil Brummitt", "U. Fernández-Arcaya", "Iain M. Suthers", "Susan K. Wiser", "Ian Donohue", "Leland J. Jackson", "R. Toby Pennington", "Thomas M. Iliffe", "Vasilis Gerovasileiou", "Paul S. Giller", "Belinda J. Robson", "Nathalie Pettorelli", "Ángela Andrade", "Arild Lindgaard", "Teemu Tahvanainen", "Aleks Terauds", "Michael A. Chadwick", "Nicholas Murray", "Justin Moat", "Patricio Pliscoff", "Irene Zager", "Richard T. Kingsford"], "year": 2022, "venue": "Nature", "cited_by_count": 302, "type": "article", "concepts": ["Ecosystem services", "Environmental resource management", "Convention on Biological Diversity", "Ecosystem management", "Total human ecosystem"], "search_query": "prompt-based image restoration learning degradation", "score": 1, "subtopic": "", "rationale": "Ecology paper on ecosystem classification, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4225672218", "doi": "https://doi.org/10.1109/cvpr52688.2022.00564", "title": "Restormer: Efficient Transformer for High-Resolution Image Restoration", "abstract": "Since convolutional neural networks (CNNs) perform well at learning generalizable image priors from large-scale data, these models have been extensively applied to image restoration and related tasks. Recently, another class of neural architectures, Transformers, have shown significant performance gains on natural language and high-level vision tasks. While the Transformer model mitigates the shortcomings of CNNs (i.e., limited receptive field and inadaptability to input content), its computational complexity grows quadratically with the spatial resolution, therefore making it infeasible to apply to most image restoration tasks involving high-resolution images. In this work, we propose an efficient Transformer model by making several key designs in the building blocks (multi-head attention and feed-forward network) such that it can capture long-range pixel interactions, while still remaining applicable to large images. Our model, named Restoration Transformer (Restormer), achieves state-of-the-art results on several image restoration tasks, including image deraining, single-image motion deblurring, defocus deblurring (single-image and dual-pixel data), and image denoising (Gaussian grayscale/color denoising, and real image denoising). The source code and pre-trained models are available at https://github.com/swz30/Restormer.", "authors": ["Syed Waqas Zamir", "Aditya Arora", "Salman Khan", "Munawar Hayat", "Fahad Shahbaz Khan", "Ming–Hsuan Yang"], "year": 2022, "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "cited_by_count": 3123, "type": "article", "concepts": ["Deblurring", "Computer science", "Artificial intelligence", "Image restoration", "Computer vision"], "search_query": "image restoration transformer architecture efficient", "score": 8, "subtopic": "Transformer Restoration", "rationale": "Foundational transformer architecture for image restoration; key baseline for transformer-based methods.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Multi-Dconv head transposed attention and gated-Dconv feed-forward network", "key_findings": "SOTA on denoising, deblurring, deraining at CVPR 2022", "limitations": "Single-task focus per model instance"}}
{"openalex_id": "https://openalex.org/W4312812783", "doi": "https://doi.org/10.1109/cvpr52688.2022.01716", "title": "Uformer: A General U-Shaped Transformer for Image Restoration", "abstract": "In this paper, we present Uformer, an effective and efficient Transformer-based architecture for image restoration, in which we build a hierarchical encoder-decoder network using the Transformer block. In Uformer, there are two core designs. First, we introduce a novel locally-enhanced window (LeWin) Transformer block, which performs non-overlapping window-based self-attention instead of global self-attention. It significantly reduces the computational complexity on high resolution feature map while capturing local context. Second, we propose a learnable multi-scale restoration modulator in the form of a multi-scale spatial bias to adjust features in multiple layers of the Uformer decoder. Our modulator demonstrates superior capability for restoring details for various image restoration tasks while introducing marginal extra parameters and computational cost. Powered by these two designs, Uformer enjoys a high capability for capturing both local and global dependencies for image restoration. To evaluate our approach, extensive experiments are conducted on several image restoration tasks, including image denoising, motion deblurring, defocus deblurring and deraining. Without bells and whistles, our Uformer achieves superior or comparable performance compared with the state-of-the-art algorithms. The code and models are available at https://github.com/ZhendongWang6/Uformer.", "authors": ["Zhendong Wang", "Xiaodong Cun", "Jianmin Bao", "Wengang Zhou", "Jianzhuang Liu", "Houqiang Li"], "year": 2022, "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "cited_by_count": 1866, "type": "article", "concepts": ["Deblurring", "Image restoration", "Computer science", "Transformer", "Encoder"], "search_query": "image restoration transformer architecture efficient", "score": 7.5, "subtopic": "Transformer Restoration", "rationale": "U-shaped transformer for image restoration with window-based self-attention; important baseline architecture.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Hierarchical encoder-decoder with learnable multi-scale modulator", "key_findings": "Effective U-shaped transformer design for multiple restoration tasks", "limitations": "Window-based attention limits global context"}}
{"openalex_id": "https://openalex.org/W4386075642", "doi": "https://doi.org/10.1109/cvpr52729.2023.00570", "title": "Efficient Frequency Domain-based Transformers for High-Quality Image Deblurring", "abstract": "We present an effective and efficient method that explores the properties of Transformers in the frequency domain for high-quality image deblurring. Our method is motivated by the convolution theorem that the correlation or convolution of two signals in the spatial domain is equivalent to an element-wise product of them in the frequency domain. This inspires us to develop an efficient frequency domain-based self-attention solver (FSAS) to estimate the scaled dot-product attention by an element-wise product operation instead of the matrix multiplication in the spatial domain. In addition, we note that simply using the naive feed-forward network (FFN) in Transformers does not generate good deblurred results. To overcome this problem, we propose a simple yet effective discriminative frequency domain-based FFN (DFFN), where we introduce a gated mechanism in the FFN based on the Joint Photographic Experts Group (JPEG) compression algorithm to discriminatively determine which low- and high-frequency information of the features should be preserved for latent clear image restoration. We formulate the proposed FSAS and DFFN into an asymmetrical network based on an encoder and decoder architecture, where the FSAS is only used in the decoder module for better image deblurring. Experimental results show that the proposed method performs favorably against the state-of-the-art approaches.", "authors": ["Lingshun Kong", "Jiangxin Dong", "Jianjun Ge", "Mingqiang Li", "Jinshan Pan"], "year": 2023, "venue": "", "cited_by_count": 263, "type": "article", "concepts": ["Deblurring", "Computer science", "Frequency domain", "Transformer", "Image quality"], "search_query": "image restoration transformer architecture efficient", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Frequency domain transformer for image deblurring; relevant efficient transformer design for restoration.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Frequency domain transformer leveraging convolution theorem", "key_findings": "Efficient deblurring via frequency domain processing", "limitations": "Focused on deblurring only"}}
{"openalex_id": "https://openalex.org/W4321497943", "doi": "https://doi.org/10.3390/s23052385", "title": "Vision Transformers in Image Restoration: A Survey", "abstract": "The Vision Transformer (ViT) architecture has been remarkably successful in image restoration. For a while, Convolutional Neural Networks (CNN) predominated in most computer vision tasks. Now, both CNN and ViT are efficient approaches that demonstrate powerful capabilities to restore a better version of an image given in a low-quality format. In this study, the efficiency of ViT in image restoration is studied extensively. The ViT architectures are classified for every task of image restoration. Seven image restoration tasks are considered: Image Super-Resolution, Image Denoising, General Image Enhancement, JPEG Compression Artifact Reduction, Image Deblurring, Removing Adverse Weather Conditions, and Image Dehazing. The outcomes, the advantages, the limitations, and the possible areas for future research are detailed. Overall, it is noted that incorporating ViT in the new architectures for image restoration is becoming a rule. This is due to some advantages compared to CNN, such as better efficiency, especially when more data are fed to the network, robustness in feature extraction, and a better feature learning approach that sees better the variances and characteristics of the input. Nevertheless, some drawbacks exist, such as the need for more data to show the benefits of ViT over CNN, the increased computational cost due to the complexity of the self-attention block, a more challenging training process, and the lack of interpretability. These drawbacks represent the future research direction that should be targeted to increase the efficiency of ViT in the image restoration domain.", "authors": ["Anas M. Ali", "Bilel Benjdira", "Anis Koubâa", "Walid El‐Shafai", "Zahid Khan", "Wadii Boulila"], "year": 2023, "venue": "Sensors", "cited_by_count": 109, "type": "article", "concepts": ["Image restoration", "Deblurring", "Computer science", "Artificial intelligence", "Convolutional neural network"], "search_query": "image restoration transformer architecture efficient", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Comprehensive survey of vision transformers in image restoration; useful overview of the field.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Survey covering ViT architectures for restoration tasks", "key_findings": "Systematic review of transformer-based restoration methods", "limitations": "Survey paper, no novel methods proposed"}}
{"openalex_id": "https://openalex.org/W4360887305", "doi": "https://doi.org/10.1109/tip.2023.3261747", "title": "CTCNet: A CNN-Transformer Cooperation Network for Face Image Super-Resolution", "abstract": "Recently, deep convolution neural networks (CNNs) steered face super-resolution methods have achieved great progress in restoring degraded facial details by joint training with facial priors. However, these methods have some obvious limitations. On the one hand, multi-task joint learning requires additional marking on the dataset, and the introduced prior network will significantly increase the computational cost of the model. On the other hand, the limited receptive field of CNN will reduce the fidelity and naturalness of the reconstructed facial images, resulting in suboptimal reconstructed images. In this work, we propose an efficient CNN-Transformer Cooperation Network (CTCNet) for face super-resolution tasks, which uses the multi-scale connected encoder-decoder architecture as the backbone. Specifically, we first devise a novel Local-Global Feature Cooperation Module (LGCM), which is composed of a Facial Structure Attention Unit (FSAU) and a Transformer block, to promote the consistency of local facial detail and global facial structure restoration simultaneously. Then, we design an efficient Feature Refinement Module (FRM) to enhance the encoded features. Finally, to further improve the restoration of fine facial details, we present a Multi-scale Feature Fusion Unit (MFFU) to adaptively fuse the features from different stages in the encoder procedure. Extensive evaluations on various datasets have assessed that the proposed CTCNet can outperform other state-of-the-art methods significantly. Source code will be available at https://github.com/IVIPLab/CTCNet.", "authors": ["Guangwei Gao", "Zixiang Xu", "Juncheng Li", "Jian Yang", "Tieyong Zeng", "Guo-Jun Qi"], "year": 2023, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 151, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Computer vision", "Face (sociological concept)", "Image resolution"], "search_query": "image restoration transformer architecture efficient", "score": 5.5, "subtopic": "Super-Resolution", "rationale": "CNN-Transformer cooperation for face super-resolution; tangentially related via architecture design.", "alignment": {"task": "low", "method": "medium", "modality": "high"}, "extraction": {"design": "CNN-Transformer cooperation network for face SR with facial priors", "key_findings": "Effective fusion of CNN and transformer features for face SR", "limitations": "Domain-specific to face images"}}
{"openalex_id": "https://openalex.org/W4406457474", "doi": "https://doi.org/10.1109/tcsvt.2025.3530090", "title": "VmambaIR: Visual State Space Model for Image Restoration", "abstract": "Image restoration is a critical task in low-level computer vision, aiming to restore high-quality images from degraded inputs. Various models, such as convolutional neural networks (CNNs), generative adversarial networks (GANs), transformers, and diffusion models (DMs), have been employed to address this problem with significant impact. However, CNNs have limitations in capturing long-range dependencies. DMs require large prior models and computationally intensive denoising steps. Transformers have powerful modeling capabilities but face challenges due to quadratic complexity with input image size. To tackle these challenges, we propose VmambaIR, one of the first works to introduce State Space Models (SSMs) with linear complexity into comprehensive image restoration tasks. Specifically, we utilize a Unet architecture to stack our proposed Omni Selective Scan (OSS) blocks, consisting of an OSS module and an Efficient Feed-Forward Network (EFFN). Our proposed omni selective scan mechanism overcomes the unidirectional modeling limitation of SSMs by efficiently modeling image information flows in all six directions to better exploit surrounding restoration information. Furthermore, we conducted a comprehensive evaluation of our VmambaIR across multiple image restoration tasks, including image deraining, single image super-resolution, and real-world image super-resolution. Extensive experimental results demonstrate that our proposed VmambaIR achieves state-of-the-art (SOTA) performance with much fewer computational resources and parameters. Our research highlights the potential of state space models as promising alternatives to the transformer and CNN architectures in serving as foundational frameworks for next-generation low-level visual tasks.", "authors": ["Yuan Shi", "Bin Xia", "Xiaoyu Jin", "Xing Wang", "Tianyu Zhao", "Xin Xia", "Xuefeng Xiao", "Wenming Yang"], "year": 2025, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 93, "type": "article", "concepts": ["Image restoration", "Computer vision", "Computer science", "Artificial intelligence", "Image (mathematics)"], "search_query": "image restoration transformer architecture efficient", "score": 7.5, "subtopic": "Transformer Restoration", "rationale": "Mamba-based state space model for image restoration; emerging architecture for efficient restoration.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Visual state space model combining Mamba with image restoration", "key_findings": "Competitive with transformers at lower computational cost", "limitations": "Relatively new paradigm, less established"}}
{"openalex_id": "https://openalex.org/W2984522085", "doi": "https://doi.org/10.1109/tci.2019.2911881", "title": "Deep Spatial–Spectral Representation Learning for Hyperspectral Image Denoising", "abstract": "Deep learning has found successful applications in restoration of two-dimensional (2-D) images including denoising, dehazing, and superresolution. However, existing deep convolutional neural network (DCNN) architecture cannot fully exploit spatial-spectral correlations in three-dimensional (3-D) hyperspectral images (HSIs) (directly extending 2-D DCNN into 3-D will significantly increase computational complexity); meantime, unlike 2-D images, there is an obstacle caused by the shortage of training data for HSIs. To meet those challenges, we present a novel, deep-learning framework for 3-D HSI denoising with the following contributions. First, inspired by the success of U-net in low-dose current-transformer denoising, we propose a novel approach of encoding rich multi-scale information of HSIs by a modified 3-D U-net. Second, we present a computationally efficient implementation of 3-D U-net based on the strategy of separable filtering. By decomposing 3-D filtering into 2-D spatial filtering and 1-D spectral filtering, we can achieve substantial savings on the number of network parameters to keep the computational complexity low. Third, we have developed a transfer learning approach of synthetically generating HSIs from RGB images as supplementary training data. The synthesized HSIs are used for the initial training of the modified 3-D U-net denoising network, which will be fine-tuned on real HSI images. Experimental results have shown that the proposed 3-D U-net denoising method significantly outperforms existing model-based HSI denoising methods.", "authors": ["Weisheng Dong", "Huan Wang", "Fangfang Wu", "Guangming Shi", "Xin Li"], "year": 2019, "venue": "IEEE Transactions on Computational Imaging", "cited_by_count": 127, "type": "article", "concepts": ["Hyperspectral imaging", "Artificial intelligence", "Noise reduction", "Computer science", "Deep learning"], "search_query": "image restoration transformer architecture efficient", "score": 5, "subtopic": "Spatial-Aware Processing", "rationale": "Spatial-spectral deep learning for hyperspectral denoising; relevant spatial-aware processing concept but different modality.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Deep CNN for joint spatial-spectral hyperspectral denoising", "key_findings": "Effective spatial-spectral feature learning for 3D image denoising", "limitations": "Hyperspectral specific, not general image restoration"}}
{"openalex_id": "https://openalex.org/W4404654752", "doi": "https://doi.org/10.1007/978-3-031-72995-9_22", "title": "When Fast Fourier Transform Meets Transformer for Image Restoration", "abstract": "", "authors": ["Xingyu Jiang", "Xiuhui Zhang", "Ning Gao", "Yue Deng"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 36, "type": "book-chapter", "concepts": ["Computer science", "Fourier transform", "Image restoration", "Transformer", "Computer vision"], "search_query": "image restoration transformer architecture efficient", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Combining FFT with transformer for image restoration; relevant efficient architecture design.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "FFT-Transformer hybrid architecture for image restoration", "key_findings": "Frequency and spatial domain fusion improves restoration", "limitations": "Limited details without abstract"}}
{"openalex_id": "https://openalex.org/W4404687984", "doi": "https://doi.org/10.1109/tip.2024.3501855", "title": "MWFormer: Multi-Weather Image Restoration Using Degradation-Aware Transformers", "abstract": "Restoring images captured under adverse weather conditions is a fundamental task for many computer vision applications. However, most existing weather restoration approaches are only capable of handling a specific type of degradation, which is often insufficient in real-world scenarios, such as rainy-snowy or rainy-hazy weather. Towards being able to address these situations, we propose a multi-weather Transformer, or MWFormer for short, which is a holistic vision Transformer that aims to solve multiple weather-induced degradations using a single, unified architecture. MWFormer uses hyper-networks and feature-wise linear modulation blocks to restore images degraded by various weather types using the same set of learned parameters. We first employ contrastive learning to train an auxiliary network that extracts content-independent, distortion-aware feature embeddings that efficiently represent predicted weather types, of which more than one may occur. Guided by these weather-informed predictions, the image restoration Transformer adaptively modulates its parameters to conduct both local and global feature processing, in response to multiple possible weather. Moreover, MWFormer allows for a novel way of tuning, during application, to either a single type of weather restoration or to hybrid weather restoration without any retraining, offering greater controllability than existing methods. Our experimental results on multi-weather restoration benchmarks show that MWFormer achieves significant performance improvements compared to existing state-of-the-art methods, without requiring much computational cost. Moreover, we demonstrate that our methodology of using hyper-networks can be integrated into various network architectures to further boost their performance. The code is available at: https://github.com/taco-group/MWFormer.", "authors": ["Ruoxi Zhu", "Zhengzhong Tu", "Jiaming Liu", "Alan C. Bovik", "Yibo Fan"], "year": 2024, "venue": "IEEE Transactions on Image Processing", "cited_by_count": 28, "type": "article", "concepts": ["Image restoration", "Computer science", "Image processing", "Degradation (telecommunications)", "Computer vision"], "search_query": "image restoration transformer architecture efficient", "score": 8.5, "subtopic": "All-in-One Restoration", "rationale": "Multi-weather degradation-aware transformer for unified restoration; highly relevant to all-in-one and spatial-aware processing.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Degradation-aware transformer handling multiple weather conditions in one model", "key_findings": "Unified multi-weather restoration with degradation awareness", "limitations": "Limited to weather-type degradations"}}
{"openalex_id": "https://openalex.org/W4221151978", "doi": "https://doi.org/10.1145/3528223.3530127", "title": "Instant neural graphics primitives with a multiresolution hash encoding", "abstract": "Neural graphics primitives, parameterized by fully connected neural networks, can be costly to train and evaluate. We reduce this cost with a versatile new input encoding that permits the use of a smaller network without sacrificing quality, thus significantly reducing the number of floating point and memory access operations: a small neural network is augmented by a multiresolution hash table of trainable feature vectors whose values are optimized through stochastic gradient descent. The multiresolution structure allows the network to disambiguate hash collisions, making for a simple architecture that is trivial to parallelize on modern GPUs. We leverage this parallelism by implementing the whole system using fully-fused CUDA kernels with a focus on minimizing wasted bandwidth and compute operations. We achieve a combined speedup of several orders of magnitude, enabling training of high-quality neural graphics primitives in a matter of seconds, and rendering in tens of milliseconds at a resolution of 1920×1080.", "authors": ["Thomas Müller", "Alex Evans", "Christoph Schied", "Alexander Keller"], "year": 2022, "venue": "ACM Transactions on Graphics", "cited_by_count": 3366, "type": "article", "concepts": ["Computer science", "Hash function", "Speedup", "Rendering (computer graphics)", "Artificial neural network"], "search_query": "image restoration transformer architecture efficient", "score": 2, "subtopic": "", "rationale": "Neural rendering/NeRF acceleration method, not directly related to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4372266706", "doi": "https://doi.org/10.1109/icassp49357.2023.10095242", "title": "Sandformer: CNN and Transformer under Gated Fusion for Sand Dust Image Restoration", "abstract": "Although Convolutional Neural Networks (CNN) have made good progress in image restoration, the intrinsic equivalence and locality of convolutions still constrain further improvements in image quality. Recent vision transformer and selfattention have achieved promising results on various computer vision tasks. However, directly utilizing Transformer for image restoration is a challenging task. In this paper, we introduce an effective hybrid architecture for sand image restoration tasks, which leverages local features from CNN and long-range dependencies captured by transformer to improve the results further. We propose an efficient hybrid structure for sand dust image restoration to solve the feature inconsistency issue between Transformer and CNN. The framework complements each representation by modulating features from the CNN-based and Transformer-based branches rather than simply adding or concatenating features. Experiments demonstrate that SandFormer achieves significant performance improvements in synthetic and real dust scenes compared to previous sand image restoration methods.", "authors": ["Jun Shi", "Bingcai Wei", "Gang Zhou", "Liye Zhang"], "year": 2023, "venue": "", "cited_by_count": 10, "type": "article", "concepts": ["Transformer", "Computer science", "Image restoration", "Convolutional neural network", "Locality"], "search_query": "image restoration transformer architecture efficient", "score": 7, "subtopic": "Transformer Restoration", "rationale": "CNN-Transformer fusion for sand dust image restoration; relevant hybrid architecture for restoration.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Gated fusion of CNN and Transformer branches for sand dust restoration", "key_findings": "Effective fusion strategy for degraded sand dust images", "limitations": "Single degradation type focus"}}
{"openalex_id": "https://openalex.org/W4382173267", "doi": "https://doi.org/10.48550/arxiv.2306.13653", "title": "ProRes: Exploring Degradation-aware Visual Prompt for Universal Image Restoration", "abstract": "Image restoration aims to reconstruct degraded images, e.g., denoising or deblurring. Existing works focus on designing task-specific methods and there are inadequate attempts at universal methods. However, simply unifying multiple tasks into one universal architecture suffers from uncontrollable and undesired predictions. To address those issues, we explore prompt learning in universal architectures for image restoration tasks. In this paper, we present Degradation-aware Visual Prompts, which encode various types of image degradation, e.g., noise and blur, into unified visual prompts. These degradation-aware prompts provide control over image processing and allow weighted combinations for customized image restoration. We then leverage degradation-aware visual prompts to establish a controllable and universal model for image restoration, called ProRes, which is applicable to an extensive range of image restoration tasks. ProRes leverages the vanilla Vision Transformer (ViT) without any task-specific designs. Furthermore, the pre-trained ProRes can easily adapt to new tasks through efficient prompt tuning with only a few images. Without bells and whistles, ProRes achieves competitive performance compared to task-specific methods and experiments can demonstrate its ability for controllable restoration and adaptation for new tasks. The code and models will be released in \\url{https://github.com/leonmakise/ProRes}.", "authors": ["Jiaqi Ma", "Tianheng Cheng", "Guoli Wang", "Qian Zhang", "Xinggang Wang", "Lefei Zhang"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 14, "type": "preprint", "concepts": ["Deblurring", "Image restoration", "Computer science", "Artificial intelligence", "Leverage (statistics)"], "search_query": "image restoration transformer architecture efficient", "score": 9, "subtopic": "All-in-One Restoration", "rationale": "Degradation-aware visual prompts for universal image restoration; directly relevant to unified restoration with spatial awareness.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Visual prompt learning for degradation-aware universal restoration", "key_findings": "Prompts enable one model to handle diverse degradations", "limitations": "arXiv preprint, prompt design complexity"}}
{"openalex_id": "https://openalex.org/W4302013160", "doi": "https://doi.org/10.48550/arxiv.2210.01069", "title": "Dual-former: Hybrid Self-attention Transformer for Efficient Image Restoration", "abstract": "Recently, image restoration transformers have achieved comparable performance with previous state-of-the-art CNNs. However, how to efficiently leverage such architectures remains an open problem. In this work, we present Dual-former whose critical insight is to combine the powerful global modeling ability of self-attention modules and the local modeling ability of convolutions in an overall architecture. With convolution-based Local Feature Extraction modules equipped in the encoder and the decoder, we only adopt a novel Hybrid Transformer Block in the latent layer to model the long-distance dependence in spatial dimensions and handle the uneven distribution between channels. Such a design eliminates the substantial computational complexity in previous image restoration transformers and achieves superior performance on multiple image restoration tasks. Experiments demonstrate that Dual-former achieves a 1.91dB gain over the state-of-the-art MAXIM method on the Indoor dataset for single image dehazing while consuming only 4.2% GFLOPs as MAXIM. For single image deraining, it exceeds the SOTA method by 0.1dB PSNR on the average results of five datasets with only 21.5% GFLOPs. Dual-former also substantially surpasses the latest desnowing method on various datasets, with fewer parameters.", "authors": ["Sixiang Chen", "Ye Tian", "Yun Liu", "Erkang Chen"], "year": 2022, "venue": "arXiv (Cornell University)", "cited_by_count": 11, "type": "preprint", "concepts": ["FLOPS", "Computer science", "Transformer", "Encoder", "Leverage (statistics)"], "search_query": "image restoration transformer architecture efficient", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Efficient hybrid self-attention transformer for image restoration; relevant architecture design.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Dual self-attention combining local and global attention efficiently", "key_findings": "Reduced computational cost while maintaining restoration quality", "limitations": "arXiv preprint"}}
{"openalex_id": "https://openalex.org/W3155072588", "doi": "https://doi.org/10.1109/tpami.2022.3204461", "title": "Image Super-Resolution Via Iterative Refinement", "abstract": "We present SR3, an approach to image Super-Resolution via Repeated Refinement. SR3 adapts denoising diffusion probabilistic models (Ho et al. 2020), (Sohl-Dickstein et al. 2015) to image-to-image translation, and performs super-resolution through a stochastic iterative denoising process. Output images are initialized with pure Gaussian noise and iteratively refined using a U-Net architecture that is trained on denoising at various noise levels, conditioned on a low-resolution input image. SR3 exhibits strong performance on super-resolution tasks at different magnification factors, on faces and natural images. We conduct human evaluation on a standard 8× face super-resolution task on CelebA-HQ for which SR3 achieves a fool rate close to 50%, suggesting photo-realistic outputs, while GAN baselines do not exceed a fool rate of 34%. We evaluate SR3 on a 4× super-resolution task on ImageNet, where SR3 outperforms baselines in human evaluation and classification accuracy of a ResNet-50 classifier trained on high-resolution images. We further show the effectiveness of SR3 in cascaded image generation, where a generative model is chained with super-resolution models to synthesize high-resolution images with competitive FID scores on the class-conditional 256×256 ImageNet generation challenge.", "authors": ["Chitwan Saharia", "Jonathan Ho", "William Chan", "Tim Salimans", "David J. Fleet", "Mohammad Norouzi"], "year": 2022, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 1551, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Pattern recognition (psychology)", "Image resolution", "Computer vision"], "search_query": "image restoration transformer architecture efficient", "score": 6, "subtopic": "Diffusion Restoration", "rationale": "Diffusion-based super-resolution; relevant as diffusion model application to restoration.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Denoising diffusion probabilistic model adapted for super-resolution", "key_findings": "High-quality SR via iterative refinement process", "limitations": "Slow inference due to iterative diffusion"}}
{"openalex_id": "https://openalex.org/W4391667544", "doi": "https://doi.org/10.48550/arxiv.2402.04139", "title": "U-shaped Vision Mamba for Single Image Dehazing", "abstract": "Currently, Transformer is the most popular architecture for image dehazing, but due to its large computational complexity, its ability to handle long-range dependency is limited on resource-constrained devices. To tackle this challenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficient single-image dehazing network. Inspired by the State Space Sequence Models (SSMs), a new deep sequence model known for its power to handle long sequences, we design a Bi-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies. Extensive experimental results demonstrate the effectiveness of our method. Our method provides a more highly efficient idea of long-range dependency modeling for image dehazing as well as other image restoration tasks. The URL of the code is \\url{https://github.com/zzr-idam/UVM-Net}. Our method takes only \\textbf{0.009} seconds to infer a $325 \\times 325$ resolution image (100FPS) without I/O handling time.", "authors": ["Zhuoran Zheng", "Chen Wu"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 15, "type": "preprint", "concepts": ["Computer vision", "Image (mathematics)", "Artificial intelligence", "Computer science", "Geology"], "search_query": "image restoration transformer architecture efficient", "score": 6.5, "subtopic": "Transformer Restoration", "rationale": "Mamba-based U-shaped network for dehazing; relevant emerging architecture for restoration.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "U-shaped Mamba architecture for efficient dehazing", "key_findings": "Linear complexity alternative to transformers for dehazing", "limitations": "Single task (dehazing), arXiv preprint"}}
{"openalex_id": "https://openalex.org/W4391417547", "doi": "https://doi.org/10.48550/arxiv.2401.15235", "title": "CascadedGaze: Efficiency in Global Context Extraction for Image Restoration", "abstract": "Image restoration tasks traditionally rely on convolutional neural networks. However, given the local nature of the convolutional operator, they struggle to capture global information. The promise of attention mechanisms in Transformers is to circumvent this problem, but it comes at the cost of intensive computational overhead. Many recent studies in image restoration have focused on solving the challenge of balancing performance and computational cost via Transformer variants. In this paper, we present CascadedGaze Network (CGNet), an encoder-decoder architecture that employs Global Context Extractor (GCE), a novel and efficient way to capture global information for image restoration. The GCE module leverages small kernels across convolutional layers to learn global dependencies, without requiring self-attention. Extensive experimental results show that our computationally efficient approach performs competitively to a range of state-of-the-art methods on synthetic image denoising and single image deblurring tasks, and pushes the performance boundary further on the real image denoising task.", "authors": ["Amirhosein Ghasemabadi", "Mohammad Salameh", "Muhammad Kamran Janjua", "Chunhua Zhou", "Fengyu Sun", "Di Niu"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 8, "type": "preprint", "concepts": ["Image restoration", "Context (archaeology)", "Extraction (chemistry)", "Image (mathematics)", "Computer science"], "search_query": "image restoration transformer architecture efficient", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Efficient global context extraction for image restoration; relevant architecture design.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Cascaded gaze mechanism for efficient global context in restoration", "key_findings": "Improved efficiency in capturing global information", "limitations": "arXiv preprint"}}
{"openalex_id": "https://openalex.org/W4399747822", "doi": "https://doi.org/10.1016/j.compag.2024.109169", "title": "Low-light wheat image enhancement using an explicit inter-channel sparse transformer", "abstract": "", "authors": ["Yu Wang", "Fei Wang", "Kun Li", "Xuping Feng", "Wenhui Hou", "Lu Liu", "Liqing Chen", "Yong He", "Yuwei Wang", "Yuwei Wang", "Yuwei Wang"], "year": 2024, "venue": "Computers and Electronics in Agriculture", "cited_by_count": 14, "type": "article", "concepts": ["Transformer", "Artificial intelligence", "Computer science", "Computer vision", "Pattern recognition (psychology)"], "search_query": "image restoration transformer architecture efficient", "score": 5, "subtopic": "Transformer Restoration", "rationale": "Sparse transformer for low-light agricultural image enhancement; domain-specific application.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Inter-channel sparse transformer for low-light wheat images", "key_findings": "Enhanced low-light images for agricultural applications", "limitations": "Very domain-specific, agricultural focus"}}
{"openalex_id": "https://openalex.org/W4377971563", "doi": "https://doi.org/10.2139/ssrn.4458244", "title": "Towards an Effective and Efficient Transformer for Rain-by-Snow Weather Removal", "abstract": "", "authors": ["Tao Gao", "Yuanbo Wen", "Kaihao Zhang", "Peng Cheng", "Ting Chen"], "year": 2023, "venue": "SSRN Electronic Journal", "cited_by_count": 8, "type": "preprint", "concepts": ["Snow", "Rain and snow mixed", "Environmental science", "Meteorology", "Transformer"], "search_query": "image restoration transformer architecture efficient", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Transformer for mixed rain-snow removal; relevant multi-weather restoration approach.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Efficient transformer for combined rain and snow removal", "key_findings": "Handles mixed weather degradation", "limitations": "SSRN preprint, specific to rain-snow mix"}}
{"openalex_id": "https://openalex.org/W2979040987", "doi": "https://doi.org/10.1109/access.2019.2945545", "title": "Comprehensive Review of Artificial Neural Network Applications to Pattern Recognition", "abstract": "The era of artificial neural network (ANN) began with a simplified application in many fields and remarkable success in pattern recognition (PR) even in manufacturing industries. Although significant progress achieved and surveyed in addressing ANN application to PR challenges, nevertheless, some problems are yet to be resolved like whimsical orientation (the unknown path that cannot be accurately calculated due to its directional position). Other problem includes; object classification, location, scaling, neurons behavior analysis in hidden layers, rule, and template matching. Also, the lack of extant literature on the issues associated with ANN application to PR seems to slow down research focus and progress in the field. Hence, there is a need for state-of-the-art in neural networks application to PR to urgently address the above-highlights problems for more successes. The study furnishes readers with a clearer understanding of the current, and new trend in ANN models that effectively addresses PR challenges to enable research focus and topics. Similarly, the comprehensive review reveals the diverse areas of the success of ANN models and their application to PR. In evaluating the performance of ANN models, some statistical indicators for measuring the performance of the ANN model in many studies were adopted. Such as the use of mean absolute percentage error (MAPE), mean absolute error (MAE), root mean squared error (RMSE), and variance of absolute percentage error (VAPE). The result shows that the current ANN models such as GAN, SAE, DBN, RBM, RNN, RBFN, PNN, CNN, SLP, MLP, MLNN, Reservoir computing, and Transformer models are performing excellently in their application to PR tasks. Therefore, the study recommends the research focus on current models and the development of new models concurrently for more successes in the field.", "authors": ["Oludare Isaac Abiodun", "Muhammad Ubale Kiru", "Aman Jantan", "Abiodun Esther Omolara", "Kemi Victoria Dada", "Abubakar Malah Umar", "Okafor Uchenwa Linus", "Humaira Arshad", "Abdullahi Aminu Kazaure", "Usman M. Gana"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 688, "type": "article", "concepts": ["Mean squared error", "Artificial neural network", "Computer science", "Mean absolute percentage error", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient", "score": 2, "subtopic": "", "rationale": "General review of neural network pattern recognition, too broad to be directly relevant.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4401824304", "doi": "https://doi.org/10.3847/1538-4357/ad5954", "title": "Deeper, Sharper, Faster: Application of Efficient Transformer to Galaxy Image Restoration", "abstract": "Abstract The Transformer architecture has revolutionized the field of deep learning over the past several years in diverse areas, including natural language processing, code generation, image recognition, and time-series forecasting. We propose to apply Zamir et al.'s efficient transformer to perform deconvolution and denoising to enhance astronomical images. We conducted experiments using pairs of high-quality images and their degraded versions, and our deep learning model demonstrates exceptional restoration of photometric, structural, and morphological information. When compared with the ground-truth James Webb Space Telescope images, the enhanced versions of our Hubble Space Telescope–quality images reduce the scatter of isophotal photometry, Sérsic index, and half-light radius by factors of 4.4, 3.6, and 4.7, respectively, with Pearson correlation coefficients approaching unity. The performance is observed to degrade when input images exhibit correlated noise, point-like sources, and artifacts. We anticipate that this deep learning model will prove valuable for a number of scientific applications, including precision photometry, morphological analysis, and shear calibration.", "authors": ["Hyosun Park", "Yongsik Jo", "Seokun Kang", "T. Kim", "M. James Jee"], "year": 2024, "venue": "The Astrophysical Journal", "cited_by_count": 8, "type": "article", "concepts": ["Physics", "Galaxy", "Astronomy", "Astrophysics", "Transformer"], "search_query": "image restoration transformer architecture efficient", "score": 5, "subtopic": "Transformer Restoration", "rationale": "Transformer for galaxy image restoration in astronomy; relevant architecture but different domain.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Efficient transformer adapted for astronomical galaxy image restoration", "key_findings": "Improved galaxy image quality via transformer architecture", "limitations": "Astronomy-specific domain"}}
{"openalex_id": "https://openalex.org/W4295122555", "doi": "https://doi.org/10.3390/app12188972", "title": "Deep Residual Learning for Image Recognition: A Survey", "abstract": "Deep Residual Networks have recently been shown to significantly improve the performance of neural networks trained on ImageNet, with results beating all previous methods on this dataset by large margins in the image classification task. However, the meaning of these impressive numbers and their implications for future research are not fully understood yet. In this survey, we will try to explain what Deep Residual Networks are, how they achieve their excellent results, and why their successful implementation in practice represents a significant advance over existing techniques. We also discuss some open questions related to residual learning as well as possible applications of Deep Residual Networks beyond ImageNet. Finally, we discuss some issues that still need to be resolved before deep residual learning can be applied on more complex problems.", "authors": ["Muhammad Shafiq", "Zhaoquan Gu"], "year": 2022, "venue": "Applied Sciences", "cited_by_count": 838, "type": "article", "concepts": ["Residual", "Deep learning", "Computer science", "Artificial intelligence", "Deep neural networks"], "search_query": "image restoration transformer architecture efficient", "score": 3, "subtopic": "", "rationale": "Survey of residual learning for image recognition, general deep learning background.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4392884081", "doi": "https://doi.org/10.1016/j.jvcir.2024.104117", "title": "GoLDFormer: A global–local deformable window transformer for efficient image restoration", "abstract": "", "authors": ["Quan Chen", "Bolun Zheng", "Chenggang Yan", "Zunjie Zhu", "Tingyu Wang", "Greg Slabaugh", "Shanxin Yuan"], "year": 2024, "venue": "Journal of Visual Communication and Image Representation", "cited_by_count": 4, "type": "article", "concepts": ["Transformer", "Computer science", "Computation", "Window (computing)", "Computer vision"], "search_query": "image restoration transformer architecture efficient", "score": 7.5, "subtopic": "Transformer Restoration", "rationale": "Global-local deformable window transformer for image restoration; relevant spatial-aware architecture.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Deformable window transformer with global-local attention for restoration", "key_findings": "Efficient global-local context extraction via deformable windows", "limitations": "Limited details without abstract"}}
{"openalex_id": "https://openalex.org/W4391944774", "doi": "https://doi.org/10.1007/s11042-024-18550-z", "title": "Underwater image enhancement using lightweight vision transformer", "abstract": "", "authors": ["Muneeba Daud", "Hammad Afzal", "Khawir Mahmood"], "year": 2024, "venue": "Multimedia Tools and Applications", "cited_by_count": 6, "type": "article", "concepts": ["Computer science", "Underwater", "Artificial intelligence", "Transformer", "Computer vision"], "search_query": "image restoration transformer architecture efficient", "score": 5.5, "subtopic": "Transformer Restoration", "rationale": "Lightweight transformer for underwater image enhancement; domain-specific restoration application.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Lightweight vision transformer for underwater enhancement", "key_findings": "Efficient underwater image quality improvement", "limitations": "Domain-specific underwater focus"}}
{"openalex_id": "https://openalex.org/W4382240242", "doi": "https://doi.org/10.1609/aaai.v37i3.25364", "title": "Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method", "abstract": "As the quality of optical sensors improves, there is a need for processing large-scale images. In particular, the ability of devices to capture ultra-high definition (UHD) images and video places new demands on the image processing pipeline. In this paper, we consider the task of low-light image enhancement (LLIE) and introduce a large-scale database consisting of images at 4K and 8K resolution. We conduct systematic benchmarking studies and provide a comparison of current LLIE algorithms. As a second contribution, we introduce LLFormer, a transformer-based low-light enhancement method. The core components of LLFormer are the axis-based multi-head self-attention and cross-layer attention fusion block, which significantly reduces the linear complexity. Extensive experiments on the new dataset and existing public datasets show that LLFormer outperforms state-of-the-art methods. We also show that employing existing LLIE methods trained on our benchmark as a pre-processing step significantly improves the performance of downstream tasks, e.g., face detection in low-light conditions. The source code and pre-trained models are available at https://github.com/TaoWangzj/LLFormer.", "authors": ["Tao Wang", "Kaihao Zhang", "Tianrun Shen", "Wenhan Luo", "Björn Stenger", "Tong Lu"], "year": 2023, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 359, "type": "article", "concepts": ["Computer science", "Benchmarking", "Benchmark (surveying)", "Artificial intelligence", "Transformer"], "search_query": "image restoration transformer architecture efficient", "score": 6.5, "subtopic": "Transformer Restoration", "rationale": "Transformer for UHD low-light enhancement; relevant efficient restoration at high resolution.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Transformer-based method for ultra-high-definition low-light enhancement", "key_findings": "Scalable transformer design for large-scale image restoration", "limitations": "Single task focus on low-light"}}
{"openalex_id": "https://openalex.org/W4366091323", "doi": "https://doi.org/10.1007/s10462-023-10466-8", "title": "Deep learning modelling techniques: current progress, applications, advantages, and challenges", "abstract": "Abstract Deep learning (DL) is revolutionizing evidence-based decision-making techniques that can be applied across various sectors. Specifically, it possesses the ability to utilize two or more levels of non-linear feature transformation of the given data via representation learning in order to overcome limitations posed by large datasets. As a multidisciplinary field that is still in its nascent phase, articles that survey DL architectures encompassing the full scope of the field are rather limited. Thus, this paper comprehensively reviews the state-of-art DL modelling techniques and provides insights into their advantages and challenges. It was found that many of the models exhibit a highly domain-specific efficiency and could be trained by two or more methods. However, training DL models can be very time-consuming, expensive, and requires huge samples for better accuracy. Since DL is also susceptible to deception and misclassification and tends to get stuck on local minima, improved optimization of parameters is required to create more robust models. Regardless, DL has already been leading to groundbreaking results in the healthcare, education, security, commercial, industrial, as well as government sectors. Some models, like the convolutional neural network (CNN), generative adversarial networks (GAN), recurrent neural network (RNN), recursive neural networks, and autoencoders, are frequently used, while the potential of other models remains widely unexplored. Pertinently, hybrid conventional DL architectures have the capacity to overcome the challenges experienced by conventional models. Considering that capsule architectures may dominate future DL models, this work aimed to compile information for stakeholders involved in the development and use of DL models in the contemporary world.", "authors": ["Shams Forruque Ahmed", "Md. Sakib Bin Alam", "Maruf Hassan", "Mahtabin Rodela Rozbu", "Taoseef Ishtiak", "Nazifa Rafa", "M. Mofijur", "A. B. M. Shawkat Ali", "Amir H. Gandomi"], "year": 2023, "venue": "Artificial Intelligence Review", "cited_by_count": 790, "type": "article", "concepts": ["Computer science", "Deep learning", "Artificial intelligence", "Machine learning", "Field (mathematics)"], "search_query": "image restoration transformer architecture efficient", "score": 2, "subtopic": "", "rationale": "General deep learning survey covering broad applications, not specific to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4408456561", "doi": "https://doi.org/10.3390/s25061803", "title": "Adaptive Vectorial Restoration from Dynamic Speckle Patterns Through Biological Scattering Media Based on Deep Learning", "abstract": "Imaging technologies based on vector optical fields hold significant potential in the biomedical field, particularly for non-invasive scattering imaging of anisotropic biological tissues. However, the dynamic and anisotropic nature of biological tissues poses severe challenges to the propagation and reconstruction of vector optical fields due to light scattering. To address this, we propose a deep learning-based polarization-resolved restoration method aimed at achieving the efficient and accurate imaging reconstruction from speckle patterns generated after passing through anisotropic and dynamic time-varying biological scattering media. By innovatively leveraging the two orthogonal polarization components of vector optical fields, our approach significantly enhances the robustness of imaging reconstruction in dynamic and anisotropic biological scattering media, benefiting from the additional information dimension of vectorial optical fields and the powerful learning capacity of a deep neural network. For the first time, a hybrid network model is designed that integrates convolutional neural networks (CNN) with a Transformer architecture for capturing local and global features of a speckle image, enabling adaptive vectorial restoration of dynamically time-varying speckle patterns. The experimental results demonstrate that the model exhibits excellent robustness and generalization capabilities in reconstructing the two orthogonal polarization components from dynamic speckle patterns behind anisotropic biological media. This study not only provides an efficient solution for scattering imaging of dynamic anisotropic biological tissues but also advances the application of vector optical fields in dynamic scattering environments through the integration of deep learning and optical technologies.", "authors": ["Yu–Chen Chen", "Shixuan Mi", "Yaping Tian", "Xiaobo Hu", "Qiangqiang Yuan", "Khian‐Hooi Chew", "Rui‐Pin Chen"], "year": 2025, "venue": "Sensors", "cited_by_count": 5, "type": "article", "concepts": ["Speckle pattern", "Robustness (evolution)", "Computer science", "Artificial intelligence", "Scattering"], "search_query": "image restoration transformer architecture efficient", "score": 3, "subtopic": "", "rationale": "Optical imaging restoration through scattering media using deep learning; tangentially related but different imaging modality.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2923477440", "doi": "https://doi.org/10.3390/inventions4010022", "title": "Internet of Things in Smart Grid: Architecture, Applications, Services, Key Technologies, and Challenges", "abstract": "Internet of Things (IoT) is a connection of people and things at any time, in any place, with anyone and anything, using any network and any service. Thus, IoT is a huge dynamic global network infrastructure of Internet-enabled entities with web services. One of the most important applications of IoT is the Smart Grid (SG). SG is a data communications network which is integrated with the power grid to collect and analyze data that are acquired from transmission lines, distribution substations, and consumers. In this paper, we talk about IoT and SG and their relationship. Some IoT architectures in SG, requirements for using IoT in SG, IoT applications and services in SG, and challenges and future work are discussed.", "authors": ["Alireza Ghasempour"], "year": 2019, "venue": "Inventions", "cited_by_count": 629, "type": "article", "concepts": ["Internet of Things", "Smart grid", "Computer science", "Key (lock)", "Architecture"], "search_query": "image restoration transformer architecture efficient", "score": 1, "subtopic": "", "rationale": "IoT and smart grid paper, completely unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4392642845", "doi": "https://doi.org/10.1109/access.2024.3375360", "title": "Decomformer: Decompose Self-Attention of Transformer for Efficient Image Restoration", "abstract": "A transformer architecture achieves outstanding performance in computer vision tasks based on the ability to capture long-range dependencies. However, a quadratic increase in complexity with respect to spatial resolution makes it impractical to apply for image restoration tasks. In this paper, we propose a Decomformer that efficiently captures global relationship by decomposing self-attention into linear combination of vectors and coefficients to reduce the heavy computational cost. This approximation not only reduces the complexity linearly, but also preserves the globality of the vanilla self-attention properly. Moreover, we apply a linear simple gate to represent the complex self-attention mechanism as the proposed decomposition directly. To show the effectiveness of our approach, we apply it to image restoration tasks including denoising, deblurring and deraining. The proposed decomposing scheme for self-attention in the Transformer achieves better or comparable results with state-of-the-arts as well as much more efficiency than most of previous approaches.", "authors": ["Eunho Lee", "Youngbae Hwang"], "year": 2024, "venue": "IEEE Access", "cited_by_count": 3, "type": "article", "concepts": ["Deblurring", "Computer science", "Image restoration", "Transformer", "Globality"], "search_query": "image restoration transformer architecture efficient", "score": 7.5, "subtopic": "Transformer Restoration", "rationale": "Efficient transformer via self-attention decomposition for image restoration; relevant architecture optimization.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Decomposed self-attention reducing quadratic complexity for restoration", "key_findings": "Efficient attention mechanism maintaining restoration quality", "limitations": "Published in IEEE Access, lower venue impact"}}
{"openalex_id": "https://openalex.org/W4403754946", "doi": "https://doi.org/10.48550/arxiv.2409.13094", "title": "DenoMamba: A fused state-space model for low-dose CT denoising", "abstract": "Low-dose computed tomography (LDCT) lower potential risks linked to radiation exposure while relying on advanced denoising algorithms to maintain diagnostic quality in reconstructed images. The reigning paradigm in LDCT denoising is based on neural network models that learn data-driven image priors to separate noise evoked by dose reduction from underlying tissue signals. Naturally, the fidelity of these priors depend on the model's ability to capture the broad range of contextual features evident in CT images. Earlier convolutional neural networks (CNN) are highly adept at efficiently capturing short-range spatial context, but their limited receptive fields reduce sensitivity to interactions over longer distances. Although transformers based on self-attention mechanisms have recently been posed to increase sensitivity to long-range context, they can suffer from suboptimal performance and efficiency due to elevated model complexity, particularly for high-resolution CT images. For high-quality restoration of LDCT images, here we introduce DenoMamba, a novel denoising method based on state-space modeling (SSM), that efficiently captures short- and long-range context in medical images. Following an hourglass architecture with encoder-decoder stages, DenoMamba employs a spatial SSM module to encode spatial context and a novel channel SSM module equipped with a secondary gated convolution network to encode latent features of channel context at each stage. Feature maps from the two modules are then consolidated with low-level input features via a convolution fusion module (CFM). Comprehensive experiments on LDCT datasets with 25\\% and 10\\% dose reduction demonstrate that DenoMamba outperforms state-of-the-art denoisers with average improvements of 1.4dB PSNR, 1.1% SSIM, and 1.6% RMSE in recovered image quality.", "authors": ["Şaban Öztürk", "Özge Duran", "Tolga Çukur"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 7, "type": "preprint", "concepts": ["Noise reduction", "Space (punctuation)", "State space", "State (computer science)", "Nuclear medicine"], "search_query": "image restoration transformer architecture efficient", "score": 4, "subtopic": "", "rationale": "Mamba-based CT denoising; medical imaging specific, tangentially related architecture.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4410729663", "doi": "https://doi.org/10.1007/s00371-025-03947-0", "title": "An asymmetric calibrated transformer network for underwater image restoration", "abstract": "", "authors": ["Xiaojiao Guo", "Shenghong Luo", "Yihang Dong", "Zexiao Liang", "Zimeng Li", "Xiujun Zhang", "Xuhang Chen"], "year": 2025, "venue": "The Visual Computer", "cited_by_count": 2, "type": "article", "concepts": ["Underwater", "Transformer", "Computer graphics", "Computer science", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient", "score": 5.5, "subtopic": "Transformer Restoration", "rationale": "Transformer for underwater image restoration; domain-specific but relevant architecture.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Asymmetric calibrated transformer adapted for underwater restoration", "key_findings": "Improved underwater image quality via asymmetric attention", "limitations": "Domain-specific underwater focus"}}
{"openalex_id": "https://openalex.org/W4367055910", "doi": "https://doi.org/10.1038/s41746-023-00811-0", "title": "Self-supervised learning for medical image classification: a systematic review and implementation guidelines", "abstract": "", "authors": ["Shih-Cheng Huang", "Anuj Pareek", "Malte Jensen", "Matthew P. Lungren", "Serena Yeung", "Akshay Chaudhari"], "year": 2023, "venue": "npj Digital Medicine", "cited_by_count": 356, "type": "review", "concepts": ["Artificial intelligence", "Computer science", "Machine learning", "Deep learning", "Supervised learning"], "search_query": "image restoration transformer architecture efficient", "score": 2, "subtopic": "", "rationale": "Medical image classification survey, not related to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4406030314", "doi": "https://doi.org/10.1007/s11760-024-03798-7", "title": "Multi-scale representation for image deraining with state space model", "abstract": "", "authors": ["Yufeng Li", "Chuanlong Xie", "Hongming Chen"], "year": 2025, "venue": "Signal Image and Video Processing", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Feature (linguistics)", "Convolutional neural network", "Block (permutation group theory)"], "search_query": "image restoration transformer architecture efficient", "score": 6.5, "subtopic": "Transformer Restoration", "rationale": "State space model for image deraining with multi-scale representation; relevant architecture for restoration.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Multi-scale state space model for single image deraining", "key_findings": "Effective multi-scale feature extraction for rain removal", "limitations": "Single degradation type"}}
{"openalex_id": "https://openalex.org/W4404275081", "doi": "https://doi.org/10.2139/ssrn.5018208", "title": "Joint Multi-Dimensional Dynamic Attention and Transformer for General Image Restoration", "abstract": "", "authors": ["Huan Zhang", "Xu Zhang", "Nian Cai", "Jianglei Di", "Yun Zhang"], "year": 2024, "venue": "SSRN Electronic Journal", "cited_by_count": 2, "type": "preprint", "concepts": ["Joint (building)", "Transformer", "Image restoration", "Computer science", "Computer vision"], "search_query": "image restoration transformer architecture efficient", "score": 7.5, "subtopic": "Transformer Restoration", "rationale": "Multi-dimensional dynamic attention transformer for general image restoration; relevant unified architecture.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Joint multi-dimensional dynamic attention with transformer for general restoration", "key_findings": "Dynamic attention adapts to different restoration tasks", "limitations": "SSRN preprint"}}
{"openalex_id": "https://openalex.org/W4283801824", "doi": "https://doi.org/10.1038/s41551-022-00898-y", "title": "Shifting machine learning for healthcare from development to deployment and from models to data", "abstract": "In the past decade, the application of machine learning (ML) to healthcare has helped drive the automation of physician tasks as well as enhancements in clinical capabilities and access to care. This progress has emphasized that, from model development to model deployment, data play central roles. In this Review, we provide a data-centric view of the innovations and challenges that are defining ML for healthcare. We discuss deep generative models and federated learning as strategies to augment datasets for improved model performance, as well as the use of the more recent transformer models for handling larger datasets and enhancing the modelling of clinical text. We also discuss data-focused problems in the deployment of ML, emphasizing the need to efficiently deliver data to ML models for timely clinical predictions and to account for natural data shifts that can deteriorate model performance.", "authors": ["Angela Zhang", "Lei Xing", "James Zou", "Joseph C. Wu"], "year": 2022, "venue": "Nature Biomedical Engineering", "cited_by_count": 373, "type": "review", "concepts": ["Software deployment", "Computer science", "Artificial intelligence", "Health care", "Machine learning"], "search_query": "image restoration transformer architecture efficient", "score": 1, "subtopic": "", "rationale": "Healthcare ML paper, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4411899995", "doi": "https://doi.org/10.1007/s00521-025-11440-x", "title": "LDFormer: lightweight dehazing transformer", "abstract": "", "authors": ["D. Pushpalatha", "P. Prithvi"], "year": 2025, "venue": "Neural Computing and Applications", "cited_by_count": 3, "type": "article", "concepts": ["Computational Science and Engineering", "Computer science", "Transformer", "Machine learning", "Electrical engineering"], "search_query": "image restoration transformer architecture efficient", "score": 6, "subtopic": "Transformer Restoration", "rationale": "Lightweight transformer for image dehazing; relevant efficient restoration architecture.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Lightweight transformer design for efficient dehazing", "key_findings": "Reduced model size while maintaining dehazing quality", "limitations": "Single task focus on dehazing"}}
{"openalex_id": "https://openalex.org/W4382568119", "doi": "https://doi.org/10.2139/ssrn.4495224", "title": "Blind Face Restoration: Benchmark Datasets and a Baseline Model", "abstract": "", "authors": ["Puyang Zhang", "Kaihao Zhang", "Wenhan Luo", "Changsheng Li", "Guoren Wang"], "year": 2023, "venue": "SSRN Electronic Journal", "cited_by_count": 5, "type": "preprint", "concepts": ["Benchmark (surveying)", "Baseline (sea)", "Computer science", "Face (sociological concept)", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient", "score": 5, "subtopic": "Real-World Degradation", "rationale": "Face restoration benchmark; relevant to real-world restoration but domain-specific.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Benchmark datasets and baseline for blind face restoration", "key_findings": "Standardized evaluation for face restoration", "limitations": "Face-specific, SSRN preprint"}}
{"openalex_id": "https://openalex.org/W4205129187", "doi": "https://doi.org/10.1109/access.2022.3142859", "title": "Particle Swarm Optimization: A Comprehensive Survey", "abstract": "Particle swarm optimization (PSO) is one of the most well-regarded swarm-based algorithms in the literature. Although the original PSO has shown good optimization performance, it still severely suffers from premature convergence. As a result, many researchers have been modifying it resulting in a large number of PSO variants with either slightly or significantly better performance. Mainly, the standard PSO has been modified by four main strategies: modification of the PSO controlling parameters, hybridizing PSO with other well-known meta-heuristic algorithms such as genetic algorithm (GA) and differential evolution (DE), cooperation and multi-swarm techniques. This paper attempts to provide a comprehensive review of PSO, including the basic concepts of PSO, binary PSO, neighborhood topologies in PSO, recent and historical PSO variants, remarkable engineering applications of PSO, and its drawbacks. Moreover, this paper reviews recent studies that utilize PSO to solve feature selection problems. Finally, eight potential research directions that can help researchers further enhance the performance of PSO are provided.", "authors": ["Tareq M. Shami", "Ayman A. El‐Saleh", "Mohammed Alswaitti", "Qasem Al-Tashi", "Mhd Amen Summakieh", "Seyedali Mirjalili"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 1158, "type": "article", "concepts": ["Particle swarm optimization", "Premature convergence", "Computer science", "Swarm behaviour", "Mathematical optimization"], "search_query": "image restoration transformer architecture efficient", "score": 1, "subtopic": "", "rationale": "Optimization algorithm survey, unrelated to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4409019412", "doi": "https://doi.org/10.1109/jsen.2025.3554650", "title": "Weather-Robust Spatial-Frequency Decoupling Transformer for Crack Segmentation", "abstract": "Using edge devices such as drones for road inspections is critical for monitoring the structural integrity of transportation infrastructure. However, the limited resources of these devices constrain the deployment of high-performance models, while dynamic weather conditions require greater model stability. To address the challenge of efficient crack detection across various environments, we propose the spatial-frequency decoupling transformer (SFDFormer). Our model integrates an all-inone restoration module and a frequency decoupling module. The restoration module, combining AdverseGAN and stacked attention-integrated iterative recovery (AIIR) modules, restores images degraded by adverse weather. The frequency decoupling module employs a lightweight parallel network architecture to establish a correspondence between frequency-domain components and spatial-domain pixels, enabling direct extraction of crack edges and region information from the raw image. This approach effectively leverages semantic details from the frequency domain for pixel-level crack segmentation. Extensive experiments across six benchmark datasets demonstrate that SFDFormer consistently outperforms existing models, setting a new standard for crack detection on edge devices under harsh weather conditions.", "authors": ["Senyang Li", "Siqi Cai", "Siohong Teng", "Siwei Wei", "Jingling Yuan", "Xian Zhong"], "year": 2025, "venue": "IEEE Sensors Journal", "cited_by_count": 3, "type": "article", "concepts": ["Decoupling (probability)", "Transformer", "Segmentation", "Computer science", "Electronic engineering"], "search_query": "image restoration transformer architecture efficient", "score": 3, "subtopic": "", "rationale": "Crack segmentation on roads, not image restoration. Weather robustness is for detection not restoration.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4285065952", "doi": "https://doi.org/10.1109/access.2022.3179517", "title": "A Review of Wavelet Analysis and Its Applications: Challenges and Opportunities", "abstract": "As a general and rigid mathematical tool, wavelet theory has found many applications and is constantly developing. This article reviews the development history of wavelet theory, from the construction method to the discussion of wavelet properties. Then it focuses on the design and expansion of wavelet transform. The main models and algorithms of wavelet transform are discussed. The construction of rational wavelet transform (RWT) is provided by examples emphasizing the advantages of RWT over traditional wavelet transform through a review of the literature. The combination of wavelet theory and neural networks is one of the key points of the review. The review covers the evolution of Wavelet Neural Network (WNN), the system architecture and algorithm implementation. The review of the literature indicates the advantages and a clear trend of fast development inWNNthat can be combined with existing neural network algorithms. This article also introduces the categories of wavelet-based applications. The advantages of wavelet analysis are summarized in terms of application scenarios with a comparison of results. Through the review, new research challenges and gaps have been clarified, which will serve as a guide for potential wavelet-based applications and new system designs.", "authors": ["Tiantian Guo", "Tongpo Zhang", "Eng Gee Lim", "Miguel López‐Benítez", "Fei Ma", "Limin Yu"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 446, "type": "review", "concepts": ["Wavelet", "Wavelet transform", "Lifting scheme", "Computer science", "Wavelet packet decomposition"], "search_query": "image restoration transformer architecture efficient", "score": 2, "subtopic": "", "rationale": "General wavelet analysis review, too broad to be directly relevant to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4393150006", "doi": "https://doi.org/10.1609/aaai.v38i2.27907", "title": "Omni-Kernel Network for Image Restoration", "abstract": "Image restoration aims to reconstruct a high-quality image from a degraded low-quality observation. Recently, Transformer models have achieved promising performance on image restoration tasks due to their powerful ability to model long-range dependencies. However, the quadratically growing complexity with respect to the input size makes them inapplicable to practical applications. In this paper, we develop an efficient convolutional network for image restoration by enhancing multi-scale representation learning. To this end, we propose an omni-kernel module that consists of three branches, i.e., global, large, and local branches, to learn global-to-local feature representations efficiently. Specifically, the global branch achieves a global perceptive field via the dual-domain channel attention and frequency-gated mechanism. Furthermore, to provide multi-grained receptive fields, the large branch is formulated via different shapes of depth-wise convolutions with unusually large kernel sizes. Moreover, we complement local information using a point-wise depth-wise convolution. Finally, the proposed network, dubbed OKNet, is established by inserting the omni-kernel module into the bottleneck position for efficiency. Extensive experiments demonstrate that our network achieves state-of-the-art performance on 11 benchmark datasets for three representative image restoration tasks, including image dehazing, image desnowing, and image defocus deblurring. The code is available at https://github.com/c-yn/OKNet.", "authors": ["Yuning Cui", "Wenqi Ren", "Alois Knoll"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 183, "type": "article", "concepts": ["Image restoration", "Kernel (algebra)", "Computer science", "Artificial intelligence", "Image (mathematics)"], "search_query": "image restoration transformer architecture efficient", "score": 7.5, "subtopic": "Transformer Restoration", "rationale": "Multi-scale omni-kernel network for image restoration with global-to-local processing; relevant spatial-aware design.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Omni-kernel module with global, large, and local branches for multi-scale features", "key_findings": "SOTA on dehazing, desnowing, and defocus deblurring on 11 benchmarks", "limitations": "CNN-based, no transformer component despite competing with them"}}
{"openalex_id": "https://openalex.org/W4375827355", "doi": "https://doi.org/10.1007/978-3-031-31417-9_40", "title": "A Transformer-Based U-Net Architecture for Fast and Efficient Image Demoireing", "abstract": "", "authors": ["Densen Puthussery", "P. S. Hrishikesh", "C. V. Jiji"], "year": 2023, "venue": "Communications in computer and information science", "cited_by_count": 1, "type": "book-chapter", "concepts": ["Deblurring", "Computer science", "Transformer", "Architecture", "Artificial intelligence"], "search_query": "image restoration transformer architecture efficient", "score": 5.5, "subtopic": "Transformer Restoration", "rationale": "Transformer U-Net for demoireing; relevant architecture but niche restoration task.", "alignment": {"task": "low", "method": "medium", "modality": "high"}, "extraction": {"design": "Transformer-based U-Net architecture for moire pattern removal", "key_findings": "Efficient demoireing via transformer U-Net", "limitations": "Very specific task, limited venue"}}
{"openalex_id": "https://openalex.org/W2997150500", "doi": "https://doi.org/10.1609/aaai.v34i07.6693", "title": "Channel Attention Is All You Need for Video Frame Interpolation", "abstract": "Prevailing video frame interpolation techniques rely heavily on optical flow estimation and require additional model complexity and computational cost; it is also susceptible to error propagation in challenging scenarios with large motion and heavy occlusion. To alleviate the limitation, we propose a simple but effective deep neural network for video frame interpolation, which is end-to-end trainable and is free from a motion estimation network component. Our algorithm employs a special feature reshaping operation, referred to as PixelShuffle, with a channel attention, which replaces the optical flow computation module. The main idea behind the design is to distribute the information in a feature map into multiple channels and extract motion information by attending the channels for pixel-level frame synthesis. The model given by this principle turns out to be effective in the presence of challenging motion and occlusion. We construct a comprehensive evaluation benchmark and demonstrate that the proposed approach achieves outstanding performance compared to the existing models with a component for optical flow computation.", "authors": ["Myungsub Choi", "Heewon Kim", "Bohyung Han", "Ning Xu", "Kyoung Mu Lee"], "year": 2020, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 325, "type": "article", "concepts": ["Computer science", "Optical flow", "Interpolation (computer graphics)", "Channel (broadcasting)", "Motion interpolation"], "search_query": "image restoration transformer architecture efficient", "score": 3, "subtopic": "", "rationale": "Video frame interpolation, not image restoration. Different task category.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W3133049266", "doi": "https://doi.org/10.1109/jstsp.2021.3053364", "title": "Editorial: Introduction to the Issue on Deep Learning for Image/Video Restoration and Compression", "abstract": "The papers in this special issue focus on deep learning for image/video restoration and compression. The huge success of deep-learning-based approaches in computer vision has inspired research in learned solutions to classic image/video processing problems, such as denoising, deblurring, dehazing, deraining, super-resolution (SR), and compression. Hence, learning-based methods have emerged as a promising nonlinear signal-processing framework for image/ video restoration and compression. Recent works have shown that learned models can achieve significant performance gains, especially in terms of perceptual quality measures, over traditional methods. Hence, the state of the art in image restoration and compression is getting redefined. This special issue covers the state of the art in learned image/video restoration and compression to promote further progress in innovative architectures and training methods for effective and efficient networks for image/video restoration and compression.", "authors": ["A. Murat Tekalp", "Michele Covell", "Radu Timofte", "Chao Dong"], "year": 2021, "venue": "IEEE Journal of Selected Topics in Signal Processing", "cited_by_count": 7, "type": "editorial", "concepts": ["Deblurring", "Image restoration", "Computer science", "Compression artifact", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5, "subtopic": "Real-World Degradation", "rationale": "Editorial overview of deep learning for image/video restoration and compression; provides field context.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Editorial summarizing special issue papers on DL restoration", "key_findings": "Overview of trends in deep learning restoration research", "limitations": "Editorial, no novel technical contribution"}}
{"openalex_id": "https://openalex.org/W4389599809", "doi": "https://doi.org/10.48550/arxiv.2312.05038", "title": "Prompt-In-Prompt Learning for Universal Image Restoration", "abstract": "Image restoration, which aims to retrieve and enhance degraded images, is fundamental across a wide range of applications. While conventional deep learning approaches have notably improved the image quality across various tasks, they still suffer from (i) the high storage cost needed for various task-specific models and (ii) the lack of interactivity and flexibility, hindering their wider application. Drawing inspiration from the pronounced success of prompts in both linguistic and visual domains, we propose novel Prompt-In-Prompt learning for universal image restoration, named PIP. First, we present two novel prompts, a degradation-aware prompt to encode high-level degradation knowledge and a basic restoration prompt to provide essential low-level information. Second, we devise a novel prompt-to-prompt interaction module to fuse these two prompts into a universal restoration prompt. Third, we introduce a selective prompt-to-feature interaction module to modulate the degradation-related feature. By doing so, the resultant PIP works as a plug-and-play module to enhance existing restoration models for universal image restoration. Extensive experimental results demonstrate the superior performance of PIP on multiple restoration tasks, including image denoising, deraining, dehazing, deblurring, and low-light enhancement. Remarkably, PIP is interpretable, flexible, efficient, and easy-to-use, showing promising potential for real-world applications. The code is available at https://github.com/longzilicart/pip_universal.", "authors": ["Zilong Li", "Yiming Lei", "Chenglong Ma", "Junping Zhang", "Hongming Shan"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 6, "type": "preprint", "concepts": ["Deblurring", "Computer science", "Image restoration", "Flexibility (engineering)", "Feature (linguistics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 9, "subtopic": "All-in-One Restoration", "rationale": "Prompt-in-prompt learning for universal image restoration; directly relevant to unified prompt-based restoration approaches.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Hierarchical prompt-in-prompt framework for universal restoration", "key_findings": "Flexible prompt-based approach handling diverse degradations", "limitations": "arXiv preprint"}}
{"openalex_id": "https://openalex.org/W4385667669", "doi": "https://doi.org/10.1007/s11263-023-01843-5", "title": "Pyramid Attention Network for Image Restoration", "abstract": "", "authors": ["Yiqun Mei", "Yuchen Fan", "Yulun Zhang", "Jiahui Yu", "Yuqian Zhou", "Ding Liu", "Yun Fu", "Thomas S. Huang", "Humphrey Shi"], "year": 2023, "venue": "International Journal of Computer Vision", "cited_by_count": 112, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Pyramid (geometry)", "Computer vision", "Image restoration"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Pyramid attention network for image restoration; relevant multi-scale attention architecture.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Multi-scale pyramid attention for image restoration", "key_findings": "Effective multi-scale feature aggregation for restoration", "limitations": "Older architecture design"}}
{"openalex_id": "https://openalex.org/W4323022514", "doi": "https://doi.org/10.1109/access.2023.3250616", "title": "A Comprehensive Review of Deep Learning-Based Real-World Image Restoration", "abstract": "Real-world imagery does not always exhibit good visibility and clean content, but often suffers from various kinds of degradations (e.g., noise, blur, rain drops, fog, color distortion, etc.), which severely affect vision-driven tasks (e.g., image classification, target recognition, and tracking, etc.). Thus, restoring the true scene from such degraded images is of significance. In recent years, a large body of deep learning-based image processing works has been exploited due to the advances in deep neural networks. This paper aims to make a comprehensive review of real-world image restoration algorithms and beyond. More specifically, this review provides overviews of critical benchmark datasets, image quality assessment methods, and four major categories of deep learning-based image restoration methods, i.e., based on convolutional neural network (CNN), generative adversarial network (GAN), Transformer, and multi-layer perceptron (MLP). The paper highlights the latest developments and advances in each category of network architecture to provide an up-to-date overview. Moreover, the representative state-of-the-art image restoration methods are compared visually and numerically. Finally, for real-world image restoration, the current situations are objectively assessed, challenges are discussed, and future directions and trends are presented.", "authors": ["Lujun Zhai", "Yonghui Wang", "Suxia Cui", "Yu Zhou"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 62, "type": "review", "concepts": ["Computer science", "Image restoration", "Artificial intelligence", "Convolutional neural network", "Deep learning"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 7, "subtopic": "Real-World Degradation", "rationale": "Comprehensive review of DL-based real-world image restoration covering multiple degradation types.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Survey of deep learning methods for real-world degradations", "key_findings": "Systematic categorization of restoration approaches and degradation types", "limitations": "Review paper, no novel methods"}}
{"openalex_id": "https://openalex.org/W4400238700", "doi": "https://doi.org/10.3390/app14135683", "title": "A Survey on Visual Mamba", "abstract": "State space models (SSM) with selection mechanisms and hardware-aware architectures, namely Mamba, have recently shown significant potential in long-sequence modeling. Since the complexity of transformers’ self-attention mechanism is quadratic with image size, as well as increasing computational demands, researchers are currently exploring how to adapt Mamba for computer vision tasks. This paper is the first comprehensive survey that aims to provide an in-depth analysis of Mamba models within the domain of computer vision. It begins by exploring the foundational concepts contributing to Mamba’s success, including the SSM framework, selection mechanisms, and hardware-aware design. Then, we review these vision Mamba models by categorizing them into foundational models and those enhanced with techniques including convolution, recurrence, and attention to improve their sophistication. Furthermore, we investigate the widespread applications of Mamba in vision tasks, which include their use as a backbone in various levels of vision processing. This encompasses general visual tasks, medical visual tasks (e.g., 2D/3D segmentation, classification, image registration, etc.), and remote sensing visual tasks. In particular, we introduce general visual tasks from two levels: high/mid-level vision (e.g., object detection, segmentation, video classification, etc.) and low-level vision (e.g., image super-resolution, image restoration, visual generation, etc.). We hope this endeavor will spark additional interest within the community to address current challenges and further apply Mamba models in computer vision.", "authors": ["Hanwei Zhang", "Ying Zhu", "Dan Wang", "Lijun Zhang", "Tianxiang Chen", "Ziyang Wang", "Zi Ye"], "year": 2024, "venue": "Applied Sciences", "cited_by_count": 132, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Sophistication", "Computer vision", "Segmentation"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 4, "subtopic": "", "rationale": "Survey on visual Mamba architectures broadly; tangentially relevant as emerging backbone for vision tasks.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4221160948", "doi": "https://doi.org/10.1109/jbhi.2022.3187103", "title": "RFormer: Transformer-Based Generative Adversarial Network for Real Fundus Image Restoration on a New Clinical Benchmark", "abstract": "Ophthalmologists have used fundus images to screen and diagnose eye diseases. However, different equipments and ophthalmologists pose large variations to the quality of fundus images. Low-quality (LQ) degraded fundus images easily lead to uncertainty in clinical screening and generally increase the risk of misdiagnosis. Thus, real fundus image restoration is worth studying. Unfortunately, real clinical benchmark has not been explored for this task so far. In this paper, we investigate the real clinical fundus image restoration problem. Firstly, We establish a clinical dataset, Real Fundus (RF), including 120 low- and high-quality (HQ) image pairs. Then we propose a novel Transformer-based Generative Adversarial Network (RFormer) to restore the real degradation of clinical fundus images. The key component in our network is the Window-based Self-Attention Block (WSAB) which captures non-local self-similarity and long-range dependencies. To produce more visually pleasant results, a Transformer-based discriminator is introduced. Extensive experiments on our clinical benchmark show that the proposed RFormer significantly outperforms the state-of-the-art (SOTA) methods. In addition, experiments of downstream tasks such as vessel segmentation and optic disc/cup detection demonstrate that our proposed RFormer benefits clinical fundus image analysis and applications.", "authors": ["Zhuo Deng", "Yuanhao Cai", "Lu Chen", "Zheng Gong", "Qiqi Bao", "Xue Yao", "Fang Dong", "Wenming Yang", "Shaochong Zhang", "Lan Ma"], "year": 2022, "venue": "IEEE Journal of Biomedical and Health Informatics", "cited_by_count": 76, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Discriminator", "Fundus (uterus)", "Benchmark (surveying)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5.5, "subtopic": "Transformer Restoration", "rationale": "Transformer-GAN for fundus image restoration; relevant architecture but medical domain specific.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Transformer-based GAN for real fundus image restoration benchmark", "key_findings": "Clinical benchmark for fundus image restoration quality", "limitations": "Medical domain specific"}}
{"openalex_id": "https://openalex.org/W3154672751", "doi": "https://doi.org/10.1155/2021/5541134", "title": "Deep CNN and Deep GAN in Computational Visual Perception‐Driven Image Analysis", "abstract": "Computational visual perception, also known as computer vision, is a field of artificial intelligence that enables computers to process digital images and videos in a similar way as biological vision does. It involves methods to be developed to replicate the capabilities of biological vision. The computer vision’s goal is to surpass the capabilities of biological vision in extracting useful information from visual data. The massive data generated today is one of the driving factors for the tremendous growth of computer vision. This survey incorporates an overview of existing applications of deep learning in computational visual perception. The survey explores various deep learning techniques adapted to solve computer vision problems using deep convolutional neural networks and deep generative adversarial networks. The pitfalls of deep learning and their solutions are briefly discussed. The solutions discussed were dropout and augmentation. The results show that there is a significant improvement in the accuracy using dropout and data augmentation. Deep convolutional neural networks’ applications, namely, image classification, localization and detection, document analysis, and speech recognition, are discussed in detail. In‐depth analysis of deep generative adversarial network applications, namely, image‐to‐image translation, image denoising, face aging, and facial attribute editing, is done. The deep generative adversarial network is unsupervised learning, but adding a certain number of labels in practical applications can improve its generating ability. However, it is challenging to acquire many data labels, but a small number of data labels can be acquired. Therefore, combining semisupervised learning and generative adversarial networks is one of the future directions. This article surveys the recent developments in this direction and provides a critical review of the related significant aspects, investigates the current opportunities and future challenges in all the emerging domains, and discusses the current opportunities in many emerging fields such as handwriting recognition, semantic mapping, webcam‐based eye trackers, lumen center detection, query‐by‐string word, intermittently closed and open lakes and lagoons, and landslides.", "authors": ["R. Abirami", "P. M. Durai Raj Vincent", "Kathiravan Srinivasan", "Usman Tariq", "Chuan‐Yu Chang"], "year": 2021, "venue": "Complexity", "cited_by_count": 77, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Image (mathematics)", "Perception", "Deep learning"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3, "subtopic": "", "rationale": "General survey on CNN and GAN for visual perception, too broad for direct relevance.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4283820866", "doi": "https://doi.org/10.1609/aaai.v36i2.20033", "title": "Close the Loop: A Unified Bottom-Up and Top-Down Paradigm for Joint Image Deraining and Segmentation", "abstract": "In this work, we focus on a very practical problem: image segmentation under rain conditions. Image deraining is a classic low-level restoration task, while image segmentation is a typical high-level understanding task. Most of the existing methods intuitively employ the bottom-up paradigm by taking deraining as a preprocessing step for subsequent segmentation. However, our statistical analysis indicates that not only deraining would benefit segmentation (bottom-up), but also segmentation would further improve deraining performance (top-down) in turn. This motivates us to solve the rainy image segmentation task within a novel top-down and bottom-up unified paradigm, in which two sub-tasks are alternatively performed and collaborated with each other. Specifically, the bottom-up procedure yields both clearer images and rain-robust features from both image and feature domains, so as to ease the segmentation ambiguity caused by rain streaks. The top-down procedure adopts semantics to adaptively guide the restoration for different contents via a novel multi-path semantic attentive module (SAM). Thus the deraining and segmentation could boost the performance of each other cooperatively and progressively. Extensive experiments and ablations demonstrate that the proposed method outperforms the state-of-the-art on rainy image segmentation.", "authors": ["Yi Li", "Yi Chang", "Chang‐Feng Yu", "Luxin Yan"], "year": 2022, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 28, "type": "article", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Task (project management)", "Scale-space segmentation"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 6.5, "subtopic": "Real-World Degradation", "rationale": "Joint deraining and segmentation with bottom-up top-down paradigm; relevant to task-aware restoration.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Unified bottom-up and top-down framework linking low-level deraining with high-level segmentation", "key_findings": "Joint optimization improves both deraining and segmentation", "limitations": "Limited to rain degradation and segmentation task"}}
{"openalex_id": "https://openalex.org/W3033307992", "doi": "https://doi.org/10.1109/access.2020.2999750", "title": "MSGAN: Generative Adversarial Networks for Image Seasonal Style Transfer", "abstract": "Although Generative Adversarial Networks (GANs) have shown remarkable successes in various computer vision tasks, they still face challenges in image season style transfer task. In this paper, we propose a multi-season Generative Adversarial Networks (MSGANs) aimed to transfer input images into other season styles. To improve the quality of the simulated images generated by the proposed MSGAN, we propose a novel loss function to guide the optimization direction of the network. Besides, we adopt the saliency information to guide the seasonal style transformation task, so as to ensure that different image contents can have different optimization weights in MSGAN. The experimental results show that the proposed MSGAN can generate high-quality simulated images from real images, and is superior to other latest methods. Not only that, the synthetic image generated by the proposed method also be used to perform depth estimation task so that prove that the synthetic images can be well applied to other computer vision tasks.", "authors": ["Fuquan Zhang", "Chuansheng Wang"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 24, "type": "article", "concepts": ["Computer science", "Task (project management)", "Artificial intelligence", "Adversarial system", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2, "subtopic": "", "rationale": "Image style transfer for seasons, not image restoration.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4393153879", "doi": "https://doi.org/10.1609/aaai.v38i6.28412", "title": "Learning from History: Task-agnostic Model Contrastive Learning for Image Restoration", "abstract": "Contrastive learning has emerged as a prevailing paradigm for high-level vision tasks, which, by introducing properly negative samples, has also been exploited for low-level vision tasks to achieve a compact optimization space to account for their ill-posed nature. However, existing methods rely on manually predefined and task-oriented negatives, which often exhibit pronounced task-specific biases. To address this challenge, our paper introduces an innovative method termed 'learning from history', which dynamically generates negative samples from the target model itself. Our approach, named Model Contrastive Learning for Image Restoration (MCLIR), rejuvenates latency models as negative models, making it compatible with diverse image restoration tasks. We propose the Self-Prior guided Negative loss (SPN) to enable it. This approach significantly enhances existing models when retrained with the proposed model contrastive paradigm. The results show significant improvements in image restoration across various tasks and architectures. For example, models retrained with SPN outperform the original FFANet and DehazeFormer by 3.41 and 0.57 dB on the RESIDE indoor dataset for image dehazing. Similarly, they achieve notable improvements of 0.47 dB on SPA-Data over IDT for image deraining and 0.12 dB on Manga109 for a 4x scale super-resolution over lightweight SwinIR, respectively. Code and retrained models are available at https://github.com/Aitical/MCLIR.", "authors": ["Gang Wu", "Junjun Jiang", "Kui Jiang", "Xianming Liu"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 11, "type": "article", "concepts": ["Task (project management)", "Computer science", "Artificial intelligence", "Image (mathematics)", "Image restoration"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 7.5, "subtopic": "All-in-One Restoration", "rationale": "Task-agnostic contrastive learning for image restoration; relevant to unified restoration training strategies.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Contrastive learning framework that is task-agnostic for restoration", "key_findings": "Historical model contrastive learning improves multi-task restoration", "limitations": "Contrastive approach may increase training complexity"}}
{"openalex_id": "https://openalex.org/W3043357501", "doi": "https://doi.org/10.1109/access.2020.3008324", "title": "FastDerainNet: A Deep Learning Algorithm for Single Image Deraining", "abstract": "Existing neural network-based methods for de-raining single images exhibit dissatisfactory results owing to the inefficient propagation of features when objects with sizes and shapes similar to those of rain streaks are present in images. Furthermore, existing methods do not consider that the abundant information included in rain streaked images could interfere with the training process. To overcome these limitations, in this paper, we propose a deep residual learning algorithm called FastDerainNet for removing rain streaks from single images. We design a deep convolutional neural network architecture, based on a deep residual network called the share-source residual module (SSRM), by substituting the origins of all shortcut connections for one point. To further improve the de-raining performance, we adopt the SSRM as the parameter layers in FastDerainNet and use image decomposition to modify the loss function. Finally, we train FastDerainNet on a synthetic dataset. By learning the residual mapping between rainy and clean image detail layers, it is able to reduce the mapping range and simplify the training process. Experiments on both synthetic and real-world images demonstrate that the proposed method achieves increased performance with regard to de-raining, in addition to preserving original details, in comparison with other state-of-the-art methods.", "authors": ["Xiuwen Wang", "Zhiwei Li", "Hongtao Shan", "Zhiyuan Tian", "Yuanhong Ren", "Wuneng Zhou"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 17, "type": "article", "concepts": ["Computer science", "Residual", "Convolutional neural network", "Deep learning", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5, "subtopic": "Real-World Degradation", "rationale": "Single image deraining network; relevant but single-task focus.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Fast CNN for single image deraining with efficient feature propagation", "key_findings": "Improved deraining with better feature propagation", "limitations": "Single task, older architecture"}}
{"openalex_id": "https://openalex.org/W2971374671", "doi": "https://doi.org/10.1109/access.2019.2939578", "title": "Color Filter Array Demosaicking Using Densely Connected Residual Network", "abstract": "Deep convolutional neural networks have been used extensively in recent image processing research, exhibiting drastically improved performance. In this study, we apply convolutional neural networks to color filter array demosaicking, which plays an essential role in single-sensor digital cameras. Contrary to conventional convolutional neural network-based demosaicking models, the proposed model does not require any initial interpolation step for mosaicked input images, which increases the computational complexity. Using a mosaicked image as input, the proposed model is trained in an end-to-end manner to generate demosaicked images outputs. Many deep neural networks experience vanishing-gradient problem, which makes models hard to be trained. To solve this problem, we apply residual learning and densely connected convolutional neural network. Moreover, we apply block-wise convolutional neural networks to consider local features. Finally, we apply a sub-pixel interpolation layer to generate demosaicked output images more efficiently and accurately. Experimental results show that our proposed model outperforms conventional solutions and state-of-the-art models.", "authors": ["Bumjun Park", "Jechang Jeong"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 16, "type": "article", "concepts": ["Demosaicing", "Convolutional neural network", "Computer science", "Artificial intelligence", "Residual"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3, "subtopic": "", "rationale": "CFA demosaicking with CNN; low-level imaging but not degradation restoration.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2949349317", "doi": "https://doi.org/10.48550/arxiv.1609.07769", "title": "Deep Joint Rain Detection and Removal from a Single Image", "abstract": "In this paper, we address a rain removal problem from a single image, even in the presence of heavy rain and rain streak accumulation. Our core ideas lie in the new rain image models and a novel deep learning architecture. We first modify an existing model comprising a rain streak layer and a background layer, by adding a binary map that locates rain streak regions. Second, we create a new model consisting of a component representing rain streak accumulation (where individual streaks cannot be seen, and thus visually similar to mist or fog), and another component representing various shapes and directions of overlapping rain streaks, which usually happen in heavy rain. Based on the first model, we develop a multi-task deep learning architecture that learns the binary rain streak map, the appearance of rain streaks, and the clean background, which is our ultimate output. The additional binary map is critically beneficial, since its loss function can provide additional strong information to the network. To handle rain streak accumulation (again, a phenomenon visually similar to mist or fog) and various shapes and directions of overlapping rain streaks, we propose a recurrent rain detection and removal network that removes rain streaks and clears up the rain accumulation iteratively and progressively. In each recurrence of our method, a new contextualized dilated network is developed to exploit regional contextual information and outputs better representation for rain detection. The evaluation on real images, particularly on heavy rain, shows the effectiveness of our novel models and architecture, outperforming the state-of-the-art methods significantly. Our codes and data sets will be publicly available.", "authors": ["Wenhan Yang", "Robby T. Tan", "Jiashi Feng", "Jiaying Liu", "Zongming Guo", "Shuicheng Yan"], "year": 2016, "venue": "arXiv (Cornell University)", "cited_by_count": 10, "type": "preprint", "concepts": ["Streak", "Computer science", "Mist", "Binary number", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 6.5, "subtopic": "Spatial-Aware Processing", "rationale": "Joint rain detection and removal with spatial awareness of rain regions; relevant spatial-aware restoration.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Joint rain detection and removal with rain density classification", "key_findings": "Spatial rain detection improves targeted removal", "limitations": "Limited to rain degradation"}}
{"openalex_id": "https://openalex.org/W4321594307", "doi": "https://doi.org/10.48550/arxiv.2302.09554", "title": "Mixed Hierarchy Network for Image Restoration", "abstract": "Image restoration is a long-standing low-level vision problem, e.g., deblurring and deraining. In the process of image restoration, it is necessary to consider not only the spatial details and contextual information of restoration to ensure the quality, but also the system complexity. Although many methods have been able to guarantee the quality of image restoration, the system complexity of the state-of-the-art (SOTA) methods is increasing as well. Motivated by this, we present a mixed hierarchy network that can balance these competing goals. Our main proposal is a mixed hierarchy architecture, that progressively recovers contextual information and spatial details from degraded images while we design intra-blocks to reduce system complexity. Specifically, our model first learns the contextual information using encoder-decoder architectures, and then combines them with high-resolution branches that preserve spatial detail. In order to reduce the system complexity of this architecture for convenient analysis and comparison, we replace or remove the nonlinear activation function with multiplication and use a simple network structure. In addition, we replace spatial convolution with global self-attention for the middle block of encoder-decoder. The resulting tightly interlinked hierarchy architecture, named as MHNet, delivers strong performance gains on several image restoration tasks, including image deraining, and deblurring.", "authors": ["Hu Gao", "Depeng Dang"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 7, "type": "preprint", "concepts": ["Deblurring", "Computer science", "Image restoration", "Hierarchy", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 7, "subtopic": "Transformer Restoration", "rationale": "Mixed hierarchy network combining spatial details and contextual information for image restoration.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Mixed hierarchy architecture balancing spatial detail and global context", "key_findings": "Effective multi-scale hierarchy for deblurring and deraining", "limitations": "arXiv preprint"}}
{"openalex_id": "https://openalex.org/W4361208495", "doi": "https://doi.org/10.3389/fpls.2023.1154176", "title": "All-in-one aerial image enhancement network for forest scenes", "abstract": "Drone monitoring plays an irreplaceable and significant role in forest firefighting due to its characteristics of wide-range observation and real-time messaging. However, aerial images are often susceptible to different degradation problems before performing high-level visual tasks including but not limited to smoke detection, fire classification, and regional localization. Recently, the majority of image enhancement methods are centered around particular types of degradation, necessitating the memory unit to accommodate different models for distinct scenarios in practical applications. Furthermore, such a paradigm requires wasted computational and storage resources to determine the type of degradation, making it difficult to meet the real-time and lightweight requirements of real-world scenarios. In this paper, we propose an All-in-one Image Enhancement Network (AIENet) that can restore various degraded images in one network. Specifically, we design a new multi-scale receptive field image enhancement block, which can better reconstruct high-resolution details of target regions of different sizes. In particular, this plug-and-play module enables it to be embedded in any learning-based model. And it has better flexibility and generalization in practical applications. This paper takes three challenging image enhancement tasks encountered in drone monitoring as examples, whereby we conduct task-specific and all-in-one image enhancement experiments on a synthetic forest dataset. The results show that the proposed AIENet outperforms the state-of-the-art image enhancement algorithms quantitatively and qualitatively. Furthermore, extra experiments on high-level vision detection also show the promising performance of our method compared with some recent baselines.", "authors": ["Zhaoqi Chen", "Chuansheng Wang", "Fuquan Zhang", "Ling Zhang", "Antoni Grau", "Edmundo Guerra"], "year": 2023, "venue": "Frontiers in Plant Science", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Drone", "Aerial image", "Block (permutation group theory)", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "All-in-one enhancement for aerial forest images handling multiple degradations; relevant unified approach.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Unified network for aerial image enhancement handling haze, rain, snow, low-light", "key_findings": "Multi-degradation handling in one model for drone imagery", "limitations": "Domain-specific to forest/aerial scenes"}}
{"openalex_id": "https://openalex.org/W4387490618", "doi": "https://doi.org/10.1109/tcsvt.2023.3323483", "title": "Joint Pixel and Frequency Feature Learning and Fusion via Channel-Wise Transformer for High-Efficiency Learned In-Loop Filter in VVC", "abstract": "Block-based video codecs such as Versatile Video Coding (VVC)/H.266, High Efficiency Video Coding (HEVC)/H.265, Advanced Video Coding (AVC)/H.264 etc. inherently introduces compression artifacts. Although these codecs have in-loop filters to correct these distortions, they are not always effective due to the complexity of the noise. Recently, deep-learning approaches emerged as a promising solution for in-loop filtering. However, most of the previous approaches were designed solely for learning from images and neglected the high-frequency signals present in the reconstructed video frames. Furthermore, some previous methods employed a multi-level feature-extraction and feature-fusion strategy to enhance performance. However, they utilized complex feature-extractors while relying on naive feature-fusion methods. In this article, we propose a novel framework called <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> , which jointly learns from both the pixel (spatial) and frequency-decomposed information and through powerful capability of a channel-wise transformer, it fuses both these information to improve performance. Our approach deviates from previous approaches by employing a simple feature-extractor coupled with an advanced transformer-based feature-fusion module. Simultaneously, <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> introduces a few fundamental modifications in the multi-head self-attention module of the channel-wise transformer to make it computationally efficient. Our experimental results show that the proposed <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> achieves a Bjøntegaard Delta (BD) - bitrate saving of up to 10.258% for the luma (Y) component under all-intra (AI) profile outperforming the VVC baseline and other state-of-the-art methods. Moreover, the proposed <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> with an efficient channel-wise transformer is twice as efficient as <italic xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">TSF-Net</i> with a vanilla channel-wise transformer.", "authors": ["Birendra Kathariya", "Zhu Li", "Geert Van der Auwera"], "year": 2023, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 20, "type": "article", "concepts": ["Computer science", "Feature extraction", "Artificial intelligence", "Feature learning", "Transformer"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 4, "subtopic": "", "rationale": "Video coding in-loop filter with transformer; related to compression artifact removal but video codec specific.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W4320713067", "doi": "https://doi.org/10.1109/access.2023.3245150", "title": "Blind Text Image Deblurring Algorithm Based on Multi-Scale Fusion and Sparse Priors", "abstract": "The goal of blind text image deblurring is to obtain a clean text image from the given blurry text image without knowing the blur kernel. Sparsity-based methods have been shown their effectiveness in various blind text image deblurring models. However, the blur kernel estimation methods based on sparse priors lack of the consideration for the brightness information about the blur kernel, which will affect the restoration effect of the blur kernel. Besides, previous methods seldom apply sparse priors to both spatial domain and transform domain information. We propose a novel blind text image deblurring model based on multi-scale fusion and sparse priors. Besides the sparse gradient prior on the latent clean text image, we add the sparse prior on the high-frequency wavelet coefficients of the latent text image, which will better constrain the solution space and obtain good clean images. The semi-quadratic splitting method is used to alternately optimize the blur kernel and the latent clean image. Meanwhile, we consider the influence of the brightness feature of the restored blur kernel. By multi-scale fusion technique on the basis of Laplacian weight and saliency weight, we fuse the computed blur kernels in three channels to improve the quality of blur kernel. The experimental results show that our algorithm has good results in the restoration of blur kernels and text images.", "authors": ["Zhe Li", "Ming Yang", "Libo Cheng", "Xiaoning Jia"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 10, "type": "article", "concepts": ["Deblurring", "Computer science", "Artificial intelligence", "Image fusion", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5, "subtopic": "Real-World Degradation", "rationale": "Text image deblurring with multi-scale fusion; relevant restoration method but domain-specific.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Multi-scale fusion with sparse priors for blind text deblurring", "key_findings": "Effective sparse prior utilization for text deblurring", "limitations": "Text-specific, limited generalization"}}
{"openalex_id": "https://openalex.org/W3189012752", "doi": "https://doi.org/10.1109/access.2021.3101319", "title": "A Model-Driven Deep Dehazing Approach by Learning Deep Priors", "abstract": "Photos taken in hazy weather are usually covered with white masks and lose important details. Haze removal is a fundamental task and a prerequisite to many other vision tasks. Single image dehazing is an ill-posed inverse problem that has attracted much attention in recent years. Generally, current single dehazing methods can be categorized into the traditional prior-based methods and the data-driven deep learning methods that respectively investigate haze-related image priors and deep architectures. In this paper, we propose a novel model-driven deep learning approach that combines the advantages of both kinds of methods. First, we build an energy model for single image dehazing with physical constraints in both color image space and haze-related feature space (implemented as dark channel space in this work), regularized by haze-related image priors. Then, we design an iterative optimization algorithm for solving the proposed dehazing energy model based on the half-quadratic splitting algorithm, and the priors are transformed to their corresponding proximal operators. Finally, inspired by the optimization algorithm, we design a deep dehazing neural network, dubbed as proximal dehaze-net, by learning the proximal operators for haze-related image priors using CNNs. Our network incorporates physical model constraints of hazes and haze-related prior learning into a novel deep architecture. Extensive experiments show that our method achieves promising performance for single image dehazing.", "authors": ["Dong Yang", "Jian Sun"], "year": 2021, "venue": "IEEE Access", "cited_by_count": 14, "type": "article", "concepts": ["Prior probability", "Computer science", "Deep learning", "Artificial intelligence", "Inpainting"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 6, "subtopic": "Real-World Degradation", "rationale": "Model-driven deep dehazing with learned priors; relevant physics-based restoration approach.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Model-driven approach combining physical haze model with deep priors", "key_findings": "Physics-informed dehazing with deep learning", "limitations": "Single task dehazing focus"}}
{"openalex_id": "https://openalex.org/W4382814212", "doi": "https://doi.org/10.1155/2023/4506331", "title": "Two‐Step Unsupervised Approach for Sand‐Dust Image Enhancement", "abstract": "In sand‐dust environments, light is scattered and absorbed, and sand‐dust images thus suffer from severe image degradation problems, such as color shifts, low contrast, and blurred details. To address these problems, we propose a two‐step unsupervised sand‐dust image enhancement algorithm. In the first step, a convenient and competent color correction method is put forward to solve the color shift problem. Considering the wavelength attenuation features of sand‐dust images, a linear stretching and blue channel compensation method is designed, and an adaptive color shift correction factor is developed to remove the color shift. In the second step, to enhance the clarity and details of the images, an unsupervised generative adversarial network is proposed, which does not require pairs of data for training. To reduce detail loss, the detail enhancement branch is designed, and the generator considers to more details through the constructed coarse‐grained and fine‐grained discriminators. The introduced multiscale perceptual loss promotes the image fidelity well. Experiments show that the proposed method achieves better color correction, enhances image details and clarity, has a better subjective effect, and outperforms existing sand‐dust image enhancement methods both quantitatively and qualitatively. Similarly, our method promotes the application capability of the target detection algorithm and also has a good enhancement effect on underwater images and haze images.", "authors": ["Guxue Gao", "Huicheng Lai", "Zhenhong Jia"], "year": 2023, "venue": "International Journal of Intelligent Systems", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Color balance", "Artificial intelligence", "Image (mathematics)", "Color correction"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5, "subtopic": "Real-World Degradation", "rationale": "Unsupervised sand-dust image enhancement; relevant degradation handling but domain-specific.", "alignment": {"task": "low", "method": "medium", "modality": "high"}, "extraction": {"design": "Two-step unsupervised approach for sand-dust enhancement", "key_findings": "Color correction and contrast enhancement for sand-dust images", "limitations": "Very specific degradation type"}}
{"openalex_id": "https://openalex.org/W4212954470", "doi": "https://doi.org/10.20944/preprints202202.0159.v1", "title": "Generative Adversarial Unsupervised Image Restoration in Hybrid Degradation Scenes", "abstract": "In this paper, we propose an unsupervised blind restoration model for images in hybrid degradation scenes. The proposed model encodes the content information and degradation information of images and then uses the attention module to disentangle the two kinds of information. It can improve the ability of disentangled presentation learning for a generative adversarial network (GAN) to restore the images in hybrid degradation scenes, enhance the detailed features of restored image and remove the artifact combining the adversarial loss, cycle-consistency loss, and perception loss. The experimental results on the DIV2K dataset and medical images show that the proposed method outperforms existing unsupervised image restoration algorithms in terms of peak signal-to-noise ratio (PSNR), structural similarity (SSIM), and subjective visual evaluation.", "authors": ["Fan Tang", "Xinyu Zhu", "Jinrong Hu", "Juhong Tie", "Jiliu Zhou", "Ying Fu"], "year": 2022, "venue": "Preprints.org", "cited_by_count": 6, "type": "preprint", "concepts": ["Artificial intelligence", "Computer science", "Image restoration", "Degradation (telecommunications)", "Generative grammar"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 7, "subtopic": "All-in-One Restoration", "rationale": "Unsupervised restoration for hybrid degradation scenes; relevant to multi-degradation handling.", "alignment": {"task": "high", "method": "medium", "modality": "high"}, "extraction": {"design": "GAN-based unsupervised model encoding content and degradation separately", "key_findings": "Handles hybrid degradation without paired data", "limitations": "Preprints.org venue, limited validation"}}
{"openalex_id": "https://openalex.org/W4379255977", "doi": "https://doi.org/10.48550/arxiv.2306.00306", "title": "Low-Light Image Enhancement with Wavelet-based Diffusion Models", "abstract": "Diffusion models have achieved promising results in image restoration tasks, yet suffer from time-consuming, excessive computational resource consumption, and unstable restoration. To address these issues, we propose a robust and efficient Diffusion-based Low-Light image enhancement approach, dubbed DiffLL. Specifically, we present a wavelet-based conditional diffusion model (WCDM) that leverages the generative power of diffusion models to produce results with satisfactory perceptual fidelity. Additionally, it also takes advantage of the strengths of wavelet transformation to greatly accelerate inference and reduce computational resource usage without sacrificing information. To avoid chaotic content and diversity, we perform both forward diffusion and denoising in the training phase of WCDM, enabling the model to achieve stable denoising and reduce randomness during inference. Moreover, we further design a high-frequency restoration module (HFRM) that utilizes the vertical and horizontal details of the image to complement the diagonal information for better fine-grained restoration. Extensive experiments on publicly available real-world benchmarks demonstrate that our method outperforms the existing state-of-the-art methods both quantitatively and visually, and it achieves remarkable improvements in efficiency compared to previous diffusion-based methods. In addition, we empirically show that the application for low-light face detection also reveals the latent practical values of our method. Code is available at https://github.com/JianghaiSCU/Diffusion-Low-Light.", "authors": ["Hai Jiang", "Ao Luo", "Songchen Han", "Haoqiang Fan", "Shuaicheng Liu"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 16, "type": "preprint", "concepts": ["Computer science", "Wavelet", "Artificial intelligence", "Inference", "Image restoration"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 6.5, "subtopic": "Diffusion Restoration", "rationale": "Wavelet-based diffusion model for low-light enhancement; relevant diffusion-based restoration approach.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Wavelet-based diffusion model for efficient low-light enhancement", "key_findings": "Reduced diffusion inference time via wavelet decomposition", "limitations": "Single task focus, arXiv preprint"}}
{"openalex_id": "https://openalex.org/W4409366360", "doi": "https://doi.org/10.1609/aaai.v39i8.32905", "title": "Debiased All-in-one Image Restoration with Task Uncertainty Regularization", "abstract": "All-in-one image restoration is a fundamental low-level vision task with significant real-world applications. The primary challenge lies in addressing diverse degradations within a single model. While current methods primarily exploit task prior information to guide the restoration models, they typically employ uniform multi-task learning, overlooking the heterogeneity in model optimization across different degradation tasks. To eliminate the bias, we propose a task-aware optimization strategy, that introduces adaptive task-specific regularization for multi-task image restoration learning. Specifically, our method dynamically weights and balances losses for different restoration tasks during training, encouraging the implementation of the most reasonable optimization route. In this way, we can achieve more robust and effective model training. Notably, our approach can serve as a plug-and-play strategy to enhance existing models without requiring modifications during inference. Extensive experiments in diverse all-in-one restoration settings demonstrate the superiority and generalization of our approach. For example, AirNet retrained with TUR achieves average improvements of 1.16 dB on three distinct tasks and 1.81 dB on five distinct all-in-one tasks. These results underscore TUR's effectiveness in advancing the SOTAs in all-in-one image restoration, paving the way for more robust and versatile image restoration.", "authors": ["Gang Wu", "Junjun Jiang", "Yijun Wang", "Kui Jiang", "Xianming Liu"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 5, "type": "article", "concepts": ["Regularization (linguistics)", "Image restoration", "Image (mathematics)", "Artificial intelligence", "Task (project management)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 8.5, "subtopic": "All-in-One Restoration", "rationale": "Debiased all-in-one restoration with task uncertainty regularization; directly relevant to unified multi-task restoration.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Task uncertainty regularization to address bias in all-in-one restoration", "key_findings": "Debiasing improves balanced performance across degradation types", "limitations": "Regularization adds training complexity"}}
{"openalex_id": "https://openalex.org/W4319302037", "doi": "https://doi.org/10.1007/s10462-023-10405-7", "title": "Deep learning: survey of environmental and camera impacts on internet of things images", "abstract": "Internet of Things (IoT) images are captivating growing attention because of their wide range of applications which requires visual analysis to drive automation. However, IoT images are predominantly captured from outdoor environments and thus are inherently impacted by the camera and environmental parameters which can adversely affect corresponding applications. Deep Learning (DL) has been widely adopted in the field of image processing and computer vision and can reduce the impact of these parameters on IoT images. Albeit, there are many DL-based techniques available in the current literature for analyzing and reducing the environmental and camera impacts on IoT images. However, to the best of our knowledge, no survey paper presents state-of-the-art DL-based approaches for this purpose. Motivated by this, for the first time, we present a Systematic Literature Review (SLR) of existing DL techniques available for analyzing and reducing environmental and camera lens impacts on IoT images. As part of this SLR, firstly, we reiterate and highlight the significance of IoT images in their respective applications. Secondly, we describe the DL techniques employed for assessing the environmental and camera lens distortion impacts on IoT images. Thirdly, we illustrate how DL can be effective in reducing the impact of environmental and camera lens distortion in IoT images. Finally, along with the critical reflection on the advantages and limitations of the techniques, we also present ways to address the research challenges of existing techniques and identify some further researches to advance the relevant research areas.", "authors": ["Roopdeep Kaur", "Gour Karmakar", "Feng Xia", "Muhammad Imran"], "year": 2023, "venue": "Artificial Intelligence Review", "cited_by_count": 13, "type": "article", "concepts": ["Computer science", "Internet of Things", "Artificial intelligence", "Field (mathematics)", "Automation"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 4, "subtopic": "", "rationale": "Survey on deep learning for IoT image quality; tangentially related to image degradation understanding.", "alignment": {"task": "low", "method": "low", "modality": "medium"}, "extraction": {"design": "N/A", "key_findings": "N/A", "limitations": "N/A"}}
{"openalex_id": "https://openalex.org/W2901114637", "doi": "https://doi.org/10.48550/arxiv.1811.08575", "title": "Unsupervised Single Image Deraining with Self-supervised Constraints", "abstract": "Most existing single image deraining methods require learning supervised models from a large set of paired synthetic training data, which limits their generality, scalability and practicality in real-world multimedia applications. Besides, due to lack of labeled-supervised constraints, directly applying existing unsupervised frameworks to the image deraining task will suffer from low-quality recovery. Therefore, we propose an Unsupervised Deraining Generative Adversarial Network (UD-GAN) to tackle above problems by introducing self-supervised constraints from the intrinsic statistics of unpaired rainy and clean images. Specifically, we firstly design two collaboratively optimized modules, namely Rain Guidance Module (RGM) and Background Guidance Module (BGM), to take full advantage of rainy image characteristics: The RGM is designed to discriminate real rainy images from fake rainy images which are created based on outputs of the generator with BGM. Simultaneously, the BGM exploits a hierarchical Gaussian-Blur gradient error to ensure background consistency between rainy input and de-rained output. Secondly, a novel luminance-adjusting adversarial loss is integrated into the clean image discriminator considering the built-in luminance difference between real clean images and derained images. Comprehensive experiment results on various benchmarking datasets and different training settings show that UD-GAN outperforms existing image deraining methods in both quantitative and qualitative comparisons.", "authors": ["Xin Jin", "Zhibo Chen", "Jianxin Lin", "Zhikai Chen", "Wei Zhou"], "year": 2018, "venue": "arXiv (Cornell University)", "cited_by_count": 8, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Discriminator", "Image (mathematics)", "Pattern recognition (psychology)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5.5, "subtopic": "Real-World Degradation", "rationale": "Unsupervised deraining with self-supervised constraints; relevant to unpaired restoration training.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Self-supervised constraints for unsupervised single image deraining", "key_findings": "Effective deraining without paired training data", "limitations": "Single degradation focus, arXiv preprint"}}
{"openalex_id": "https://openalex.org/W4388878512", "doi": "https://doi.org/10.1109/access.2023.3335618", "title": "Delving Deeper Into Image Dehazing: A Survey", "abstract": "Images captured under foggy or hazy weather conditions are affected by the scattering of atmospheric particles, resulting in decreased contrast and color variation, thereby limiting their practical applications. In recent years, deep learning methods showcase significant advancements in image dehazing. However, the complexity and degradation factors in hazy images challenge the generalization capacity of dehazing methods. This paper comprehensively reviews the recent developments in single-image dehazing techniques based on deep learning. From the perspectives of Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN), different models are introduced and classified into four categories: Encoder-Decoder, Multi-Module, Multi-Branch, and Dual-Generative Adversarial Networks. The robustness and effectiveness of deep learning models are analyzed by comparing their performance and model complexity on public datasets. Additionally, limitations of current benchmark datasets and evaluation metrics are identified, and unresolved issues and future research directions are discussed. Our efforts in this paper will serve as a comprehensive reference for future research and call for further development in deep learning-based image dehazing.", "authors": ["Guohou Li", "Jia Li", "Gongchao Chen", "Zhibin Wang", "Songlin Jin", "Chang Ding", "Weidong Zhang"], "year": 2023, "venue": "IEEE Access", "cited_by_count": 9, "type": "article", "concepts": ["Computer science", "Robustness (evolution)", "Deep learning", "Artificial intelligence", "Benchmark (surveying)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5.5, "subtopic": "Real-World Degradation", "rationale": "Comprehensive survey on image dehazing methods; useful background on single-task restoration.", "alignment": {"task": "medium", "method": "medium", "modality": "high"}, "extraction": {"design": "Survey covering dehazing methods from classical to deep learning", "key_findings": "Systematic categorization of dehazing approaches and benchmarks", "limitations": "Survey paper, single degradation focus"}}
{"openalex_id": "https://openalex.org/W4221075701", "doi": "https://doi.org/10.3390/rs14061513", "title": "Unsupervised Remote Sensing Image Super-Resolution Guided by Visible Images", "abstract": "Remote sensing images are widely used in many applications. However, due to being limited by the sensors, it is difficult to obtain high-resolution (HR) images from remote sensing images. In this paper, we propose a novel unsupervised cross-domain super-resolution method devoted to reconstructing a low-resolution (LR) remote sensing image guided by an unpaired HR visible natural image. Therefore, an unsupervised visible image-guided remote sensing image super-resolution network (UVRSR) is built. The network is divided into two learnable branches: a visible image-guided branch (VIG) and a remote sensing image-guided branch (RIG). As HR visible images can provide rich textures and sufficient high-frequency information, the purpose of VIG is to treat them as targets and make full use of their advantages in reconstruction. Specially, we first use a CycleGAN to drag the LR visible natural images to the remote sensing domain; then, we apply an SR network to upscale these simulated remote sensing domain LR images. However, the domain gap between SR remote sensing images and HR visible targets is massive. To enforce domain consistency, we propose a novel domain-ruled discriminator in the reconstruction. Furthermore, inspired by the zero-shot super-resolution network (ZSSR) to explore the internal information of remote sensing images, we add a remote sensing domain inner study to train the SR network in RIG. Sufficient experimental works show UVRSR can achieve superior results with state-of-the-art unpaired and remote sensing SR methods on several challenging remote sensing image datasets.", "authors": ["Zili Zhang", "Yan Tian", "Jianxiang Li", "Yiping Xu"], "year": 2022, "venue": "Remote Sensing", "cited_by_count": 14, "type": "article", "concepts": ["Remote sensing", "Computer science", "Artificial intelligence", "Image (mathematics)", "Computer vision"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5, "subtopic": "Super-Resolution", "rationale": "Remote sensing super-resolution guided by visible images; relevant SR method but domain-specific.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "Unsupervised SR for remote sensing using visible image guidance", "key_findings": "Cross-modal guidance improves remote sensing SR", "limitations": "Domain-specific to remote sensing"}}
{"openalex_id": "https://openalex.org/W4366327759", "doi": "https://doi.org/10.48550/arxiv.2304.08291", "title": "Refusion: Enabling Large-Size Realistic Image Restoration with Latent-Space Diffusion Models", "abstract": "This work aims to improve the applicability of diffusion models in realistic image restoration. Specifically, we enhance the diffusion model in several aspects such as network architecture, noise level, denoising steps, training image size, and optimizer/scheduler. We show that tuning these hyperparameters allows us to achieve better performance on both distortion and perceptual scores. We also propose a U-Net based latent diffusion model which performs diffusion in a low-resolution latent space while preserving high-resolution information from the original input for the decoding process. Compared to the previous latent-diffusion model which trains a VAE-GAN to compress the image, our proposed U-Net compression strategy is significantly more stable and can recover highly accurate images without relying on adversarial optimization. Importantly, these modifications allow us to apply diffusion models to various image restoration tasks, including real-world shadow removal, HR non-homogeneous dehazing, stereo super-resolution, and bokeh effect transformation. By simply replacing the datasets and slightly changing the noise network, our model, named Refusion, is able to deal with large-size images (e.g., 6000 x 4000 x 3 in HR dehazing) and produces good results on all the above restoration problems. Our Refusion achieves the best perceptual performance in the NTIRE 2023 Image Shadow Removal Challenge and wins 2nd place overall.", "authors": ["Ziwei Luo", "Fredrik Gustafsson", "Zheng Zhao", "Jens Sjölund", "Thomas B. Schön"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 6, "type": "preprint", "concepts": ["Computer science", "Image restoration", "Artificial intelligence", "Distortion (music)", "Computer vision"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 7, "subtopic": "Diffusion Restoration", "rationale": "Diffusion model for realistic large-size image restoration; relevant diffusion-based restoration approach.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Latent-space diffusion model enhanced for realistic large-size restoration", "key_findings": "Improved applicability of diffusion models for realistic restoration", "limitations": "arXiv preprint, slow inference"}}
{"openalex_id": "https://openalex.org/W3163628478", "doi": "https://doi.org/10.1371/journal.pone.0251337", "title": "An end-to-end sea fog removal network using multiple scattering model", "abstract": "An end-to-end sea fog removal network using multiple scattering model was proposed. In this network, the atmospheric multiple scattering model was re-formulated and used for sea fog removal. Compared with the atmospheric single scattering model, the atmospheric multiple scattering model could more comprehensively consider the effect of multiple scattering, which was important to the dense fog scenes, such as in ocean scene. Therefore, we used the atmospheric multiple scattering model to avoid image blurring. The model can directly generate the dehazing results, and unify the three parameters of the transmission map, the atmospheric light and the blur kernel into one formula. The latest smooth dilation and sub-pixel techniques were used in the network model. The latest techniques can avoid the gridding artifacts and the halo artifacts, the multi-scale sub-network was used to consider the features of multi-scale. In addition, multiple loss functions were used in end-to-end network. In the experimental results, the model was superior to the state-of-the-art models in terms of quantitatively and qualitatively.", "authors": ["Shunmin An", "Xixia Huang", "Zhangjing Zheng", "Linling Wang"], "year": 2021, "venue": "PLoS ONE", "cited_by_count": 8, "type": "article", "concepts": ["Scattering", "Halo", "Atmospheric model", "Computer science", "Diffuse sky radiation"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5, "subtopic": "Real-World Degradation", "rationale": "Physics-based deep network for sea fog removal; domain-specific but relevant restoration approach.", "alignment": {"task": "low", "method": "medium", "modality": "medium"}, "extraction": {"design": "End-to-end network using atmospheric multiple scattering model for sea fog", "key_findings": "Physics-informed approach improves sea fog removal", "limitations": "Very domain-specific to sea fog"}}

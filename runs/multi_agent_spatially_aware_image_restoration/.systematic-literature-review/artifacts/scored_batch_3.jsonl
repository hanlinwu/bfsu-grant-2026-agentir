{"openalex_id": "https://openalex.org/W4385769398", "doi": "https://doi.org/10.3390/sym15081571", "title": "Symmetric Enhancement of Visual Clarity through a Multi-Scale Dilated Residual Recurrent Network Approach for Image Deraining", "abstract": "Images captured during rainy days present the challenge of maintaining a symmetrical balance between foreground elements (like rain streaks) and the background scenery...", "authors": ["Jameel Ahmed Bhutto", "Ruihong Zhang", "Zia-ur Rahman"], "year": 2023, "venue": "Symmetry", "cited_by_count": 7, "type": "article", "concepts": ["Computer science", "Residual", "Artificial intelligence", "Scale (ratio)", "Process (computing)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3.0, "subtopic": "", "rationale": "Single-task deraining with CNN/LSTM — low-level restoration but no agentic, all-in-one, or spatial-aware components.", "alignment": {"task": "medium", "method": "low", "modality": "low"}, "extraction": {"design": "Multi-scale dilated residual recurrent network with LSTM/GRU and channel attention for image deraining.", "key_findings": "Outperforms SOTA on seven benchmark datasets using multi-scale receptive fields and channel attention.", "limitations": "Single-task only; no generalisation to other degradations."}}
{"openalex_id": "https://openalex.org/W4309427392", "doi": "https://doi.org/10.48550/arxiv.2111.08892", "title": "SAPNet: Segmentation-Aware Progressive Network for Perceptual Contrastive Deraining", "abstract": "Deep learning algorithms have recently achieved promising deraining performances...", "authors": ["Shen Zheng", "Changjie Lu", "WU Yu-xiong", "Gaurav Gupta"], "year": 2021, "venue": "arXiv (Cornell University)", "cited_by_count": 4, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Segmentation", "Pattern recognition (psychology)", "Perception"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5.0, "subtopic": "Spatial-Aware Processing", "rationale": "Integrates segmentation awareness into deraining — partial concept overlap with spatial-aware degradation processing.", "alignment": {"task": "medium", "method": "medium", "modality": "low"}, "extraction": {"design": "Progressive dilated units + unsupervised background segmentation (UBS) + perceptual contrastive loss for deraining.", "key_findings": "Segmentation guidance improves deraining and benefits downstream detection/segmentation tasks.", "limitations": "Segmentation is unsupervised and limited to background; no multi-degradation or agent-based components."}}
{"openalex_id": "https://openalex.org/W3097097973", "doi": "https://doi.org/10.1109/access.2020.3034238", "title": "Wavelet Based Deep Recursive Pyramid Convolution Residual Network for Single Image Rain Removal", "abstract": "Image rain removal aims to separate the background image from the rainy image...", "authors": ["Tian Tian Gong", "Jun Sheng Wang"], "year": 2020, "venue": "IEEE Access", "cited_by_count": 3, "type": "article", "concepts": ["Residual", "Convolution (computer science)", "Computer science", "Pyramid (geometry)", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "Single-task deraining CNN with wavelet; no spatial awareness, no agents, no all-in-one.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Wavelet transform + deep recursive pyramid convolution residual network for deraining.", "key_findings": "Fewer parameters with recursive model; outperforms SOTA on synthetic and real datasets.", "limitations": "Single-task, low citation count, limited novelty."}}
{"openalex_id": "https://openalex.org/W4206086042", "doi": "https://doi.org/10.1109/access.2021.3132148", "title": "Universal Framework for Joint Image Restoration and 3D Body Reconstruction", "abstract": "Recent works have demonstrated excellent state-of-the-art achievements in image restoration and 3D body reconstruction from an input image...", "authors": ["Jonathan Samuel Lumentut", "Matthew Marchellus", "Joshua Santoso", "Tae Hyun Kim", "Ju Yong Chang", "In Kyu Park"], "year": 2021, "venue": "IEEE Access", "cited_by_count": 3, "type": "article", "concepts": ["Computer science", "Boosting (machine learning)", "Image restoration", "Artificial intelligence", "Image (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3.0, "subtopic": "", "rationale": "Joint restoration + 3D body reconstruction framework; touches image restoration but focus is on body reconstruction, not relevant methods.", "alignment": {"task": "medium", "method": "low", "modality": "low"}, "extraction": {"design": "Universal test-time adaptation framework combining image restoration with 3D body reconstruction.", "key_findings": "Self-boosting via pseudo-data at test time improves both restoration and reconstruction.", "limitations": "Very specific to body reconstruction; not aligned with multi-agent or spatial-aware restoration."}}
{"openalex_id": "https://openalex.org/W4308900645", "doi": "https://doi.org/10.48550/arxiv.2112.05147", "title": "Learning Deep Context-Sensitive Decomposition for Low-Light Image Enhancement", "abstract": "Enhancing the quality of low-light images plays a very important role...", "authors": ["Long Ma", "Risheng Liu", "Jiaao Zhang", "Xin Fan", "Zhongxuan Luo"], "year": 2021, "venue": "arXiv (Cornell University)", "cited_by_count": 5, "type": "preprint", "concepts": ["Computer science", "Context (archaeology)", "Artificial intelligence", "Deep learning", "Encoder"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3.0, "subtopic": "", "rationale": "Low-light enhancement with context-sensitive decomposition; single-task, no agent/spatial-aware components.", "alignment": {"task": "medium", "method": "low", "modality": "low"}, "extraction": {"design": "Two-stream illumination/reflectance decomposition with context-sensitive connections; CSDNet and CSDGAN variants.", "key_findings": "Context-sensitive decomposition outperforms SOTA on 7 benchmarks; lightweight SLiteCSDNet with 0.03M parameters.", "limitations": "Single degradation type only; no generalisation or agent-based elements."}}
{"openalex_id": "https://openalex.org/W4293499157", "doi": "https://doi.org/10.1109/access.2022.3202888", "title": "Single Image Raindrop Removal Using a Non-Local Operator and Feature Maps in the Frequency Domain", "abstract": "Taking a photo on a rainy day may result in a photo with raindrops...", "authors": ["Shinya Ezumi", "Masaaki Ikehara"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 4, "type": "article", "concepts": ["Frequency domain", "Computer science", "Convolution (computer science)", "Operator (biology)", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "Single-task raindrop removal; frequency-domain CNN, no relevance to agents or spatial-aware restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Non-local operator + frequency-domain feature maps via FFT for raindrop removal.", "key_findings": "Non-local consistency and frequency-domain features improve raindrop removal quality.", "limitations": "Single degradation, narrow scope."}}
{"openalex_id": "https://openalex.org/W4385849093", "doi": "https://doi.org/10.48550/arxiv.2308.06998", "title": "Mutual Information-driven Triple Interaction Network for Efficient Image Dehazing", "abstract": "Multi-stage architectures have exhibited efficacy in image dehazing...", "authors": ["Hao Shen", "Zhong-Qiu Zhao", "Yulun Zhang", "Zhao Zhang"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Computer science", "Mutual information", "Redundancy (engineering)", "Encoder", "Interaction information"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3.0, "subtopic": "", "rationale": "Efficient dehazing with spatial-frequency features; single-task, no agents or all-in-one design.", "alignment": {"task": "medium", "method": "low", "modality": "low"}, "extraction": {"design": "Two-stage spatial-frequency dual domain network with adaptive triple interaction module for dehazing.", "key_findings": "Cross-domain/scale/stage feature aggregation reduces redundancy and improves performance.", "limitations": "Single-task dehazing only."}}
{"openalex_id": "https://openalex.org/W2768996629", "doi": "https://doi.org/10.1109/cvpr.2018.00258", "title": "xUnit: Learning a Spatial Activation Function for Efficient Image Restoration", "abstract": "In recent years, deep neural networks (DNNs) achieved unprecedented performance in many low-level vision tasks...", "authors": ["Idan Kligvasser", "Tamar Rott Shaham", "Tomer Michaeli"], "year": 2018, "venue": "", "cited_by_count": 4, "type": "preprint", "concepts": ["Computer science", "Image restoration", "Deep neural networks", "Pixel", "Activation function"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3.0, "subtopic": "", "rationale": "Efficient spatial activation unit for restoration; reduces model size but no multi-degradation or agent components.", "alignment": {"task": "medium", "method": "low", "modality": "low"}, "extraction": {"design": "Learnable spatial activation function (xUnit) replacing standard activations in denoising/deraining/SR networks.", "key_findings": "Reduces model size by ~50% without performance loss across multiple restoration tasks.", "limitations": "Architecture-level contribution only; not directly related to all-in-one or agent-based systems."}}
{"openalex_id": "https://openalex.org/W4405291967", "doi": "https://doi.org/10.3390/app142411565", "title": "MCIDN: Deblurring Network for Metal Corrosion Images", "abstract": "The analysis of corrosion images is crucial in materials science...", "authors": ["Jiaxiang Wang", "Meng Wan", "Pufen Zhang", "Sijie Chang", "Hao Du", "Peng Shi", "Hongying Yu", "Dongbai Sun", "Jue Wang", "Yangang Wang"], "year": 2024, "venue": "Applied Sciences", "cited_by_count": 3, "type": "article", "concepts": ["Deblurring", "Materials science", "Computer science", "Artificial intelligence", "Image processing"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "Domain-specific deblurring for metal corrosion images; no relevance to agents, SAM, or general restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Dual-domain spatial-frequency attention network for metal corrosion image deblurring.", "key_findings": "PSNR 32.86 dB and SSIM 0.9768 on corrosion dataset.", "limitations": "Very narrow domain; not generalisable."}}
{"openalex_id": "https://openalex.org/W4403661836", "doi": "https://doi.org/10.48550/arxiv.2409.08510", "title": "CasDyF-Net: Image Dehazing via Cascaded Dynamic Filters", "abstract": "Image dehazing aims to restore image clarity and visual quality by reducing atmospheric scattering and absorption effects...", "authors": ["Yinglong Wang", "Bin He"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Net (polyhedron)", "Image (mathematics)", "Computer science", "Computer vision", "Dynamic imaging"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "Single-task dehazing with cascaded dynamic filters; no multi-degradation, agent, or spatial-aware components.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Cascaded dynamic filters for multi-branch feature extraction in dehazing.", "key_findings": "PSNR 43.21 dB on RESIDE-Indoor.", "limitations": "Single task only."}}
{"openalex_id": "https://openalex.org/W4375957537", "doi": "https://doi.org/10.48550/arxiv.2305.03997", "title": "Dual Degradation Representation for Joint Deraining and Low-Light Enhancement in the Dark", "abstract": "Rain in the dark poses a significant challenge to deploying real-world applications...", "authors": ["Xin Lin", "Jingtong Yue", "Chao Ren", "Chunle Guo", "Chongyi Li", "Yang, Ming-Hsuan"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 4, "type": "preprint", "concepts": ["Computer science", "Artificial intelligence", "Degradation (telecommunications)", "Pairwise comparison", "Feature (linguistics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 5.0, "subtopic": "Real-World Degradation", "rationale": "Handles joint/mixed degradation (rain + low-light) in real-world settings; aligns with mixed degradation handling theme.", "alignment": {"task": "high", "method": "medium", "modality": "low"}, "extraction": {"design": "End-to-end L2RIRNet with dual degradation representation network and Fourier detail guidance for joint deraining+low-light enhancement.", "key_findings": "Separate luminance and rain degradation representations improve joint restoration; new synthetic+real dataset contributed.", "limitations": "Only two degradation types combined; no agent or prompt-based design."}}
{"openalex_id": "https://openalex.org/W4311728785", "doi": "https://doi.org/10.3390/s22249587", "title": "PRAGAN: Progressive Recurrent Attention GAN with Pretrained ViT Discriminator for Single-Image Deraining", "abstract": "Images captured in bad weather are not conducive to visual tasks...", "authors": ["Bingcai Wei", "Di Wang", "Zhuang Wang", "Liye Zhang"], "year": 2022, "venue": "Sensors", "cited_by_count": 3, "type": "article", "concepts": ["Discriminator", "Correctness", "Computer science", "Artificial intelligence", "Transformer"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "GAN-based single-image deraining; no multi-degradation or agent-based components.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "GAN with ViT discriminator and progressive recurrent attention for single-image deraining.", "key_findings": "ViT discriminator improves perceptual quality; works with small training data.", "limitations": "Single task; narrow scope."}}
{"openalex_id": "https://openalex.org/W2985670408", "doi": "https://doi.org/10.48550/arxiv.2005.03155", "title": "NTIRE 2020 Challenge on Image Demoireing: Methods and Results", "abstract": "This paper reviews the Challenge on Image Demoireing that was part of the New Trends in Image Restoration and Enhancement (NTIRE) workshop...", "authors": ["Shanxin Yuan", "Radu Timofte"], "year": 2020, "venue": "arXiv (Cornell University)", "cited_by_count": 3, "type": "preprint", "concepts": ["Image (mathematics)", "Computer science", "Artificial intelligence", "Computer vision", "Fidelity"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "Challenge survey on demoireing; niche task with no relation to agents, SAM, or all-in-one restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Survey of NTIRE 2020 demoireing challenge methods (single and burst tracks).", "key_findings": "Multiple deep learning approaches evaluated on PSNR for demoireing.", "limitations": "Narrow task; no generalisation."}}
{"openalex_id": "https://openalex.org/W4313328176", "doi": "https://doi.org/10.32604/cmc.2023.031444", "title": "CLGA Net: Cross Layer Gated Attention Network for Image Dehazing", "abstract": "In this paper, we propose an end-to-end cross-layer gated attention network (CLGA-Net) to directly restore fog-free images...", "authors": ["Shengchun Wang", "Baoxuan Huang", "Tsz Ho Wong", "Huang Jin-gui", "Hong Deng"], "year": 2022, "venue": "Computers, materials & continua", "cited_by_count": 3, "type": "article", "concepts": ["Residual", "Computer science", "Decoding methods", "Encoding (memory)", "Layer (electronics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "Single-task dehazing with cross-layer gating; low relevance to research theme.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "U-Net based cross-layer gated attention network for single image dehazing.", "key_findings": "Cross-layer gating preserves spatial information lost in standard U-Net for dehazing.", "limitations": "Single task, low citation."}}
{"openalex_id": "https://openalex.org/W4385767441", "doi": "https://doi.org/10.21203/rs.3.rs-3240803/v1", "title": "A Hybrid CNN-Transformer Architecture with Frequency Domain Contrastive Learning for Image Deraining", "abstract": "Image deraining is a challenging task that involves restoring degraded images affected by rain streaks...", "authors": ["Cheng Wang", "Wei Li"], "year": 2023, "venue": "Research Square", "cited_by_count": 2, "type": "preprint", "concepts": ["Computer science", "Transformer", "Convolutional neural network", "Encoder", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3.0, "subtopic": "", "rationale": "Hybrid CNN-Transformer for deraining; Transformer architecture is tangentially relevant but single-task only.", "alignment": {"task": "medium", "method": "low", "modality": "low"}, "extraction": {"design": "Two-stage encoder-decoder with triple attention + residual dual-branch transformer + frequency contrastive loss for deraining.", "key_findings": "Frequency contrastive learning bridges derained and clean images in frequency domain.", "limitations": "Single task; preprint with no venue."}}
{"openalex_id": "https://openalex.org/W4295350396", "doi": "https://doi.org/10.1007/s40747-022-00865-9", "title": "Multi-scale progressive blind face deblurring", "abstract": "", "authors": ["Hao Zhang", "Canghong Shi", "Xian Zhang", "Linfeng Wu", "Xiaojie Li", "Jing Peng", "Xi Wu", "Jiancheng Lv"], "year": 2022, "venue": "Complex & Intelligent Systems", "cited_by_count": 3, "type": "article", "concepts": ["Deblurring", "Artificial intelligence", "Computer science", "Face (sociological concept)", "Computer vision"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 2.0, "subtopic": "", "rationale": "Face-specific blind deblurring; single-task narrow domain, no relation to key themes.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Multi-scale progressive blind deblurring for face images.", "key_findings": "Progressive framework improves face deblurring quality.", "limitations": "Face-specific domain, narrow scope."}}
{"openalex_id": "https://openalex.org/W4313008082", "doi": "https://doi.org/10.1109/access.2022.3213025", "title": "Deep Learning for Screen-Shot Image Demoiréing: A Survey", "abstract": "Image demoiréing is an important image processing technology in computer vision, used to remove the moiré from images...", "authors": ["Shouming Hou", "Yabing Wang", "Kai Li", "Yinggang Zhao", "Baoyun Lu", "Liya Fan"], "year": 2022, "venue": "IEEE Access", "cited_by_count": 2, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Deep learning", "Image quality", "Field (mathematics)"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 1.0, "subtopic": "", "rationale": "Survey on demoireing; niche topic completely outside core themes.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Survey of deep learning demoireing methods.", "key_findings": "Reviews sampling, network design, and learning strategies for demoireing.", "limitations": "Niche single task."}}
{"openalex_id": "https://openalex.org/W4409370074", "doi": "https://doi.org/10.1609/aaai.v39i3.32257", "title": "SIDL: A Real-World Dataset for Restoring Smartphone Images with Dirty Lenses", "abstract": "Smartphone cameras are ubiquitous in daily life, yet their performance can be severely impacted by dirty lenses, leading to degraded image quality...", "authors": ["Sooyoung Choi", "Sungyong Park", "Heewon Kim"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 1, "type": "article", "concepts": ["Smartphone application", "Computer science", "Smartphone app", "Computer vision", "Optometry"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 4.0, "subtopic": "", "rationale": "New real-world restoration dataset for lens contamination; relevant to real-world degradation but no agent or spatial-aware methods.", "alignment": {"task": "medium", "method": "low", "modality": "medium"}, "extraction": {"design": "New SIDL dataset with diverse real-world lens contamination (water drops, fingerprints, dust) paired with clean images.", "key_findings": "Existing SOTA restoration models struggle with diverse real-world lens contaminants.", "limitations": "Dataset contribution only; no novel restoration method."}}
{"openalex_id": "https://openalex.org/W4391909273", "doi": "https://doi.org/10.21597/jist.1328255", "title": "Enhance or Leave It: An Investigation of the Image Enhancement in Small Object Detection in Aerial Images", "abstract": "Recent years of object detection (OD), a fundamental task in computer vision, have witnessed the rise of numerous practical applications...", "authors": ["Alpay Tekin", "Ahmet Selman Bozkır"], "year": 2024, "venue": "Iğdır Üniversitesi Fen Bilimleri Enstitüsü Dergisi", "cited_by_count": 3, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Computer vision", "Object detection", "Motion blur"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 3.0, "subtopic": "", "rationale": "Investigates image enhancement for object detection in aerial images; touches real-world degradation but focus is object detection pipeline, not restoration methods.", "alignment": {"task": "medium", "method": "low", "modality": "low"}, "extraction": {"design": "Evaluate MPRNet-based enhancement before YOLO 6/7/8 on VisDrone under noise, blur, and rain.", "key_findings": "Enhancement improves detection; YOLO8 best performer.", "limitations": "Enhancement used as preprocessing only; no novel restoration contribution."}}
{"openalex_id": "https://openalex.org/W4361192474", "doi": "https://doi.org/10.21203/rs.3.rs-2717815/v1", "title": "DC-GAN with Feature Attention for Single Image Dehazing", "abstract": "In recent years, the frequent occurrence of smog weather has affected people's health...", "authors": ["Tewodros Megabiaw Tassew", "Xuan Nie"], "year": 2023, "venue": "", "cited_by_count": 2, "type": "preprint", "concepts": ["Feature (linguistics)", "Image (mathematics)", "Computer science", "Materials science", "Artificial intelligence"], "search_query": "image denoising deblurring dehazing deraining deep learning", "score": 1.0, "subtopic": "", "rationale": "GAN-based dehazing preprint with low citation; no relevant methodology overlap.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "WGAN-GP with dense/residual blocks and channel/pixel attention for dehazing.", "key_findings": "Moderate PSNR/SSIM on NTIRE2018 and SOTS datasets.", "limitations": "Preprint with no venue; low performance."}}
{"openalex_id": "https://openalex.org/W4390874575", "doi": "https://doi.org/10.1109/iccv51070.2023.00371", "title": "Segment Anything", "abstract": "We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation...", "authors": ["Alexander M. Kirillov", "Eric Mintun", "Nikhila Ravi", "Hanzi Mao", "Chloe Rolland", "Laura Gustafson", "Tete Xiao", "Spencer Whitehead", "Alexander C. Berg", "Wan-Yen Lo", "Piotr Dollar", "Ross Girshick"], "year": 2023, "venue": "", "cited_by_count": 7782, "type": "article", "concepts": ["Computer science", "Segmentation", "Task (project management)", "Artificial intelligence", "Shot (pellet)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 8.0, "subtopic": "Foundation Models Vision", "rationale": "SAM is a foundational component in the spatially-aware image restoration pipeline — used for region-level segmentation before degradation analysis.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Promptable segmentation model trained on SA-1B (1B masks, 11M images) with point/box/mask prompts.", "key_findings": "Zero-shot performance competitive with or superior to supervised models across diverse segmentation tasks.", "limitations": "Segmentation only — does not perform restoration or degradation analysis."}}
{"openalex_id": "https://openalex.org/W4364383051", "doi": "https://doi.org/10.48550/arxiv.2304.04155", "title": "Segment Anything Model (SAM) for Digital Pathology: Assess Zero-shot Segmentation on Whole Slide Imaging", "abstract": "The segment anything model (SAM) was released as a foundation model for image segmentation...", "authors": ["Ruining Deng"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 96, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Scale-space segmentation", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM evaluation in digital pathology; domain is medical imaging, not relevant to image restoration.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Zero-shot SAM evaluation on WSI segmentation tasks (tumor, tissue, nuclei).", "key_findings": "SAM works well for large connected objects but struggles with dense instance segmentation in pathology.", "limitations": "Medical imaging domain; no restoration relevance."}}
{"openalex_id": "https://openalex.org/W4396996869", "doi": "https://doi.org/10.1145/3654704", "title": "Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM)", "abstract": "The advent of foundation models signals a new era in artificial intelligence...", "authors": ["Virmarie Maquiling"], "year": 2024, "venue": "Proceedings of the ACM on Computer Graphics and Interactive Techniques", "cited_by_count": 10, "type": "article", "concepts": ["Shot (pellet)", "Segmentation", "Artificial intelligence", "Zero (linguistics)", "Computer science"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM applied to eye/gaze estimation; completely irrelevant to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM zero-shot segmentation of pupil/iris in VR eye-tracking images.", "key_findings": "93.34% IoU for pupil segmentation with box prompts.", "limitations": "Narrow gaze estimation domain."}}
{"openalex_id": "https://openalex.org/W4385481295", "doi": "https://doi.org/10.1016/j.media.2023.102918", "title": "Segment anything model for medical image analysis: An experimental study", "abstract": "", "authors": ["Maciej A. Mazurowski"], "year": 2023, "venue": "Medical Image Analysis", "cited_by_count": 623, "type": "article", "concepts": ["Artificial intelligence", "Image (mathematics)", "Computer science", "Computer vision", "Pattern recognition (psychology)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM evaluation in medical imaging; high citation but irrelevant domain for image restoration.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Comprehensive SAM evaluation across medical imaging segmentation tasks.", "key_findings": "SAM generalises variably across different medical modalities and structures.", "limitations": "Medical imaging only."}}
{"openalex_id": "https://openalex.org/W4391021462", "doi": "https://doi.org/10.1109/tgrs.2024.3356074", "title": "RSPrompter: Learning to Prompt for Remote Sensing Instance Segmentation Based on Visual Foundation Model", "abstract": "Leveraging the extensive training data from SA-1B, the Segment Anything Model (SAM) demonstrates remarkable generalization and zero-shot capabilities...", "authors": ["Keyan Chen"], "year": 2024, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 271, "type": "article", "concepts": ["Segmentation", "Computer science", "Generalization", "Artificial intelligence", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 3.0, "subtopic": "", "rationale": "SAM adapted for remote sensing segmentation via prompt learning; SAM-based but focused on remote sensing, not restoration.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Prompt learning on SAM for automated instance segmentation in remote sensing images.", "key_findings": "Learns to generate appropriate SAM prompts for semantically aware remote sensing segmentation.", "limitations": "Remote sensing domain; no restoration component."}}
{"openalex_id": "https://openalex.org/W4388129777", "doi": "https://doi.org/10.1016/j.jag.2023.103540", "title": "The Segment Anything Model (SAM) for remote sensing applications: From zero to one shot", "abstract": "Segmentation is an essential step for remote sensing image processing...", "authors": ["Lucas Prado Osco"], "year": 2023, "venue": "International Journal of Applied Earth Observation and Geoinformation", "cited_by_count": 261, "type": "article", "concepts": ["Zero (linguistics)", "Shot (pellet)", "Geography", "Computer science", "Cartography"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM for remote sensing; no restoration relevance.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "SAM evaluation with various prompts on multi-scale remote sensing datasets; novel text+one-shot technique.", "key_findings": "One-shot fine-tuning improves SAM accuracy for remote sensing.", "limitations": "Remote sensing domain only."}}
{"openalex_id": "https://openalex.org/W4402727760", "doi": "https://doi.org/10.1109/cvpr52733.2024.01525", "title": "EfficientSAM: Leveraged Masked Image Pretraining for Efficient Segment Anything", "abstract": "Segment Anything Model (SAM) has emerged as a powerful tool for numerous vision applications...", "authors": ["Yunyang Xiong"], "year": 2024, "venue": "", "cited_by_count": 168, "type": "article", "concepts": ["Computer science", "Image (mathematics)", "Artificial intelligence", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 5.0, "subtopic": "Foundation Models Vision", "rationale": "Lightweight SAM variant via knowledge distillation; relevant to deploying SAM in restoration pipelines on edge devices.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "Masked image pretraining (SAMI) to reconstruct SAM encoder features; trains lightweight EfficientSAM with reduced complexity.", "key_findings": "EfficientSAM achieves competitive zero-shot segmentation with significantly fewer parameters than SAM.", "limitations": "Segmentation only; no integration with restoration modules."}}
{"openalex_id": "https://openalex.org/W4379141755", "doi": "https://doi.org/10.3390/diagnostics13111947", "title": "Generalist Vision Foundation Models for Medical Imaging: A Case Study of Segment Anything Model on Zero-Shot Medical Segmentation", "abstract": "Medical image analysis plays an important role in clinical diagnosis...", "authors": ["Peilun Shi"], "year": 2023, "venue": "Diagnostics", "cited_by_count": 116, "type": "article", "concepts": ["Segmentation", "Medical imaging", "Optical coherence tomography", "Artificial intelligence", "Computer science"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "Medical SAM evaluation; completely irrelevant to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM zero-shot evaluation on 9 medical imaging benchmarks.", "key_findings": "SAM generalizes variably; fine-tuning with small data yields strong improvements.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4411124654", "doi": "https://doi.org/10.1016/j.bspc.2025.108086", "title": "SIT-SAM: A semantic-integration transformer that adapts the Segment Anything Model to zero-shot medical image semantic segmentation", "abstract": "", "authors": ["Wentao Shi", "Junjun He", "Yiqing Shen"], "year": 2025, "venue": "Biomedical Signal Processing and Control", "cited_by_count": 3, "type": "article", "concepts": ["Segmentation", "Computer science", "Transformer", "Artificial intelligence", "Zero (linguistics)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "Medical SAM adaptation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Semantic-integration transformer adapting SAM for medical semantic segmentation.", "key_findings": "Improves SAM semantic segmentation in medical images.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4386781846", "doi": "https://doi.org/10.3390/s23187884", "title": "Enhancing Agricultural Image Segmentation with an Agricultural Segment Anything Model Adapter", "abstract": "The Segment Anything Model (SAM) is a versatile image segmentation model...", "authors": ["Yaqin Li"], "year": 2023, "venue": "Sensors", "cited_by_count": 70, "type": "article", "concepts": ["Adapter (computing)", "Segmentation", "Computer science", "Artificial intelligence", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM adapter for agricultural segmentation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Agricultural domain adapter for SAM enabling zero-shot crop/pest segmentation.", "key_findings": "Average Dice improved by 41.48% over default SAM on agricultural tasks.", "limitations": "Agricultural domain only."}}
{"openalex_id": "https://openalex.org/W4379474533", "doi": "https://doi.org/10.48550/arxiv.2306.01567", "title": "Segment Anything in High Quality", "abstract": "The recent Segment Anything Model (SAM) represents a big leap in scaling up segmentation models...", "authors": ["Ke Lei", "Mingqiao Ye", "Martin Danelljan", "Yifan Liu", "Yu-Wing Tai", "Chi-Keung Tang", "Fisher Yu"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 109, "type": "preprint", "concepts": ["Computer science", "Segmentation", "Security token", "Artificial intelligence", "Quality (philosophy)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 6.0, "subtopic": "Foundation Models Vision", "rationale": "HQ-SAM improves mask quality for intricate structures — directly relevant to spatially-aware restoration that relies on precise region segmentation.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "HQ-SAM adds learnable High-Quality Output Token to SAM's decoder, fusing early+final ViT features; trained on 44K fine-grained masks.", "key_findings": "Improves fine-grained zero-shot segmentation across 10 datasets; only 4h training on 8 GPUs.", "limitations": "Segmentation only; no restoration integration."}}
{"openalex_id": "https://openalex.org/W4401819803", "doi": "https://doi.org/10.1016/j.media.2024.103310", "title": "MA-SAM: Modality-agnostic SAM adaptation for 3D medical image segmentation", "abstract": "", "authors": ["Cheng Chen"], "year": 2024, "venue": "Medical Image Analysis", "cited_by_count": 146, "type": "article", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Encoder", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "Medical 3D SAM adaptation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Modality-agnostic adapter for SAM targeting 3D medical image segmentation.", "key_findings": "Adapter achieves good 3D segmentation across CT and MRI.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4391272787", "doi": "https://doi.org/10.48550/arxiv.2401.14159", "title": "Grounded SAM: Assembling Open-World Models for Diverse Visual Tasks", "abstract": "We introduce Grounded SAM, which uses Grounding DINO as an open-set object detector to combine with the segment anything model (SAM)...", "authors": ["Tianhe Ren", "Shilong Liu", "Ailing Zeng"], "year": 2024, "venue": "arXiv (Cornell University)", "cited_by_count": 88, "type": "preprint", "concepts": ["Pipeline (software)", "Computer science", "Segmentation", "Benchmark (surveying)", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 7.0, "subtopic": "Foundation Models Vision", "rationale": "Grounded SAM combines open-world detection + SAM segmentation via text prompts — directly relevant to spatial-aware restoration pipeline that detects and segments degraded regions by text description.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Pipeline combining Grounding DINO (open-set detection) + SAM for text-prompted detection and segmentation; extended with BLIP, Stable Diffusion, etc.", "key_findings": "Achieves 48.7 mAP on SegInW zero-shot benchmark; enables automatic annotation, controllable editing.", "limitations": "Not applied to restoration; requires text prompts for localisation."}}
{"openalex_id": "https://openalex.org/W4391991763", "doi": "https://doi.org/10.1109/tgrs.2024.3368168", "title": "Adapting Segment Anything Model for Change Detection in VHR Remote Sensing Images", "abstract": "Vision Foundation Models (VFMs) such as the Segment Anything Model (SAM) allow zero-shot or interactive segmentation of visual contents...", "authors": ["Lei Ding"], "year": 2024, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 137, "type": "article", "concepts": ["Remote sensing", "Change detection", "Computer science", "Artificial intelligence", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM adapted for remote sensing change detection; no restoration relevance.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "FastSAM visual encoder + convolutional adaptor for change detection in VHR remote sensing images.", "key_findings": "SAM-CD outperforms supervised methods with sample-efficient learning.", "limitations": "Remote sensing change detection domain."}}
{"openalex_id": "https://openalex.org/W4365816982", "doi": "https://doi.org/10.48550/arxiv.2304.05396", "title": "SAM.MD: Zero-shot medical image segmentation capabilities of the Segment Anything Model", "abstract": "Foundation models have taken over natural language processing and image generation domains due to the flexibility of prompting...", "authors": ["Saikat Roy"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 64, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Image (mathematics)", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "Medical SAM evaluation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM zero-shot evaluation on abdominal CT organ segmentation.", "key_findings": "SAM generalises reasonably to CT; can be catalyst for semi-automatic annotation tools.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4402727436", "doi": "https://doi.org/10.1109/cvpr52733.2024.02636", "title": "SAM-6D: Segment Anything Model Meets Zero-Shot 6D Object Pose Estimation", "abstract": "Zero-shot 6D object pose estimation involves the detection of novel objects with their 6D poses in cluttered scenes...", "authors": ["Jiehong Lin"], "year": 2024, "venue": "", "cited_by_count": 82, "type": "article", "concepts": ["Zero (linguistics)", "Computer vision", "Object (grammar)", "Computer science", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM for 6D pose estimation; not relevant to restoration.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "SAM + pose estimation model for zero-shot 6D object pose in RGB-D images.", "key_findings": "Outperforms existing methods on BOP Benchmark.", "limitations": "Pose estimation domain."}}
{"openalex_id": "https://openalex.org/W4390971106", "doi": "https://doi.org/10.1109/bibm58861.2023.10386032", "title": "Segment Anything Model (SAM) for Medical Image Segmentation: A Preliminary Review", "abstract": "Medical image segmentation is a critical component in a variety of clinical applications...", "authors": ["Leying Zhang", "Xiaokang Deng", "Lu Yu"], "year": 2023, "venue": "", "cited_by_count": 87, "type": "review", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Image segmentation", "Deep learning"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "Medical SAM review; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Review of SAM applications in medical image segmentation.", "key_findings": "Taxonomy of SAM approaches across modalities, organs, datasets.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4393159543", "doi": "https://doi.org/10.1609/aaai.v38i7.28514", "title": "SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation", "abstract": "The Segment Anything Model (SAM) is a powerful foundation model that has revolutionised image segmentation...", "authors": ["Wenxi Yue"], "year": 2024, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 72, "type": "article", "concepts": ["Surgical instrument", "Class (philosophy)", "Artificial intelligence", "Computer vision", "Segmentation"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for surgical instrument segmentation; completely irrelevant to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Lightweight prototype-based class prompt encoder for SAM in surgical instrument segmentation.", "key_findings": "SOTA on EndoVis2017/2018 with minimal tunable parameters.", "limitations": "Surgical domain."}}
{"openalex_id": "https://openalex.org/W4404177154", "doi": "https://doi.org/10.1007/978-3-031-72855-6_14", "title": "IRSAM: Advancing Segment Anything Model for Infrared Small Target Detection", "abstract": "", "authors": ["Mingjin Zhang"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 115, "type": "book-chapter", "concepts": ["Computer science", "Infrared", "Artificial intelligence", "Computer vision", "Optics"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM for infrared small target detection; detection task, no restoration relevance.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "SAM adaptation for infrared small target detection.", "key_findings": "High citation; strong performance on infrared target detection.", "limitations": "Detection-only; infrared domain."}}
{"openalex_id": "https://openalex.org/W4388823372", "doi": "https://doi.org/10.1101/2023.11.17.567630", "title": "CellSAM: A Foundation Model for Cell Segmentation", "abstract": "Cells are a fundamental unit of biological organization, and identifying them in imaging data is a critical task...", "authors": ["Uriah Israel"], "year": 2023, "venue": "", "cited_by_count": 51, "type": "preprint", "concepts": ["Computer science", "Segmentation", "Workflow", "Artificial intelligence", "Market segmentation"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for cell segmentation in biology; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "CellSAM uses object detector (CellFinder) to prompt SAM for universal cell segmentation.", "key_findings": "Human-level performance across mammalian cells, yeast, bacteria.", "limitations": "Biology domain."}}
{"openalex_id": "https://openalex.org/W4394597311", "doi": "https://doi.org/10.1109/wacv57701.2024.00817", "title": "Segment anything, from space?", "abstract": "Recently, the first foundation model developed specifically for image segmentation tasks was developed, termed the Segment Anything Model (SAM)...", "authors": ["Simiao Ren"], "year": 2024, "venue": "", "cited_by_count": 58, "type": "article", "concepts": ["Space (punctuation)", "Computer science", "Operating system"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM evaluation for overhead/remote sensing imagery; no restoration relevance.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Evaluates SAM zero-shot performance on overhead remote sensing benchmarks.", "key_findings": "SAM often generalises to overhead imagery but fails in some cases due to unique characteristics.", "limitations": "Remote sensing domain only."}}
{"openalex_id": "https://openalex.org/W4388666409", "doi": "https://doi.org/10.1016/j.atech.2023.100367", "title": "The Segment Anything Model (SAM) for accelerating the smart farming revolution", "abstract": "Precision agriculture uses accurate identification and mapping of crop features by automated mechanisms...", "authors": ["Alberto Carraro", "Marco Sozzi", "Francesco Marinello"], "year": 2023, "venue": "Smart Agricultural Technology", "cited_by_count": 51, "type": "article", "concepts": ["Computer science", "Segmentation", "Artificial intelligence", "Context (archaeology)", "Identification (biology)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for precision agriculture; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM evaluation for semantic segmentation in precision agriculture context.", "key_findings": "SAM shows promise for zero-shot generalisation in agricultural segmentation.", "limitations": "Agricultural domain only."}}
{"openalex_id": "https://openalex.org/W4367692241", "doi": "https://doi.org/10.48550/arxiv.2305.00035", "title": "SAM on Medical Images: A Comprehensive Study on Three Prompt Modes", "abstract": "The Segment Anything Model (SAM) made an eye-catching debut recently...", "authors": ["Dongjie Cheng"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 54, "type": "preprint", "concepts": ["Computer science", "Generalization", "Segmentation", "Artificial intelligence", "Modalities"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM on medical images; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Comprehensive SAM zero-shot study on 12+ public medical datasets with 3 prompt modes.", "key_findings": "Bounding box prompts work best; performance varies widely across datasets.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4402915908", "doi": "https://doi.org/10.1109/cvprw63382.2024.00367", "title": "SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding", "abstract": "The landscape of publicly available vision foundation models (VFMs), such as CLIP and Segment Anything Model (SAM), is expanding rapidly...", "authors": ["Haoxiang Wang"], "year": 2024, "venue": "", "cited_by_count": 65, "type": "article", "concepts": ["Foundation (evidence)", "Computer science", "Artificial intelligence", "Information retrieval", "Geography"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 6.0, "subtopic": "Foundation Models Vision", "rationale": "Merges SAM (spatial) and CLIP (semantic) into a unified model — directly relevant to VLM-based spatial-aware restoration that requires both spatial segmentation and semantic understanding.", "alignment": {"task": "medium", "method": "high", "modality": "high"}, "extraction": {"design": "Multi-task distillation merging SAM and CLIP into a single ViT using continual learning; SAM-CLIP reduces inference cost vs. deploying both models.", "key_findings": "+6.8%/+5.9% mIoU improvement on Pascal-VOC/COCO-Stuff zero-shot semantic segmentation.", "limitations": "Segmentation/recognition only; no restoration integration."}}
{"openalex_id": "https://openalex.org/W4383180710", "doi": "https://doi.org/10.48550/arxiv.2307.01197", "title": "Segment Anything Meets Point Tracking", "abstract": "The Segment Anything Model (SAM) has established itself as a powerful zero-shot image segmentation model...", "authors": ["Frano Rajic"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 38, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Computer vision", "Artificial intelligence", "Benchmark (surveying)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 2.0, "subtopic": "", "rationale": "SAM + point tracking for video segmentation; temporal tracking domain, no restoration relevance.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "SAM-PT: point-centric interactive video segmentation using SAM + long-term point tracking.", "key_findings": "Point propagation with SAM achieves better zero-shot performance than mask propagation on video benchmarks.", "limitations": "Video segmentation domain."}}
{"openalex_id": "https://openalex.org/W4366457071", "doi": "https://doi.org/10.48550/arxiv.2304.08506", "title": "When SAM Meets Medical Images: An Investigation of Segment Anything Model (SAM) on Multi-phase Liver Tumor Segmentation", "abstract": "Learning to segmentation without large-scale samples is an inherent capability of human...", "authors": ["Chuanfei Hu", "Xinde Li"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 37, "type": "preprint", "concepts": ["Segmentation", "Computer science", "Artificial intelligence", "Computer vision", "Image (mathematics)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "Medical SAM evaluation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM investigation on multi-phase liver tumor segmentation.", "key_findings": "Large gap between SAM performance and expectation in medical imaging.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4401008913", "doi": "https://doi.org/10.1016/j.atech.2024.100515", "title": "Leaf only SAM: A segment anything pipeline for zero-shot automated leaf segmentation", "abstract": "", "authors": ["Dominic Williams", "Fraser Macfarlane", "Avril Britten"], "year": 2024, "venue": "Smart Agricultural Technology", "cited_by_count": 38, "type": "article", "concepts": ["Shot (pellet)", "Pipeline (software)", "Segmentation", "Zero (linguistics)", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for leaf segmentation in agriculture; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM pipeline for automated zero-shot leaf segmentation in plant science.", "key_findings": "Effective zero-shot leaf segmentation without manual prompts.", "limitations": "Agricultural domain."}}
{"openalex_id": "https://openalex.org/W4388283708", "doi": "https://doi.org/10.1109/tmm.2023.3330047", "title": "FoodSAM: Any Food Segmentation", "abstract": "In this paper, we explore the zero-shot capability of the Segment Anything Model (SAM) for food image segmentation...", "authors": ["Xing Lan"], "year": 2023, "venue": "IEEE Transactions on Multimedia", "cited_by_count": 41, "type": "article", "concepts": ["Segmentation", "Computer science", "Market segmentation", "Artificial intelligence", "Scale-space segmentation"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for food image segmentation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "FoodSAM integrates coarse semantic masks with SAM for food instance/panoptic/promptable segmentation.", "key_findings": "First work achieving instance, panoptic, and promptable segmentation on food images.", "limitations": "Food domain only."}}
{"openalex_id": "https://openalex.org/W4395015601", "doi": "https://doi.org/10.1088/1742-6596/2722/1/012012", "title": "All-in-SAM: from Weak Annotation to Pixel-wise Nuclei Segmentation with Prompt-based Finetuning", "abstract": "The Segment Anything Model (SAM) is a recently proposed prompt-based segmentation model...", "authors": ["Can Cui"], "year": 2024, "venue": "Journal of Physics Conference Series", "cited_by_count": 35, "type": "article", "concepts": ["Annotation", "Segmentation", "Artificial intelligence", "Computer science", "Pixel"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for nuclei segmentation with weak annotations; biomedical domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM-based pipeline from weak annotations to full finetuning for nuclei segmentation.", "key_findings": "Outperforms SOTA on Monuseg without strong pixel-level annotations.", "limitations": "Biomedical domain."}}
{"openalex_id": "https://openalex.org/W4396825686", "doi": "https://doi.org/10.1016/j.conbuildmat.2024.136573", "title": "Fine-tuning vision foundation model for crack segmentation in civil infrastructures", "abstract": "", "authors": ["Kang Ge"], "year": 2024, "venue": "Construction and Building Materials", "cited_by_count": 45, "type": "article", "concepts": ["Foundation (evidence)", "Segmentation", "Artificial intelligence", "Computer science", "Computer vision"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for crack segmentation in civil engineering; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Fine-tuning SAM for crack segmentation in civil infrastructure images.", "key_findings": "Fine-tuned SAM outperforms zero-shot on crack detection.", "limitations": "Civil engineering domain."}}
{"openalex_id": "https://openalex.org/W4403649753", "doi": "https://doi.org/10.1007/978-3-031-72390-2_60", "title": "MedCLIP-SAM: Bridging Text and Image Towards Universal Medical Image Segmentation", "abstract": "", "authors": ["Taha Koleilat"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 33, "type": "book-chapter", "concepts": ["Bridging (networking)", "Computer science", "Image segmentation", "Computer vision", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "CLIP+SAM for medical segmentation; medical domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "MedCLIP + SAM fusion for zero-shot universal medical image segmentation.", "key_findings": "Text-image bridging improves medical segmentation.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4402961794", "doi": "https://doi.org/10.1007/978-3-031-72775-7_24", "title": "Open-Vocabulary SAM: Segment and Recognize Twenty-Thousand Classes Interactively", "abstract": "", "authors": ["Haobo Yuan"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 34, "type": "book-chapter", "concepts": ["Computer science", "Vocabulary", "Artificial intelligence", "Natural language processing", "Computer graphics (images)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 5.0, "subtopic": "Foundation Models Vision", "rationale": "Open-vocabulary SAM enabling text-driven segmentation of 20K classes — relevant to text-prompted spatial-aware degradation region identification.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "Extends SAM with open-vocabulary recognition for 20K classes via interactive segmentation.", "key_findings": "Enables recognition-segmentation unification at scale.", "limitations": "Segmentation/recognition only; no restoration."}}
{"openalex_id": "https://openalex.org/W4391929768", "doi": "https://doi.org/10.1109/bibe60311.2023.00025", "title": "Zero-Shot Performance of the Segment Anything Model (SAM) in 2D Medical Imaging", "abstract": "This study evaluates the potential of the Segment Anything Model (SAM) as a robust alternative for medical imaging segmentation...", "authors": ["Christian Mattjie"], "year": 2023, "venue": "", "cited_by_count": 33, "type": "article", "concepts": ["Zero (linguistics)", "Shot (pellet)", "Computer science", "Medical imaging", "Medical physics"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "Medical SAM evaluation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM zero-shot evaluation across 6 medical imaging datasets with 8 prompting strategies.", "key_findings": "Bounding box strategy outperforms or matches benchmarks in some datasets.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4389213248", "doi": "https://doi.org/10.1007/978-3-031-47401-9_23", "title": "SAM Meets Robotic Surgery: An Empirical Study on Generalization, Robustness and Adaptation", "abstract": "", "authors": ["An Wang"], "year": 2023, "venue": "Lecture notes in computer science", "cited_by_count": 38, "type": "book-chapter", "concepts": ["Computer science", "Robustness (evolution)", "Minimum bounding box", "Generalizability theory", "Bounding overwatch"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for robotic surgery; surgical domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Empirical SAM study on generalization and robustness in robotic surgery imaging.", "key_findings": "SAM generalizes partially to surgical imagery with adaptation.", "limitations": "Surgical domain."}}
{"openalex_id": "https://openalex.org/W4402916510", "doi": "https://doi.org/10.1109/cvprw63382.2024.00526", "title": "Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero-shot Medical Image Segmentation", "abstract": "The Segment Anything Model (SAM) and CLIP are remarkable vision foundation models (VFMs)...", "authors": ["Sidra Aleem"], "year": 2024, "venue": "", "cited_by_count": 26, "type": "article", "concepts": ["Cascade", "Shot (pellet)", "Computer science", "Segmentation", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM+CLIP cascade for medical segmentation; medical domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SaLIP pipeline: SAM generates masks, CLIP retrieves ROI mask, SAM re-segments target organ.", "key_findings": "Improves zero-shot medical segmentation without training.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4402781391", "doi": "https://doi.org/10.1109/cvpr52733.2024.01074", "title": "One-Prompt to Segment All Medical Images", "abstract": "Large foundation models, known for their strong zero-shot generalization, have excelled in visual and language applications...", "authors": ["Junde Wu", "Min Xu"], "year": 2024, "venue": "", "cited_by_count": 29, "type": "article", "concepts": ["Computer science", "Computer vision", "Medical imaging", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "One-prompt medical image segmentation; medical domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "One-Prompt model trained on 64 medical datasets to segment unseen tasks with a single prompted sample.", "key_findings": "Superior zero-shot segmentation on 14 unseen medical datasets.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4409363472", "doi": "https://doi.org/10.1609/aaai.v39i19.34255", "title": "TinySAM: Pushing the Envelope for Efficient Segment Anything Model", "abstract": "Recently segment anything model (SAM) has shown powerful segmentation capability...", "authors": ["Han Shu"], "year": 2025, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 20, "type": "article", "concepts": ["Envelope (radar)", "Computer science", "Telecommunications", "Radar"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 6.0, "subtopic": "Knowledge Distillation", "rationale": "Knowledge distillation + quantization to create lightweight SAM (TinySAM) — relevant to efficient SAM deployment in mobile/edge restoration pipelines.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "Full-stage KD with hard prompt sampling + post-training quantization + hierarchical everything strategy for TinySAM.", "key_findings": "Orders of magnitude computational reduction with minimal zero-shot performance degradation.", "limitations": "Segmentation only; no restoration integration."}}
{"openalex_id": "https://openalex.org/W4392154986", "doi": "https://doi.org/10.3390/rs16050797", "title": "Segment Anything Model Can Not Segment Anything: Assessing AI Foundation Model's Generalizability in Permafrost Mapping", "abstract": "This paper assesses trending AI foundation models...", "authors": ["Wenwen Li"], "year": 2024, "venue": "Remote Sensing", "cited_by_count": 28, "type": "article", "concepts": ["Generalizability theory", "Permafrost", "Foundation (evidence)", "Geology", "Oceanography"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for geospatial permafrost mapping; geoscience domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM evaluation on permafrost features with various prompt strategies.", "key_findings": "SAM shows promise but limitations in challenging natural landscape segmentation.", "limitations": "Geospatial domain."}}
{"openalex_id": "https://openalex.org/W4391109864", "doi": "https://doi.org/10.1038/s41467-024-44824-z", "title": "Segment anything in medical images", "abstract": "", "authors": ["Jun Ma", "Yuting He", "Feifei Li", "Lin Han", "Chenyu You", "Bo Wang"], "year": 2024, "venue": "Nature Communications", "cited_by_count": 1973, "type": "article", "concepts": ["Computer science", "Computational biology", "Medicine", "Biology"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "MedSAM; high citation but medical domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "MedSAM: SAM fine-tuned on 1.5M medical image-mask pairs across 10 modalities.", "key_findings": "SOTA on 86 medical segmentation tasks.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4397001004", "doi": "https://doi.org/10.1016/j.compag.2024.109045", "title": "An innovative segment anything model for precision poultry monitoring", "abstract": "", "authors": ["Xiao Yang"], "year": 2024, "venue": "Computers and Electronics in Agriculture", "cited_by_count": 23, "type": "article", "concepts": ["Computer science", "Engineering", "Artificial intelligence"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for poultry monitoring; agricultural domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM adaptation for precision poultry monitoring.", "key_findings": "Improved poultry monitoring accuracy.", "limitations": "Agricultural domain."}}
{"openalex_id": "https://openalex.org/W4390190003", "doi": "https://doi.org/10.1109/iccvw60793.2023.00184", "title": "Semantic Segmentation using Foundation Models for Cultural Heritage: an Experimental Study on Notre-Dame de Paris", "abstract": "The zero-shot performance of foundation models has captured a lot of attention...", "authors": ["Kevin Revy"], "year": 2023, "venue": "", "cited_by_count": 16, "type": "article", "concepts": ["Segmentation", "Foundation (evidence)", "Popularity", "Computer science", "Cultural heritage"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM+DINO+CLIP for cultural heritage segmentation; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Grounding DINO + CLIP + SAM pipeline for zero-shot semantic segmentation of cultural heritage images.", "key_findings": "SAM successfully identifies objects in cathedral imagery.", "limitations": "Cultural heritage domain."}}
{"openalex_id": "https://openalex.org/W4382319386", "doi": "https://doi.org/10.48550/arxiv.2306.13731", "title": "How to Efficiently Adapt Large Segmentation Model(SAM) to Medical Images", "abstract": "The emerging scale segmentation model, Segment Anything (SAM), exhibits impressive capabilities in zero-shot segmentation for natural images...", "authors": ["Xinrong Hu", "Xiaowei Xu", "Yiyu Shi"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 29, "type": "preprint", "concepts": ["Computer science", "Segmentation", "Artificial intelligence", "Encoder", "Inference"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM adaptation for medical imaging; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Freeze SAM encoder and finetune lightweight prediction heads for medical segmentation.", "key_findings": "AutoSAM significantly improves medical segmentation with limited labeled data.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4402753822", "doi": "https://doi.org/10.1109/cvpr52733.2024.02207", "title": "Improving the Generalization of Segmentation Foundation Model under Distribution Shift via Weakly Supervised Adaptation", "abstract": "The success of large language models has inspired the computer vision community to explore image segmentation foundation model...", "authors": ["Haojie Zhang"], "year": 2024, "venue": "", "cited_by_count": 24, "type": "article", "concepts": ["Generalization", "Foundation (evidence)", "Segmentation", "Adaptation (eye)", "Computer science"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 3.0, "subtopic": "", "rationale": "SAM adaptation for corrupted/distribution-shifted images — partial relevance to handling real-world degraded images.", "alignment": {"task": "medium", "method": "medium", "modality": "low"}, "extraction": {"design": "Self-training with anchor regularization and low-rank finetuning to adapt SAM to target distributions including corrupted natural images.", "key_findings": "Outperforms pre-trained SAM and SOTA domain adaptation on 5 downstream tasks including corrupted images.", "limitations": "Focuses on segmentation robustness, not restoration."}}
{"openalex_id": "https://openalex.org/W4405594810", "doi": "https://doi.org/10.1016/j.rineng.2024.103784", "title": "Tea leaf disease detection using segment anything model and deep convolutional neural networks", "abstract": "", "authors": ["A. Balasundaram"], "year": 2024, "venue": "Results in Engineering", "cited_by_count": 28, "type": "article", "concepts": ["Convolutional neural network", "Artificial intelligence", "Computer science", "Pattern recognition (psychology)"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for tea leaf disease detection; agricultural domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM + CNN for tea leaf disease detection.", "key_findings": "Improved disease detection with SAM segmentation.", "limitations": "Agricultural domain."}}
{"openalex_id": "https://openalex.org/W4386987615", "doi": "https://doi.org/10.1016/j.icarus.2023.115797", "title": "A flexible deep learning crater detection scheme using Segment Anything Model (SAM)", "abstract": "Craters are one of the most important morphological features in planetary exploration...", "authors": ["Iraklis Giannakis"], "year": 2023, "venue": "Icarus", "cited_by_count": 39, "type": "article", "concepts": ["Impact crater", "Orbiter", "Computer science", "Artificial intelligence", "Contouring"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM for planetary crater detection; astronomy domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "SAM zero-shot crater detection on lunar/Mars satellite imagery.", "key_findings": "Successfully identifies crater-like objects across different data types.", "limitations": "Planetary science domain."}}
{"openalex_id": "https://openalex.org/W4406322219", "doi": "https://doi.org/10.1109/tgrs.2025.3529031", "title": "PointSAM: Pointly-Supervised Segment Anything Model for Remote Sensing Images", "abstract": "Segment anything model (SAM) is an advanced foundational model for image segmentation...", "authors": ["Nanqing Liu"], "year": 2025, "venue": "IEEE Transactions on Geoscience and Remote Sensing", "cited_by_count": 38, "type": "article", "concepts": ["Remote sensing", "Computer science", "Computer vision", "Artificial intelligence", "Geology"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 1.0, "subtopic": "", "rationale": "SAM with point supervision for remote sensing; irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "PointSAM: self-training + prototype regularization + negative prompt calibration for point-supervised RS segmentation.", "key_findings": "Significantly outperforms direct SAM testing on remote sensing datasets.", "limitations": "Remote sensing domain."}}
{"openalex_id": "https://openalex.org/W4402980275", "doi": "https://doi.org/10.1109/icme57554.2024.10687602", "title": "PA-SAM: Prompt Adapter SAM for High-Quality Image Segmentation", "abstract": "The Segment Anything Model (SAM) has exhibited outstanding performance in various image segmentation tasks...", "authors": ["Zhaozhi Xie"], "year": 2024, "venue": "", "cited_by_count": 15, "type": "article", "concepts": ["Adapter (computing)", "Computer science", "Artificial intelligence", "Computer vision", "Image segmentation"], "search_query": "segment anything model SAM zero-shot segmentation", "score": 5.0, "subtopic": "Foundation Models Vision", "rationale": "Prompt adapter for SAM enhancing mask quality in real-world contexts — relevant to SAM-based spatial-aware restoration needing high-quality region masks.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "Prompt-driven adapter for SAM optimizing mask decoder at sparse/dense prompt levels.", "key_findings": "Outperforms other SAM-based methods in high-quality, zero-shot, open-set segmentation.", "limitations": "Segmentation only; no restoration integration."}}
{"openalex_id": "https://openalex.org/W4382462760", "doi": "https://doi.org/10.1609/aaai.v37i2.25353", "title": "Exploring CLIP for Assessing the Look and Feel of Images", "abstract": "Measuring the perception of visual content is a long-standing problem in computer vision...", "authors": ["Jianyi Wang", "Kelvin C. K. Chan", "Chen Change Loy"], "year": 2023, "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "cited_by_count": 461, "type": "article", "concepts": ["Computer science", "Perception", "Task (project management)", "Quality (philosophy)", "Prior probability"], "search_query": "visual language model image quality assessment", "score": 6.0, "subtopic": "Image Quality Assessment", "rationale": "CLIP-based IQA for quality and abstract perception — relevant as VLM-based quality assessment in restoration evaluation.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "Exploits CLIP visual-language prior with prompt pairing for zero-shot IQA without task-specific training.", "key_findings": "CLIP captures meaningful perceptual priors generalizing to IQA and aesthetic assessment.", "limitations": "IQA only; not applied to guiding restoration."}}
{"openalex_id": "https://openalex.org/W2067404301", "doi": "https://doi.org/10.1111/j.1365-2648.2007.04569.x", "title": "The qualitative content analysis process", "abstract": "Inductive content analysis is used in cases where there are no previous studies dealing with the phenomenon...", "authors": ["Satu Elo", "Helvi Kyngas"], "year": 2008, "venue": "Journal of Advanced Nursing", "cited_by_count": 21175, "type": "article", "concepts": ["Operationalization", "Content analysis", "Phenomenon", "Computer science", "Content (measure theory)"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Qualitative content analysis in nursing; completely irrelevant to image restoration or VLM.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Methodology paper on qualitative content analysis in nursing research.", "key_findings": "Framework for inductive/deductive content analysis.", "limitations": "Social science; no vision relevance."}}
{"openalex_id": "https://openalex.org/W4402704606", "doi": "https://doi.org/10.1109/cvpr52733.2024.02408", "title": "Q-Instruct: Improving Low-Level Visual Abilities for Multi-Modality Foundation Models", "abstract": "Multi-modality large language models (MLLMs)...", "authors": ["Haoning Wu", "Zicheng Zhang"], "year": 2024, "venue": "", "cited_by_count": 62, "type": "article", "concepts": ["Modality (human-computer interaction)", "Foundation (evidence)", "Computer science", "Artificial intelligence", "Human-computer interaction"], "search_query": "visual language model image quality assessment", "score": 8.0, "subtopic": "Image Quality Assessment", "rationale": "Q-Instruct creates VLM instruction-following data for low-level IQA — directly supports VLM-based quality assessment in agent-based restoration pipelines.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Q-Pathway: 58K human feedbacks on 18,973 images; GPT-converted to 200K Q-Instruct instruction-response pairs for MLLM low-level visual training.", "key_findings": "Q-Instruct consistently improves low-level visual capabilities (IQA, quality description) across multiple base models.", "limitations": "IQA/description training data contribution; no restoration component."}}
{"openalex_id": "https://openalex.org/W2137295153", "doi": "https://doi.org/10.1137/1114019", "title": "Non-Parametric Estimation of a Multivariate Probability Density", "abstract": "", "authors": ["V. A. Epanechnikov"], "year": 1969, "venue": "Theory of Probability and Its Applications", "cited_by_count": 1799, "type": "article", "concepts": ["Multivariate statistics", "Mathematics", "Multivariate kernel density estimation", "Estimation", "Density estimation"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Statistics paper on kernel density estimation; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Mathematical paper on non-parametric multivariate density estimation.", "key_findings": "Epanechnikov kernel for optimal density estimation.", "limitations": "Pure statistics; no vision relevance."}}
{"openalex_id": "https://openalex.org/W4409383105", "doi": "https://doi.org/10.1016/j.isprsjprs.2025.03.028", "title": "RSGPT: A remote sensing vision language model and benchmark", "abstract": "", "authors": ["Yuan Hu"], "year": 2025, "venue": "ISPRS Journal of Photogrammetry and Remote Sensing", "cited_by_count": 64, "type": "article", "concepts": ["Benchmark (surveying)", "Computer science", "Remote sensing", "Artificial intelligence", "Computer vision"], "search_query": "visual language model image quality assessment", "score": 3.0, "subtopic": "", "rationale": "VLM for remote sensing tasks; relevant to VLM methodology but remote sensing domain, not restoration.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Remote sensing VLM with benchmark for captioning and visual QA.", "key_findings": "VLM adapted effectively for remote sensing tasks.", "limitations": "Remote sensing domain; no restoration."}}
{"openalex_id": "https://openalex.org/W2952481429", "doi": "https://doi.org/10.1038/s41598-017-17204-5", "title": "QuPath: Open source software for digital pathology image analysis", "abstract": "", "authors": ["Peter Bankhead"], "year": 2017, "venue": "Scientific Reports", "cited_by_count": 7975, "type": "article", "concepts": ["Computer science", "Scripting language", "Software", "Digital pathology", "Extensibility"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Pathology software tool; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Open-source pathology image analysis software QuPath.", "key_findings": "Enables flexible digital pathology analysis.", "limitations": "Digital pathology domain."}}
{"openalex_id": "https://openalex.org/W1480729244", "doi": "https://doi.org/10.1159/000369778", "title": "Aspirin plus Clopidogrel as Secondary Prevention after Stroke or Transient Ischemic Attack: A Systematic Review and Meta-Analysis", "abstract": "", "authors": ["Qinghua Zhang"], "year": 2014, "venue": "Cerebrovascular Diseases", "cited_by_count": 11545, "type": "review", "concepts": ["Medicine", "Clopidogrel", "Aspirin", "Internal medicine", "Stroke (engine)"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Medical pharmacology meta-analysis; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Meta-analysis of aspirin + clopidogrel for stroke prevention.", "key_findings": "Short-term combination reduces stroke recurrence.", "limitations": "Medical domain."}}
{"openalex_id": "https://openalex.org/W3107527779", "doi": "https://doi.org/10.1093/nar/gkaa1074", "title": "The STRING database in 2021: customizable protein-protein networks, and functional characterization of user-uploaded gene/measurement sets", "abstract": "", "authors": ["Damian Szklarczyk"], "year": 2020, "venue": "Nucleic Acids Research", "cited_by_count": 8221, "type": "article", "concepts": ["Biology", "Upload", "Gene", "String (physics)", "Computational biology"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Protein-protein interaction database; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "STRING database for protein-protein interaction networks.", "key_findings": "Covers 14,000+ organisms.", "limitations": "Bioinformatics domain."}}
{"openalex_id": "https://openalex.org/W4400070365", "doi": "https://doi.org/10.1109/lsp.2024.3420083", "title": "Vision-Language Consistency Guided Multi-Modal Prompt Learning for Blind AI Generated Image Quality Assessment", "abstract": "Recently, textual prompt tuning has shown inspirational performance in adapting CLIP models to natural image quality assessment...", "authors": ["Jun Fu", "Wei Zhou", "Qiuping Jiang", "Hantao Liu", "Guangtao Zhai"], "year": 2024, "venue": "IEEE Signal Processing Letters", "cited_by_count": 24, "type": "article", "concepts": ["Computer science", "Consistency (knowledge bases)", "Artificial intelligence", "Image quality", "Quality (philosophy)"], "search_query": "visual language model image quality assessment", "score": 6.0, "subtopic": "Image Quality Assessment", "rationale": "CLIP-based multi-modal prompt learning for AI-generated image IQA — relevant to VLM quality assessment in restoration evaluation.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "CLIP-AGIQA: learnable textual+visual prompts + text-to-image alignment quality task for blind AGIQA.", "key_findings": "Multi-modal prompt learning outperforms SOTA on AGIQA datasets.", "limitations": "AI-generated image quality focus; not applied to restoration evaluation."}}
{"openalex_id": "https://openalex.org/W2089739736", "doi": "https://doi.org/10.1097/00006324-200111000-00006", "title": "Customized Corneal Ablation: the Quest for Supervision", "abstract": "", "authors": ["Mohan Merchea"], "year": 2001, "venue": "Optometry and Vision Science", "cited_by_count": 87, "type": "article", "concepts": ["Ablation", "Optometry", "Ophthalmology", "Computer science", "Medicine"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Ophthalmic surgery review; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Textbook review on wavefront-guided corneal ablation.", "key_findings": "Overview of customized refractive surgery.", "limitations": "Ophthalmology domain."}}
{"openalex_id": "https://openalex.org/W4404536559", "doi": "https://doi.org/10.1007/978-3-031-72904-1_9", "title": "A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment", "abstract": "", "authors": ["Tianhe Wu", "Kede Ma", "Jie Liang", "Yujiu Yang", "Lei Zhang"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 24, "type": "book-chapter", "concepts": ["Computer science", "Quality (philosophy)", "Natural language processing", "Image quality", "Artificial intelligence"], "search_query": "visual language model image quality assessment", "score": 7.0, "subtopic": "Image Quality Assessment", "rationale": "Comprehensive MLLM study for IQA — highly relevant to VLM-driven IQA in agent-based restoration pipelines.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Systematic evaluation of multiple MLLMs on diverse IQA tasks and datasets.", "key_findings": "MLLMs show promising low-level IQA capabilities; CLIP-based models particularly effective.", "limitations": "Evaluation study; no restoration integration."}}
{"openalex_id": "https://openalex.org/W2116634113", "doi": "https://doi.org/10.1093/bioinformatics/btg405", "title": "affy - analysis of Affymetrix GeneChip data at the probe level", "abstract": "", "authors": ["Laurent Gautier"], "year": 2004, "venue": "Bioinformatics", "cited_by_count": 5349, "type": "article", "concepts": ["Computer science", "Gene chip analysis", "R package", "Flexibility (engineering)", "Data mining"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Bioinformatics gene chip analysis; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "R package for Affymetrix microarray analysis.", "key_findings": "Enables probe-level microarray data analysis.", "limitations": "Bioinformatics domain."}}
{"openalex_id": "https://openalex.org/W4402448026", "doi": "https://doi.org/10.3390/hydrology11090148", "title": "The Implementation of Multimodal Large Language Models for Hydrological Applications", "abstract": "", "authors": ["Likith Kadiyala"], "year": 2024, "venue": "Hydrology", "cited_by_count": 35, "type": "article", "concepts": ["Computer science", "Multimodal therapy", "Environmental science", "Remote sensing", "Geology"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "MLLMs for hydrology; completely irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Comparison of GPT-4V, Gemini, LLaVA for hydrological tasks.", "key_findings": "GPT-4V best for interpreting visual hydrological data.", "limitations": "Hydrology domain."}}
{"openalex_id": "https://openalex.org/W4413146669", "doi": "https://doi.org/10.1109/cvpr52734.2025.02245", "title": "Video-MME: The First-Ever Comprehensive Evaluation Benchmark of Multi-modal LLMs in Video Analysis", "abstract": "", "authors": ["Chaoyou Fu"], "year": 2025, "venue": "", "cited_by_count": 38, "type": "article", "concepts": ["Benchmark (surveying)", "Computer science", "Modal", "Artificial intelligence", "Geography"], "search_query": "visual language model image quality assessment", "score": 3.0, "subtopic": "", "rationale": "Video MLLM evaluation benchmark; relevant to VLM methodology but video domain.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Video-MME: MLLM video benchmark across 6 domains, varying durations, multi-modal inputs.", "key_findings": "Gemini 1.5 Pro best commercial model; performance declines with video length.", "limitations": "Video analysis domain."}}
{"openalex_id": "https://openalex.org/W2809254203", "doi": "https://doi.org/10.1007/s13244-018-0639-9", "title": "Convolutional neural networks: an overview and application in radiology", "abstract": "", "authors": ["Rikiya Yamashita"], "year": 2018, "venue": "Insights into Imaging", "cited_by_count": 4417, "type": "review", "concepts": ["Convolutional neural network", "Computer science", "Artificial intelligence", "Leverage (statistics)", "Overfitting"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "CNN overview for radiology; medical domain.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Review of CNNs in radiology applications.", "key_findings": "CNNs outperform traditional methods in radiology.", "limitations": "Radiology domain."}}
{"openalex_id": "https://openalex.org/W4387076386", "doi": "https://doi.org/10.48550/arxiv.2309.14181", "title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision", "abstract": "The rapid evolution of Multi-modality Large Language Models (MLLMs) has catalyzed a shift in computer vision from specialized models to general-purpose foundation models...", "authors": ["Haoning Wu", "Zicheng Zhang", "Erli Zhang"], "year": 2023, "venue": "arXiv (Cornell University)", "cited_by_count": 20, "type": "preprint", "concepts": ["Perception", "Computer science", "Benchmark (surveying)", "Construct (python library)", "Correctness"], "search_query": "visual language model image quality assessment", "score": 8.0, "subtopic": "Image Quality Assessment", "rationale": "Q-Bench holistically evaluates MLLM low-level vision abilities (perception, description, quality assessment) — core to VLM-based quality feedback in agent restoration pipelines.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Q-Bench: three evaluation dimensions (low-level perception QA, low-level description, IQA score alignment) on LLVisionQA, LLDescribe, and 7 IQA datasets for 15+ MLLMs.", "key_findings": "MLLMs have preliminary but unstable low-level visual skills; clear areas for enhancement identified.", "limitations": "Evaluation benchmark; no restoration component."}}
{"openalex_id": "https://openalex.org/W2166667242", "doi": "https://doi.org/10.1017/s0140525x01003922", "title": "The magical number 4 in short-term memory: A reconsideration of mental storage capacity", "abstract": "", "authors": ["Nelson Cowan"], "year": 2001, "venue": "Behavioral and Brain Sciences", "cited_by_count": 6665, "type": "article", "concepts": ["Mental capacity", "Limit (mathematics)", "Stimulus (psychology)", "Computer science", "Short-term memory"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Cognitive psychology about short-term memory; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Cognitive psychology study on short-term memory capacity.", "key_findings": "Central capacity limit ~4 chunks in STM.", "limitations": "Cognitive psychology; no vision relevance."}}
{"openalex_id": "https://openalex.org/W3120387768", "doi": "https://doi.org/10.1016/s0140-6736(20)32656-8", "title": "RETRACTED: 6-month consequences of COVID-19 in patients discharged from hospital: a cohort study", "abstract": "", "authors": ["Chaolin Huang"], "year": 2021, "venue": "The Lancet", "cited_by_count": 4238, "type": "article", "concepts": ["Medicine", "Cohort", "Pneumonia", "Logistic regression", "Emergency medicine"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Retracted COVID-19 cohort study; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Retracted cohort study on 6-month COVID-19 consequences.", "key_findings": "Retracted.", "limitations": "Medical domain; retracted."}}
{"openalex_id": "https://openalex.org/W1787224781", "doi": "https://doi.org/10.1371/journal.pone.0130140", "title": "On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation", "abstract": "", "authors": ["Sebastian Bach"], "year": 2015, "venue": "PLoS ONE", "cited_by_count": 4413, "type": "article", "concepts": ["MNIST database", "Computer science", "Artificial intelligence", "Pixel", "Pascal (unit)"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Layer-wise relevance propagation for classifier explanations; XAI method, not IQA or restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "LRP method for pixel-wise explanation of CNN classifier decisions.", "key_findings": "Pixel-wise decomposition enables visualization of classification contributions.", "limitations": "Explainability method; not IQA or restoration."}}
{"openalex_id": "https://openalex.org/W4390193237", "doi": "https://doi.org/10.4274/dir.2023.232496", "title": "Educating the next generation of radiologists: a comparative report of ChatGPT and e-learning resources", "abstract": "", "authors": ["Ismail Mese"], "year": 2023, "venue": "Diagnostic and Interventional Radiology", "cited_by_count": 23, "type": "article", "concepts": ["Medicine", "Multimedia", "Flexibility (engineering)", "Chatbot", "Learning styles"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "ChatGPT for radiology education; medical education domain, irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Comparative study of ChatGPT vs e-learning for radiology residents.", "key_findings": "Integration of ChatGPT with expert e-learning improves education.", "limitations": "Medical education domain."}}
{"openalex_id": "https://openalex.org/W4387969352", "doi": "https://doi.org/10.1145/3581783.3611969", "title": "AesCLIP: Multi-Attribute Contrastive Learning for Image Aesthetics Assessment", "abstract": "Image aesthetics assessment (IAA) aims at predicting the aesthetic quality of images...", "authors": ["Xiangfei Sheng"], "year": 2023, "venue": "", "cited_by_count": 26, "type": "article", "concepts": ["Computer science", "Domain (mathematical analysis)", "Artificial intelligence", "Representation (politics)", "Image (mathematics)"], "search_query": "visual language model image quality assessment", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "CLIP-based multi-attribute contrastive learning for image aesthetics — relevant to VLM-based perceptual quality assessment in restoration.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "AesCLIP: multi-attribute aesthetic contrastive learning with CLIP for image aesthetics assessment.", "key_findings": "Aesthetic attribute-aware CLIP representation improves IAA on 4 public databases.", "limitations": "Aesthetics assessment only; not directly for restoration quality."}}
{"openalex_id": "https://openalex.org/W4401726215", "doi": "https://doi.org/10.1109/tpami.2024.3445770", "title": "Q-Bench+: A Benchmark for Multi-Modal Foundation Models on Low-Level Vision From Single Images to Pairs", "abstract": "The rapid development of Multi-modality Large Language Models (MLLMs) has navigated a paradigm shift in computer vision...", "authors": ["Zicheng Zhang", "Haoning Wu", "Erli Zhang", "Guangtao Zhai", "Weisi Lin"], "year": 2024, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 17, "type": "article", "concepts": ["Modal", "Artificial intelligence", "Benchmark (surveying)", "Computer science", "Foundation (evidence)"], "search_query": "visual language model image quality assessment", "score": 8.0, "subtopic": "Image Quality Assessment", "rationale": "Q-Bench+ extends MLLM low-level vision evaluation to image pairs — directly relevant to VLM-based IQA component comparing restored vs degraded images.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Extends Q-Bench to pairwise: LLVisionQA+ (2990 single + 1999 pairs), LLDescribe+ (499 single + 450 pairs), IQA score evaluation on 7 datasets with 24 MLLMs.", "key_findings": "Only GPT-4V shows higher pairwise accuracy vs single-image (like humans); identifies clear capability gaps.", "limitations": "Benchmark only; no restoration integration."}}
{"openalex_id": "https://openalex.org/W4312219151", "doi": "https://doi.org/10.1145/3573891", "title": "Dynamic Convolution-based Encoder-Decoder Framework for Image Captioning in Hindi", "abstract": "", "authors": ["Santosh Kumar Mishra"], "year": 2022, "venue": "ACM Transactions on Asian and Low-Resource Language Information Processing", "cited_by_count": 19, "type": "article", "concepts": ["Closed captioning", "Computer science", "Hindi", "Encoder", "Artificial intelligence"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Hindi image captioning; NLP domain, no relevance to restoration or IQA.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "CNN-LSTM with dynamic convolution encoder and X-Linear attention for Hindi image captioning.", "key_findings": "Proposed method outperforms baselines on Hindi captioning.", "limitations": "Hindi NLP domain."}}
{"openalex_id": "https://openalex.org/W4319662928", "doi": "https://doi.org/10.1371/journal.pdig.0000198", "title": "Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models", "abstract": "", "authors": ["Tiffany H. Kung"], "year": 2023, "venue": "PLOS Digital Health", "cited_by_count": 3279, "type": "article", "concepts": ["Concordance", "United States Medical Licensing Examination", "Medical education", "Computer science", "Licensure"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "ChatGPT for USMLE medical licensing; medical education, irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "ChatGPT performance evaluation on USMLE Steps 1-3.", "key_findings": "ChatGPT performs near passing threshold without specialized training.", "limitations": "Medical education domain."}}
{"openalex_id": "https://openalex.org/W4390987121", "doi": "https://doi.org/10.57197/jdr-2023-0051", "title": "Empowering the Visually Impaired: Translating Handwritten Digits into Spoken Language with HRNN-GOA and Haralick Features", "abstract": "", "authors": ["Mohammed Alshehri"], "year": 2024, "venue": "Journal of Disability Research", "cited_by_count": 24, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Robustness (evolution)", "Speech recognition", "Feature extraction"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Handwritten digit recognition for visually impaired; accessibility domain, irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "HRNN-GOA + Haralick features for handwritten digit-to-speech translation.", "key_findings": "SOTA performance on digit recognition.", "limitations": "Accessibility/assistive technology domain."}}
{"openalex_id": "https://openalex.org/W4405016353", "doi": "https://doi.org/10.1007/978-3-031-78125-4_4", "title": "CLIP-AGIQA: Boosting the Performance of AI-Generated Image Quality Assessment with CLIP", "abstract": "", "authors": ["Zhenchen Tang"], "year": 2024, "venue": "Lecture notes in computer science", "cited_by_count": 10, "type": "book-chapter", "concepts": ["Computer science", "Boosting (machine learning)", "Image quality", "Artificial intelligence", "Quality assessment"], "search_query": "visual language model image quality assessment", "score": 6.0, "subtopic": "Image Quality Assessment", "rationale": "CLIP for AI-generated image quality assessment — relevant to VLM-based quality evaluation in restoration pipelines.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "CLIP-based approach to improve AI-generated image quality assessment.", "key_findings": "CLIP priors boost AGIQA performance.", "limitations": "AI-generated image quality focus."}}
{"openalex_id": "https://openalex.org/W2510708214", "doi": "https://doi.org/10.2337/dc13-s011", "title": "Standards of Medical Care in Diabetes-2013", "abstract": "", "authors": [], "year": 2012, "venue": "Diabetes Care", "cited_by_count": 4416, "type": "article", "concepts": ["Medicine", "Diabetes mellitus", "MEDLINE", "Family medicine", "Endocrinology"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Diabetes clinical guidelines; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Standards of medical care in diabetes.", "key_findings": "Clinical recommendations for diabetes management.", "limitations": "Medical domain."}}
{"openalex_id": "https://openalex.org/W4401990587", "doi": "https://doi.org/10.1109/icmew63481.2024.10645451", "title": "Q-Boost: On Visual Quality Assessment Ability of Low-Level Multi-Modality Foundation Models", "abstract": "Recent advancements in Multi-modality Large Language Models (MLLMs) have demonstrated remarkable capabilities in complex high-level vision tasks...", "authors": ["Zicheng Zhang", "Haoning Wu"], "year": 2024, "venue": "", "cited_by_count": 13, "type": "article", "concepts": ["Modality (human-computer interaction)", "Foundation (evidence)", "Computer science", "Quality (philosophy)", "Artificial intelligence"], "search_query": "visual language model image quality assessment", "score": 7.0, "subtopic": "Image Quality Assessment", "rationale": "Q-Boost enhances MLLM IQA/VQA with triadic tone + multi-prompt ensemble — relevant to VLM-based quality feedback in restoration pipelines.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Q-Boost strategy: triadic tone integration (positive/neutral/negative prompts) + multi-prompt ensemble for MLLM IQA/VQA.", "key_findings": "Outstanding zero-shot performance on IQA/VQA tasks with Q-Boost strategy.", "limitations": "Quality assessment prompting strategy; no restoration integration."}}
{"openalex_id": "https://openalex.org/W2150353123", "doi": "https://doi.org/10.2196/jmir.8.2.e9", "title": "eHealth Literacy: Essential Skills for Consumer Health in a Networked World", "abstract": "", "authors": ["Cameron D. Norman", "Harvey A. Skinner"], "year": 2006, "venue": "Journal of Medical Internet Research", "cited_by_count": 2380, "type": "review", "concepts": ["eHealth", "Health literacy", "Literacy", "Health care", "Information literacy"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "eHealth literacy paper; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Model of eHealth literacy for consumer health.", "key_findings": "Framework for eHealth literacy skills.", "limitations": "Health informatics domain."}}
{"openalex_id": "https://openalex.org/W2566149141", "doi": "https://doi.org/10.1109/jstsp.2016.2639328", "title": "Fully Deep Blind Image Quality Predictor", "abstract": "In general, owing to the benefits obtained from original information, full-reference image quality assessment (FR-IQA) achieves relatively higher prediction accuracy than no-reference image quality assessment (NR-IQA)...", "authors": ["Jongyoo Kim", "Sanghoon Lee"], "year": 2016, "venue": "IEEE Journal of Selected Topics in Signal Processing", "cited_by_count": 455, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Convolutional neural network", "Image quality", "Pattern recognition (psychology)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 6.0, "subtopic": "Image Quality Assessment", "rationale": "Deep blind IQA (BIECON) using FR-IQA behavior imitation — relevant baseline for no-reference IQA used in restoration quality evaluation.", "alignment": {"task": "medium", "method": "high", "modality": "medium"}, "extraction": {"design": "BIECON: CNN-based NR-IQA mimicking FR-IQA behavior via local quality maps as intermediate targets.", "key_findings": "Achieves NR-IQA performance comparable to FR-IQA methods.", "limitations": "Classic IQA only; no restoration pipeline integration."}}
{"openalex_id": "https://openalex.org/W2797079651", "doi": "https://doi.org/10.1016/j.patcog.2018.04.016", "title": "Blind image quality prediction by exploiting multi-level deep representations", "abstract": "", "authors": ["Fei Gao", "Jun Yu", "Suguo Zhu", "Qingming Huang", "Qi Tian"], "year": 2018, "venue": "Pattern Recognition", "cited_by_count": 120, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Pattern recognition (psychology)", "Image (mathematics)", "Quality (philosophy)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "Multi-level deep feature blind IQA — relevant to no-reference quality assessment methods used in restoration evaluation.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "Multi-level deep representation extraction for blind IQA prediction.", "key_findings": "Multi-level features improve blind IQA prediction accuracy.", "limitations": "Synthetic distortion datasets; limited real-world applicability."}}
{"openalex_id": "https://openalex.org/W2971622202", "doi": "https://doi.org/10.1109/access.2019.2938900", "title": "A Survey of DNN Methods for Blind Image Quality Assessment", "abstract": "Blind image quality assessment (BIQA) methods aim to predict quality of images as perceived by humans without access to a reference image...", "authors": ["Xiaohan Yang", "Fan Li", "Hantao Liu"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 73, "type": "article", "concepts": ["Novelty", "Computer science", "Artificial intelligence", "Artificial neural network", "Image quality"], "search_query": "image quality assessment no-reference blind deep learning", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "Survey of DNN-based blind IQA methods — relevant background for no-reference IQA in restoration pipelines.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "Survey categorizing DNN methods for blind IQA by role of DNN; performance comparison on LIVE, TID2013, CSIQ, LIVE-challenge.", "key_findings": "DNN-based BIQA significantly outperforms handcrafted methods on various distortion types.", "limitations": "Survey only; limited to 2019; no real-world mixed degradation coverage."}}
{"openalex_id": "https://openalex.org/W2083704334", "doi": "https://doi.org/10.1109/icip.2014.7025102", "title": "Deep learning network for blind image quality assessment", "abstract": "Nowadays, blind image quality assessment (BIQA) has been intensively studied with machine learning...", "authors": ["Ke Gu", "Guangtao Zhai", "Xiaokang Yang", "Wenjun Zhang"], "year": 2014, "venue": "", "cited_by_count": 61, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Distortion (music)", "Support vector machine", "Machine learning"], "search_query": "image quality assessment no-reference blind deep learning", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "Early deep learning BIQA (DIQI) — foundational for blind IQA research relevant to restoration quality evaluation.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "DIQI: deep CNN for blind image quality assessment on TID2013 dataset.", "key_findings": "DNN captures essential image quality attributes better than shallow methods.", "limitations": "Early work with limited datasets."}}
{"openalex_id": "https://openalex.org/W3193517049", "doi": "https://doi.org/10.1109/iccv48922.2021.01008", "title": "Learning Conditional Knowledge Distillation for Degraded-Reference Image Quality Assessment", "abstract": "An important scenario for image quality assessment (IQA) is to evaluate image restoration (IR) algorithms...", "authors": ["Heliang Zheng", "Huan Yang", "Jianlong Fu", "Zheng-Jun Zha", "Jiebo Luo"], "year": 2021, "venue": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "cited_by_count": 52, "type": "article", "concepts": ["Computer science", "Artificial intelligence", "Metric (unit)", "Image quality", "Quality (philosophy)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 7.0, "subtopic": "Image Quality Assessment", "rationale": "DR-IQA explicitly for evaluating image restoration algorithms using degraded references — directly relevant to quality evaluation in restoration pipelines where clean references are unavailable.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "DR-IQA: knowledge distillation to transfer knowledge from pristine references to degraded-reference IQA for blind image restoration evaluation.", "key_findings": "DR-IQA achieves near full-reference IQA performance using only degraded images as references; provides differentiable metric for GAN-based restoration.", "limitations": "Requires degraded reference; not fully blind; evaluated on specific restoration tasks."}}
{"openalex_id": "https://openalex.org/W2963833613", "doi": "https://doi.org/10.1016/j.mri.2018.07.003", "title": "A machine-learning framework for automatic reference-free quality assessment in MRI", "abstract": "", "authors": ["Thomas Kustner"], "year": 2018, "venue": "Magnetic Resonance Imaging", "cited_by_count": 61, "type": "article", "concepts": ["Computer science", "Image quality", "Artificial intelligence", "Quality assurance", "Scanner"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "MRI quality assessment; medical imaging domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "ML framework for reference-free MRI quality assessment.", "key_findings": "Automated MRI quality scoring without reference scans.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W3016917677", "doi": "https://doi.org/10.1016/j.ins.2020.04.030", "title": "Blind quality assessment for image superresolution using deep two-stream convolutional networks", "abstract": "", "authors": ["Wei Zhou", "Qiuping Jiang", "Yuwang Wang", "Zhibo Chen", "Weiping Li"], "year": 2020, "venue": "Information Sciences", "cited_by_count": 77, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Discriminative model", "Convolutional neural network", "Pattern recognition (psychology)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 6.0, "subtopic": "Image Quality Assessment", "rationale": "Blind IQA specifically for super-resolution output — directly relevant to evaluating restoration output quality.", "alignment": {"task": "high", "method": "medium", "modality": "high"}, "extraction": {"design": "Two-stream CNN for blind quality assessment of super-resolved images.", "key_findings": "Two-stream architecture captures both distortion and content features for SR quality assessment.", "limitations": "Super-resolution specific; not generalised to other degradation types."}}
{"openalex_id": "https://openalex.org/W2752223497", "doi": "https://doi.org/10.48550/arxiv.1708.08190", "title": "A Probabilistic Quality Representation Approach to Deep Blind Image Quality Prediction", "abstract": "Blind image quality assessment (BIQA) remains a very challenging problem due to the unavailability of a reference image...", "authors": ["Hui Zeng", "Lei Zhang", "Alan C. Bovik"], "year": 2017, "venue": "arXiv (Cornell University)", "cited_by_count": 61, "type": "preprint", "concepts": ["Probabilistic logic", "Artificial intelligence", "Quality (philosophy)", "Computer science", "Representation (politics)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "Probabilistic quality representation (PQR) for deep BIQA — relevant to blind IQA for assessing restoration output quality.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "PQR: models subjective score distribution rather than scalar for deep BIQA training.", "key_findings": "PQR speeds up convergence and improves BIQA accuracy over scalar regression.", "limitations": "Preprint; limited dataset coverage."}}
{"openalex_id": "https://openalex.org/W2296265007", "doi": "https://doi.org/10.1109/icip.2015.7351221", "title": "Difference of Gaussian statistical features based blind image quality assessment: A deep learning approach", "abstract": "Nowadays, natural scene statistics (NSS) based blind image quality assessment (BIQA) models trained by machine learning, tend to achieve excellent performance...", "authors": ["Yaqi Lv"], "year": 2015, "venue": "", "cited_by_count": 45, "type": "article", "concepts": ["Pooling", "Computer science", "Support vector machine", "Artificial intelligence", "Generalization"], "search_query": "image quality assessment no-reference blind deep learning", "score": 4.0, "subtopic": "", "rationale": "DoG-based deep BIQA — relevant but early/narrow work; limited generalization to restoration evaluation.", "alignment": {"task": "medium", "method": "medium", "modality": "low"}, "extraction": {"design": "Local normalized multi-scale DoG features + 3-step DNN for BIQA.", "key_findings": "DoG features with DNN pooling achieve SOTA on two benchmark databases.", "limitations": "Narrow feature set; older approach."}}
{"openalex_id": "https://openalex.org/W2925250639", "doi": "https://doi.org/10.1109/access.2019.2905615", "title": "No-Reference Quality Assessment for Pansharpened Images via Opinion-Unaware Learning", "abstract": "The high-quality pansharpened image with both high spatial resolution and high spectral fidelity is highly desirable...", "authors": ["Bingzhong Zhou"], "year": 2019, "venue": "IEEE Access", "cited_by_count": 21, "type": "article", "concepts": ["Panchromatic film", "Multispectral image", "Computer science", "Artificial intelligence", "Distortion (music)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 2.0, "subtopic": "", "rationale": "NR-IQA for pansharpened remote sensing images; narrow domain, not relevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Opinion-unaware NR-IQA for pansharpened images using MVG model on spectral/spatial features.", "key_findings": "MVG-based approach captures spatial and spectral distortions in pansharpened images.", "limitations": "Remote sensing pansharpening domain only."}}
{"openalex_id": "https://openalex.org/W2793583884", "doi": "https://doi.org/10.1109/icip.2017.8296869", "title": "Deep blind image quality assessment by employing FR-IQA", "abstract": "In this paper, we propose a convolutional neural network (CNN)-based no-reference image quality assessment (NR-IQA)...", "authors": ["Jongyoo Kim", "Sanghoon Lee"], "year": 2017, "venue": "", "cited_by_count": 21, "type": "article", "concepts": ["Computer science", "Convolutional neural network", "Pooling", "Artificial intelligence", "Deep learning"], "search_query": "image quality assessment no-reference blind deep learning", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "Conference version of BIECON for blind IQA — relevant to no-reference quality evaluation.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "BIECON (conference version): CNN NR-IQA using FR-IQA metrics as intermediate targets.", "key_findings": "Achieves SOTA NR-IQA comparable to FR methods.", "limitations": "Conference version; superseded by journal version."}}
{"openalex_id": "https://openalex.org/W4292559719", "doi": "https://doi.org/10.1016/j.imed.2022.08.001", "title": "Automated assessment of transthoracic echocardiogram image quality using deep neural networks", "abstract": "", "authors": ["Robert B. Labs"], "year": 2022, "venue": "Intelligent Medicine", "cited_by_count": 20, "type": "article", "concepts": ["Image quality", "Computer science", "Artificial intelligence", "Transthoracic echocardiogram", "Deep learning"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Deep learning for echocardiogram quality assessment; medical imaging domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "DNN for automated echocardiogram image quality scoring.", "key_findings": "Automated quality assessment for cardiac ultrasound.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W3149775056", "doi": "https://doi.org/10.1109/tpami.2021.3071759", "title": "Active Fine-Tuning from gMAD Examples Improves Blind Image Quality Assessment", "abstract": "The research in image quality assessment (IQA) has a long history, and significant progress has been made by leveraging recent advances in deep neural networks (DNNs)...", "authors": ["Zhihua Wang", "Kede Ma"], "year": 2021, "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "cited_by_count": 30, "type": "article", "concepts": ["Computer science", "Generalizability theory", "Artificial intelligence", "Set (abstract data type)", "Image quality"], "search_query": "image quality assessment no-reference blind deep learning", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "Active learning for BIQA using gMAD competition — relevant to improving IQA models for restoration quality evaluation.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "Active fine-tuning: gMAD competition between BIQA and FR-IQA methods to spot weaknesses; human annotation of hard cases; iterative fine-tuning.", "key_findings": "gMAD-guided active fine-tuning improves BIQA generalizability without degrading existing databases.", "limitations": "Requires iterative human annotation; complex pipeline."}}
{"openalex_id": "https://openalex.org/W3212793811", "doi": "https://doi.org/10.1109/tcsvt.2021.3128014", "title": "Multi-Angle Projection Based Blind Omnidirectional Image Quality Assessment", "abstract": "Most of the existing blind omnidirectional image quality assessment (BOIQA) methods are based on data-driven approach...", "authors": ["Hao Jiang"], "year": 2021, "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "cited_by_count": 21, "type": "article", "concepts": ["Artificial intelligence", "Computer science", "Computer vision", "Projection (relational algebra)", "Feature extraction"], "search_query": "image quality assessment no-reference blind deep learning", "score": 3.0, "subtopic": "", "rationale": "Blind omnidirectional IQA; specialized 360-degree image domain, not restoration-relevant.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Multi-angle projection with tensor decomposition and piecewise fitting for omnidirectional IQA.", "key_findings": "MP-BOIQA achieves competitive performance on 3 omnidirectional IQA datasets.", "limitations": "Omnidirectional/360-degree image domain only."}}
{"openalex_id": "https://openalex.org/W4210559218", "doi": "https://doi.org/10.1007/s00500-021-06662-9", "title": "Deep ensembling for perceptual image quality assessment", "abstract": "", "authors": ["Nisar Ahmed"], "year": 2022, "venue": "Soft Computing", "cited_by_count": 20, "type": "article", "concepts": ["Computer science", "Benchmark (surveying)", "Artificial intelligence", "Distortion (music)", "Generalization"], "search_query": "image quality assessment no-reference blind deep learning", "score": 4.0, "subtopic": "", "rationale": "Deep ensemble for perceptual IQA — weakly relevant as IQA for restoration but standard approach without unique contribution.", "alignment": {"task": "medium", "method": "low", "modality": "medium"}, "extraction": {"design": "Deep ensemble model for perceptual blind IQA.", "key_findings": "Ensemble approach improves generalization in perceptual IQA.", "limitations": "Standard approach; limited novelty."}}
{"openalex_id": "https://openalex.org/W4206481149", "doi": "https://doi.org/10.1016/s0140-6736(21)00218-x", "title": "Parkinson's disease", "abstract": "", "authors": ["Bastiaan R. Bloem", "Michael S. Okun", "Christine Klein"], "year": 2021, "venue": "The Lancet", "cited_by_count": 3263, "type": "review", "concepts": ["Disease", "Parkinson's disease", "Medicine", "Parkinsonism", "Levodopa"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Parkinson's disease medical review; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Clinical review of Parkinson's disease.", "key_findings": "Overview of PD epidemiology, pathophysiology, and treatment.", "limitations": "Neurology domain."}}
{"openalex_id": "https://openalex.org/W2922226472", "doi": "https://doi.org/10.1109/istel.2018.8661024", "title": "No-Reference Image Quality Assessment using Transfer Learning", "abstract": "With the recent advancements in deep learning, high performance neural networks have been introduced...", "authors": ["Hatef Otroshi Shahreza", "Arash Amini", "Hamid Behroozi"], "year": 2018, "venue": "", "cited_by_count": 17, "type": "article", "concepts": ["Transfer of learning", "Convolutional neural network", "Computer science", "Artificial intelligence", "Artificial neural network"], "search_query": "image quality assessment no-reference blind deep learning", "score": 5.0, "subtopic": "Image Quality Assessment", "rationale": "Transfer learning for in-the-wild NR-IQA — relevant to blind quality evaluation of restoration outputs.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "Transfer learning from pretrained CNNs for in-the-wild NR-IQA; predicts opinion score distribution.", "key_findings": "Transfer learning with score distribution prediction outperforms non-deep methods.", "limitations": "Small dataset; limited citation."}}
{"openalex_id": "https://openalex.org/W4385574853", "doi": "https://doi.org/10.1109/tmm.2023.3301276", "title": "Going the Extra Mile in Face Image Quality Assessment: A Novel Database and Model", "abstract": "An accurate computational model for image quality assessment (IQA) benefits many vision applications...", "authors": ["Shaolin Su"], "year": 2023, "venue": "IEEE Transactions on Multimedia", "cited_by_count": 19, "type": "article", "concepts": ["Computer science", "Face (sociological concept)", "Artificial intelligence", "Image quality", "Generative model"], "search_query": "image quality assessment no-reference blind deep learning", "score": 3.0, "subtopic": "", "rationale": "Face-specific IQA with generative priors; narrow domain but generative prior idea tangentially relevant.", "alignment": {"task": "low", "method": "medium", "modality": "low"}, "extraction": {"design": "Large 20K face IQA database + deep model with generative priors for blind face IQA.", "key_findings": "Generative priors improve blind face IQA; largest annotated face IQA database.", "limitations": "Face-specific domain."}}
{"openalex_id": "https://openalex.org/W3217519524", "doi": "https://doi.org/10.1016/j.image.2021.116576", "title": "QL-IQA: Learning distance distribution from quality levels for blind image quality assessment", "abstract": "", "authors": ["Rui Gao", "Ziqing Huang", "Shiguang Liu"], "year": 2021, "venue": "Signal Processing Image Communication", "cited_by_count": 14, "type": "article", "concepts": ["Quality Score", "Image quality", "Artificial intelligence", "Computer science", "Distortion (music)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 4.0, "subtopic": "", "rationale": "Quality level-based distribution learning for BIQA — weakly relevant to IQA in restoration evaluation.", "alignment": {"task": "medium", "method": "low", "modality": "medium"}, "extraction": {"design": "QL-IQA: learns distance distribution from quality levels for improved BIQA.", "key_findings": "Quality level distance distribution improves BIQA prediction.", "limitations": "Standard BIQA; limited novelty."}}
{"openalex_id": "https://openalex.org/W4327946446", "doi": "https://doi.org/10.3390/healthcare11060887", "title": "ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns", "abstract": "", "authors": ["Malik Sallam"], "year": 2023, "venue": "Healthcare", "cited_by_count": 2517, "type": "review", "concepts": ["Health care", "Documentation", "MEDLINE", "Context (archaeology)", "Medical education"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "ChatGPT in healthcare systematic review; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Systematic review of ChatGPT use in healthcare education, research, and practice.", "key_findings": "Benefits and concerns of ChatGPT in clinical settings.", "limitations": "Healthcare domain."}}
{"openalex_id": "https://openalex.org/W3147474004", "doi": "https://doi.org/10.1109/tmm.2021.3068561", "title": "Motion Blur Removal With Quality Assessment Guidance", "abstract": "Non-uniform blind motion deblurring is a challenging yet fundamental task in the computer vision field...", "authors": ["Jichun Li", "Bo Yan", "Qing Lin", "Ang Li", "Chenxi Ma"], "year": 2021, "venue": "IEEE Transactions on Multimedia", "cited_by_count": 17, "type": "article", "concepts": ["Deblurring", "Computer science", "Artificial intelligence", "Residual", "Metric (unit)"], "search_query": "image quality assessment no-reference blind deep learning", "score": 7.0, "subtopic": "Image Quality Assessment", "rationale": "IQA-guided deblurring — directly relevant to using quality assessment to guide and improve restoration, bridging IQA and restoration themes.", "alignment": {"task": "high", "method": "high", "modality": "high"}, "extraction": {"design": "Deep DEBLUR-IQA: non-reference IQA network for deblurred images guides deblurring network optimization; efficient RDB/LRB architecture.", "key_findings": "IQA-guided enhancement improves subjective deblurring quality while maintaining good PSNR; 50x faster than multi-scale CNN methods.", "limitations": "Motion deblurring only; IQA network needs training separately."}}
{"openalex_id": "https://openalex.org/W2974196484", "doi": "https://doi.org/10.1016/j.ophtha.2019.09.014", "title": "An Ophthalmologist's Guide to Deciphering Studies in Artificial Intelligence", "abstract": "", "authors": ["Daniel Shu Wei Ting", "Aaron Lee", "Tien Yin Wong"], "year": 2019, "venue": "Ophthalmology", "cited_by_count": 54, "type": "editorial", "concepts": ["Artificial intelligence", "Scopus", "Deep learning", "Medicine", "Scheimpflug principle"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Ophthalmology AI guide; medical domain, irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Editorial guide for ophthalmologists on interpreting AI studies.", "key_findings": "Framework for evaluating AI study quality in ophthalmology.", "limitations": "Medical editorial."}}
{"openalex_id": "https://openalex.org/W2751069891", "doi": "https://doi.org/10.1038/sdata.2017.117", "title": "Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features", "abstract": "", "authors": ["Spyridon Bakas"], "year": 2017, "venue": "Scientific Data", "cited_by_count": 2781, "type": "article", "concepts": ["Glioma", "Segmentation", "Neuroradiologist", "Glioblastoma", "Magnetic resonance imaging"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Cancer MRI segmentation dataset; medical domain, irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Expert segmentation labels and radiomic features for TCGA glioma MRI.", "key_findings": "Provides comprehensive glioma segmentation annotations.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W2952218014", "doi": "https://doi.org/10.1109/taslp.2019.2915167", "title": "Conv-TasNet: Surpassing Ideal Time-Frequency Magnitude Masking for Speech Separation", "abstract": "", "authors": ["Yi Luo", "Nima Mesgarani"], "year": 2019, "venue": "IEEE/ACM Transactions on Audio Speech and Language Processing", "cited_by_count": 1952, "type": "article", "concepts": ["Magnitude (astronomy)", "Ideal (ethics)", "Masking (illustration)", "Separation (statistics)", "Speech recognition"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Speech separation; audio domain, irrelevant to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Conv-TasNet: fully-convolutional time-domain audio separation with linear encoder-decoder.", "key_findings": "Surpasses ideal T-F magnitude masking in two and three speaker separation.", "limitations": "Audio/speech domain."}}
{"openalex_id": "https://openalex.org/W4384071683", "doi": "https://doi.org/10.1038/s41586-023-06291-2", "title": "Large language models encode clinical knowledge", "abstract": "", "authors": ["Karan Singhal"], "year": 2023, "venue": "Nature", "cited_by_count": 2617, "type": "article", "concepts": ["Computer science", "Benchmark (surveying)", "Language model", "Comprehension", "Artificial intelligence"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Medical LLM (Med-PaLM); clinical knowledge domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Med-PaLM: LLM for medical QA evaluated on USMLE-style questions.", "key_findings": "LLMs can encode clinical knowledge at expert level.", "limitations": "Clinical knowledge domain."}}
{"openalex_id": "https://openalex.org/W4324046518", "doi": "https://doi.org/10.1080/14703297.2023.2190148", "title": "Chatting and cheating: Ensuring academic integrity in the era of ChatGPT", "abstract": "", "authors": ["Debby Cotton", "Peter A. Cotton", "J. Reuben Shipway"], "year": 2023, "venue": "Innovations in Education and Teaching International", "cited_by_count": 1714, "type": "article", "concepts": ["Cheating", "Academic dishonesty", "Academic integrity", "Honesty", "Engineering ethics"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Academic integrity and ChatGPT; education domain, irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Discussion of ChatGPT challenges to academic integrity in higher education.", "key_findings": "Universities need proactive policies for responsible ChatGPT use.", "limitations": "Education domain."}}
{"openalex_id": "https://openalex.org/W2077663753", "doi": "https://doi.org/10.1371/journal.pmed.1001744", "title": "Critical Appraisal and Data Extraction for Systematic Reviews of Prediction Modelling Studies: The CHARMS Checklist", "abstract": "", "authors": ["Karel G. M. Moons"], "year": 2014, "venue": "PLoS Medicine", "cited_by_count": 1804, "type": "article", "concepts": ["Checklist", "Critical appraisal", "Data extraction", "Systematic review", "MEDLINE"], "search_query": "image quality assessment no-reference blind deep learning", "score": 1.0, "subtopic": "", "rationale": "Systematic review methodology checklist; medical research methods, irrelevant to computer vision.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "CHARMS checklist for critical appraisal of prediction modelling systematic reviews.", "key_findings": "Standardised data extraction framework for prediction models.", "limitations": "Medical research methodology domain."}}
{"openalex_id": "https://openalex.org/W2050788534", "doi": "https://doi.org/10.1044/jshr.0103.227", "title": "Myoelastic-Aerodynamic Theory of Voice Production", "abstract": "", "authors": ["Janwillem van den Berg"], "year": 1958, "venue": "Journal of Speech and Hearing Research", "cited_by_count": 511, "type": "article", "concepts": ["Aerodynamics", "Production (economics)", "Speech production", "Computer science", "Speech recognition"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "1958 phonation theory paper; completely irrelevant to computer vision or restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Classic phonation theory paper on myoelastic-aerodynamic mechanisms of voice production.", "key_findings": "Foundational theory of vocal fold vibration.", "limitations": "Speech/phonation domain from 1958."}}
{"openalex_id": "https://openalex.org/W4404515348", "doi": "https://doi.org/10.1016/j.inffus.2024.102790", "title": "TextFusion: Unveiling the power of textual semantics for controllable image fusion", "abstract": "", "authors": ["Chunyang Cheng", "Tianyang Xu", "Xiaojun Wu", "Hui Li", "Xi Li", "Zhangyong Tang", "Josef Kittler"], "year": 2024, "venue": "Information Fusion", "cited_by_count": 25, "type": "article", "concepts": ["Computer science", "Semantics (computer science)", "Image (mathematics)", "Power (physics)", "Fusion"], "search_query": "visual language model image quality assessment", "score": 5.0, "subtopic": "Foundation Models Vision", "rationale": "Text-semantic-guided controllable image fusion — relevant to text/VLM-driven image processing pipelines, though focused on fusion not restoration.", "alignment": {"task": "medium", "method": "medium", "modality": "medium"}, "extraction": {"design": "TextFusion uses textual semantics to control image fusion (infrared+visible), enabling semantic-aware fusion output.", "key_findings": "Textual semantics improve controllability and quality of image fusion.", "limitations": "Image fusion task, not restoration."}}
{"openalex_id": "https://openalex.org/W2582406074", "doi": "https://doi.org/10.1186/s12913-017-2031-8", "title": "Acceptability of healthcare interventions: an overview of reviews and development of a theoretical framework", "abstract": "", "authors": ["Mandeep Sekhon", "Martin Cartwright", "Jill Francis"], "year": 2017, "venue": "BMC Health Services Research", "cited_by_count": 3572, "type": "article", "concepts": ["Nursing research", "Health informatics", "Health administration", "Medicine", "Public health"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Healthcare intervention acceptability framework; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Theoretical framework for healthcare intervention acceptability.", "key_findings": "Framework covers affective attitude, burden, ethicality, opportunity costs.", "limitations": "Health services research domain."}}
{"openalex_id": "https://openalex.org/W1909740415", "doi": "https://doi.org/10.1186/s12880-015-0068-x", "title": "Metrics for evaluating 3D medical image segmentation: analysis, selection, and tool", "abstract": "", "authors": ["Abdel Aziz Taha", "Allan Hanbury"], "year": 2015, "venue": "BMC Medical Imaging", "cited_by_count": 2601, "type": "article", "concepts": ["Computer science", "Segmentation", "Metric (unit)", "Scale-space segmentation", "Image segmentation"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "3D medical image segmentation metrics; medical imaging domain, irrelevant to restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Analysis and comparison of metrics for 3D medical image segmentation evaluation.", "key_findings": "Framework for selecting appropriate segmentation evaluation metrics.", "limitations": "Medical imaging domain."}}
{"openalex_id": "https://openalex.org/W4220959955", "doi": "https://doi.org/10.1002/cl2.1230", "title": "PRISMA2020: An R package and Shiny app for producing PRISMA 2020-compliant flow diagrams", "abstract": "", "authors": ["Neal Haddaway", "Matthew J. Page", "Chris C. Pritchard", "Luke A. McGuinness"], "year": 2022, "venue": "Campbell Systematic Reviews", "cited_by_count": 2683, "type": "article", "concepts": ["Interactivity", "Transparency (behavior)", "Computer science", "World Wide Web", "Computer security"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "PRISMA systematic review tool; methodology paper, completely irrelevant to image restoration.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "R package and Shiny app for PRISMA 2020 flow diagram generation.", "key_findings": "Interactive PRISMA-compliant flow diagrams for systematic reviews.", "limitations": "Systematic review methodology domain."}}
{"openalex_id": "https://openalex.org/W2048505725", "doi": "https://doi.org/10.1016/j.jalz.2014.01.001", "title": "A conceptual framework for research on subjective cognitive decline in preclinical Alzheimer's disease", "abstract": "", "authors": ["Frank Jessen"], "year": 2014, "venue": "Alzheimer s & Dementia", "cited_by_count": 2885, "type": "review", "concepts": ["Comparability", "Cognitive decline", "Terminology", "Disease", "Cognition"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Alzheimer's disease framework; medical domain, completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "Conceptual framework for subjective cognitive decline research in preclinical Alzheimer's.", "key_findings": "Research criteria and core features for SCD studies.", "limitations": "Neurology/dementia domain."}}
{"openalex_id": "https://openalex.org/W2510708214", "doi": "https://doi.org/10.2337/dc13-s011", "title": "Standards of Medical Care in Diabetes-2013", "abstract": "", "authors": [], "year": 2012, "venue": "Diabetes Care", "cited_by_count": 4416, "type": "article", "concepts": ["Medicine", "Diabetes mellitus", "MEDLINE", "Family medicine", "Endocrinology"], "search_query": "visual language model image quality assessment", "score": 1.0, "subtopic": "", "rationale": "Diabetes clinical standards; completely irrelevant.", "alignment": {"task": "low", "method": "low", "modality": "low"}, "extraction": {"design": "ADA standards of medical care for diabetes management.", "key_findings": "Evidence-based recommendations for diabetes care.", "limitations": "Endocrinology/diabetes domain."}}
